<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Looping</title>
  
  <subtitle>Watch, learn and practise</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://guyuecanhui.github.io/"/>
  <updated>2019-04-13T06:54:01.836Z</updated>
  <id>https://guyuecanhui.github.io/</id>
  
  <author>
    <name>胡诚</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>特征组合之FFM</title>
    <link href="https://guyuecanhui.github.io/2019/04/13/ffm/"/>
    <id>https://guyuecanhui.github.io/2019/04/13/ffm/</id>
    <published>2019-04-13T06:43:50.000Z</published>
    <updated>2019-04-13T06:54:01.836Z</updated>
    
    <content type="html"><![CDATA[<p>前段时间搞 LR 的特征优化，切身体会到人工特征工程实在太费劲了，一方面发掘高价值的特征十分困难，另一方面某些特征之间需要组合才能有效，比如用户对视频的某个特征的偏好，就必须将视频的特征和用户的特征进行组合。LR 是线性模型，没法自动做特征组合，只能人工搞，但人工来干这事就相当麻烦了。自然而然的，就会想到用可以自动组合特征的模型。现在了解的包括 FM、FFM 等基于矩阵分解的模型、基于 GBDT 之类的树模型和基于 DNN 的网络模型。这篇文章先介绍下 FFM 模型。</p><h2 id="FFM-模型简介"><a href="#FFM-模型简介" class="headerlink" title="FFM 模型简介"></a>FFM 模型简介</h2><p>FFM (Field-aware Factorization Machines)$^{[1]}$是 Yuchin Juan 等人在台大期间提出的用于 CTR 预估的模型。它是对 FM 模型的推广，提到 FM 又不得不提到 Poly2 模型，好在它们三个的关系十分简单和明确：</p><ol><li><p>Poly2 模型是将所有特征进行两两组合，也就是当特征有 $n$ 个的时候，需要 $O(n^2)$ 个参数，而且这些参数之间是<strong>相互独立</strong>的，意味着<strong>每个参数都需要足够的样本来训练</strong>，也就是每对特征都同时出现在足够多的样本里。因此如果无法满足海量样本的要求时，这个模型很难训练出来。它的模型如下（其中 $h(i,j)$ 作用是将 $i,j$ 映射成一个自然数）：</p><script type="math/tex; mode=display">\phi_{poly2}(\mathcal{w},\mathcal{x}) = \sum_{j_1=1}^n\sum_{j_2=j_1+1}^n w_{h(j_1,j_2)}x_{j_1}x_{j_2} \qquad (1)</script></li><li><p>FM 模型是为每个特征训练一个隐向量，而特征组合的权重就是这两个特征的隐向量点积，假设隐向量的长度为 $k$，那么需要 $O(nk)$ 个参数，因此参数的规模要比 Poly2 小很多（这里可以认为 Poly2 为每个特征生成的向量长度为 $n$），训练数据量要求也就没那么高了。它的原始形态 (2) 和简化计算形态 (3) 分别如下：</p></li></ol><script type="math/tex; mode=display">\phi_{FM}(\mathcal{w},\mathcal{x})= \sum_{j_1=1}^n\sum_{j_2=j_1+1}^n (\mathcal{w}_{j_1}\cdot\mathcal{w}_{j_2})x_{j_1}x_{j_2} \qquad (2)</script><script type="math/tex; mode=display">\phi_{FM}(\mathcal{w},\mathcal{x})=\frac{1}{2}\sum_{j=1}^n(\mathcal{s}-\mathcal{w}_j x_j), \quad \mathcal{s}=\sum_{j'=1}^n\mathcal{w}_{j'} x_{j'} \qquad (3)</script><ol><li>FFM 模型是为每个特征对每一个 Field 学习一个隐向量，一个 Field 可以认为是特征所属的属性，比如用户的常驻地可以看成是一个 Field、视频的分类可以看成是另一个 Field，假设有 $f$ 个 Field，每个隐向量长度为 $k$，则FFM模型需要 $O(nfk)$ 个参数，看起来比 FM 多很多，但是实际上由于每个特征对不同 Field 的作用都是单独学习的，因此 FFM 的 $k$ 往往比 FM 的 $k$ 小很多。它的模型如下：</li></ol><script type="math/tex; mode=display">\phi_{FFM}(\mathcal{w},\mathcal{x})= \sum_{j_1=1}^n\sum_{j_2=j_1+1}^n (\mathcal{w}_{j_1,f_2}\cdot\mathcal{w}_{j_2,f_1})x_{j_1}x_{j_2} \qquad (4)</script><p>FFM 为什么要把Field拎出来考虑呢？举个例子，还是在视频推荐里，假设只考虑用户的年龄特征、视频的分类特征和演员特征，FM 在学用户年龄特征的时候是综合考虑视频分类和演员来得到的，然而从直观上来看，年龄对分类的影响和对演员的影响是不同的，因此更自然的想法是对分类和演员各学一个隐向量，效果应该会更好。</p><p>换句话说，如果特征有明显的 Field 划分，用 FFM 模型理论上是优于 FM 的；但是如果不满足这个条件，例如在 NLP 领域，所有特征都属于一个 Field，FFM 模型的优势就不明显了。<br>另外，Field 很容易对应到一个类别，因此 FFM 特别适合处理类别特征，对于连续特征，如果离散化处理效果比较好也还OK，否则优势也不明显。<br>因此，<strong>FFM 主要适合处理类别特征，并且喜欢稀疏数据，而不适合处理连续特征，不适合处理 Field 数量很少的数据</strong>。</p><h2 id="FFM-模型实现"><a href="#FFM-模型实现" class="headerlink" title="FFM 模型实现"></a>FFM 模型实现</h2><p>由于官方只提供了 FFM 模型的 C++ 实现$^{[2]}$，而我们主要是基于 Spark 的，因此需要一份 scala 实现。网上也找了一下，发现 Vince Shieh 实现的一份代码$^{[3]}$，但是 review 以后发现参数有点问题，因此考虑自己实现一份。<br>实现的 FFM 的核心就在于如何计算梯度，如何更新模型。论文的模型 (4) 是简化处理，在实现的时候还需要带上全局偏置和线性部分，完整的模型如下：</p><script type="math/tex; mode=display">\phi_{FFM}(\mathcal{w},\mathcal{x})= w_0 + \sum_{j=1}^n w_jx_j+ \sum_{j_1=1}^n\sum_{j_2=j_1+1}^n (\mathcal{w}_{j_1,f_2}\cdot\mathcal{w}_{j_2,f_1})x_{j_1}x_{j_2} \qquad (5)</script><p>而 FFM 用于 CTR 预估时，目标优化函数定义成：</p><script type="math/tex; mode=display">\mathcal{L}=\min_{\mathcal{w}} \frac{\lambda}{2}||\mathcal{w}||^2_2+\sum_{i=1}^m \log(1+e^{-y_i\phi(\mathcal{w},\mathcal{x})}) \qquad (6)</script><p>使用 SG 的方式进行更新，即每次使用一个样本 $(y,\mathcal{x})$ 来更新模型，其中，$\mathcal{x}$ 的格式为 $\mathcal{x}=[f<em>{i_1}j</em>{i<em>1}x</em>{i<em>1},\cdots,f</em>{i<em>t}j</em>{i<em>t}x</em>{i_t}]$，表示该样本中 $t$ 个非零特征，$f$ 表示特征的域编号，$j$ 表示特征编号，$x$ 表示特征取值（对于 one-hot 编码，$x=1$）。<br>首先对式 (6) 中各权重计算梯度：</p><script type="math/tex; mode=display">\begin{cases}g_0=\lambda w_0+\kappa \\g_j=\lambda w_j+\kappa w_j \\\mathcal{g}_{j_1,f_2}=\lambda \mathcal{w}_{j_1,f_2}+\kappa \mathcal{w}_{j_2,f_1} \\\mathcal{g}_{j_2,f_1}=\lambda \mathcal{w}_{j_2,f_1}+\kappa \mathcal{w}_{j_1,f_2}\end{cases}, \quad \kappa=\frac{-y_ie^{-y_i\phi(\mathcal{w},\mathcal{x})}}{1+e^{-y_i\phi(\mathcal{w},\mathcal{x})}} \qquad (7)</script><p>然后使用 AdaGrad 对累积梯度进行更新（这里也可以不用 AdaGrad，直接使用 GD，或者用 Adam 等其他方法更新）：</p><script type="math/tex; mode=display">\begin{cases}G_i=G_i+g_i^2 \\w_i=w_i-\frac{\eta}{\sqrt{G_i}} g_i\end{cases},\quad i=0, i_1, \cdots, i_t \qquad (8)</script><script type="math/tex; mode=display">\begin{cases}(G_{j_1,f_2})_d=(G_{j_1,f_2})_d+(g_{j_1,f_2})_d^2 \\(G_{j_2,f_1})_d=(G_{j_2,f_1})_d+(g_{j_2,f_1})_d^2 \\(w_{j_1,f_2})_d=(w_{j_1,f_2})_d-\frac{\eta}{\sqrt{(G_{j_1,f_2})_d}} (g_{j_1,f_2})_d \\(w_{j_2,f_1})_d=(w_{j_2,f_1})_d-\frac{\eta}{\sqrt{(G_{j_2,f_1})_d}} (g_{j_2,f_1})_d\end{cases}, \quad d=1,\cdots, k,\qquad (9)</script><p>基于以上各式，可以很容易把算法写出来了：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Algorithm: Train FFM using SG</span><br><span class="line"><span class="number">1.</span> init G = ones(n,f,k)</span><br><span class="line"><span class="number">2.</span> init g = rand(n,f,k)[<span class="number">0</span>,<span class="number">1</span>/sqrt(k)]</span><br><span class="line"><span class="number">3.</span> <span class="keyword">for</span> epoch = <span class="number">1</span> to t:</span><br><span class="line"><span class="number">4.</span>     <span class="keyword">for</span> i = <span class="number">1</span> to m:</span><br><span class="line"><span class="number">5.</span>         sample a data point (y,x)</span><br><span class="line"><span class="number">6.</span>         calculate kappa by (<span class="number">7</span>)</span><br><span class="line"><span class="number">7.</span>         <span class="keyword">for</span> xi, xj <span class="keyword">in</span> x:</span><br><span class="line"><span class="number">8.</span>             calculate gradients by (<span class="number">7</span>)</span><br><span class="line"><span class="number">9.</span>             update weights by (<span class="number">8</span>)(<span class="number">9</span>)</span><br></pre></td></tr></table></figure></p><p>论文中指出，FFM 特别容易过拟合，其中，正则化系数 $\lambda$ 越小，效果越好但越容易过拟合；学习率 $\eta$ 越大，学习速度越快也越容易过拟合。我自己试了几个数据集，使用 $\lambda=0.00002,\ \eta=0.1,\ k=4$，一般 1~4 轮都差不多OK了，再多就容易过拟合。<br>为了防止过拟合，论文提出使用 <strong>early stopping</strong> 技术，即将训练数据进一步划分成训练集和验证集，每一轮用训练集更新完模型后，用验证集计算 logloss，并记录验证集 logloss 开始上升的轮数 $r$，最后再用整个数据集训练 $r$ 轮。但是实际在用的时候，可以线下调一个比较好的参数，然后直接放到线上去用，等数据发生变化，或者定时去重新评估这些参数。</p><p>自己用 scala 实现的 FFM 模型没有使用指令集加速，只是将训练数据划分成多个 partition 并行训练，然后将参数合并（求平均），效果差一些。我拿 libFFM 做了一个性能的比较……<strong>完败</strong>……唉，Spark 做数值计算还是不太行啊！</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] Juan, Yuchin, et al. “Field-aware Factorization Machines for CTR Prediction.” ACM Conference on Recommender Systems ACM, 2016:43-50.<br>[2] <a href="https://github.com/guestwalk/libffm" target="_blank" rel="noopener">https://github.com/guestwalk/libffm</a><br>[3] <a href="https://github.com/VinceShieh/spark-ffm" target="_blank" rel="noopener">https://github.com/VinceShieh/spark-ffm</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;前段时间搞 LR 的特征优化，切身体会到人工特征工程实在太费劲了，一方面发掘高价值的特征十分困难，另一方面某些特征之间需要组合才能有效，比如用户对视频的某个特征的偏好，就必须将视频的特征和用户的特征进行组合。LR 是线性模型，没法自动做特征组合，只能人工搞，但人工来干这事就
      
    
    </summary>
    
      <category term="推荐系统" scheme="https://guyuecanhui.github.io/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="推荐" scheme="https://guyuecanhui.github.io/tags/%E6%8E%A8%E8%8D%90/"/>
    
      <category term="排序" scheme="https://guyuecanhui.github.io/tags/%E6%8E%92%E5%BA%8F/"/>
    
      <category term="特征工程" scheme="https://guyuecanhui.github.io/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"/>
    
      <category term="特征组合" scheme="https://guyuecanhui.github.io/tags/%E7%89%B9%E5%BE%81%E7%BB%84%E5%90%88/"/>
    
  </entry>
  
  <entry>
    <title>可能是最好懂的ItemCF解释了</title>
    <link href="https://guyuecanhui.github.io/2019/04/13/itemcf/"/>
    <id>https://guyuecanhui.github.io/2019/04/13/itemcf/</id>
    <published>2019-04-13T05:56:07.000Z</published>
    <updated>2019-04-13T06:53:12.599Z</updated>
    
    <content type="html"><![CDATA[<p>说到推荐系统，可能最为人熟知的算法就是协同过滤，特别是其中的 ItemCF，自亚马逊文章发表以后，得到了广泛而成功的应用。这篇文章主要谈谈我的理解。</p><h2 id="ItemCF-推导过程"><a href="#ItemCF-推导过程" class="headerlink" title="ItemCF 推导过程"></a>ItemCF 推导过程</h2><p>首先，ItemCF 依赖一个隐含的假设：就是每个用户的兴趣都局限在某几个方面，因此如果两个物品属于一个用户的兴趣列表，那么这两个物品可能就属于有限的几个领域，而如果两个物品属于很多用户的兴趣列表，那么它们就可能属于同一个领域，因而有很大的相似度。</p><p>从这个假设出发，我们可以认为两个视频相似表现在它们被很多用户同时观看，两个物品共同观看的人数越多，说明它们的相似度越高，用公式来表达就是：</p><script type="math/tex; mode=display">s_{i,j}=|N(i)\cap N(j)| \qquad (1)</script><p>其中，$N(i)$ 表示观看视频 $i$ 的人群集合，$|N(i)\cap N(j)|$ 表示同时播放过 $i,j$ 的人数。但是由于热点视频可能并不代表用户的真实兴趣（有可能是运营推送，或者仅仅是由于追热心理），因此需要惩罚那些热点的视频，可以通过将共同观看人数除以与视频总观看数相关的系数来实现，例如使用以下方式：</p><script type="math/tex; mode=display">s_{i,j}=\frac{|N(i)\cap N(j)|}{\sqrt{|N(i)|\cdot|N(j)|}} \qquad (2)</script><p>但是仅仅惩罚热点视频也还不够，有些人就是闲的无聊，有什么看什么，这种情况下他表现出来的就未必是真实的兴趣了（就不满足我们的隐含假设），他的行为也就不太能作为我们的协同的依据，因此需要对这种人做降权，例如使用以下方式：</p><script type="math/tex; mode=display">s_{i,j}=\frac{\sum_{u\in N(i)\cap N(j)}\frac{1}{log(1+|M(u)|)}}{\sqrt{|N(i)|\cdot|N(j)|}} \qquad (3)</script><p>其中，$M(u)$ 表示用户 $u$ 观看的视频集合。另外，如果用户对视频 $i$ 观看了 80%，而对视频 $j$ 只看了 10%，那用户对这两个视频的喜欢程度也是不相同的，因此我们还可以对用户对两个视频观看的完成度差异做降权，差异越大，相似度也越低，例如使用以下方式：</p><script type="math/tex; mode=display">s_{i,j}=\frac{\sum_{u\in N(i)\cap N(j)}\frac{\cos(r_u(i),r_u(j))}{log(1+|M(u)|)}}{\sqrt{|N(i)|\cdot|N(j)|}} \qquad (4)</script><p>其中，$r_u(i)$ 表示用户 $u$ 对视频 $i$ 的观看完成度。最后，将所有视频与其他视频的相似度做 $max$ 归一化，得到：</p><script type="math/tex; mode=display">s_{i,j}'=\frac{s_{i,j}}{\max_j s_{i,j}} \qquad (5)</script><p>归一化使得所有物品的相似度取值都在 (0,1] 之间，这个相似度已经可以直接用于相关推荐场景。另外，有研究表明，这种归一化可以提高 ItemCF 用于个性化推荐时的准确度、覆盖率和多样性。</p><p>那基于 ItemCF 如何进行个性化推荐呢？主要是考虑推荐与用户的观看历史最相似的视频，即计算每个视频与用户观看视频集合的相似度作为作为是否观看该视频的预测值：</p><script type="math/tex; mode=display">p_u(i)=\frac{\sum_{j\in M(u)} s_{i,j}\cdot r_u(j)}{\sum_{j\in M(u)} s_{i,j}} \qquad (6)</script><p>最后，再根据预测值从大到小选取 TopN 个视频作为推荐结果。</p><h2 id="优化与讨论"><a href="#优化与讨论" class="headerlink" title="优化与讨论"></a>优化与讨论</h2><p>其实从第1部分的介绍来看，基于 ItemCF 的思想可以做很多改进。例如：</p><ol><li>如果感觉算出来的结果仍然偏向热门视频时，可以增加式 (4) 的分母大小；</li><li>如果觉得用户只有观看完完成度很高时才是真实兴趣，那可以将式 (4) 的 $cos(\cdot)$ 部分改成类似 $r_u(i)\cdot r_u(j)$ 的形式；</li><li>如果觉得需要更多的考虑用户的短期兴趣，做即时的推荐，那可以将式 (6) 中的用户观看历史限制在最近几次，甚至一次；</li></ol><p>如果把用户-视频考虑成一个二部图，ItemCF 实际上是基于图的结构，执行了一次从用户到视频的兴趣扩散过程。可以考虑下图中的视频 $v_1,v_3​$，它们没有直接的共同观看，因此用 ItemCF 算出来的相似度为 0，但是实际上 $u_1,u_2​$ 都观看了 $v_2​$，因此可以认为用户 $u_1,u_2​$ 存在一定的相似性，因此如果执行一次视频-用户-视频的兴趣扩散过程就能够捕获 $v_1,v_3​$ 的相似度了。</p><p><img src="/2019/04/13/itemcf/itemcf-f1.png" alt="itemcf-f1"></p><p>后面一种思路实际上就是 SimRank，但是由于需要执行多次兴趣扩散（即对二部图做多次迭代计算），SimRank 的计算复杂度相当高，在业务数据量大的情况下需要强大的算力支持，以后会再讨论下我在 SimRank 模型上的尝试。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;说到推荐系统，可能最为人熟知的算法就是协同过滤，特别是其中的 ItemCF，自亚马逊文章发表以后，得到了广泛而成功的应用。这篇文章主要谈谈我的理解。&lt;/p&gt;
&lt;h2 id=&quot;ItemCF-推导过程&quot;&gt;&lt;a href=&quot;#ItemCF-推导过程&quot; class=&quot;headerl
      
    
    </summary>
    
      <category term="推荐系统" scheme="https://guyuecanhui.github.io/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="推荐" scheme="https://guyuecanhui.github.io/tags/%E6%8E%A8%E8%8D%90/"/>
    
      <category term="协同过滤" scheme="https://guyuecanhui.github.io/tags/%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4/"/>
    
      <category term="算法" scheme="https://guyuecanhui.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>置信区间在推荐中的应用</title>
    <link href="https://guyuecanhui.github.io/2019/04/13/confidence-interval/"/>
    <id>https://guyuecanhui.github.io/2019/04/13/confidence-interval/</id>
    <published>2019-04-13T05:22:05.000Z</published>
    <updated>2019-04-13T06:20:57.503Z</updated>
    
    <content type="html"><![CDATA[<p>学过统计的同学都对置信区间的概念非常熟悉，实际上，离开置信区间谈统计值没啥意义，或者说经常会造成很大的误导。简单来讲，置信区间是指基于观测样本来估计一个未知参数（如均值）时，我们相当确定（用置信度来度量）参数可能的取值范围。如果不考虑置信区间的概念，在我们观察到有 2 个用户喜欢一个视频、1 个用户不喜欢一个视频时，会估计该视频的推荐度为 66%，而认为它是一个高质量的视频，如果一旦将它进行大规模推荐时，很可能发现这个视频的实际转化率低的可怜。</p><p>因此在推荐里，置信区间是需要密切关注的概念。在推荐领域实践中，我从 3 个简单的算法来分别介绍置信区间的应用。</p><h2 id="Wilson-区间法来判断视频质量"><a href="#Wilson-区间法来判断视频质量" class="headerlink" title="Wilson 区间法来判断视频质量"></a>Wilson 区间法来判断视频质量</h2><p>在引言的例子中，我们组的海威同学利用 Wilson 区间法来估计视频的推荐度，或者说，来建立视频质量评估模型（模型的一部分）。利用视频播放行为数据来统计视频的播放转化率时，假设视频展示的总数为 $n$，用户实际播放的总数为 $m$，则直接计算出来的播放转化率为 $p=\frac{m}{n}$。如果 $n$ 越大，说明 $p$ 的估计置信度越高，否则置信度越低。由于视频质量直接决定了我们是否会大规模推荐这个视频，因此在估计 $p$ 时采用的是宁缺毋滥的策略，这个时候可以巧妙的用置信区间的下界来代替 $p$ 作为播放转化率的估计。</p><p>具体到 Wilson 区间的计算公式，可以参考<a href="https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Wilson_score_interval" target="_blank" rel="noopener">wiki</a>（基于正态分布假设），这里只搬个公式：</p><script type="math/tex; mode=display">p_w = \max(0, \frac{p+\frac{z^2}{2n}}{1+\frac{z^2}{n}}-\frac{z}{1+\frac{z^2}{n}}\sqrt{\frac{p(1-p)}{n}+\frac{z^2}{4n^2}})</script><p>其中，$z$ 为某置信度（如 95% 置信度）下查表可得，$n$ 在实际代入时，需要加上平滑因子（如 0.1），防止展示数据丢失导致 $n=0$。从公式可知，基于 Wilson 区间估计的播放转化率最小接近于 0（$n$ 在实际时很可能取到平滑因子），最大接近于 $p$。</p><h2 id="UCB算法来平衡探索与应用（E-amp-E）"><a href="#UCB算法来平衡探索与应用（E-amp-E）" class="headerlink" title="UCB算法来平衡探索与应用（E&amp;E）"></a>UCB算法来平衡探索与应用（E&amp;E）</h2><p>Wilson区间法是用置信区间的下限来减少数据量不足时误判的可能，主要是用来选出精品视频用来广泛推荐。但是一直这样保守推荐，会导致有些视频得不到充分的曝光，就难以评估其实际的转化率，导致推荐出来的所谓精品只是次优的选择。因此，在应用（Expoit）目前已知比较好的视频进行推荐的同时，也要保持一定比例的探索（Explore），即尝试一下那些曝光较少的视频。EE算法里一个常用的算法是 LinUCB，由于涉及特征构造，这里只介绍一个简化版本 UCB，大致思路是一样的。</p><p>UCB（Upper Confidence Bound）是一种多臂老虎机算法（MAB），也勉强算一种简化的强化学习算法，调性十足。同样以估计播放转化率为例，它的思路是利用置信区间的上界来代替 $p$ 作为估计值，实际上是提高了曝光不足视频（即长尾视频）的估计值。</p><p>UCB 主要解决的问题在于，如何计算置信区间的上界，既能保证随着曝光总量的增加，那些未被探索的视频越来越少，又能保证长久来看，能选到精品的视频。为了实现这个目标，一个常用的启发式公式如下：</p><script type="math/tex; mode=display">p_u=\max_{i}(p_i+\sqrt{\frac{2\ln t}{n_i}})</script><p>其中，$p_i$ 为某个视频 $n_i$ 次曝光计算的平均转化率，$t$ 表示所有视频总共的曝光数。可以看到，随着曝光总数的增加，曝光很少的视频第二项值会很大，因此所有视频都会得到保底的曝光（t=100000 时至少有 28 次）。但是随着 $n_i$ 继续增加，主要决定因素又变成了 $p_i$，即历史平均转化率高的视频更可能被选中。</p><h2 id="Thompson-采样来进行随机长尾推荐"><a href="#Thompson-采样来进行随机长尾推荐" class="headerlink" title="Thompson 采样来进行随机长尾推荐"></a>Thompson 采样来进行随机长尾推荐</h2><p>UCB 算法在实际于新物品增加快的场景（例如短视频推荐，平均每天新增几万部短视频）时，由于计算过程是确定性的，存在一直只推新物品的问题。为了增加一些随机性，可以考虑用 Thompson 采样算法。它既不使用置信区间的上界，也不使用下界，而是每次基于 Beta(m, n-m) 分布进行采样（注意，这里的 m 和 n 是每个视频单独维护的参数）。</p><p>我们知道，Beta 分布实际上是“白努力”过程的成功率，曝光数 $n$ 越大，Beta 分布的曲线越像是一个倒钟的形状，且钟的开口越窄，最后收于期望：$p=\frac{m}{n}$。反过来说，当使用 Thompson 采样来选择推荐的视频时，虽然每个视频长期来选中的概率取决于其转化率，但是当曝光数量少时，Beta 分布开口很大，也更容易得到比期望大或者小的采样结果，从而引入了随机性。不过从实际应用来看，当媒资库时的视频数量很多时，大部分选中的视频还是新视频。</p><p>本文简单的介绍了统计区间在推荐中的一些简单应用，既有利用置信区间的下界来选精品，也有利用置信区间的上界来探索，还有利用整个分布来引入随机性。所有算法都是用简单的数学公式就能达到我们期望的效果，是比人工规则优美的多的形式。当然，举的示例都是推荐的核心问题，没有这么简单就能讲清楚，涉及大量的数据处理和参数调优，需要不断尝试和改进。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;学过统计的同学都对置信区间的概念非常熟悉，实际上，离开置信区间谈统计值没啥意义，或者说经常会造成很大的误导。简单来讲，置信区间是指基于观测样本来估计一个未知参数（如均值）时，我们相当确定（用置信度来度量）参数可能的取值范围。如果不考虑置信区间的概念，在我们观察到有 2 个用
      
    
    </summary>
    
      <category term="推荐系统" scheme="https://guyuecanhui.github.io/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="推荐" scheme="https://guyuecanhui.github.io/tags/%E6%8E%A8%E8%8D%90/"/>
    
      <category term="统计" scheme="https://guyuecanhui.github.io/tags/%E7%BB%9F%E8%AE%A1/"/>
    
      <category term="置信区间" scheme="https://guyuecanhui.github.io/tags/%E7%BD%AE%E4%BF%A1%E5%8C%BA%E9%97%B4/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://guyuecanhui.github.io/2019/04/10/hello-world/"/>
    <id>https://guyuecanhui.github.io/2019/04/10/hello-world/</id>
    <published>2019-04-10T13:57:37.514Z</published>
    <updated>2019-04-10T13:57:37.514Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
</feed>
