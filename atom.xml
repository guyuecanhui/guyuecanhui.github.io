<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>HCigmoid</title>
  
  <subtitle>Watch, learn and practise</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://guyuecanhui.github.io/"/>
  <updated>2020-12-08T15:47:38.132Z</updated>
  <id>https://guyuecanhui.github.io/</id>
  
  <author>
    <name>古月残辉</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>加权随机采样</title>
    <link href="https://guyuecanhui.github.io/2020/12/05/weighted-sample/"/>
    <id>https://guyuecanhui.github.io/2020/12/05/weighted-sample/</id>
    <published>2020-12-05T14:54:16.000Z</published>
    <updated>2020-12-08T15:47:38.132Z</updated>
    
    <content type="html"><![CDATA[<p>加权随机采样在推荐系统中随处可见，既可能用在模型训练数据处理过程中，也可能用于一些规则式的推荐策略里。典型的场景例如：</p><ol><li>在新用户冷启动时，我们可以通过某些指标评估出内容的质量，并根据质量得分来将内容加权随机推荐给新用户，质量越高的内容，被曝光给新用户的概率也越大。</li><li>在样本采样时，有一种方法是对每条正样本，随机从所有的内容中选取 $k$ 个负样本，而每个内容被选为负样本的概率与其热度成正比（例如 <strong>word2vec</strong> 的 <strong>negative sampling</strong> 技术）。</li><li>基于用户历史行为可以构建内容的有向图，当用户行为较稀疏时，我们可以使用 <strong>deepwalk</strong> 之类的算法在图中随机游走，生成内容的序列，再基于 <strong>word2vec</strong> 等算法生成这些内容的 embedding。在随机游走时，比如当前到达节点 $v$，那么下一次游走到其他节点的概率，与有向边的权重正相关。</li></ol><p>以上这些加权采样的场景往往都不可避免的面对大数据量挑战，因此对性能要求较高。而再细分一下，上面的场景 1, 2 都属于无放回采样，也就是需要采样的内容都不相同；而场景 3 则属于有放回采样，即允许采到相同的样本。本文就这两类加权随机采样问题分别探讨高效的解法。</p><a id="more"></a><h3 id="常规方案——基数法"><a href="#常规方案——基数法" class="headerlink" title="常规方案——基数法"></a>常规方案——基数法</h3><p>先再把问题抽象并更正式一点的描述一下：假设列表 $S$ 中有 $n$ 个元素，初始时，已知每个元素 $i$ 被抽取的概率为 $p<em>i: \sum</em>{i=1}^n p_i=1$，则：</p><ol><li>无放回加权随机采样是指，随机从 $S$ 中不放回的抽取 $m$ 个元素，每个元素 $i$ 被抽取的概率为 $q<em>i= \frac{p_i}{\sum</em>{j\in S’}p_j}$，其中 $S’$ 表示该次抽样时所有剩余元素的集合；</li><li>有放回加权随机采样是指，随机从 $S$ 中有放回的抽取 $m$ 个元素，每个元素 $i$ 被抽取的概率为 $p_i$。</li></ol><p>一般来讲，我们更希望获得一种时间复杂度低的抽样算法，也就是能够用尽可能少的步骤来得到 $m$ 个抽样的结果。在不考虑极致的精度和极端场景时，一种简单粗暴的方案是基于基数的抽样算法，这也是 <strong>word2vec</strong> 官方实现$^{[1]}$的策略：</p><ol><li>生成一个超大的数组 $A$，数组长度为 $k$，例如 $k=10^8$，或者 $k=\text{ceil}(1/\min(p_i))$；</li><li>将数组中的元素填充为集合元素的 index，元素 $i$ 的 index 被填充的数量为 $\lfloor k\cdot \sum<em>{j\le i} p_i\rfloor - \lfloor k\cdot \sum</em>{j&lt; i} p_i\rfloor$；</li><li>每次生成随机整数 $r: 0\le r &lt; k$，并将 $A[r]$ 对应的元素作为采样结果；</li><li>对于无放回的情况，还需要记录已经采样的结果集合，如果采样的结果出现在集合中，则重新采样，直到得到 $m$ 个不同的采样结果。</li></ol><p>我们将这种方法称为基数法。这种方法在 $S$ 中元素的数量远远超过 $m$，并且每个元素被抽取的概率远远小于 $1$ 时有较高的效率，是一种空间换时间的策略。但是在极端情况下，例如某个元素 $i$ 的 $p_i$ 接近 $1$ 时，无放回的抽样效率可能极低，因为每次抽样绝大概率抽到 $i$，进而需要重新抽样。另外，由于第 $2$ 步实际是一种近似策略，只能保证大体上数据 $A$ 中的元素 index 数量与其抽样概率成正相关，而不能保留精确的比例。因此，在需要更高效率和更高精度的条件下，我们可以考虑下面的方案。</p><h3 id="有放回加权随机采样——Alias-Method"><a href="#有放回加权随机采样——Alias-Method" class="headerlink" title="有放回加权随机采样——Alias Method"></a>有放回加权随机采样——Alias Method</h3><p>虽然基数法应用在有放回加权随机采样时，每次采样的时间复杂度为 $O(1)$，但是我们获得的实际上是一种非精确的采样，并且基数法的空间复杂度较高。相对而言，<strong>Alias Method</strong>$^{[2]}$ 是一种空间和时间都极为高效的算法，它的主要流程分为初始化和采样两步：首先用 $O(n)$ 的复杂度初始化两个长度为 $n$ 的数组，然后基于这两个数组进行采样，每次采样的复杂度为 $O(1)$。下面详细介绍下这种方法的流程。</p><p>首先将所有元素的抽样概率都乘以 $n$，得到一个平均概率为 $1$ 的新的采样概率 $Q=[q_1, q_2, \cdots,q_n]$，然后对这些概率进行两两组合：</p><ol><li>选择一个概率不超过 $1$ 的元素 $i$：$q_i\le 1$，设置 $Prob[i]=q_i$；</li><li>选择一个概率不小于 $1$ 的元素 $j$：$q_j\ge 1$，设置 $Alias[i] = j$，并将 $q_j:=q_j-(1-q_i)$，即用 $q_j$ 来补足 $q_i$ 少于 $1$ 的部分；</li></ol><p>这样组合以后，我们得到了两个数组：原始概率 $Prob$ 和组合元素索引 $Alias$。从构造的过程中，我们可以发现这两个数组的长度都是 $n$，并且 $Prob$ 对应的类别顺序与 $P$ 一致，而 $Alias$ 则保存着跟原始类别进行概率组合的类别编号。进一步的，对于每个数组下标 $i$，它一定会对应一个原始的元素 $i$，以及至多一个组合元素 $Alias[i]$，这个组合元素是用来跟 $i$ 一起将概率凑成 $1$ 的。</p><p>基于这两个数组，在每次采样时，只需要生成两个随机数：</p><ol><li>第一个随机数范围是 $r_1\in[1,n]$，用于确定原始元素，假设 $r_1=i$；</li><li>第二个随机数范围是 $r_2\in [0,1]$，如果 $r_2&lt; Prob[i]$，本次采样的类别就是原始元素 $i$，否则本次采样的类别是其组合元素 $j=Alias[i]$；</li></ol><p>到这里，大家肯定会好奇，在两两组合概率时，是不是一定能找到一种方案，使得对于所有的元素 $i$，一定能为其找到最多一个组合类别，使得它们的概率之和为 $1$。答案当然是肯定的，我们可以用归纳法进行证明：</p><ol><li>当 $n=1$ 时，$Prob[1]=1$, $Alias[1]=null$，命题显然成立；</li><li>对于任意正整数 $k$，假设当 $n=k$ 时命题成立，则当 $n=k+1$ 时，我们一定能找到两个类别 $c_i, c_j$，满足 $q_i\le 1, q_j\ge 1$，则我们设置 $Prob[i]=q_i$，$Alias[i] = j$，$q_j:=q_j-(1-q_i)$ 后，得到除 $c_i$ 外的 $k$ 个类别，它们的平均概率仍为 $1$，因此根据假设，$n=k+1$ 时，命题仍然成立。</li></ol><p>因此，我们按上面的组合策略，一定能成功构造出一个 $Alias$ 和 $Prob$ 的数组。</p><p>下面提供了一个 <strong>python</strong> 版本的实现，仅供参考。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> numpy.random <span class="keyword">as</span> npr</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AliasMethodSampling</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, p)</span>:</span></span><br><span class="line">        self.prob, self.alias = self._setup_alias(p)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_setup_alias</span><span class="params">(self, p)</span>:</span></span><br><span class="line">        small, large = [], []</span><br><span class="line">        n = len(p)</span><br><span class="line">        prob, alias = np.zeros(n), np.zeros(n, dtype=np.int)</span><br><span class="line">        <span class="comment"># init small and large array</span></span><br><span class="line">        <span class="keyword">for</span> i, pi <span class="keyword">in</span> enumerate(p):</span><br><span class="line">            prob[i] = pi * n</span><br><span class="line">            small.append(i) <span class="keyword">if</span> prob[i] &lt; <span class="number">1.0</span> <span class="keyword">else</span> large.append(i)</span><br><span class="line">        <span class="comment"># fill a small element each iteration</span></span><br><span class="line">        <span class="keyword">while</span> small <span class="keyword">and</span> large:</span><br><span class="line">            il, ig = small.pop(), large.pop()</span><br><span class="line">            alias[il] = ig</span><br><span class="line">            prob[ig] = (prob[ig] + prob[il]) - <span class="number">1</span></span><br><span class="line">            small.append(ig) <span class="keyword">if</span> prob[ig] &lt; <span class="number">1</span> <span class="keyword">else</span> large.append(ig)</span><br><span class="line">        <span class="comment"># handle numerical instability</span></span><br><span class="line">        <span class="keyword">while</span> large:</span><br><span class="line">            print(<span class="string">'only large exists'</span>, prob, alias, large, small)</span><br><span class="line">            prob[large.pop()] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> small:</span><br><span class="line">            print(<span class="string">'only small exists'</span>, prob, alias, large, small)</span><br><span class="line">            prob[small.pop()] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> prob, alias</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">take_sample</span><span class="params">(self)</span>:</span></span><br><span class="line">        i_rand = npr.randint(len(self.prob))</span><br><span class="line">        <span class="keyword">return</span> i_rand <span class="keyword">if</span> npr.rand() &lt; self.prob[i_rand] <span class="keyword">else</span> self.alias[i_rand]</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">probs, cnt = [<span class="number">0.1</span>, <span class="number">0.5</span>, <span class="number">0.2</span>, <span class="number">0.05</span>, <span class="number">0.15</span>], np.zeros(<span class="number">5</span>)</span><br><span class="line">alias = AliasMethodSampling(probs)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000000</span>):</span><br><span class="line">    cnt[alias.take_sample()] += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">cnt / <span class="number">1000000</span></span><br></pre></td></tr></table></figure><h3 id="无放回加权随机采样——A-ExpJ-算法"><a href="#无放回加权随机采样——A-ExpJ-算法" class="headerlink" title="无放回加权随机采样——A-ExpJ 算法"></a>无放回加权随机采样——A-ExpJ 算法</h3><p>在上面讨论的有放回加权随机采样情形中，每次抽样时，每个元素的抽样概率实际上是不发生变化的，我们也不需要知道之前抽样的结果是什么。但是在无放回情形中，每次抽到一个元素后，后面就不能再抽到相同的元素，也就意味着每次抽样后，元素的抽样概率会发生变化；并且我们需要记录之前抽样的结果有哪些，来防止抽到重复的元素。</p><p>前面也提到了，应用基数法来进行无放回加权随机采样的主要问题是可能重复抽到同一个元素，而生成随机数的成本其实是很高的，极端场景下，我们需要生成随机数的次数远大于 $n$。</p><p>文献 $[3]$ 提出了一种基于代理特征来采样的方法，也就是对于每个元素 $i$，我们选取服从均匀分布的随机数 $u_i=\text{rand}(0,1)$，用 $k_i=u_i^{1/p_i}$ 来作为采样的关键值，并选择关键值最大的 $m$ 个样本作为采样结果。这样，我们至多需要生成 $n$ 个随机数，就能完成采样过程。至于 $k_i$ 选择的正确性可以参考文献 $[3]$ 中的证明。基于这种代理特征的好处是，不需要知道每个元素的采样概率，只需要知道其权重即可 (也就是说不需要知道所有元素的总权重，无需做概率的归一化)，这就特别适合流式采样的场景。</p><p>当然，这里选择关键值最大的 $m$ 个样本可以采用最大堆来实现，这样就只需要进行一次全量 $O(n)$ 扫描，同时只要保留 $m$ 个当前最大的结果即可，这就是 <strong>A-Res</strong> 算法。在绝大多数场景中，<strong>A-Res</strong> 算法已经足够高效了。</p><p>为了进一步减少随机数生成的数量，作者提出了 <strong>A-ExpJ</strong> 算法，能将随机数的生成量从 $O(n)$ 减少到 $O(m\log⁡(\frac{n}{m})))$。实际上就是用计算复杂度比较低的反向计算来代替复杂度高的随机数生成，并直接跳过一些关键值明显较小的元素。具体步骤如下：</p><ol><li>将列表 $S$ 的前 $m$ 个元素放入结果集合 $R$；</li><li>对于结果集里的每个元素，计算关键值 $k_i=u_i^{(1/p_i)}$，其中 $u_i=\text{rand}(0,1)$；</li><li>将 $R$ 中小最的关键值记为阈值 $k_{min}$；</li><li>对剩下的元素重复以下步骤：<ol><li>令 $r=\text{rand}(0,1)$ 且 $x_p=\log(r)/\log(t)$；</li><li>从当前元素 $c$ 开始跳过元素，直到遇到元素 $i$，满足 $p<em>c+p</em>{c+1}+\cdots +p<em>{i−1}&lt;x_p\le p_c+p</em>{c+1}+\cdots+p_{i−1}+p_i$；</li><li>使用 $i$ 替换 $R$ 中关键值最小的元素；</li><li>令 $t=k^{p<em>i}</em>{min}$, $r_2=\text{rand}(t,1)$, $i$ 的关键值 $k_i=r_2^{(1/p_i)}$；</li><li>令新的阈值 $k_{min}$ 为此时 $R$ 中的最小关键值。</li></ol></li></ol><p>下面提供了一种 <strong>python</strong> 实现，仅供参考。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">a_expj_sample</span><span class="params">(prob, m)</span>:</span></span><br><span class="line">    <span class="string">""" 根据 prob 数组无放回随机抽取 m 个元素 """</span></span><br><span class="line">    topn = []</span><br><span class="line">    <span class="keyword">for</span> i, pi <span class="keyword">in</span> enumerate(prob[:m]):</span><br><span class="line">        heapq.heappush(topn, (random.random() ** (<span class="number">1</span>/pi), i))</span><br><span class="line">        </span><br><span class="line">    thres, w_sum = topn[<span class="number">0</span>][<span class="number">0</span>], <span class="number">0</span></span><br><span class="line">    xw = math.log(random.random()) / math.log(thres)</span><br><span class="line">    i = m</span><br><span class="line">    <span class="keyword">for</span> pi <span class="keyword">in</span> prob[m:]:</span><br><span class="line">        <span class="keyword">if</span> w_sum + pi &gt;= xw:</span><br><span class="line">            tw = thres ** pi</span><br><span class="line">            r2 = random.uniform(tw, <span class="number">1</span>)</span><br><span class="line">            ki = r2 ** (<span class="number">1</span>/pi)</span><br><span class="line">            heapq.heappop(topn)</span><br><span class="line">            heapq.heappush(topn, (ki, i))</span><br><span class="line">            thres = topn[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">            xw = math.log(random.random()) / math.log(thres)</span><br><span class="line">            w_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            w_sum += pi</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> [item[<span class="number">1</span>] <span class="keyword">for</span> item <span class="keyword">in</span> topn]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">probs = [<span class="number">0.1</span>, <span class="number">0.5</span>, <span class="number">0.2</span>, <span class="number">0.05</span>, <span class="number">0.15</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">4</span>):</span><br><span class="line">    cnt = np.zeros(<span class="number">5</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000000</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> a_expj_sample(probs, k):</span><br><span class="line">            cnt[j] += <span class="number">1</span></span><br><span class="line">    print(k, <span class="string">':'</span>, cnt / <span class="number">1000000</span> / k)</span><br></pre></td></tr></table></figure><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>本文主要介绍了三种加权采样的算法，其中，有放回加权随机采样推荐使用 <strong>Alias Method</strong>，无放回加权随机采样推荐使用 <strong>A-ExpJ</strong> 或者 <strong>A-Res</strong>，如果对精度要求没那么高，并且样本权重呈现非极端的分布，也可以使用简单的基数法。本篇讨论的算法主要应用场景在于<strong>我们已知每个元素的采样权重，进而可以设置其采样概率</strong>。但是有些情况下，我们是<strong>不知道这些元素的分布是什么样</strong>，而我们希望从这些未知分布中抽取样本，再利用这些样本对目标做一个估计。这时就需要考虑重要性采样、马尔可夫链蒙特卡罗方法、<strong>Gibbs</strong> 采样等采样算法，后面有机会再讨论吧。</p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] Github: word2vec. dav: <a href="https://github.com/dav/word2vec/blob/master/src/word2vec.c" target="_blank" rel="noopener">https://github.com/dav/word2vec/blob/master/src/word2vec.c</a>.</p><p>[2] Darts,Dice, and coids. Keith. 2011: <a href="http://www.keithschwarz.com/darts-dice-coins" target="_blank" rel="noopener">http://www.keithschwarz.com/darts-dice-coins</a>.</p><p>[3] Efraimidis, Pavlos S. , and P. G. Spirakis . “Weighted random sampling with a reservoir.” <em>Information Processing Letters</em>97.5(2006):181-185.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;加权随机采样在推荐系统中随处可见，既可能用在模型训练数据处理过程中，也可能用于一些规则式的推荐策略里。典型的场景例如：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在新用户冷启动时，我们可以通过某些指标评估出内容的质量，并根据质量得分来将内容加权随机推荐给新用户，质量越高的内容，被曝光给新用户的概率也越大。&lt;/li&gt;
&lt;li&gt;在样本采样时，有一种方法是对每条正样本，随机从所有的内容中选取 $k$ 个负样本，而每个内容被选为负样本的概率与其热度成正比（例如 &lt;strong&gt;word2vec&lt;/strong&gt; 的 &lt;strong&gt;negative sampling&lt;/strong&gt; 技术）。&lt;/li&gt;
&lt;li&gt;基于用户历史行为可以构建内容的有向图，当用户行为较稀疏时，我们可以使用 &lt;strong&gt;deepwalk&lt;/strong&gt; 之类的算法在图中随机游走，生成内容的序列，再基于 &lt;strong&gt;word2vec&lt;/strong&gt; 等算法生成这些内容的 embedding。在随机游走时，比如当前到达节点 $v$，那么下一次游走到其他节点的概率，与有向边的权重正相关。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以上这些加权采样的场景往往都不可避免的面对大数据量挑战，因此对性能要求较高。而再细分一下，上面的场景 1, 2 都属于无放回采样，也就是需要采样的内容都不相同；而场景 3 则属于有放回采样，即允许采到相同的样本。本文就这两类加权随机采样问题分别探讨高效的解法。&lt;/p&gt;
    
    </summary>
    
      <category term="数学" scheme="https://guyuecanhui.github.io/categories/%E6%95%B0%E5%AD%A6/"/>
    
    
      <category term="weighted sample" scheme="https://guyuecanhui.github.io/tags/weighted-sample/"/>
    
      <category term="有放回采样" scheme="https://guyuecanhui.github.io/tags/%E6%9C%89%E6%94%BE%E5%9B%9E%E9%87%87%E6%A0%B7/"/>
    
      <category term="alias method" scheme="https://guyuecanhui.github.io/tags/alias-method/"/>
    
      <category term="无放回采样" scheme="https://guyuecanhui.github.io/tags/%E6%97%A0%E6%94%BE%E5%9B%9E%E9%87%87%E6%A0%B7/"/>
    
      <category term="A-ExpJ" scheme="https://guyuecanhui.github.io/tags/A-ExpJ/"/>
    
  </entry>
  
  <entry>
    <title>Fast Greedy MAP for DPP 论文精读</title>
    <link href="https://guyuecanhui.github.io/2020/07/29/paper-2018-hulu-dpp_map/"/>
    <id>https://guyuecanhui.github.io/2020/07/29/paper-2018-hulu-dpp_map/</id>
    <published>2020-07-29T14:31:30.000Z</published>
    <updated>2020-07-29T14:58:38.567Z</updated>
    
    <content type="html"><![CDATA[<div class="note success"><p><strong>论文引用:</strong> Chen, Laming, Guoxin Zhang, and Eric Zhou. “Fast greedy map inference for determinantal point process to improve recommendation diversity.” <em>Advances in Neural Information Processing Systems</em>. 2018. </p></div><p>内容推荐系统的设计宗旨是帮助用户从近乎无限的内容中找到自己喜欢的，为了这个目标，推荐系统最主要的两个任务就是探索与利用。利用的含义是当推荐系统有足够的依据推测用户当下可能喜欢什么的时候，将相关的内容推荐给用户；探索的含义是当推荐系统不知道用户是否喜欢某个品类的内容时，推荐少量这些品类的精选内容给用户，试探用户的反馈。利用的任务我们通常交给排序算法去解决；而探索的任务则困难得多，或者说风险高得多，它需要借助排序之外的手段去实现，例如基于用户实时反馈进行快速试探（冷启动），或者保持一定比例的流量专门做试探，等等。</p><p>无论使用哪种方式，这些试探的内容还是需要和排序的结果进行融合后，以一定的顺序展示给用户。由于这两类任务是不可比的，在进行融合时很容易就引入一些人工规则。人工规则设计的好其实也是一项技术活，更简单的办法是用算法来将这些结果进行融合，既能最大化用户的喜好，又能引入尽可能多样的内容。本文主要介绍基于 <strong>DPP</strong> 的多样性算法。</p><a id="more"></a><h3 id="DPP-简介"><a href="#DPP-简介" class="headerlink" title="DPP 简介"></a>DPP 简介</h3><p><strong>DPP</strong> 最早是在量子物理学中引入 $^{[1]}$，用于估计费米子系统在热平衡状态下的分布，它能够精确的描述粒子间的斥力。在内容推荐领域，我们可以把斥力与物品间的相似度进行类比：对于一个推荐列表，我们希望列表内的物品不是那么雷同，换句话说，我们希望相似的物品能够相互排斥，这就很符合 <strong>DPP</strong> 的建模场景，因此 <strong>DPP</strong> 经常被用于做物品的多样性调整。</p><p><strong>DPP</strong> 用于推荐系统中来提升推荐列表多样性时，最大的优势在于，它能够直接估计整个列表的得分，而不是两两之间进行比较，因此它对所有物品间的相似关系考虑的更加全面。它的精确定义可以参考 wiki $^{[2]}$。以内容推荐场景来说，给定一个离散的内容集合 <script type="math/tex">Z=\{1,2,\cdots,m\}</script> 及其关联的一个内核矩阵 $\boldsymbol{L}\in \mathbb{R}^{m\times m}$，一个 <strong>DPP</strong> $\mathcal{P}$ 是对该集合所有子集的一个概率度量，并且每个子集 $Y\subseteq Z$ 的概率与该子集投影在内核矩阵中的主子矩阵的行列式 $^{[3]} $ 成正比：</p><script type="math/tex; mode=display">\mathcal{P}(Y)\propto \text{det}(\boldsymbol{L}_Y)</script><p>内核矩阵马上会介绍如何构造，这里只需要知道它是半正定的 (<strong>PSD</strong>, positive semidefinite)，因此 $\det(\boldsymbol{L}_Y) \ge 0$。举个例子，给定 $Z={1,2}$，<script type="math/tex">\boldsymbol{L}=\left[\begin{matrix}2,1\\1,1\end{matrix}\right]</script>，则 <strong>DPP</strong> $\mathcal{P}$ 对 $Z$ 所有子集的概率度量如下：</p><script type="math/tex; mode=display">\begin{matrix}\begin{align}(未归一化)\\\mathcal{P}(\varnothing)&\propto \text{det}(\varnothing)=1 \\\mathcal{P}(\{1\})&\propto \text{det}([2])=2\\\mathcal{P}(\{2\})&\propto \text{det}([1])=1\\\mathcal{P}(\{1,2\})&\propto \text{det}(\boldsymbol{L})=1\end{align}\end{matrix}\Rightarrow\begin{matrix}(归一化后)\\\mathcal{P}(\varnothing)&=0.2\\\mathcal{P}(\{1\})&=0.4\\\mathcal{P}(\{2\})&=0.2\\\mathcal{P}(\{1,2\})&=0.2\end{matrix}</script><p>在这个例子里，我们想找到最大概率的集合就是 <script type="math/tex">\{1\}</script>，寻找这个集合的过程就是最大后验推断 (<strong>MAP</strong>, maximum a posteriori)。不幸的是，<strong>DPP</strong> 的 <strong>MAP</strong> 问题是 NP-hard 的；幸运的是，$\log(\det(\cdot))$ 是一个 submodular 函数 $^{[4]}$，而submodular 函数的贪心算法有 1/2 的最优近似保证。由此，文章基于 <strong>DPP</strong> 模型提出了一种 <strong>MAP</strong> 的贪心近似推断方法，将时间复杂度降到 $O(n^2m)$，其中，$m$ 表示候选集合内容数量，$n$ 表示待推荐的内容数量。本文只介绍单个短列表内的 <strong>DPP</strong> 模型推断，基于窗口的长列表的推断可以参考论文或者其他博客。</p><h3 id="DPP-建模"><a href="#DPP-建模" class="headerlink" title="DPP 建模"></a>DPP 建模</h3><p>前面简单介绍了 <strong>DPP</strong> 模型的概念和特点，接下来考虑将 <strong>DPP</strong> 模型应用到以下典型场景：从排序模型输出的列表 $Z$ 中选择 top $n$ 的内容 $Y$ 推荐给用户，既能保证列表里的内容都是用户感兴趣的，同时提升推荐列表的多样性。<strong>DPP</strong> 建模的核心在于内核矩阵的构建。</p><p>要保证用户感兴趣，也就是要保证推荐内容与用户的相关性，一般可以通过排序得分来度量，我们把列表 $Z$ 中内容的排序分记为 <script type="math/tex">\boldsymbol{r}=[r_1, r_2, \cdots, r_m]</script>。</p><p>而内容的多样性一般通过内容间是不是不相似来度量。相似度评估可以是隐式的，例如基于物品的 embedding；也可以是规则式的，比如只考察可读的几个维度：标签、分类、作者等，然后基于 <strong>Jaccard</strong> 相似度来计算。我们把列表 $Z$ 中内容两两间相似度记为 $\boldsymbol{S}$，其中，$\boldsymbol{S}_{i,j}$ 表示内容 $i,j$ 之间的相似度，相似度的取值需要缩放到区间 $[0,1]$。</p><p>那怎么生成内核矩阵呢？前面提到，内核矩阵需要是半正定的，因此可以被分解为 $\boldsymbol{L}=\boldsymbol{B}^\top \boldsymbol{B}$，其中，$\boldsymbol{B}\in\mathbb{R}^{m\times m}$ 的每一列 $\boldsymbol{b}_i$ 可以看成是相应内容的表示向量，这个表示向量既要考虑与用户的相关性，又能用于相似度计算，因此可以设计成 $\boldsymbol{b}_i=r_i \boldsymbol{f}_i$，$\boldsymbol{f}_i$ 表示内容 $i$ 的 embedding 向量，或者是元数据的 onehot 编码等。这样，</p><script type="math/tex; mode=display">\boldsymbol{L}_{i,j}=\langle\boldsymbol{b}_i,\boldsymbol{b}_j\rangle=\langle r_i\boldsymbol{f}_i,r_j\boldsymbol{f}_j\rangle=r_ir_j\langle\boldsymbol{f}_i,\boldsymbol{f}_j\rangle=r_ir_j\boldsymbol{S}_{i,j}</script><p>写成矩阵的形式就是：</p><script type="math/tex; mode=display">\boldsymbol{L}=\text{diag}(\boldsymbol{r}) \cdot \boldsymbol{S}\cdot \text{diag}(\boldsymbol{r})</script><p>为了能够贪心求解，我们对目标行列式取对数，得到 submodular 的目标，即找到最优的列表 $Y$ 来最大化：</p><script type="math/tex; mode=display">\begin{align}\log\mathcal{P}(Y) \propto \log\det(\boldsymbol{L}_{Y})&=\log\Big(\det\big(\text{diag}(\boldsymbol{r}_Y) \cdot \boldsymbol{S}_Y\cdot \text{diag}(\boldsymbol{r}_Y)\big)\Big) \\&=\log\Big(\det\big(\text{diag}(\boldsymbol{r}_Y)\big) \cdot\det\big( \boldsymbol{S}_Y\big) \cdot\det\big(  \text{diag}(\boldsymbol{r}_Y)\big)\Big) \\&=2\sum_{i\in Y}\log(r_i) + \log \det\big( \boldsymbol{S}_Y\big)\end{align}</script><p>这里矩阵或者向量的下标为 $Y$ 表示得到 $Y$ 中所有元素在矩阵/向量的索引得到的主子矩阵/向量。这样，我们就能看出来，最终推荐列表 $Y$ 的 DPP 概率得分实际上是 $\sum_{i\in R}\log(r_i)$ 与 $\log \det\big( \boldsymbol{S}_Y\big)$ 的线性组合。前者表示内容 $i$ 的排序得分，后者表示 $Y$ 中内容的差异得分。</p><p>为了能够调整排序分与相似分的权重，可以将上式进一步调整成下式：</p><script type="math/tex; mode=display">\begin{align}\log\mathcal{P}(Y) &\propto \theta \cdot \sum_{i\in Y}r_i + (1-\theta)\cdot\log \det\big( \boldsymbol{S}_Y\big) \\&\propto\frac{\theta}{2(1-\theta)} \cdot \sum_{i\in Y}r_i + \log \det\big( S_R\big)+ \frac{\theta}{2(1-\theta)} \cdot \sum_{i\in Y}r_i\\&\overset{\alpha=\frac{\theta}{2(1-\theta)}}{=} \sum_{i\in Y}\log\big(e^{\alpha r_i}) + \log \det\big( \boldsymbol{S}_Y\big)+ \sum_{i\in Y}\log\big(e^{\alpha r_i})\\&=\log\Big(\det\big(\text{diag}(e^{\alpha\boldsymbol{r}_Y}) \cdot \boldsymbol{S}_Y\cdot \text{diag}(e^{\alpha\boldsymbol{r}_Y})\big)\Big)\end{align}</script><p>再回到内核矩阵上来，我们得到了一个新的 $\boldsymbol{L}_{Y} = \text{diag}(e^{\alpha\boldsymbol{r}_Y}) \cdot \boldsymbol{S}_Y\cdot \text{diag}(e^{\alpha\boldsymbol{r}_Y})$，其中，$\alpha=\frac{\theta}{2(1-\theta)}$，$\theta\in [0,1)$，$\theta$ 越大，排序得分的影响越大，$\theta$ 越小，列表中的内容差异越大。</p><p>需要说明的是，这种构造方法只有在 $\boldsymbol{S}$ 是半正定的情况下，才能保证 $\boldsymbol{L}$ 是半正定的。</p><h3 id="Fast-Greedy-MAP-Inference"><a href="#Fast-Greedy-MAP-Inference" class="headerlink" title="Fast Greedy MAP Inference"></a>Fast Greedy MAP Inference</h3><p>假设我们已经构造出内容推荐场景下的内核矩阵 $\boldsymbol{L}$，下面就需要贪心每次向最终推荐列表 $Y$ 中添加内容 $j$，使得我们的 submodular 的目标增益最大：</p><script type="math/tex; mode=display">j = \arg \max_{i\in Z-Y} \log \det(\boldsymbol{L}_{Y\cup\{i\}}) - \log \det(\boldsymbol{L}_{Y})</script><p>首先，我们推导一下，要最大化目标增益，其实我们每次只需要找到一个内容 $i$，它在 $\boldsymbol{L} $ 主子矩阵 <script type="math/tex">\boldsymbol{L}_{Y\cup\{i\}}</script> 的 Cholesky 分解矩阵的对角元素最大即可。</p><p>具体来讲，如果 $\boldsymbol{L}$ 是半正定的，则 $\boldsymbol{L}$ 的任意主子矩阵 $\boldsymbol{L}_Y$ 也是半正定的，因此可以进行 Cholesky 分解。但是由于半正定矩阵的 Cholesky 分解不唯一，我们姑且假设 $\boldsymbol{L}_Y$ 是正定的（后面会讨论异常如何处理），则它可以被分解为：</p><script type="math/tex; mode=display">\boldsymbol{L}_Y=\boldsymbol{V}\boldsymbol{V}^\top</script><p>这里 $\boldsymbol{V}$ 是一个下三角矩阵，并且对角线上的元素都是正实数；$Y$ 是我们目前根据贪心规则已经从候选列表 $Z$ 选出的部分的推荐结果。对于内容 $i\in Z-Y$，<script type="math/tex">Y'=Y\cup \{i\}</script> 在 $\boldsymbol{L} $ 上投影的主子矩阵 $\boldsymbol{L}_{Y’}$ 可以表示为：</p><script type="math/tex; mode=display">\boldsymbol{L}_{Y'} = \left [\begin{matrix}\boldsymbol{L}_{Y} & \boldsymbol{L}_{Y,i}\\\boldsymbol{L}_{i,Y} & \boldsymbol{L}_{i,i}\end{matrix}\right ]=\left [\begin{matrix}\boldsymbol{V} & \boldsymbol{0}\\\boldsymbol{c}_i & d_i\end{matrix}\right ]\left [\begin{matrix}\boldsymbol{V} & \boldsymbol{0}\\\boldsymbol{c}_i & d_i\end{matrix}\right ]^\top=\left [\begin{matrix}\boldsymbol{V}\boldsymbol{V}^\top & \boldsymbol{V}\boldsymbol{c}_i^\top\\\boldsymbol{c}_i\boldsymbol{V}^\top+d_i\boldsymbol{c}_i^\top & \boldsymbol{c}_i\boldsymbol{c}_i^\top+d_i^2\end{matrix}\right ] \qquad(1)</script><p>根据式 $(1)$ 可以得 <script type="math/tex">\det(\boldsymbol{L}_{Y'})</script> 与 <script type="math/tex">\det(\boldsymbol{L}_{Y})</script> 的关系：</p><script type="math/tex; mode=display">\begin{align}\det(\boldsymbol{L}_{Y'}) = \det\left(\left [\begin{matrix}\boldsymbol{V} & \boldsymbol{0}\\\boldsymbol{c}_i & d_i\end{matrix}\right ]\left [\begin{matrix}\boldsymbol{V} & \boldsymbol{0}\\\boldsymbol{c}_i & d_i\end{matrix}\right ]^\top \right)&=\det\left(\left [\begin{matrix}\boldsymbol{V} & \boldsymbol{0}\\\boldsymbol{c}_i & d_i\end{matrix}\right ]\right)\det\left(\left [\begin{matrix}\boldsymbol{V} & \boldsymbol{0}\\\boldsymbol{c}_i & d_i\end{matrix}\right ]^\top\right) \\&=\left(\det(\boldsymbol{V})\cdot d_i\right)^2 \\&=\det(\boldsymbol{V}\boldsymbol{V}^\top)\cdot d_i^2\\&=\det(\boldsymbol{L}_Y)\cdot d_i^2\end{align}</script><p>因此，基于当前局部最优结果 $Y$，下一个被选中的内容 $j$ 满足：</p><script type="math/tex; mode=display">j = \arg \max_{i\in Z-Y} \log \det(\boldsymbol{L}_{Y\cup\{i\}}) - \log \det(\boldsymbol{L}_{Y}) = \arg\max_{i\in Z-Y} \log(d_i^2)</script><p>也就是说，在给定当前推荐列表 $Y$ 的情况下，我们只需要计算所有剩下候选内容 $i\in Z-Y$ 对应的 $d_i$ 值即可，可以认为 $\log(d_i^2)$ 就是我们每次选中内容 $i$ 得到的边际增益，为了保证这个增益始终为正，需要保证 $d_i^2&gt;1$ (当然，这个增益物理含义不明确，实际上小于 $0$ 问题也不大)。</p><p>观察式 $(1)$ 可得：</p><script type="math/tex; mode=display">d_i^2=\boldsymbol{L}_{i,i}-\parallel\boldsymbol{c}_i\parallel^2_2</script><p>正常来讲，我们需要从矩阵 $\boldsymbol{V}$ 的左上角开始，按行或者按列依次算出所有的 $\boldsymbol{V}_{k,l}$，最后才能得出 $d_i$ $^{[6]}$，但是这样的复杂度太高了。文章提出了一种迭代的计算方法，在每次得到最优推荐结果的同时，记录所有的 $\boldsymbol{c}_i$，并在计算下一轮最优结果时更新这些 $\boldsymbol{c}_i$。</p><p>怎么更新 $\boldsymbol{c}_i$ 呢？假设我们在某一轮已经找到最优的内容 $j$，在找的过程中，已经计算并保存所有的 $\boldsymbol{c}_k, \ k\in Z$；当我们再找下一个最优内容 $i$ 时，由于 $Y$ 中的内容数量会增加一个，$\boldsymbol{c}_i$ 的维度也会相应的增加一维，记待更新的向量为 $\boldsymbol{c}_i’=[\boldsymbol{c}_i, e_i]$。还是观察式 $(1)$ 的右上角项，易知在本轮：</p><script type="math/tex; mode=display">\begin{align}\left [\begin{matrix}\boldsymbol{V} & \boldsymbol{0}\\\boldsymbol{c}_j & d_j\end{matrix}\right ]\boldsymbol{c}_i'^\top = \boldsymbol{L}_{Y',i}=\left [\begin{matrix}\boldsymbol{L}_{Y,i}\\\boldsymbol{L}_{j,i}\end{matrix}\right ]&\Rightarrow\langle[\boldsymbol{c}_j d_j], \boldsymbol{c}_i'\rangle=\boldsymbol{L}_{j,i} \\&\Rightarrow\langle\boldsymbol{c}_j , \boldsymbol{c}_i\rangle+ d_j\cdot e_i=\boldsymbol{L}_{j,i}\\&\Rightarrow e_i = \frac{\boldsymbol{L}_{j,i}-\langle\boldsymbol{c}_j , \boldsymbol{c}_i\rangle}{d_j}\end{align}</script><p>由此可以进一步算出，</p><script type="math/tex; mode=display">d_i'^2=\boldsymbol{L}_{i,i}-\parallel\boldsymbol{c}_i'\parallel^2_2=\boldsymbol{L}_{i,i}-\parallel\boldsymbol{c}_i\parallel^2_2 -e_i^2=d_i^2-e_i^2</script><p>初始时，$Y=\varnothing$，<script type="math/tex">d_i^2=\boldsymbol{L}_{i,i}</script>，<script type="math/tex">j=\arg \max_{i\in Z} d_i^2</script>。</p><h3 id="算法整体流程"><a href="#算法整体流程" class="headerlink" title="算法整体流程"></a>算法整体流程</h3><p>上面我们推导了内核矩阵如何构建，基于内核矩阵如何贪心的找到增益最高的推荐列表。最后总结一下整个算法流程（python 实现可参考 $[6]$）：</p><hr><h2 id="Fast-Greedy-MAP-Inference-for-DPP"><a href="#Fast-Greedy-MAP-Inference-for-DPP" class="headerlink" title="Fast Greedy MAP Inference for DPP"></a>Fast Greedy MAP Inference for DPP</h2><ol><li><strong>Input</strong>: candidates $Z=[0,1,\cdots m-1]$, similarity matrix of candidates $\boldsymbol{S}\in \mathbb{R}^{m\times m}$, ranking vector of candidates <script type="math/tex">\boldsymbol{r}=[r_0,r_1,\cdots,r_{m-1}]</script>, recommend item count $n$</li><li><strong>Initialize</strong>: $\boldsymbol{L} = \text{diag}(e^{\alpha\boldsymbol{r}}) \cdot \boldsymbol{S}\cdot \text{diag}(e^{\alpha\boldsymbol{r}})$, $\boldsymbol{C}=\boldsymbol{0}_{m\times n}$, $\boldsymbol{d}^2=\text{diag}(\boldsymbol{L})$, $j=\arg \max \boldsymbol{d}^2$, $Y=[j]$</li><li><strong>for</strong> $k$ <strong>in</strong> range($0$, $n-1$):</li><li>&emsp;&emsp;<script type="math/tex">\boldsymbol{e}=(\boldsymbol{L}_{j,:}-\boldsymbol{C}_{:,:k}\cdot \boldsymbol{C}_{j,:k})/ \sqrt{\boldsymbol{d}^2_j}</script></li><li>&emsp;&emsp;$\boldsymbol{C}_{:,k} = \boldsymbol{e}$</li><li>&emsp;&emsp;$\boldsymbol{d}^2_j = -\infty$</li><li>&emsp;&emsp;$j=\arg \max \boldsymbol{d}^2$</li><li>&emsp;&emsp;<strong>if</strong> $\boldsymbol{d}^2_j&lt;\epsilon$:</li><li>&emsp;&emsp;&emsp;&emsp;<strong>break</strong></li><li>&emsp;&emsp;$Y=[Y, j]$</li><li><strong>return</strong> $Y$</li></ol><hr><p>前面提到，我们假设 $\boldsymbol{S}$ 和 $\boldsymbol{L} $ 是半正定的，但是在推导迭代公式的时候却假设 $\boldsymbol{L}_Y $ 是正定的，因此在实际计算的时候可能得到 $d_j=0$，导致第 4 步的数值不稳定，因此在第 8 步引入一个很小的 $\epsilon&gt;0$，当 $d_j^2&lt;\epsilon$ 时，就进入异常处理程序。这里写的是直接返回结果，实际也可以将列表用某种策略填充到 $n$ 个再返回。</p><p>什么情况下会发生这个问题呢？回顾前文，如果有两个内容 $i,j$ 的表征向量线性相关/元数据完全相同，这个时候 $\boldsymbol{b}_i,\boldsymbol{b}_j$ 是线性相关的，如果它们都被选到推荐列表 $Y$ 中时，就会导致 $\det(\boldsymbol{L}_Y )=0$，说明此时 $\boldsymbol{L}_Y $ 半正定，其 Cholesky 分解的矩阵 $\boldsymbol{V}$ 对角线元素为 $0$，即 $d_j=0$。</p><p>这种情况在现实中是可能出现的，可以考虑在计算相似矩阵 $\boldsymbol{S}$ 的时候，为每两个内容的相似度加上一个小的随机数（要对称的加），保证 $\boldsymbol{S}$ 是正定的即可，但是这种方式可能对推荐结果有一定的影响。当然，如果 $Z$ 足够多，而且里面内容足够多样，这种情况出现的概率就非常低了。</p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] Macchi, Odile. “The coincidence approach to stochastic point processes.” <em>Advances in Applied Probability</em> 7.1 (1975): 83-122.</p><p>[2] Determinantal point process. <a href="https://en.wikipedia.org/wiki/Determinantal_point_process" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Determinantal_point_process</a></p><p>[3] 正定矩阵. <a href="https://zh.wikipedia.org/wiki/%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5</a></p><p>[4] Submodular函数. <a href="https://guyuecanhui.github.io/2018/08/16/sub-modular/">https://guyuecanhui.github.io/2018/08/16/sub-modular/</a></p><p>[5] Cholesky分解. <a href="https://zh.wikipedia.org/wiki/Cholesky%E5%88%86%E8%A7%A3" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/Cholesky%E5%88%86%E8%A7%A3</a></p><p>[6] fast-map-dpp. laming-chen. <a href="https://github.com/laming-chen/fast-map-dpp/blob/master/dpp.py" target="_blank" rel="noopener">https://github.com/laming-chen/fast-map-dpp/blob/master/dpp.py</a></p>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;note success&quot;&gt;&lt;p&gt;&lt;strong&gt;论文引用:&lt;/strong&gt; Chen, Laming, Guoxin Zhang, and Eric Zhou. “Fast greedy map inference for determinantal point process to improve recommendation diversity.” &lt;em&gt;Advances in Neural Information Processing Systems&lt;/em&gt;. 2018. &lt;/p&gt;&lt;/div&gt;
&lt;p&gt;内容推荐系统的设计宗旨是帮助用户从近乎无限的内容中找到自己喜欢的，为了这个目标，推荐系统最主要的两个任务就是探索与利用。利用的含义是当推荐系统有足够的依据推测用户当下可能喜欢什么的时候，将相关的内容推荐给用户；探索的含义是当推荐系统不知道用户是否喜欢某个品类的内容时，推荐少量这些品类的精选内容给用户，试探用户的反馈。利用的任务我们通常交给排序算法去解决；而探索的任务则困难得多，或者说风险高得多，它需要借助排序之外的手段去实现，例如基于用户实时反馈进行快速试探（冷启动），或者保持一定比例的流量专门做试探，等等。&lt;/p&gt;
&lt;p&gt;无论使用哪种方式，这些试探的内容还是需要和排序的结果进行融合后，以一定的顺序展示给用户。由于这两类任务是不可比的，在进行融合时很容易就引入一些人工规则。人工规则设计的好其实也是一项技术活，更简单的办法是用算法来将这些结果进行融合，既能最大化用户的喜好，又能引入尽可能多样的内容。本文主要介绍基于 &lt;strong&gt;DPP&lt;/strong&gt; 的多样性算法。&lt;/p&gt;
    
    </summary>
    
      <category term="论文精读" scheme="https://guyuecanhui.github.io/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/"/>
    
    
      <category term="推荐" scheme="https://guyuecanhui.github.io/tags/%E6%8E%A8%E8%8D%90/"/>
    
      <category term="多样性" scheme="https://guyuecanhui.github.io/tags/%E5%A4%9A%E6%A0%B7%E6%80%A7/"/>
    
      <category term="DPP" scheme="https://guyuecanhui.github.io/tags/DPP/"/>
    
      <category term="MAP" scheme="https://guyuecanhui.github.io/tags/MAP/"/>
    
  </entry>
  
  <entry>
    <title>MA-GNN 论文精读</title>
    <link href="https://guyuecanhui.github.io/2020/07/04/paper-2020-noha-magnn/"/>
    <id>https://guyuecanhui.github.io/2020/07/04/paper-2020-noha-magnn/</id>
    <published>2020-07-04T13:54:13.000Z</published>
    <updated>2020-07-18T16:03:29.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note success"><p><strong>论文引用：</strong>Ma, Chen, et al. “Memory Augmented Graph Neural Networks for Sequential Recommendation.” <em>arXiv preprint arXiv:1912.11730</em> (2019). </p></div><p><strong>MA-GNN</strong> 是华为诺亚实验室发表在 <strong>AAAI 2020</strong> 上基于序列的长短兴趣建模和 topK 推荐的模型。文章主要解决了用户长短期兴趣如何建模、如何融和，以及如何显式建模物品的共现关系并进而用于推荐的问题。</p><a id="more"></a><h2 id="背景与动机"><a href="#背景与动机" class="headerlink" title="背景与动机"></a>背景与动机</h2><p>在个性化推荐系统中，把握一个用户兴趣及其演变最直接和有效的途径是挖掘其行为序列。</p><p>研究表明，用户未来可能交互的物品与其历史有过交互的物品高度相关。基于这个发现，我们可以从用户行为序列中尝试提取他可能的兴趣。而用户的兴趣又可以进一步细分为长短期兴趣：从长期来看，用户的序列偏向于某个/某些类别的物品；但是在短期来看，用户的兴趣可能短暂的偏移到某个特定的类别。由于存在这种时序关系，本文说的用户行为序列是基于时间发生的先后进行排列的。</p><p>以小视频播放为例，用户长期兴趣可能是军事、战争；偶尔刷到一个钓鱼的视频（探索），感觉挺有意思的，这时候可能会希望看更多相似的视频，这时候用户的短期兴趣就变成了钓鱼；用户看了几条钓鱼的视频，可能会觉得很有趣，逐渐将其演变成长期兴趣；也可能觉得没多大意思，又想继续看军事类的视频了。推荐系统需要兼顾用户的长短期兴趣，根据用户实时反馈适当的增加或者减少基于用户短期兴趣的推荐。</p><p>文章认为，要构建一个基于用户长短兴趣推荐的模型，核心有三点：</p><ol><li>用户长期兴趣：体现在用户历史长期的行为序列中；</li><li>用户短期兴趣：体现在用户最近的数个行为序列中；</li><li>物品共现模式：基于用户历史序列和全局的统计分析，预测他可能还会喜欢什么；</li></ol><p>下面详细介绍文章的解决方案。</p><h2 id="MA-GNN-Memory-Augmented-Graph-Neural-Networks"><a href="#MA-GNN-Memory-Augmented-Graph-Neural-Networks" class="headerlink" title="MA-GNN (Memory Augmented Graph Neural Networks)"></a>MA-GNN (Memory Augmented Graph Neural Networks)</h2><p>文章要解决的问题是：给定用户 $u$ 的行为序列，从某个时间点进行划分，将该时间点以前的序列称为历史序列并作为训练数据，用 $H^u$ 表示；将该时间点以后的序列称为目标序列并作为测试数据，用 $T^u$ 表示；训练模型来为这些用户推荐 topK 个物品，并评估这些推荐结果是否在测试数据中出现，评估指标可以使用 <strong>Recall@10</strong> 和 <strong>NDCG@10</strong> 等。这是一个典型的离线任务。</p><p>为了解决这个问题，文章设计了多个模块并进行集成，网络架构如下图所示。</p><img src="/2020/07/04/paper-2020-noha-magnn/magnn-architecture.png" title="MA-GNN 整体架构"><p>首先基于用户的历史行为，用矩阵分解等方式生成用户的稳定兴趣；基于用户短期行为，挖掘物品共现关系，并用 <strong>GNN</strong> (Graph Neural Network) 提取其短期兴趣；基于用户长期行为，用 <strong>MDAtt</strong> (Multi-dimention Attention) &amp; <strong>MemNet</strong> (Memory Network) 提取其长期兴趣；基于 <strong>gateNet</strong> 对长短期兴趣进行融合；最后基于所有这些信息进行推荐。下面详细介绍下几个主要的模块。</p><h3 id="用户、物品向量表示"><a href="#用户、物品向量表示" class="headerlink" title="用户、物品向量表示"></a>用户、物品向量表示</h3><p>由于物品和用户都是高维稀疏的，因此在建模之前需要获得他们在同一向量空间的低秩表示。这个表示一方面是方便联系用户和物品进行建模，另一方面也反映了用户的稳定兴趣。获得这种表示的方法有很多，文章使用了传统的矩阵分解，即对于每个用户有过交互的物品生成一条记录，用 $p_u\in \mathbb{R}^d$ 表示用户 $u$ 的向量，用 $q_i\in \mathbb{R}^d$ 表示物品 $i$ 的向量，用 $p_u^{\top}\cdot q_i$ 来预测用户是否会与该物品发生交互。</p><p>这只是获得表达的一种方式，它的主要问题是只能对有过行为的用户/物品生成 embedding，并且只能离线训练和更新。我们也可以加一些 side information，使用类似 <strong>TowerModel</strong> 的模型来生成用户 embedding，这样能够生成新用户/物品的表示。</p><h3 id="短期兴趣建模"><a href="#短期兴趣建模" class="headerlink" title="短期兴趣建模"></a>短期兴趣建模</h3><p>短期兴趣体现在用户最新的几次交互序列中，它会强烈的影响用户近期的行为。因此在建模用户短期兴趣时，文章只考虑每个用户 $u$ 最近 $t$ 个交互的子序列 $S^u $，并通过 <strong>GNN</strong> (Graph Neural Netwrok) 来聚合这个子序列的信息，从而生成用户的短期兴趣。</p><p><strong>GNN</strong> 能够比较好的学习 local structure，并对邻居信息进行聚合。为了生成 graph，文章采用的方式是对每个用户的历史序列，依次将每个物品与其后 3 个物品分别添加无向边并设置权重为 1（如果边已经存在，就将权重加 1）。我们可以将物品进行编号，然后得到所有历史序列生成的一个连接矩阵 $A$，矩阵的每个元素 $A_{i,j}$ 表示物品 $i$ 与物品 $j$ 的边权，最后再按行对权重进行求和归一化。如下图所示：</p><img src="/2020/07/04/paper-2020-noha-magnn/item-adj-mat.png" title="物品邻接矩阵构建示例"><p>连接矩阵 $A$ 主要是为了编码每个物品在无向图中的邻居信息。基于此，文章构建了一个两层的 <strong>GNN</strong> 来生成用户的短期兴趣，对于用户 $u$ 和他最近交互子序列 $S^u$，第一层对这个序列中每个物品 $i$ 生成一个带局部结构编码的隐向量：</p><script type="math/tex; mode=display">h_i=\tanh\big(W^{(1)}\cdot[\sum_{k\in \mathcal{N_i}} e_kA_{i,k};e_i]\big), \quad \forall i\in S^u</script><p>这里符号 $[\cdot;\cdot]$ 表示向量拼接，即将两个 $d$ 维向量拼接成一个 $2d$ 维的向量；$e_k\in \mathbb{R}^d$ 表示物品 $k$ 的 embedding，它是网络参数的一部分，需要跟上面的 $q_k$ 区分开；$W^{(1)}\in \mathbb{R}^{d\times 2d}$ 也是 <strong>GNN</strong> 参数。</p><p>第二层将序列中所有物品的隐向量进行 avg-pooling，得到用户的短期兴趣表示 $p_u^s$：</p><script type="math/tex; mode=display">p_u^s=\frac{1}{n}\sum_{i\in S^u} h_i</script><p>其中，$W^{(2)}\in \mathbb{R}^{d\times 2d}$ 是 <strong>GNN</strong> 参数。基于 $p_u^s$，我们就已经可以进行短期兴趣召回了。但是这个召回过于偏重最近 $t$ 个交互物品，可能会丢失用户的长期兴趣。</p><h3 id="长期兴趣建模"><a href="#长期兴趣建模" class="headerlink" title="长期兴趣建模"></a>长期兴趣建模</h3><p>为了将用户的长期兴趣考虑进来，我们需要挖掘用户 $u$ 在 $ S^u$ 之前的序列中的兴趣，记为 $L^u $，长度记为 $m$，它的矩阵表示记为 $\mathcal{L}_u$。文章为了减少存储并避免学到的长期兴趣与 $p_u $ 相似，借鉴 <strong>Transformer</strong> 的思想，对序列中物品的位置编码后，计算 <strong>MDAtt</strong>，生成用户长期行为的 query 向量，再根据共享 $K,V$ 矩阵计算加权后的用户长期兴趣。具体过程如下：</p><ol><li>对用户的行为序列 $L^u$ 进行位置编码，其中 $P(\cdot)$ 表示位置编码函数，参考 <strong>Transformer</strong> 论文 $^{[1]}$，用户历史行为序列用 $\mathcal{L}_u\in\mathbb{R}^{d\times m}$ 来表示：<script type="math/tex; mode=display">\mathcal{L}_u :=\mathcal{L}_u+P(\mathcal{L}_u)</script></li><li>计算用户历史序列 $L^u$ 与其稳定兴趣 $p_u$ 的 MDAtt 权重矩阵 $\alpha_u \in \mathbb{R}^{h\times m}$，这里的 attention 使用加和的形式 $^{[1]}$，并使用 $h$ 维 attention。因此，$\alpha_u$ 的每一行表示用户历史的行为与其稳定兴趣的权重，而不同的行则表示从不同的角度得到的权重。其中，$W_a^{(1)},\ W_a^{(2)}\in\mathbb{R}^{d\times d},\ W_a^{(3)}\in\mathbb{R}^{h\times d}$ 均为 attention 相关的参数矩阵。<script type="math/tex; mode=display">\alpha_u = \text{softmax}\Big(W_a^{(3)} \tanh\big(W_a^{(1)}\mathcal{L}_u+(W_a^{(2)}p_u)\otimes \boldsymbol{1}_m\big)\Big)</script></li><li>计算每维 attetion 的加权向量，并进行 avg-pooling，得到用户历史行为的 query 向量 $z_u\in\mathbb{R}^d$：<script type="math/tex; mode=display">z_u = \text{avg}\big(\tanh(\alpha_u\cdot \mathcal{L}_u)\big)</script></li><li>用 $K,V\in\mathbb{R}^{d\times n}$ 表示所有用户共享的内存网络，它们的每一列对应于一种隐式的用户兴趣，我们保存 $n$ 个隐式兴趣。我们计算 $z_u$ 与各个隐式兴趣 $K$ 向量的相关性，并作为权重计算它与 $V$ 向量的加权和，再加上残差，得到这个用户长期的综合隐式兴趣向量 $p_u^l$：<script type="math/tex; mode=display">p_u^l=z_u+\text{softmax}(z_u\cdot K)\cdot V^{\top}</script></li></ol><p>其中，第 4 步中的 $K, V$ 矩阵就是文章所谓的内存网络 (<strong>MemNet</strong>)，它的计算跟 <strong>Self-Attention</strong> 过程很像，区别在于 <strong>Self-Attention</strong> 中，每个物品都对应 $K, V$ 矩阵的一个向量，而这里则是一个隐式的兴趣对应于一个 $K, V$ 向量。</p><h3 id="长短期兴趣融合"><a href="#长短期兴趣融合" class="headerlink" title="长短期兴趣融合"></a>长短期兴趣融合</h3><p>前面介绍了对于用户 $u$，基于 <strong>GNN</strong> 生成最近 $t$ 个交互的表示 $p_u^s$，基于 <strong>MDAtt</strong> 和 <strong>MemNet</strong> 生成历史 $m$ 个行为的表示 $p_u^l$，接下来文章考虑如何将长短兴趣进行融合。</p><p>一个比较直观的想法是将长短期兴趣进行线性加权，比如长、短期兴趣各占 $50\%$。但是这就引入了一个很难调的超参，并且实际上用户的兴趣是动态变化的，例如有时候突然想看某些类别的视频，这个时候短期兴趣占主导，看了一会可能就没那么上头了，这时候慢慢又回归到长期兴趣来，从这个例子中我们可以看出这个超参可能是动态变化的。</p><p>因此，文章的方案是借鉴 <strong>gateNet</strong> 的思想，自动的学习这个权重如何生成。具体来讲，引入参数矩阵 $W_g^{(1)}$,$W_g^{(2)}$,$W_g^{(3)}\in\mathbb{R}^{d\times d}$ 来学习权重 $g_u$，进而算出加权融合后的兴趣表示 $p^c_u$：</p><script type="math/tex; mode=display">\begin{align}g_u &= \sigma\big(W_g^{(1)}\cdot p_u^s + W_g^{(2)}\cdot p_u^l + W_g^{(3)}\cdot p_u\big)\\p_u^c &=g_u \odot p_u^s+(\boldsymbol{1}_d-g_u)\odot p_u^l\end{align}</script><h3 id="物品共现模型"><a href="#物品共现模型" class="headerlink" title="物品共现模型"></a>物品共现模型</h3><p>在预测用户是否喜欢某个物品的时候，一方面看他是否对该物品感兴趣（通过用户与物品向量表示来计算），另一方面还可以看看用户历史有过行为的物品与该物品的共现关系，即大多数据有过类似行为的用户会不会对该物品感兴趣。文章通过一个双线性映射函数来显式的对物品的共现关系进行建模，对于物品 $i,j$，它们的共现强度为：</p><script type="math/tex; mode=display">e_i^{\top}\cdot W_r\cdot q_j</script><p>其中，$W_r\in \mathbb{R}^{d\times d}$ 是用来捕获物品在隐向量空间中的关联关系。这样，根据用户 $u$ 短期行为列表 $S^u$ 中所有物品与某个物品 $j$ 的共现强度的均值，我们就能估算从统上来讲，用户是否会对该物品感兴趣：</p><script type="math/tex; mode=display">c_{u,j}=\frac{1}{n}\sum_{i\in S^u} e_i^\top\cdot W_r\cdot q_j</script><h3 id="预测与训练"><a href="#预测与训练" class="headerlink" title="预测与训练"></a>预测与训练</h3><p>基于用户长短期兴趣表示以及物品间共现关系的表示，我们可以预测用户 $u$ 对某个物品 $j$ 的喜好为：</p><script type="math/tex; mode=display">r_{u,j}=p_u^\top\cdot q_j + p_u^{c\top}\cdot q_j+c_{u,j}</script><p>在训练时，文章使用 pair-wise 的 <strong>BPR</strong> 目标，即最大化正例和负例的差距：</p><script type="math/tex; mode=display">\arg\min_{P,Q,E,\Theta} \sum_u\sum_l\sum_{S^u,L^u,i,j} -\log \sigma(r_{u,i}-r_{u,j})+\lambda(\parallel P\parallel ^2+\parallel Q\parallel ^2+\parallel E\parallel^2+\parallel \Theta\parallel ^2)</script><p>其中，$i$ 表示正例，$j$ 表示负例，通常是随机从未观测的样本中采样，$\Theta$ 表示所有可学习的网络参数，$P,Q$ 分别表示用户/物品的向量表示 (矩阵分解生成)，$E$ 表示物品的 embedding table (网络参数)。使用反向传播和 <strong>GD</strong> 来优化该目标。</p><h3 id="实验与讨论"><a href="#实验与讨论" class="headerlink" title="实验与讨论"></a>实验与讨论</h3><p>文章的对比实验表示 <strong>MA-GNN</strong> 在离线效果上有一定的优化，并且研究了 head 数量和 <strong>MemNet</strong> 中隐式兴趣个数的影响，结果表明这两个值越大越好，但是 <strong>MemNet</strong> 的容量更重要一些。文章还可视化了 <strong>MemNet</strong> 的权重，发现相似的视频生成的 query 对应的 attention 权重也比较相似。</p><p>总体来看，这篇文章借鉴了 <strong>GNN</strong>、<strong>MDAtt+MemNet</strong>、<strong>gateNet</strong>、<strong>bilinearMap</strong>、<strong>MF</strong> 等思想，将序列推荐问题分解成三个小的子问题并用不同的技术去解决，最终通过端到端的训练将整个过程糅合在一起。有些地方的处理可能还是太复杂了，例如 loss 的设计，还有 <strong>MF</strong> 是否可以简化掉等，会导致生产环境中的样本组织、训练和线上推理的复杂度过高，在实际应用的时候可以根据实际情况进行调整。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Vaswani, Ashish, et al. “Attention is all you need.” <em>Advances in neural information processing systems</em>. 2017.<br>[2] Attention机制详解（一）——Seq2Seq中的Attention. <a href="https://zhuanlan.zhihu.com/p/47063917" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/47063917</a>.</p>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;note success&quot;&gt;&lt;p&gt;&lt;strong&gt;论文引用：&lt;/strong&gt;Ma, Chen, et al. “Memory Augmented Graph Neural Networks for Sequential Recommendation.” &lt;em&gt;arXiv preprint arXiv:1912.11730&lt;/em&gt; (2019). &lt;/p&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;MA-GNN&lt;/strong&gt; 是华为诺亚实验室发表在 &lt;strong&gt;AAAI 2020&lt;/strong&gt; 上基于序列的长短兴趣建模和 topK 推荐的模型。文章主要解决了用户长短期兴趣如何建模、如何融和，以及如何显式建模物品的共现关系并进而用于推荐的问题。&lt;/p&gt;
    
    </summary>
    
      <category term="论文精读" scheme="https://guyuecanhui.github.io/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/"/>
    
    
      <category term="推荐" scheme="https://guyuecanhui.github.io/tags/%E6%8E%A8%E8%8D%90/"/>
    
      <category term="GNN" scheme="https://guyuecanhui.github.io/tags/GNN/"/>
    
      <category term="长短期兴趣" scheme="https://guyuecanhui.github.io/tags/%E9%95%BF%E7%9F%AD%E6%9C%9F%E5%85%B4%E8%B6%A3/"/>
    
      <category term="序列推荐" scheme="https://guyuecanhui.github.io/tags/%E5%BA%8F%E5%88%97%E6%8E%A8%E8%8D%90/"/>
    
      <category term="attention" scheme="https://guyuecanhui.github.io/tags/attention/"/>
    
  </entry>
  
  <entry>
    <title>Tversky 对比模型及其在推荐系统中的应用</title>
    <link href="https://guyuecanhui.github.io/2020/06/02/tversky-contrast-model/"/>
    <id>https://guyuecanhui.github.io/2020/06/02/tversky-contrast-model/</id>
    <published>2020-06-02T15:18:08.000Z</published>
    <updated>2020-07-25T14:32:49.459Z</updated>
    
    <content type="html"><![CDATA[<p>物品相似度评估在推荐中当属核心问题之一，尤其是当用户有一些明确的喜好、或者当前有一个明确的消费目标的时候，推荐与用户搜索内容/当前浏览内容相似的内容，能够极大的提升用户体验。例如，“猜你喜欢”、“再来一条”、“相关推荐” 等场景，就是围绕用户的这类诉求设计的，它属于 ”探索与利用“ 中的 ”利用“。</p><p>相似度评估已经是一个研究十分深入的领域，尤其是在心理学领域。我们往往说不清楚到底什么样的物品是相似的，或者说为什么两个物品不相似。出现这个问题，可能是因为在不同的情境下，我们不自觉的有不同的判断标准，使用了不同的特征，或者对不同的特征有不同的权重等等。这也导致了我们很难客观度量模型相似度评估的准不准，在很多业务场景下引发一些 badcase。</p><a id="more"></a><p>本文先简单的介绍一下推荐系统中的相似模型，再重点介绍一个心理学研究上的经典相似模型：<strong>Tversky</strong> <strong>对比模型</strong>。</p><h2 id="推荐系统中的相似模型"><a href="#推荐系统中的相似模型" class="headerlink" title="推荐系统中的相似模型"></a>推荐系统中的相似模型</h2><p>目前业界常用的相似度评估的模型一般分为两类：基于内容相似和基于协同相似。</p><p>基于协同相似有经典的算法，比如 <strong>itemCF</strong>、<strong>ALS</strong>、<strong>SimRank++</strong> 等；也有深度的模型，比如 <strong>TowerModel</strong>、<strong>GCN</strong> 等，先生成物品的 embedding，然后基于距离度量函数（主要是 cosine 距离）来评估物品间相似度。虽然这里面有一些算法也能够结合物品的内容信息，但是它们的主要问题还是：不可解释、受物品热度影响大、冷启动效果不好。</p><p>而基于内容的相似模型（比如标签相似）则有比较好的解释性，而且只要标签的质量好，完全可以应对新内容的启动问题。当然，基于内容的相似也可以结合用户的协同信息进行调优，比如基于群体统计来学习不同标签的权重等。因此实际使用中，基于内容的相似模型还是不可或缺的，通常作为补充的召回，或者在特定场景下使用（例如物品冷启动）。</p><p>基于内容的相似通常使用内容特征（这里称为标签）的匹配来计算，比如基于标签集合的 <strong>Jaccard</strong> 加权相似度、基于词袋向量/加权向量的余弦/欧氏距离等，这些基于距离度量函数的评估方法（包括上面提到的基于协同的模型），隐式的假设了我们对物品的相似度评估是对称的，即物品 $a$ 与物品 $b$ 的相似度满足：$s(a,b)=s(b,a)$，这个假设是否满足，在心理学上也是过讨论的，下面再来看一个心理学上的经典理论。</p><h2 id="相似度评估的心理学研究"><a href="#相似度评估的心理学研究" class="headerlink" title="相似度评估的心理学研究"></a>相似度评估的心理学研究</h2><p>心理学家在研究是什么影响了人们对相似度的评估时，一般首先是会设计一些强迫选择（forced choice）的实验。实验常见的设计比如给用户两个物品，让用户回答它们是否相似；或者给用户一个目标物品和两个备选物品，让用户选择哪个与目标更相似。其中，后面一种方案评估的是人们相对相似的评价，可以避免每个人内在的偏好，因此得到的数据更客观和一致，预测能力也更强。例如文献 $[1]$ 就设计了相对相似实验，用来建立用户在线购买时装场景下的相似评估模型。</p><p>在相似评估建模方面，除了对称相似模型，还有非对称相似模型。Tversky 等人在上世纪 70 年代，针对人如何评估物品间的相似度进行研究，提出了<strong>对比模型</strong>（<strong>Tversky Contrast Model</strong> $^{[2] }$），它与我们当前流行使用的基于距离度量函数的方案相比最大的差别表现在，<strong>对比模型</strong>中物品间的相似度是非对称的。</p><p>为什么说我们的相似度评估是非对称的呢？文献 $[2]$ 中给出一些例子，挺有意思的（怕翻译了失去原来的意味，所以引的原文）：</p><ol><li>We say “the portrait resembles the person” rather than “the person resembles the portrait”.</li><li>We say “the son resembles the father” rather than “the father resembles the son”.</li><li>We say “an ellipse is like a circle”, not “a circle is like an ellipse”.</li><li>We say “Turks fight like tigers” and not “tigers fight like Turks”.</li><li>The poet writes “my love is as deep as the ocean”, not “the ocean is as deep as my love”.</li></ol><p>可以看到，尤其是当物品间存在一些类比、或者不那么直接的联系的时候，我们的相似评估呈现很明显的非对称性。这可能是因为我们在评估这些相似的时候，关注了不同的特征、使用了不同的权重。Tversky 基于这些观察，提出了经典的<strong>对比模型</strong>。</p><h3 id="Tversky-对比模型"><a href="#Tversky-对比模型" class="headerlink" title="Tversky 对比模型"></a>Tversky <strong>对比模型</strong></h3><p><strong>Tversky</strong> <strong>对比模型</strong>的核心思想是将人们评估相似度的过程抽象成一个特征比较的过程，而且比较不仅仅关注相同的特征，还关注不同的特征。其中，每个特征的权重可能不同，并且双方共有的特征与单方独有的特征权重也不相同。它基于如下假设：</p><ol><li><strong>Matching</strong>：对于 $a$ 和 $b$，它们的相似度是它们特征集合关系的函数：$s(a,b)=g(A\cap B,A-B,B-A)$；</li><li><strong>Monotonicity</strong>：当 $A\cap B \supset A\cap C,\ A-B \subset A- C, \ B-A\subset C-A$ 时，$s(a,b)\ge s(a,c)$；</li><li><strong>Independence</strong>：每个特征对相似度的影响是独立的；</li><li><strong>Solvability</strong>：基于现有的特征集合能够将不相似的物品区分开来；</li><li><strong>Invariance</strong>：Invariance ensures that the equivalence of intervals is preserved across factors.</li></ol><p>其中，满足条件 1, 2 的 $g$  被称为一个匹配函数（<strong>MatchingFunction</strong>），它衡量两个目标根据特征的匹配程度。Tversky 在文献 $[1]$ 中证明了，当满足以上 5 条假设的时候，一定存在一个相似度度量 $S$ 和一个非负的权重函数 $f$ 使下式成立：</p><script type="math/tex; mode=display">\begin{align}&S(a,b)\ge S(c,d), &  \text{iff}\ \ s(a,b)\ge s(c,d)\\&S(a,b)=\theta f(A\cap B)-\alpha f(A- B) - \beta f(B-A), &\theta,\alpha,\beta\ge 0 \qquad (1)\end{align}</script><p>注意，这里 $s(a,b)$ 表示 $a,b$ 的实际相似度，而 $S(a,b)$ 表示我们建模后，对 $a,b$ 相似度的度量。</p><p>我们把式 $(1)$ 称为 <strong>Tversky</strong> <strong>对比模型</strong>，或简称<strong>对比模型</strong>。它最大的特点是将特征匹配拆分成 $A\cup B$、$A-B$、$B-A$ 三个部分，并分别赋予权重，从而当 $\alpha \not = \beta$ 时，$S(a,b)\not =S(b,a)$，即物品间相似是不对称的。另外，可以通过权重函数 $f()$ 函数来对每个特征赋予不同的重要性，这也满足我们在判断相似时更关注一些重要的特征是否匹配的现象。</p><p>作者还指出，<strong>对比模型</strong>可能是匹配函数最简单的形式。当然还可以考虑匹配函数的其他形式，例如下面的 <strong>RatioModel</strong>：</p><script type="math/tex; mode=display">S(a,b)=\frac{f(A\cap B)}{f(A\cap B)+\alpha f(A-B) + \beta f(B-A)}, \quad\alpha,\beta\ge 0 \qquad(2)</script><p>由于式 $(2)$ 中每一项都为正，因此 $S(a,b) $ 取值范围为 $[0,1]$，并且：</p><ul><li>当 $\alpha=\beta=1$ 时，<strong>RatioModel</strong> 退化成 $\frac{f(A\cap B)}{f(A\cup B)}$；</li><li>当 $\alpha=\beta=0.5$ 时，<strong>RatioModel</strong> 退化成 $\frac{f(A\cap B)}{f(A)+f(B)}$；</li><li>当 $\alpha=1, \beta=0$ 时，<strong>RatioModel</strong> 退化成 $\frac{f(A\cap B)}{f(A)}$；</li></ul><h3 id="模型的应用"><a href="#模型的应用" class="headerlink" title="模型的应用"></a>模型的应用</h3><p><strong>Tversky</strong> <strong>对比模型</strong>一眼看上去就非常符合常理，十分吸引人。但是实际上在应用到推荐系统中时，其复杂性就远远高于它的形式上的简单性。我们需要根据实际场景数据学到参数 $\theta,\alpha,\beta$，并且学到一个合理的权重函数，这里的难点主要在于：如何设置正负样本？样本怎么组织？</p><p>文献 $[1]$ 介绍了他们在时装线上商城上实践的经验，他们通过设置一些问卷实验来收集数据。问卷发放给典型的用户，每次给他们一张时装的图片作为目标，然后给出两张在特征上有所不同的时装图片作为备选，让用户选择哪一张备选图片与目标最相似，如下图所示。用户问卷收集完毕后，还需要经过一些统计上的处理才能作为后续的训练数据。</p><div style="width:70%; margin:auto"><img src="/2020/06/02/tversky-contrast-model/queries.png" title="实验设计：上面图片为目标图片，下面两张为备选图片"></div><p>样本组织上，作者基于<strong>对比模型</strong>按如下过程来生成一个样本，并设置标签：</p><script type="math/tex; mode=display">\begin{align}\begin{cases}Y&=I\big(S(T,A)-S(T,B)\big) \\S(T,X) &= \theta w^\top\cdot x_{T\cap A} -\alpha w^\top\cdot x_{T- A} -\beta w^\top\cdot x_{A-T}\end{cases}\end{align}</script><p>其中，$I(x)$ 是指示函数，当 $x&gt; 0$ 时 $I(x)=1$，否则 $I(x)=0$；$T$ 表示实验中的目标时装的特征集合，$A,B$ 表示两个备选时装的特征集合，$w$ 表示每个特征的权重。</p><p>根据这种方式，就可以对每个用户的每次选择生成一条样本：每条样本需要计算目标与备选的对比相似度，然后求差，作为样本的输入；假如用户选 $A$，则样本为正，否则样本为负。</p><p>在训练的时候，则用 $\delta\big(S(T,A)-S(T,B)\big)$ 来计算标签预测值，并设置如下损失函数：</p><script type="math/tex; mode=display">L(\gamma)=logloss(\alpha,\beta,\theta,w)-\frac{1}{\mu}\log(\alpha)-\frac{1}{\mu}\log(\beta)-\frac{1}{\mu}\log(\theta)</script><p>其中，$-\frac{1}{\mu}\log(\alpha)-\frac{1}{\mu}\log(\beta)-\frac{1}{\mu}\log(\theta)$ 表示  <strong>LogBarrier</strong> 惩罚，主要是为了限制 $\alpha,\beta,\theta$ 非负，$\mu\gg 0$ 为 <strong>LogBarrier</strong> 参数。</p><p>文章实验结果表明，在他们的场景下，各个特征的权重确实不同，并且 $\theta&gt;\alpha&gt;\beta$，表明拥有共同特征还是占主导作用，而 $\alpha&gt;\beta$ 表明目标有而备选没有的特征起次要作用，并且用户的相似度估计确实是非对称的。</p><p>文献 $[1]$ 的经验在复用的时候，主要是要解决人工标注的问题，还有如何选择目标/备选物品，如何确定选用哪些特征等。在与运营发生类似于 ”给我推的一点也不相似“ 的争端时，给他们设计一个问卷吧~</p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] Winecoff, Amy A., et al. “Users in the loop: a psychologically-informed approach to similar item retrieval.” <em>Proceedings of the 13th ACM Conference on Recommender Systems</em>. 2019.<br>[2] Tversky, Amos. “Features of similarity.” <em>Psychological review</em> 84.4 (1977): 327.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;物品相似度评估在推荐中当属核心问题之一，尤其是当用户有一些明确的喜好、或者当前有一个明确的消费目标的时候，推荐与用户搜索内容/当前浏览内容相似的内容，能够极大的提升用户体验。例如，“猜你喜欢”、“再来一条”、“相关推荐” 等场景，就是围绕用户的这类诉求设计的，它属于 ”探索与利用“ 中的 ”利用“。&lt;/p&gt;
&lt;p&gt;相似度评估已经是一个研究十分深入的领域，尤其是在心理学领域。我们往往说不清楚到底什么样的物品是相似的，或者说为什么两个物品不相似。出现这个问题，可能是因为在不同的情境下，我们不自觉的有不同的判断标准，使用了不同的特征，或者对不同的特征有不同的权重等等。这也导致了我们很难客观度量模型相似度评估的准不准，在很多业务场景下引发一些 badcase。&lt;/p&gt;
    
    </summary>
    
      <category term="推荐系统" scheme="https://guyuecanhui.github.io/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="相似度" scheme="https://guyuecanhui.github.io/tags/%E7%9B%B8%E4%BC%BC%E5%BA%A6/"/>
    
      <category term="相似模型" scheme="https://guyuecanhui.github.io/tags/%E7%9B%B8%E4%BC%BC%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="tversky" scheme="https://guyuecanhui.github.io/tags/tversky/"/>
    
      <category term="内容推荐" scheme="https://guyuecanhui.github.io/tags/%E5%86%85%E5%AE%B9%E6%8E%A8%E8%8D%90/"/>
    
  </entry>
  
  <entry>
    <title>xDeepFM 论文精读</title>
    <link href="https://guyuecanhui.github.io/2020/05/26/paper-2018-msra-xdeepfm/"/>
    <id>https://guyuecanhui.github.io/2020/05/26/paper-2018-msra-xdeepfm/</id>
    <published>2020-05-26T14:57:32.000Z</published>
    <updated>2020-06-10T13:46:05.216Z</updated>
    
    <content type="html"><![CDATA[<div class="note success"><p><strong>论文引用:</strong> Lian, Jianxun, et al. “xdeepfm: Combining explicit and implicit feature interactions for recommender systems.” <em>Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</em>. 2018. </p></div><p><strong>xDeepFM</strong> 是中科大和 <strong>MSRA</strong> 发表在 <strong>KDD 2018</strong> 上用于 <strong>CTR</strong> 预估的模型。这个模型充分借鉴了 <strong>DCN</strong>、<strong>FM</strong> 的思想，提出了一种新的将特征按 vector 进行交叉的结构 <strong>CIN</strong>，并且这个结构与 <strong>CNN</strong> 和 <strong>RNN</strong> 有一定的相似性。从实验来看，效果的确不错，但是工程效率实在是个难题。</p><a id="more"></a><h2 id="背景与动机"><a href="#背景与动机" class="headerlink" title="背景与动机"></a>背景与动机</h2><p>原始特征就像是未雕琢的原石，很难直接发挥出有效的作用，在预测系统中，我们通常需要对原始特征进行一定的组合变换，来取得比较好的效果。其中，特征交叉（即将离散特征值拼成一个新的特征值）能够衡量原始特征间的交互关系，提供在组合场景下有指导性的信息，对预测效果影响也比较显著，因此自动完成并提炼这种特征变换成为了众多模型（<strong>FM</strong>、<strong>DeepFM</strong>、<strong>DCN</strong> 等）设计显式交叉结构最主要的目的。</p><p>虽然 <strong>DeepFM</strong>、<strong>FNN</strong>、<strong>PNN</strong> 等模型能够完成特征的二阶显式交叉，并且通过 <strong>MLP</strong> 来完成特征的高阶隐式交叉，但是 <strong>xDeepFM</strong> 作者认为，单纯靠 <strong>DNN</strong> 来捕获高阶交叉特征效果无法保证，既说不清楚学到的函数是什么样的，也没法证明最多能学到几阶交叉，而且 <strong>MLP</strong> 本质上还是按 bit 进行交叉，物理含义也难以解释。</p><p><strong>DCN</strong> 模型前面也介绍过，是典型的能够提供高阶显式交叉能力，文章则证明了，<strong>DCN</strong> 的 CrossNet 结构每一层实际只能学到 embedding 层的张量积的形式。这个实际上就是看法的不同。对于第 $i+1$ 层 CrossNet，它的输出是根据 embedding 层的输入 $x_0$ 和第 $i$ 层的输出变换得到的：</p><script type="math/tex; mode=display">x_{i+1} = x_0x_i^{\top}w_{i+1}+x_i</script><p>我们之前说 CrossNet 能够捕获所有特征两两交叉的信息，是源自它有一项 <script type="math/tex">x_0x_i^{\top}</script>，它的结果是个矩阵，包含两个向量每一位的乘积，然后再乘 $w_{i+1}$ 相当于是 pooling 或者信息压缩。</p><p>而文章作者是看到上式等价于 <script type="math/tex">x_{i+1}=x_0(x_i^{\top}w_{i+1})+x_i</script>，而括号内的是一个标量，因此我们可以根据归纳法得到：</p><script type="math/tex; mode=display">\begin{align}x_1=&x_0(x_0^{\top}w_1)+x_0 = x_0(x_0^{\top}w_1+1)=\alpha^{(1)}x_0 \\x_2=&x_0(x_1^{\top}w_1)+x_1 = x_0\big((\alpha^1x_0)^{\top}w_1\big)+\alpha^{(1)}x_0=x_0\big((\alpha^{(1)}x_0)^{\top}w_1+\alpha^{(1)}\big)=\alpha^{(2)} x_0 \\\cdots \\x_{i+1}=& x_0\big((\alpha^{(i)}x_0)^{\top}w_{i+1}+\alpha^{(i)})=\alpha^{(i+1)}x_0\end{align}</script><p>这里的 $\alpha^i$ 是个标量，从这个表达式来看，CrossNet 的确每一层学到的是 $x_0$ 的张量积的形式。但是这并不是说 $x_k$ 与 $x_0$ 是线性相关的，只是说学到的函数形式比较受限。</p><p>因此文章设计 <strong>CIN</strong> 的核心思路有两个：一个是能够提供逐层高阶的显式特征交叉能力，另外特征交叉是按 vector 粒度进行，目标则是学到更加复杂的函数形式。</p><h2 id="CIN-架构"><a href="#CIN-架构" class="headerlink" title="CIN 架构"></a>CIN 架构</h2><p>文章提出 <strong>CIN</strong> 网络来完成特征显式交叉，简单来讲，它是将每一层的所有特征向量与输入层的所有特征向量进行点乘，然后用多个卷积核去做卷积，来生成特征交互的结果。具体来讲，它的交互过程如下：</p><p>记特征的 field 数量为 $m$，每个 field 特征对应的 embedding 维度都为 $d$，记 embedding 层输入为 $X^0\in \mathbb{R}^{m\times d}$，记第 $k+1$ 层 <strong>CIN</strong> 的输入（即第 $k$ 层的输出）为 <script type="math/tex">X^k\in \mathbb{R}^{h_k\times d}</script>。这里，<script type="math/tex">h_k</script> 是我们设置的超参数，例如，我们设置 <strong>CIN</strong> 的 layers 为 $[128, 128, 128]$ 时，它实际上指定了 <strong>CIN</strong> 有三层，且第 $k$ 层的权重矩阵 $W^k\in\mathbb{R}^{h_{k-1}\times m}$ 的数量为 $128$。</p><p>假设我们已经算出来前 $k-1$ 层的输出 $X^{k-1}$，则第 $k$ 层的输出 $X^k$ 的计算过程如下：</p><ol><li><p>计算出 $X^{k-1}$ 与 $X^0$ 的所有 field 特征向量间的 Hadamard 积，即将第 $k-1$ 层 <strong>CIN</strong> 输出的 <script type="math/tex">h_{k-1}</script> 个特征向量与 embedding 层的 $m$ 个特征向量做向量级的两两交叉，得到了 <script type="math/tex">h_{k-1}\times m</script> 个交叉向量，每个向量还是 $d$ 维：</p><script type="math/tex; mode=display">Z^k_{i,j} = X^{k-1}_{i,*}\circ X^0_{j,*}, \qquad 1\le i\le h_{k-1},1\le j\le m</script></li><li><p>在第 $k$ 层构造 <script type="math/tex">h_k</script> 个可训练的权重矩阵，每个权重矩阵 <script type="math/tex">W^{k,h}</script> 的维度为 <script type="math/tex">(h_{k-1},m)</script>，矩阵的每个元素对应了上一步中每个向量的权重，计算第 $h$ 个权重矩阵对所有向量的加权和，得到这个权重矩阵对应的加权向量 <script type="math/tex">X_{h,*}^k</script>，即第 $k$ 层 <strong>CIN</strong> 的输出 $X^k$ 的第 $h$ 行，每一行还是 $d$ 维：</p></li></ol><script type="math/tex; mode=display">X_{h,*}^k=\sum_{i=1}^{h_{k-1}} \sum_{j=1}^m W^{k,h}_{i,j} \cdot Z_{i,j}^k, \qquad 1\le h\le h_k</script><p>这样，我们就能够得到所有 <strong>CIN</strong> 层的输出 ${X^1,\cdots,X^n}$，并且一直保持 $X^i$ 的每一行是 $d$ 维的向量，从而保证每层都能与 $X^0$ 进行 vector 粒度的交叉。</p><p>整个 <strong>CIN</strong> 网络的输出则是将每个 <script type="math/tex">X^i\in \mathbb{R}^{h_i\times d}</script> 按列进行 sum pooling，得到一个 $h_i$ 维的向量 $x_i$，然后将所有 $x_i$ 进行拼接，得到一个 $\sum_i h_i$ 维的向量。上面的过程如果用卷积的思路，可以参考下面的图示：</p><img src="/2020/05/26/paper-2018-msra-xdeepfm/cin-flow.png" title="CIN 计算过程示意"><p>由于 <strong>CIN</strong> 层中每个权重矩阵实际上是相对独立的，每一个权重矩阵都对应了所有的特征交叉信息。因此在实现中，还可以将每个 $X^i$ 分成 <script type="math/tex">X^i_{0:h_i/2-1,*}</script> 和 <script type="math/tex">X^i_{h_i/2:,*}</script>，前一半进行 sum pooling 后得到 $h_i/2$ 维向量直接接到输出层，后一半则作为下一层的输入。</p><h3 id="网络分析"><a href="#网络分析" class="headerlink" title="网络分析"></a>网络分析</h3><p>由于模型里可训练的参数主要是权重矩阵，根据上面的分析，<strong>CIN</strong> 的总参数量为 <script type="math/tex">\sum_k h_k\cdot h_{k-1}\cdot m</script>。文章也提出，如果 $h_k$ 比较大的话，可以将每个权重矩阵做 L-order decomposition，用两个小矩阵的乘积来代替，可以进一步减少参数量。</p><p>举个例子，比如 $100$ 个 field 的 $[128, 128, 128]$ 的 <strong>CIN</strong> 网络，参数量为 $3\times 128\times 128\times 100=4915200$；假设 embedding 维度为 $16$，$[128, 128, 128]$ 的 <strong>MLP</strong> 参数量为 $16\times 100\times 128+128\times 128+128\times 128=237568$；<strong>CIN</strong> 要明显多出不少。</p><p><strong>CIN</strong> 每一层计算需要 $O(mh^2d)$ 的时间复杂度，$t$ 层的复杂度为 $O(mh^2dt)$，明显比 <strong>MLP</strong> 的 $O(mhd+h^2t)$ 大很多，实际跑下来，<strong>xDeepFM</strong> 一个 epoch 用时大概是 <strong>DeepFM</strong> 的 3 倍。因此，<strong>xDeepFM</strong> 模型无论是参数量还是训练、推理的速度，都对工程化有很高的要求。</p><p>关于 <strong>CIN</strong> 的交叉能力，从上面的网络计算过程来看，也容易知道，<strong>CIN</strong> 的交叉阶数是逐层加 1 的，这里就不展开说明了。</p><p>最后，<strong>CIN</strong> 可以与 <strong>MLP</strong> 组成并行架构，也就是文章提出的 <strong>xDeepFM</strong>，兼具显式交叉和隐式交叉的能力，如下图所示，这貌似也已经是一个通用的做法了。</p><img src="/2020/05/26/paper-2018-msra-xdeepfm/xdeepfm-architecture.png" title="xDeepFM 整体架构">]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;note success&quot;&gt;&lt;p&gt;&lt;strong&gt;论文引用:&lt;/strong&gt; Lian, Jianxun, et al. “xdeepfm: Combining explicit and implicit feature interactions for recommender systems.” &lt;em&gt;Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp;amp; Data Mining&lt;/em&gt;. 2018. &lt;/p&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;xDeepFM&lt;/strong&gt; 是中科大和 &lt;strong&gt;MSRA&lt;/strong&gt; 发表在 &lt;strong&gt;KDD 2018&lt;/strong&gt; 上用于 &lt;strong&gt;CTR&lt;/strong&gt; 预估的模型。这个模型充分借鉴了 &lt;strong&gt;DCN&lt;/strong&gt;、&lt;strong&gt;FM&lt;/strong&gt; 的思想，提出了一种新的将特征按 vector 进行交叉的结构 &lt;strong&gt;CIN&lt;/strong&gt;，并且这个结构与 &lt;strong&gt;CNN&lt;/strong&gt; 和 &lt;strong&gt;RNN&lt;/strong&gt; 有一定的相似性。从实验来看，效果的确不错，但是工程效率实在是个难题。&lt;/p&gt;
    
    </summary>
    
      <category term="论文精读" scheme="https://guyuecanhui.github.io/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/"/>
    
    
      <category term="推荐" scheme="https://guyuecanhui.github.io/tags/%E6%8E%A8%E8%8D%90/"/>
    
      <category term="排序" scheme="https://guyuecanhui.github.io/tags/%E6%8E%92%E5%BA%8F/"/>
    
      <category term="特征交叉" scheme="https://guyuecanhui.github.io/tags/%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/"/>
    
      <category term="ctr" scheme="https://guyuecanhui.github.io/tags/ctr/"/>
    
      <category term="CIN" scheme="https://guyuecanhui.github.io/tags/CIN/"/>
    
  </entry>
  
  <entry>
    <title>AutoInt 论文精读</title>
    <link href="https://guyuecanhui.github.io/2020/05/09/paper-2019-pku-autoint/"/>
    <id>https://guyuecanhui.github.io/2020/05/09/paper-2019-pku-autoint/</id>
    <published>2020-05-09T15:46:32.000Z</published>
    <updated>2020-06-10T13:40:02.338Z</updated>
    
    <content type="html"><![CDATA[<div class="note success"><p><strong>论文引用:</strong> Song, Weiping, et al. “Autoint: Automatic feature interaction learning via self-attentive neural networks.” <em>Proceedings of the 28th ACM International Conference on Information and Knowledge Management</em>. 2019. </p></div><p>这是一篇北京大学发表在 <strong>CIKM 2019</strong> 的文章，看作者列表没有企业背景，主要还是提供一些理论思路。文章的核心也是想通过自动挖掘特征间的高阶交互关系来提升减少人工特征工程，但是与前面的 <strong>DeepFM</strong>、<strong>DCN</strong> 等能够提供显式特征交叉能力的模型最大的差别在于：本文是通过不同 field 间特征做 <strong>Self-Attention</strong> 来实现特征的交互，也因此获得了一定的特征组合的可视化能力（<em>即文章中声称提供了较好的可解释性</em>）。</p><a id="more"></a><h3 id="背景与动机"><a href="#背景与动机" class="headerlink" title="背景与动机"></a>背景与动机</h3><p>其实已有的深度模型的相关工作基本核心都是在做高阶的特征交叉，但是诸如 <strong>PNN</strong>、<strong>FNN</strong>、<strong>DeepCrossing</strong>、<strong>Wide&amp;Deep</strong>、<strong>DeepFM</strong> 等模型，主要是依赖前馈网络来实现高阶特征交叉，主要的问题是特征交叉过程是隐式的，很难解释是哪些特征间的组合起到了关键作用，这个问题也存在于 <strong>DCN</strong>、<strong>xDeepFM</strong> 等提供显式特征交叉能力的模型中。</p><p>另外一些提供显式特征交叉能力的模型和算法也存在各种各样的问题，比如基于树+embedding 的$^{[1,2,3]}$，会将训练过程分裂成几个部分；比如显式做所有特征的高阶组合的 <strong>HOFM</strong> 模型$^{[4]}$，参数量过大，高于 5 阶的组合基本不可用（<em>实际上根据张俊林的说法，高于 4 阶的特征组合就已经收益很低了，这在 <strong>DCN</strong> 的测试中也得到了一定的验证</em>）。</p><p>基于这个背景，文章的目标是想找到一种特征自动进行高阶交叉的方法，既能弥补 <strong>MLP</strong> 对乘性特征组合捕获能力不强的弱点，又能够较好的解释哪些特征组合比较有效。</p><h3 id="AutoInt-网络设计"><a href="#AutoInt-网络设计" class="headerlink" title="AutoInt 网络设计"></a>AutoInt 网络设计</h3><h4 id="模型概览"><a href="#模型概览" class="headerlink" title="模型概览"></a>模型概览</h4><p><strong>AutoInt</strong> 网络内部主要包括两块，如下图所示：</p><img src="/2020/05/09/paper-2019-pku-autoint/autoint.png" title="AutoInt 整体架构"><p><strong>AutoInt</strong> 底层是 embedding 层，类似于 <strong>DeepFM</strong> 的设计，将所有的离散、连续特征都映射成一个等长的 embedding 向量，其中，离散特征是直接 lookup embedding 表，多值的离散特征使用 average pooling；连续特征则相当于乘以一个不含 bias 的 <strong>Dense</strong> 层。</p><p><strong>AutoInt</strong> 核心是上面的交互层，使用 <strong>Multi-head Self-Attention</strong> 来实现，并且可以叠加多层，实现特征的高阶交叉。作者认为，特征组合的关键是知道哪些特征组合在一起有强大的表征能力，这个实际上相当于在人工特征工程中进行特征选择，那么在深度网络里怎么自动去实现特征组合的选择呢？作者受到 <strong>Self-Attention</strong> 的启发，考虑让每个 field 的特征与其他 field 的特征分别做 attention，根据 attention 的权重来判断该 field 特征与其他 field 特征组合的重要性，越重要的组合给予的权重越高，最后生成加权后的 sum pooling 作为该 field 特征与所有其他 field 特征组合的结果。</p><h4 id="Self-Attention-层计算流程详解"><a href="#Self-Attention-层计算流程详解" class="headerlink" title="Self-Attention 层计算流程详解"></a>Self-Attention 层计算流程详解</h4><p>关于 <strong>Self-Attention</strong> 相关的理论和应用，后面还会再单独介绍，感觉这一块是后面网络发展的重点。下面仅仅结合计算过程再详细的说明一下上面的思路，使用的符号与文章略有不同。</p><ol><li>假设输入特征一共有 $m$ 个 field，每个 field 的特征记为 $\boldsymbol{x}_i$，对应的 embedding 向量记为 $\boldsymbol{e}_i$；所有 field 拼接起来的 embedding 记为 $\boldsymbol{e}$；</li><li>考虑第 $i$ 个 field 的特征 $\boldsymbol{x}_i$ 对应的 embedding 向量 $\boldsymbol{e}_i$，首先计算它经过单层 Self-Attention 后生成的特征组合向量 $\tilde{\boldsymbol{e}}_i$（<em>其他 field 的计算过程完全相同</em>）；</li><li>对于 head $h$，根据该 head 中的 query、key、value 矩阵，计算第 $i$ 个 field 特征的 query 向量和所有其他 field 特征的 key、value 向量：<script type="math/tex; mode=display">\begin{cases}\boldsymbol{q}_i^{(h)} = \boldsymbol{W}_q^{(h)}\boldsymbol{e}_i \\\boldsymbol{k}_j^{(h)} = \boldsymbol{W}_k^{(h)}\boldsymbol{e}_j \\\boldsymbol{v}_j^{(h)} = \boldsymbol{W}_v^{(h)}\boldsymbol{e}_j\end{cases} \qquad j=1,\cdots,m</script></li><li>计算第 $i$ 个 field 的 query 向量与所有其他 field 特征对应的 key 向量的 attention 权重 <script type="math/tex">a_{i,j}^{(h)}</script>：<script type="math/tex; mode=display">a_{i,j}^{(h)} = \frac{\exp(\boldsymbol{q}_i^{(h)}\cdot\boldsymbol{k}_j^{(h)})}{\sum_{l=1}^m \exp(\boldsymbol{q}_i^{(h)}\cdot \boldsymbol{k}_l^{(h)})}</script></li><li>计算第 $i$ 个 field 对应的所有其他 field 的加权 value 向量 $\tilde{\boldsymbol{e}}_i^{(h)}$，作为第 $h$ 个 head 中第 $i$ 个 field 特征与所有其他 field 特征交互后的组合向量：<script type="math/tex; mode=display">\tilde{\boldsymbol{e}}_i^{(h)}=\sum_{j=1}^m a_{i,j}^{(h)} \boldsymbol{v}_j^{(h)}</script></li><li>将所有 head 的结果进行 concat，得到第 $i$ 个 field 特征与所有其他 field 特征交互后的组合向量：<script type="math/tex; mode=display">\tilde{\boldsymbol{e}}_i = \tilde{\boldsymbol{e}}_i^{(1)}\oplus\tilde{\boldsymbol{e}}_i^{(2)}\oplus\cdots\oplus\tilde{\boldsymbol{e}}_i^{(k)}</script></li><li>将所有 field 的组合向量进行 concat，并加上输入层，得到单层 Self-Attention 的输出向量 $\tilde{\boldsymbol{e}}$：<script type="math/tex; mode=display">\tilde{\boldsymbol{e}}' = \tilde{\boldsymbol{e}}_1 \oplus\tilde{\boldsymbol{e}}_2\oplus\cdots\oplus\tilde{\boldsymbol{e}}_m \\\tilde{\boldsymbol{e}}=\text{ReLU}(\tilde{\boldsymbol{e}}'+\boldsymbol{W}\cdot \boldsymbol{e})</script></li></ol><p><strong>说明：</strong></p><ul><li>与 google 的原始论文 $[5]$ 相比，<strong>AutoInt</strong> 中的 <strong>Self-Attention</strong> 没有进行 scale，即第 4 步求 softmax 之前没有将内积除以一个缩放系数，导致的结果是突出了高效组合的重要性。当然，在实现的时候还是可以尝试把缩放加进来；</li><li>文献 $[5]$ 在最后一步还会再过一个 <strong>LayerNormalization</strong>，文章里并没有加；实现的时候可以加了看看效果；</li><li>在实现的时候，假设 embedding 的维度为 $d$，head 的数量为 $k$，则可以设置每个 head 中 query、key、value 矩阵 $\boldsymbol{W}^{(h)}$ 的维度为 $(\frac{d}{k}, d)$，这样得到的 $\tilde{\boldsymbol{e}}_i^{(h)}$ 就是 $\frac{d}{k}$ 维，将 $k$ 个 head 的结果 concat 后，$\tilde{\boldsymbol{e}}_i$ 又变成了 $d$ 维，从而保证输入的维度与输出的维度相同；这样的话，最后一步中矩阵 $\boldsymbol{W}$ 其实就不需要了（<em>文章的实验中 $\boldsymbol{e}$ 与 $\tilde{\boldsymbol{e}}’$ 维度不同，因此需要通过 $\boldsymbol{W}$ 将 $\boldsymbol{e}$ 变成与 $\tilde{\boldsymbol{e}}’$ 相同的维度</em>）。</li></ul><h4 id="Self-Attention-交叉能力分析"><a href="#Self-Attention-交叉能力分析" class="headerlink" title="Self-Attention 交叉能力分析"></a>Self-Attention 交叉能力分析</h4><p>文章将有 $p$ 个不同 field 特征乘性组合的特征称为 $p$ 阶组合特征，记为 <script type="math/tex">g(x_{i_1},\cdots,x_{i_p})</script>，从计算过程容易看出来，<script type="math/tex">\tilde{\boldsymbol{e}}_i^{(h)}</script> 乃至 $\tilde{\boldsymbol{e}}_i$ 都是包含 $\boldsymbol{x}_i$ 与所有 <script type="math/tex">\boldsymbol{x}_j\ (j=1,\cdots,i-1,i+1,\cdots,m )</script> 交互的 2 阶组合特征：${g(x_i,x_1),g(x_i,x_2),\cdots,g(x_i,x_m)}$。因此，单层 Self-Attention 就能表征所有 field 的 2 阶组合特征。</p><p>到了两层时，由于第一层输出中每个 field 相当于都是包含了所有的 2 阶组合，因此它的输出就包含了 3 阶和 4 阶的组合特征，例如 $g(x_1,x_2,x_3,x_4)$ 就包含在 $\tilde{\boldsymbol{e}}_1$ 和 $\tilde{\boldsymbol{e}}_3$ 的交互中。同理，三层 <strong>Self-Attention</strong> 就包含 8 阶内的组合特征……与 <strong>DCN</strong> 中的 cross 层相比，cross 每层增加 1 阶特征组合，而 <strong>Self-Attention</strong> 每层增加 1 倍特征组合。</p><h4 id="应用与讨论"><a href="#应用与讨论" class="headerlink" title="应用与讨论"></a>应用与讨论</h4><p>上面已经介绍了 embedding 层和 <strong>Self-Attetion</strong> 层，其中，<strong>Self-Attention</strong> 层是可以直接堆叠的，由于有残差结构的设计（最后一步加上了输入），理论上可以堆的比较深（文章的实验也证明了这个设计是比较有效的）。它还可以作为子结构，通过串联或者并联的方式，嵌入到其他网络中去，例如：</p><ul><li><strong>串联：</strong>最上面一层的 <strong>Self-Attention</strong> 输出可以直接送到 <strong>LR</strong> 里输出预测结果，或者再接一个 <strong>MLP</strong> 再输出预测结果；</li><li><strong>并联：</strong>embedding 层同时作为输入，送到 <strong>MLP</strong>、<strong>FM</strong>、cross 等其他层中，最后所有层结果进行 concat，送到 <strong>LR</strong> 中输出预测结果；</li></ul><p>训练一般还是使用 logloss 作为损失函数，用 <strong>Adam</strong> 等优化算法进行优化。</p><p>我在我们的数据集上测试的时候，发现 <strong>Self-Attention</strong> 层数也是 3 层就够了，到了 4 层测试 <strong>AUC</strong> 反而会降低，这与文章的参数是吻合的。</p><p>至于文章另外一个鼓吹的亮点，即特征组合的可解释性，实际上就是画出 attention 权重的热力图，主要是用于数据分析，感觉除了汇报好看点，也没啥实际的用处。</p><p>最后想说的一点，文章将不同 field 的特征当成了序列来做 <strong>Self-Attention</strong>，但其实 <strong>Self-Attention</strong> 也经常会用于对序列特征做 pooling，这也会在以后一起介绍。</p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] Wang, Xiang, et al. “Tem: Tree-enhanced embedding model for explainable recommendation.” <em>Proceedings of the 2018 World Wide Web Conference</em>. 2018.<br>[2] Zhao, Qian, Yue Shi, and Liangjie Hong. “Gb-cent: Gradient boosted categorical embedding and numerical trees.” <em>Proceedings of the 26th International Conference on World Wide Web</em>. 2017.<br>[3] Zhu, Jie, et al. “Deep embedding forest: Forest-based serving with deep embedding features.” <em>Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>. 2017.<br>[4] Blondel, Mathieu, et al. “Higher-order factorization machines.” <em>Advances in Neural Information Processing Systems</em>. 2016.<br>[5] Vaswani, Ashish, et al. “Attention is all you need.” <em>Advances in neural information processing systems</em>. 2017.</p>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;note success&quot;&gt;&lt;p&gt;&lt;strong&gt;论文引用:&lt;/strong&gt; Song, Weiping, et al. “Autoint: Automatic feature interaction learning via self-attentive neural networks.” &lt;em&gt;Proceedings of the 28th ACM International Conference on Information and Knowledge Management&lt;/em&gt;. 2019. &lt;/p&gt;&lt;/div&gt;
&lt;p&gt;这是一篇北京大学发表在 &lt;strong&gt;CIKM 2019&lt;/strong&gt; 的文章，看作者列表没有企业背景，主要还是提供一些理论思路。文章的核心也是想通过自动挖掘特征间的高阶交互关系来提升减少人工特征工程，但是与前面的 &lt;strong&gt;DeepFM&lt;/strong&gt;、&lt;strong&gt;DCN&lt;/strong&gt; 等能够提供显式特征交叉能力的模型最大的差别在于：本文是通过不同 field 间特征做 &lt;strong&gt;Self-Attention&lt;/strong&gt; 来实现特征的交互，也因此获得了一定的特征组合的可视化能力（&lt;em&gt;即文章中声称提供了较好的可解释性&lt;/em&gt;）。&lt;/p&gt;
    
    </summary>
    
      <category term="论文精读" scheme="https://guyuecanhui.github.io/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/"/>
    
    
      <category term="推荐" scheme="https://guyuecanhui.github.io/tags/%E6%8E%A8%E8%8D%90/"/>
    
      <category term="排序" scheme="https://guyuecanhui.github.io/tags/%E6%8E%92%E5%BA%8F/"/>
    
      <category term="注意力" scheme="https://guyuecanhui.github.io/tags/%E6%B3%A8%E6%84%8F%E5%8A%9B/"/>
    
      <category term="self-attention" scheme="https://guyuecanhui.github.io/tags/self-attention/"/>
    
      <category term="ctr" scheme="https://guyuecanhui.github.io/tags/ctr/"/>
    
  </entry>
  
  <entry>
    <title>DeepFM 论文精读</title>
    <link href="https://guyuecanhui.github.io/2020/04/30/paper-2017-noah-deepfm/"/>
    <id>https://guyuecanhui.github.io/2020/04/30/paper-2017-noah-deepfm/</id>
    <published>2020-04-30T14:30:24.000Z</published>
    <updated>2020-06-10T13:44:01.847Z</updated>
    
    <content type="html"><![CDATA[<div class="note success"><p><strong>论文引用:</strong> Guo, Huifeng, et al. “DeepFM: a factorization-machine based neural network for CTR prediction.” <em>arXiv preprint arXiv:1703.04247</em> (2017). </p></div><p><strong>DeepFM</strong> 是华为诺亚实验室受 <strong>FM</strong> 和 wide &amp; deep 模型启发，发表在 <strong>IJCAI 2017</strong> 的一个 <strong>CTR</strong> 预估模型，从国内企业的实践分享来看，其效果受到了广泛的认可。它的核心思想是将 wide &amp; deep 网络中的 wide 层用 <strong>FM</strong> 层代替，增加了特征的二阶自动交叉能力，并且在实现上天然可以将 <strong>FM</strong> 层的 embedding 与 deep 层共享。</p><a id="more"></a><h3 id="DeepFM-架构"><a href="#DeepFM-架构" class="headerlink" title="DeepFM 架构"></a>DeepFM 架构</h3><p>随着深度网络的兴起，<strong>DNN</strong> 尤其是 <strong>MLP</strong> 的结构往往被用作非线性的特征提取器，并且取得了比较好的效果。然而文章指出，<strong>只保留特征的高阶非线性组合并不如同时保留特征的低阶组合和高阶组合效果好</strong>。这也是文章核心的出发点之一。但是 wide &amp; deep 模型中只有特征的一阶和高阶组合，因此一些有效的的二阶/三阶组合只能靠工程师人工挖掘组合出来，放到 wide 层。这个时候 <strong>FM</strong> 模型又出场了，用它来代替 wide 层，既能保留原始特征，又能自动做原始特征的二阶组合，这样就能节省很多人工特征交叉的工作。当然对于三阶及以上特征的显式组合，还是只能靠人工做一些工作，或者用前面讲的 <strong>DCN</strong> 中的 cross 等结构去捕获。</p><p><strong>DeepFM</strong> 的模型架构如下图所示，首先将所有的特征转成长度相同的 embedding，然后依照 <strong>FM</strong> 模型构建 <strong>FM</strong> 层，再将所有 embedding 拼接后，送到 <strong>MLP</strong> 层，最后在顶层进行拼接后，送到 <strong>LR</strong> 层，计算二分类损失。</p><img src="/2020/04/30/paper-2017-noah-deepfm/deepfm_architecture.png" title="图 1. DeepFM 整体架构"><p>从架构来看，<strong>DeepFM</strong> 没有什么创新的子结构，主要还是在当时提出了一个比较好的思路。下面再聊一聊模型中的一些细节处理。</p><h3 id="特征处理"><a href="#特征处理" class="headerlink" title="特征处理"></a>特征处理</h3><p>由于诺亚在应用市场推荐场景中没有使用连续特征，因此该模型也没有考虑连续特征的处理。但是实际上 <strong>FM</strong> 本身是支持连续特征的，所以如果有连续特征，应该也是需要将每一维连续特征转成一个 embedding。</p><p>对于多值的离散特征，这里有两种处理方案。一种是只考虑 field 之间的特征交叉，这种思路下，我们在生成多值离散特征的 embedding 时可以使用某种 pooling 策略，建议使用 sum pooling，因为这种情况下相当于是每个取值都与另外一维特征做了交叉；另一种是考虑所有特征取值的交叉，这种思路下，就需要将多值特征每个取值的 embedding 进行 concat，再送到 <strong>FM</strong> 层和 <strong>MLP</strong> 层。</p><h3 id="效果测试"><a href="#效果测试" class="headerlink" title="效果测试"></a>效果测试</h3><p>我测试了一下 <strong>DeepFM</strong> 每个子结构的性能（使用 pooling 策略），以只使用线性部分作为基线的话，只使用 FM 的交叉部分能够提升 $4.91\%$，只使用 <strong>MLP</strong> 部分能够提升 $9.30\%$，全部使用能够提升 $9.38\%$，从数据来看，<strong>FM</strong> 层的确能带来少量的提升。</p><h3 id="从-DeepFM-到-DeepFFM"><a href="#从-DeepFM-到-DeepFFM" class="headerlink" title="从 DeepFM 到 DeepFFM"></a>从 DeepFM 到 DeepFFM</h3><p>最后有一个小问题值得思考和讨论一下，<strong>DeepFM</strong> 使用 <strong>FM</strong> 层代替 wide 层，那能不能使用 <strong>FFM</strong> 来代替 wide 层呢？或者有没有什么类似的思路，让每个特征与其他 field 特征进行交叉的时候能够有不同的表征？</p><p>最直接的方案就是将 embedding 层进行扩展（称为 <strong>NeuralFFM</strong> $^{[1]}$），即将原来每个 field 对应一个二维的 embedding matrix，扩展为每个 field 对应一个三维的 embedding matrix，使得每个特征都对应于一个二维的 embedding matrix，在交叉时同时根据 source/target field ID 来 lookup 相应的 embedding vector，如图 2 所示。假设 field 的数量为 $m$，这种方案实际上是将 embedding 的参数量增加为原来的 $m$ 倍。这种方案貌似最早是南大在比赛中使用过，效果还不错。但是由于 embedding 层本来就已经贡献了整个模型主要的参数量，这种方案无论是在 train、store 还是 serving 都十分吃资源。</p><img src="/2020/04/30/paper-2017-noah-deepfm/neuralffm_architecture.png" title="图 2. NeuralFFM 整体架构"><p>还有一种思路是使用 self-attention 的思路 $^{[2]}$，将每个 field 与其他 field 计算 attention 值，作为其他 field 对该 field 相关的权重，然后再计算加权的 pooling，作为该 field 与其他所有 field 特征的交互结果。这个方案我们在 后续介绍 <a href="https://guyuecanhui.github.io/2020/05/09/paper-2019-pku-autoint/">AutoInt</a> 时会再详细说明。</p><p>张俊林等人则同时采用了这两种思路，提出了 <strong>FAT-DeepFFM</strong> $^{[3]}$，即 embedding 层使用 <strong>FFM</strong> 的扩展，在交互层使用 attention 机制，如下所示。但是张俊林自己在分享中都表示这种思路尝试一下就好了 $^{[4]}$，所以这里就学习一下这种思路，不详细介绍了，大家在生产环境中还是谨慎使用。</p><img src="/2020/04/30/paper-2017-noah-deepfm/deepffm_architecture.png" title="图 3. FAT-DeepFFM 整体架构"><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] Yang, Yi, et al.. “Neural field-aware factorization machine.” <em><a href="https://cs.nju.edu.cn/31/60/c1654a209248/page.htm" target="_blank" rel="noopener">https://cs.nju.edu.cn/31/60/c1654a209248/page.htm</a></em>. 2017.</p><p>[2] Song, Weiping, et al. “Autoint: Automatic feature interaction learning via self-attentive neural networks.” <em>Proceedings of the 28th ACM International Conference on Information and Knowledge Management</em>. 2019.</p><p>[3] Zhang, Junlin, Tongwen Huang, and Zhiqi Zhang. “FAT-DeepFFM: Field Attentive Deep Field-aware Factorization Machine.” <em>arXiv preprint arXiv:1905.06336</em> (2019).</p><p>[4] 张俊林. “FFM及DeepFFM模型在推荐系统的探索.” <em><a href="https://zhuanlan.zhihu.com/p/67795161" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/67795161</a></em>. 2019.</p>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;note success&quot;&gt;&lt;p&gt;&lt;strong&gt;论文引用:&lt;/strong&gt; Guo, Huifeng, et al. “DeepFM: a factorization-machine based neural network for CTR prediction.” &lt;em&gt;arXiv preprint arXiv:1703.04247&lt;/em&gt; (2017). &lt;/p&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;DeepFM&lt;/strong&gt; 是华为诺亚实验室受 &lt;strong&gt;FM&lt;/strong&gt; 和 wide &amp;amp; deep 模型启发，发表在 &lt;strong&gt;IJCAI 2017&lt;/strong&gt; 的一个 &lt;strong&gt;CTR&lt;/strong&gt; 预估模型，从国内企业的实践分享来看，其效果受到了广泛的认可。它的核心思想是将 wide &amp;amp; deep 网络中的 wide 层用 &lt;strong&gt;FM&lt;/strong&gt; 层代替，增加了特征的二阶自动交叉能力，并且在实现上天然可以将 &lt;strong&gt;FM&lt;/strong&gt; 层的 embedding 与 deep 层共享。&lt;/p&gt;
    
    </summary>
    
      <category term="论文精读" scheme="https://guyuecanhui.github.io/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/"/>
    
    
      <category term="推荐" scheme="https://guyuecanhui.github.io/tags/%E6%8E%A8%E8%8D%90/"/>
    
      <category term="排序" scheme="https://guyuecanhui.github.io/tags/%E6%8E%92%E5%BA%8F/"/>
    
      <category term="特征组合" scheme="https://guyuecanhui.github.io/tags/%E7%89%B9%E5%BE%81%E7%BB%84%E5%90%88/"/>
    
      <category term="特征交叉" scheme="https://guyuecanhui.github.io/tags/%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/"/>
    
  </entry>
  
  <entry>
    <title>Deep &amp; Cross 论文精读</title>
    <link href="https://guyuecanhui.github.io/2020/04/15/paper-2017-google-dcn/"/>
    <id>https://guyuecanhui.github.io/2020/04/15/paper-2017-google-dcn/</id>
    <published>2020-04-15T13:50:20.000Z</published>
    <updated>2020-06-10T13:43:13.677Z</updated>
    
    <content type="html"><![CDATA[<div class="note success"><p><strong>论文引用:</strong> Wang, Ruoxi, et al. “Deep &amp; cross network for ad click predictions.” <em>Proceedings of the ADKDD’17</em>. 2017. 1-7. </p></div><p>本文是 Stanford 和 Google 联合发表在 <strong>KDD</strong> 2017 workshop 上的一篇 <strong>CTR</strong> 预估模型，模型采用 <strong>Wide&amp;Deep</strong> 架构，最大的创新点在于将 wide 层替换成 cross 层，省去了原本大量的人工特征工程的工作，由 cross 层提供显式的高阶特征组合能力，同时保持较低的参数量和计算量。</p><a id="more"></a><h3 id="背景与动机"><a href="#背景与动机" class="headerlink" title="背景与动机"></a>背景与动机</h3><p>随着深度网络的兴起，各大厂纷纷尝试用深度网络来作为特征提取器，并取得了显著的效果。尤其是 Wide&amp;Deep 架构的提出，让大家意识到可以在模型中同时使用 <strong>DNN</strong> 来捕获特征的复杂映射关系，使用线性模型来记忆组合特征，但是这里的线性模型中的组合特征其实还是工程师针对具体场景人工构造的。</p><p>进一步，大家考虑将 wide 层用自动特征组合的网络来替换，例如用 <strong>FM</strong> 来代替 wide 层 (<strong>DeepFM</strong>)，能够提供了二阶的自动特征组合能力。本文则更进一步，设计出 cross 网络来代替 wide 层，能够提供任意高阶的特征组合能力 (与 cross 层数相同)，同时保持很低的计算和存储开销。</p><p>那有了 <strong>MLP</strong> 层为什么还需要 cross 层呢？我的理解是，<strong>MLP</strong> 层更擅长的是进行特征复杂的非线性变换，这些非线性变换通常是隐式的、对于乘性的特征组合捕获能力不强，而人基于对业务的深入理解能够显式构造一些十分有效的组合特征，如果让 <strong>MLP</strong> 层去学，可能需要比较大的参数规模才能学到。这也是 <strong>Wide&amp;Deep</strong> 为什么还需要保留 wide 层的原因。而 cross 层则设计为显式的进行特征组合，能够保证每一层都保留上一层的组合信息，并增加一阶组合，因此可以认为这两个结构是互补的。</p><p>当然，这里的 cross 层由于参数数量的限制，容量有限，我们仍然可以在 <strong>DCN</strong> 的基础上增加 wide 层来强化对部分人工特征的记忆，或者将 cross 层作为一个子网嵌入到其他排序网络中去，作为高阶特征提取器。</p><h3 id="DCN-网络架构"><a href="#DCN-网络架构" class="headerlink" title="DCN 网络架构"></a>DCN 网络架构</h3><p>前面提到了，<strong>DCN</strong> 的主要创新点在于设计了 cross 层来做特征的显式组合，同时只使用很少的参数。乍一看感觉有点神奇，如果要学习 $n$ 个特征的 $k$ 阶组合，按道理讲我们需要 $C_n^k$ 个参数 ($O(d^n)$)，那怎么进行参数的压缩呢？先可以回顾一下 <strong>FM</strong>，它本质上是学习了每个特征的隐向量，然后用两个特征隐向量的内积来代替这两个特征组合的系数，这样能够共享统计强度，并减少参数量。<strong>DCN</strong> 的 cross 层则更进一步，它每一层的设计如下：</p><script type="math/tex; mode=display">\boldsymbol{x}_{l+1}=\boldsymbol{x}_0 \boldsymbol{x}_l^{\top}\boldsymbol{w}_l + \boldsymbol{b}_l + \boldsymbol{x}_l \qquad(1)</script><p>即第 $l+1$ 层的输入与第 $l$ 层的输入和原始的特征输入有关。再具体点来说，式 $(1)$ 右边的第一项是原始特征与 $l$ 阶特征的笛卡尔积，再与一个权重向量相乘。简单用归纳法可以看出，从表达式上来讲，$\boldsymbol{x}_0 \boldsymbol{x}_l$ 是能够包含所有 $l+1$ 阶的特征组合，这一项再乘以一个权重向量，相当于对特征组合的信息做了 weighted sum pooling，或者换句话说，$\boldsymbol{x}_0 \boldsymbol{x}_l^{\top}$ 的每一列 $i$ 共享同一个参数 $\boldsymbol{w}_l^{(i)}$；式 $(1)$ 最后再加上原始特征输入实际上是类似于残差网络的结构，主要是帮助模型训练。关于式 $(1)$ 文章还提供了一个可视化的图片方便理解，如下所示：</p><img src="/2020/04/15/paper-2017-google-dcn/dcn_cross.png" title="图 1. Cross 层结构设计"><p>到这里我们可以简单的分析一下这个 cross 层有以下特点：</p><ol><li>它的显式特征组合是通过输入与每一层进行笛卡尔积来获得，但是在保存的时候，进行了 pooling，极大的降低了存储的开销；</li><li>它每层的权重实际上是一个 $d$ 维的向量 (而非两层全连接网络的 <script type="math/tex">n_i\times n_{i-1}</script> 的张量)，因此参数规模控制在 $O(md)$ 的级别，其中 $m$ 是 cross 网络的层数，$d$ 是初始特征维度；</li><li>实际计算的时候，可以根据交换律先计算 $\boldsymbol{x_0} (\boldsymbol{x}_l^{\top}\boldsymbol{w})$ 中括号内的部分，将乘法次数降到 $O(d)$ 次，从而整个 cross 网络的推理复杂度也降到了 $O(md)$。</li><li>cross 网络不存在非线性的变换，并且由于权重的连乘，在训练的时候存在梯度消失或者爆炸的风险。</li></ol><p>我们可以将 cross 层作为一个子结构加入到其他网络中去，例如 <strong>DCN</strong> 就可以看成是普通的 <strong>MLP</strong> + cross 的架构，其中，<strong>MLP</strong> 部分主要来做特征的非线性变换，一般就是几层全连接的隐含层，使用 <strong>relu</strong> 进行激活。整体的架构如下：</p><img src="/2020/04/15/paper-2017-google-dcn/dcn_architecture.png" title="图 1. DCN 整体架构"><p>在特征处理时，连续特征做归一化，离散特征先查 embedding，拼接在一起作为原始输入 $\boldsymbol{x}_0$，并分别输入到 cross 层和 <strong>MLP</strong> 层，将两个结构的输出拼接后，经过一个 <strong>LR</strong> 输出预测结果，训练的时候使用带 <strong>L2</strong> 范数的 logloss 作为 <strong>Cost Function</strong>，用 <strong>Adam</strong> 之类的优化算法求解。</p><p>对于模型训练，文章还分享了一些小技巧：</p><ol><li><strong>MLP</strong> 层使用了 batch normalization，并设置梯度截断值为 100；</li><li>使用 early stop 来进行正则化，相对于 L2 正则和 dropout 更有效；感觉 <strong>DCN</strong> 的确比较容易过拟合，我在测试时发现，当数据量比较大，并且将模型的参数规模调整到一个合适的量级，一个 epoch 基本已经达到最优了，继续训练可能就会导致测试 <strong>AUC</strong> 下降；</li><li>$d$ 维类别特征的 embedding size 设置参考计算式：$6\times d^{\frac{1}{4}}$；但是感觉在我们的场景里还是太大了，个人倾向于设置成 $\log$ 的函数。在资源允许的情况下，embedding size 设置大一点对测试 <strong>AUC</strong> 是有正向帮助的，但是也增加了过拟合的风险；</li></ol><h3 id="实验与讨论"><a href="#实验与讨论" class="headerlink" title="实验与讨论"></a><strong>实验与讨论</strong></h3><p>文章主要在 <a href="https://www.kaggle.com/c/criteo-display-ad-challenge" target="_blank" rel="noopener">criteo 数据集</a>上进行了一些对比实验，除了证明 <strong>DCN</strong> 比 benchmark 都好很多以外，还重点强调了 <strong>DCN</strong> 在同等参数量下能够达到更低的误差、在同等误差的情况下能够使用更少的参数。另外，还单独测试了增加 cross 结构的确能够大幅的降低模型的误差。</p><p>文章比较的时候，<strong>LR</strong>、<strong>FM</strong> 等模型使用的特征与 <strong>DCN</strong> 实际上是有差别的，做了更多的特征工程。为了测试模型本身的效果，我在我们业务的数据集上也跟一些常见模型对比测试了一下，离线效果确实还不错，而且即使只用 cross 层，也能超过 <strong>FFM</strong> 的效果。</p><p>我也单独测试了 <strong>DCN</strong> 各个子结构的性能，经过若干贪心调优后，以 <strong>LR</strong> 作为基线 (即将 <strong>DCN</strong> 的 <strong>MLP</strong> 层和 cross 层的输入 $\boldsymbol{x_0}$ 直接送到 <strong>LR</strong> 层)，只使用 cross 层的测试 <strong>AUC</strong> 提升了 $4.5\%$，只使用 <strong>MLP</strong> 层的测试 <strong>AUC</strong> 提升了 $5.5\%$，而两者都用的测试 <strong>AUC</strong> 提升了 $6.3\%$。只使用 cross 层效果不如只使用 <strong>MLP</strong> 层的主要原因是参数数量少了很多，即使是 10 层的 cross 层参数量也就相当于一个只含有 20 个神经元的单层全连接 <strong>MLP</strong>。如果设定两者的参数量相同的情况下，在我们的数据集上，只使用 cross 层能够比只使用 <strong>MLP</strong> 层高出 $1‰$。但是 cross 层想要把参数量提上来其实很困难，在测试中，cross 层达到 20 层的时候，训练的时长比 4 层增加 $200\%$，并且 loss 在某个 batch 以后突然爆炸（不影响 <strong>AUC</strong> 评估），因此感觉 cross 层还是只能作为一个辅助的子结构使用。一个可以尝试的方法是同时使用 2 ~ 4 层的 cross 层 (5 层相对于 4 层的收益已经很少了)，在顶层进行 concat，最后送到 <strong>LR</strong> 中去。</p>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;note success&quot;&gt;&lt;p&gt;&lt;strong&gt;论文引用:&lt;/strong&gt; Wang, Ruoxi, et al. “Deep &amp;amp; cross network for ad click predictions.” &lt;em&gt;Proceedings of the ADKDD’17&lt;/em&gt;. 2017. 1-7. &lt;/p&gt;&lt;/div&gt;
&lt;p&gt;本文是 Stanford 和 Google 联合发表在 &lt;strong&gt;KDD&lt;/strong&gt; 2017 workshop 上的一篇 &lt;strong&gt;CTR&lt;/strong&gt; 预估模型，模型采用 &lt;strong&gt;Wide&amp;amp;Deep&lt;/strong&gt; 架构，最大的创新点在于将 wide 层替换成 cross 层，省去了原本大量的人工特征工程的工作，由 cross 层提供显式的高阶特征组合能力，同时保持较低的参数量和计算量。&lt;/p&gt;
    
    </summary>
    
      <category term="论文精读" scheme="https://guyuecanhui.github.io/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/"/>
    
    
      <category term="推荐" scheme="https://guyuecanhui.github.io/tags/%E6%8E%A8%E8%8D%90/"/>
    
      <category term="排序" scheme="https://guyuecanhui.github.io/tags/%E6%8E%92%E5%BA%8F/"/>
    
      <category term="特征组合" scheme="https://guyuecanhui.github.io/tags/%E7%89%B9%E5%BE%81%E7%BB%84%E5%90%88/"/>
    
      <category term="特征交叉" scheme="https://guyuecanhui.github.io/tags/%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/"/>
    
  </entry>
  
  <entry>
    <title>AUC 理解与应用</title>
    <link href="https://guyuecanhui.github.io/2020/04/04/auc/"/>
    <id>https://guyuecanhui.github.io/2020/04/04/auc/</id>
    <published>2020-04-04T13:54:19.000Z</published>
    <updated>2020-06-10T13:16:31.518Z</updated>
    
    <content type="html"><![CDATA[<p><strong>AUC</strong> 是一个对分类器预测数值不敏感的指标，具有比较好的稳定性，也因此成为推荐系统中最常用的模型离线指标之一。但是就这个如此常见的指标，很多人对它也只是一知半解，知道该用它，也知道调用函数去计算它，但是对它的计算过程、它还有哪些用处，却知之甚少。这篇文章就再唠叨一下 <strong>AUC</strong> 的概念、计算过程以及它如何应用于特征选择上。</p><a id="more"></a><h2 id="AUC-Area-Under-the-Curve-的概念"><a href="#AUC-Area-Under-the-Curve-的概念" class="headerlink" title="AUC (Area Under the Curve) 的概念"></a>AUC (Area Under the Curve) 的概念</h2><p><strong>AUC</strong>（Area Under Curve）被定义为 <strong>ROC</strong> 曲线下与坐标轴围成的面积。<strong>AUC</strong> 主要用来评估二分类问题的准确率，即随机给定一个正样本和一个负样本，分类器预测该正样本的得分比预测该负样本的得分大的概率。</p><p><strong>AUC</strong> 越接近 1 表明这个分类器的性能越好，随机猜测的 <strong>AUC</strong> 接近 0.5，如果一个分类器的 <strong>AUC</strong> 低于 0.5，只需要将它的结果取反就能一下子提高模型性能。</p><h2 id="AUC-的计算"><a href="#AUC-的计算" class="headerlink" title="AUC 的计算"></a>AUC 的计算</h2><p>根据 <strong>AUC</strong> 的含义，给定样本的真实标签和预测得分，计算分类器的 <strong>AUC</strong> 指标，主要有三种方法：梯形法、穷举法和序数法。</p><h3 id="梯形法-trapezoid-method"><a href="#梯形法-trapezoid-method" class="headerlink" title="梯形法 (trapezoid method)"></a>梯形法 (trapezoid method)</h3><p>梯形法就是先根据真实标签和预测得分，画出 <strong>ROC</strong> 曲线，然后简单地将每个相邻的点以直线连接，计算连线下方的总面积。<strong>ROC</strong> 曲线的详细说明可以参考 wiki，这里给出一个简单的绘制方法：</p><ol><li>计算所有样本中正样本数 <script type="math/tex">n_{pos}</script> 和负样本数 <script type="math/tex">n_{neg}</script>，进一步计算 x 轴的步长为 <script type="math/tex">s_x=\frac{1}{n_{neg}}</script>，y 轴的步长为 <script type="math/tex">s_y=\frac{1}{n_{pos}}</script>；</li><li>初始化 <strong>ROC</strong> 曲线在原点 $(0,0)$；</li><li>将所有样本按预测得分降序排列，然后按顺序进行以下判断并绘制：<ul><li>如果当前样本为正样本，则 <strong>ROC</strong> 曲线沿 y 轴向上移动单位步长 $s_y$；</li><li>如果当前样本为负样本，则 <strong>ROC</strong> 曲线沿 x 轴向右移动单位步长 $s_x$；</li><li>假设有连续 $k$ 个样本预测得分相同，其中有 $k_p$ 个正样本和 $k_n$ 个负样本，则 <strong>ROC</strong> 曲线沿着向量 $(k_n\cdot s_x,k_p\cdot s_y)$ 进行移动；</li></ul></li></ol><p>有了 <strong>ROC</strong> 曲线，我们可以用梯形法计算 <strong>ROC</strong> 曲线下的面积。举个例子：假设有 6 条样本，某个分类器对每个样本的预测得分 <script type="math/tex">\hat{y}</script> 及其真实标签 <script type="math/tex">y</script> 如下表所示：</p><div class="table-container"><table><thead><tr><th style="text-align:center">ID</th><th style="text-align:center">$\hat{y}$</th><th style="text-align:center">$y$</th></tr></thead><tbody><tr><td style="text-align:center">A</td><td style="text-align:center">0.1</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">B</td><td style="text-align:center">0.3</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">C</td><td style="text-align:center">0.5</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">D</td><td style="text-align:center">0.5</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">E</td><td style="text-align:center">0.7</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">F</td><td style="text-align:center">0.9</td><td style="text-align:center">1</td></tr></tbody></table></div><p>则根据上面的 <strong>ROC</strong> 画法，我们计算出步长 $s_x=s_y=\frac{1}{3}$，再通过依次观察 F $\rightarrow$ A 的真实标签，可以画出如下的红色 <strong>ROC</strong> 曲线，并计算出曲线下的面积为：$\frac{1}{3}\times \frac{1}{3}+\frac{1}{2}\times(\frac{1}{3}+\frac{2}{3})\times\frac{1}{3}+\frac{1}{3}=0.61$。</p><img src="/2020/04/04/auc/roc.png" title="图 1. ROC 曲线示例"><h3 id="穷举法"><a href="#穷举法" class="headerlink" title="穷举法"></a>穷举法</h3><p>穷举法就是穷举样本中所有的正负样本对并计数，从而计算这些样本对中正样本预测得分大于负样本预测得分的比例。假设正例集合为 <script type="math/tex">N_{pos}</script>，正例数量为 <script type="math/tex">n_{pos}</script> ；负例集合为 <script type="math/tex">N_{neg}</script>，负例数量为 <script type="math/tex">n_{neg}</script>，则：</p><script type="math/tex; mode=display">AUC = \frac{\sum I(\hat{y}_{pos}, \hat{y}_{neg})}{n_{pos}\cdot n_{neg}}\qquad(1)</script><p>其中，<script type="math/tex">I(.,.)</script> 是指示函数：</p><script type="math/tex; mode=display">I(\hat{y}_{pos}, \hat{y}_{neg})=\begin{cases}1, \qquad &\hat{y}_{pos} > \hat{y}_{neg} \\0.5, \qquad &\hat{y}_{pos} = \hat{y}_{neg} \\0, \qquad &\hat{y}_{pos} < \hat{y}_{neg}\end{cases} \qquad(2)</script><p>例如，在上一小节中的例子中有 3 个正例 (BDF) 和 3 个负例 (ACE)，一共有 $3\times 3=9$ 种组合，每种组合的得分如下：</p><div class="table-container"><table><thead><tr><th style="text-align:center">负正样本对</th><th style="text-align:center">指示函数得分</th></tr></thead><tbody><tr><td style="text-align:center">AB</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">AD</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">AF</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">CB</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">CD</td><td style="text-align:center">0.5</td></tr><tr><td style="text-align:center">CF</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">EB</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">ED</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">EF</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">合计</td><td style="text-align:center">5.5</td></tr></tbody></table></div><p>因此，该分类器的 $AUC=\frac{5.5}{9}=0.61$，是个相当差的分类器了。</p><h3 id="序数法"><a href="#序数法" class="headerlink" title="序数法"></a>序数法</h3><p>穷举法比较适合小数据量情况下的计算，但是其实其中有很多比较是重复的。例如当我们按上例中 $\hat{y}$ 将样本排好序以后，对某个正样本而言，它上面的所有负样本数就是它的得分，没必要再穷举其他的样本对。因此我们考虑将样本排序后，基于样本序数来计算 <strong>AUC</strong>，这里略去推导过程，直接给出计算方法：</p><script type="math/tex; mode=display">AUC=\frac{\sum_{i\in N_{pos}}r_i - \frac{n_{pos}(1+n_{pos})}{2}}{n_{pos}\cdot n_{neg}}\qquad(3)</script><p>其中，$r_i$ 就是按 $\hat{y}$ 排序后，第 $i$ 个样本的序号，如果有多个样本预测得分相同，则这些样本的序号直接求平均。例如对于上面的例子，我们可以对这些样本做如下的编号：</p><div class="table-container"><table><thead><tr><th style="text-align:center">ID</th><th style="text-align:center">$\hat{y}$</th><th style="text-align:center">$y$</th><th style="text-align:center">$r$</th></tr></thead><tbody><tr><td style="text-align:center">A</td><td style="text-align:center">0.1</td><td style="text-align:center">0</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">B</td><td style="text-align:center">0.3</td><td style="text-align:center">1</td><td style="text-align:center">2</td></tr><tr><td style="text-align:center">C</td><td style="text-align:center">0.5</td><td style="text-align:center">0</td><td style="text-align:center">3.5</td></tr><tr><td style="text-align:center">D</td><td style="text-align:center">0.5</td><td style="text-align:center">1</td><td style="text-align:center">3.5</td></tr><tr><td style="text-align:center">E</td><td style="text-align:center">0.7</td><td style="text-align:center">0</td><td style="text-align:center">5</td></tr><tr><td style="text-align:center">F</td><td style="text-align:center">0.9</td><td style="text-align:center">1</td><td style="text-align:center">6</td></tr></tbody></table></div><p>其中，CD 的预测得分相同，因此它们的编号为 $\frac{3+4}{2}=3.5$。根据式 $(3)$ 我们可以算出所有正样本的序数和为 $2+3.5+6=11.5$，$AUC=\frac{11.5-3\times 4\div 2}{3\times 3}=0.61$。</p><h3 id="Group-AUC"><a href="#Group-AUC" class="headerlink" title="Group AUC"></a>Group AUC</h3><p>上面介绍了通常意义下 <strong>AUC</strong> 的计算方法，这个指标实际上是将所有的正负样本放在一起，来衡量模型整体的排序能力。但是在推荐场景下，实际上我们更关心的是<strong>对单个用户而言，推荐结果的相对顺序</strong>，至于不同用户之间是否正样本的得分一定比负样本高，其实影响并不大。</p><p>因此，在某些场景下 <strong>AUC</strong> 可能无法真实的度量模型的排序能力 (比如离线指标相对较高，但是线上指标相对较差)，这时可以考虑尝试使用 <strong>GAUC</strong> 来度量。</p><p><strong>GAUC</strong> 实际上就是按用户进行分组，计算每个用户下样本排序的 <strong>AUC</strong>，再汇总加权得分，计算公式如下：</p><script type="math/tex; mode=display">GAUC=\frac{\sum_{u}w_u \cdot AUC_u}{\sum_{u}w_u}\qquad(4)</script><p>这里的用户权重 <script type="math/tex">w_u</script> 可以设置为该用户的点击数/曝光数。至于每个用户样本的 <script type="math/tex">AUC_u</script> 计算还是参考式 $(1)$ 或式 $(3)$。</p><h2 id="单特征-AUC-的计算"><a href="#单特征-AUC-的计算" class="headerlink" title="单特征 AUC 的计算"></a>单特征 AUC 的计算</h2><p>特征选择中一个重要的技术就是单特征 <strong>AUC</strong> 的计算，它体现了这维特征正确划分样本的能力。单特征 <strong>AUC</strong> 越高，这维特征也就越重要，尤其是在线性模型中。</p><h3 id="单值离散特征的-AUC-计算"><a href="#单值离散特征的-AUC-计算" class="headerlink" title="单值离散特征的 AUC 计算"></a>单值离散特征的 AUC 计算</h3><p>单值离散特征是指特征取值是离散特征，而且每个样本中该特征取值只有一个，例如用户的城市、性别等。我们基于训练数据和测试数据可以使用以下算法高效的计算该特征的 <strong>AUC</strong> (推导过程参考<a href="https://blog.csdn.net/u013019431/article/details/92851053" target="_blank" rel="noopener">这里</a>)：</p><ol><li>计算这维特征的每个特征值在训练数据中的正样本占比；</li><li>在测试数据中，用第 1 步计算的结果作为样本的预测值；</li><li>基于上一小节中的 <strong>AUC</strong> 计算方法计算理论上该特征在 <strong>LR</strong> 下的 <strong>AUC</strong>；</li></ol><p>举个例子，我们考虑性别特征的单值 <strong>AUC</strong> 计算，假设有 10 条样本 (前 6 条作为训练样本，后 4 条作为测试样本)：</p><div class="table-container"><table><thead><tr><th style="text-align:center">ID</th><th style="text-align:center">gender</th><th style="text-align:center">$y$</th><th style="text-align:center">$\hat{y}$</th></tr></thead><tbody><tr><td style="text-align:center">A</td><td style="text-align:center">m</td><td style="text-align:center">0</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">B</td><td style="text-align:center">f</td><td style="text-align:center">1</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">C</td><td style="text-align:center">m</td><td style="text-align:center">1</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">D</td><td style="text-align:center">f</td><td style="text-align:center">0</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">E</td><td style="text-align:center">f</td><td style="text-align:center">1</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">F</td><td style="text-align:center">m</td><td style="text-align:center">0</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">G</td><td style="text-align:center">m</td><td style="text-align:center">1</td><td style="text-align:center">0.33</td></tr><tr><td style="text-align:center">H</td><td style="text-align:center">f</td><td style="text-align:center">1</td><td style="text-align:center">0.67</td></tr><tr><td style="text-align:center">I</td><td style="text-align:center">f</td><td style="text-align:center">1</td><td style="text-align:center">0.67</td></tr><tr><td style="text-align:center">J</td><td style="text-align:center">m</td><td style="text-align:center">0</td><td style="text-align:center">0.33</td></tr></tbody></table></div><p>我们先根据训练样本 A-F 计算性别为 m 的正样本比例为 $0.33$，性别为 f 的正样本比例为 $0.67$，因此我们预测样本 G-J 的得分依次为 $[0.33,0.67,0.67,0.33]$，从而根据式 $(1)$ 可以很快算出来，这维特征的 <strong>AUC</strong> 为 $(0.5+1+1)/3=0.83$。</p><h3 id="多值离散特征的-AUC-评估"><a href="#多值离散特征的-AUC-评估" class="headerlink" title="多值离散特征的 AUC 评估"></a>多值离散特征的 AUC 评估</h3><p>多值离散特征是指特征取值是离散特征，而且每个样本中该特征取值可能有多个，例如视频的标签、演员等。虽然单值离散特征可以高效的计算它的 <strong>AUC</strong>，遗憾的是，多值离散特征的 <strong>AUC</strong> 似乎无法进行类似的推导。因此我们目前还是通过仅使用这一维特征构建训练数据，用于训练 <strong>LR</strong> 模型，再用该 <strong>LR</strong> 模型预测测试数据的得分，用模型的 <strong>AUC</strong> 来作为该特征的 <strong>AUC</strong>。</p><p>实际上，单值离散特征也可以用建模型的方式来评估，我们两种方法都尝试了，结果证明两种方法得到的结果是十分接近的。</p><h3 id="连续特征的-AUC-评估"><a href="#连续特征的-AUC-评估" class="headerlink" title="连续特征的 AUC 评估"></a>连续特征的 AUC 评估</h3><p>连续特征就是指取值是连续值的特征，比如视频的播放次数、播放完成度等。</p><p>有一些特征如年龄，虽然是连续值，但是因为取值有限，既可以作为连续特征，也可以作为离散特征。但是连续特征，尤其是非均匀分布、或者偏序关系不明确的连续特征，对于线性模型是不太友好的，例如我们考虑预测用户是否播放一个恐怖电影，可能年龄大的或者年龄小的用户都不喜欢看，而比较年轻的用户最喜欢，线性模型就难以区分了。</p><p>因此，如果在线性模型中使用连续值特征，除了像播放完成度这类取值范围有限且偏序关系一致 (播放完成度越高，通常表明视频质量越好，用户点击的概率也越大) 的连续特征，我们最好还是按下面的算法来评估某连续特征的单特征 <strong>AUC</strong>：</p><ol><li>在训练数据中使用该连续特征训练 <strong>GBDT</strong> 模型；</li><li>如果第 1 步中使用多棵树，则用第 1 步训练的 <strong>GBDT</strong> 对测试数据中的该连续特征进行分桶，将分桶结果作为新的多值离散特征，并使用多值离散特征的 <strong>AUC</strong> 评估方法进行评估；</li><li>如果第 1 步中使用单棵树，则用第 1 步训练的 <strong>GBDT</strong> 对测试数据中的该连续特征进行分桶，将分桶结果作为新的单值离散特征，并使用单值离散特征的 <strong>AUC</strong> 计算方法进行评估；</li></ol><p>至于使用单棵树还是多棵树，最好参数与模型实际执行的特征变换保持一致。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;AUC&lt;/strong&gt; 是一个对分类器预测数值不敏感的指标，具有比较好的稳定性，也因此成为推荐系统中最常用的模型离线指标之一。但是就这个如此常见的指标，很多人对它也只是一知半解，知道该用它，也知道调用函数去计算它，但是对它的计算过程、它还有哪些用处，却知之甚少。这篇文章就再唠叨一下 &lt;strong&gt;AUC&lt;/strong&gt; 的概念、计算过程以及它如何应用于特征选择上。&lt;/p&gt;
    
    </summary>
    
      <category term="特征工程" scheme="https://guyuecanhui.github.io/categories/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"/>
    
    
      <category term="推荐" scheme="https://guyuecanhui.github.io/tags/%E6%8E%A8%E8%8D%90/"/>
    
      <category term="指标" scheme="https://guyuecanhui.github.io/tags/%E6%8C%87%E6%A0%87/"/>
    
      <category term="AUC" scheme="https://guyuecanhui.github.io/tags/AUC/"/>
    
  </entry>
  
  <entry>
    <title>DICM with AMS 论文精读</title>
    <link href="https://guyuecanhui.github.io/2019/11/24/paper-2018-ali-dicm/"/>
    <id>https://guyuecanhui.github.io/2019/11/24/paper-2018-ali-dicm/</id>
    <published>2019-11-24T13:50:20.000Z</published>
    <updated>2020-06-10T13:44:37.912Z</updated>
    
    <content type="html"><![CDATA[<div class="note success"><p><strong>论文引用:</strong> Ge, Tiezheng , et al. “Image Matters: Visually modeling user behaviors using Advanced Model Server.” (2018). </p></div><p>本文是阿里发表在 <strong>CIKM 2018</strong> 上的文章，主要思路是将用户历史有过行为 (文章实际使用了点击行为) 的图片来对用户视觉兴趣进行建模，在广告 <strong>CTR</strong> 预估时就能够估计用户对广告图片的喜好，从而提升 <strong>CTR</strong> 预估的准确率。由于用户在商品页面行为历史通常较为丰富，因此训练样本中会包含大量的图片特征，这些特征使用传统的 <strong>PS</strong> 架构无法有效训练，因此文章提出了 <strong>AMS</strong> (<em>Advanced Model Server</em>) 架构，能够平衡存储和通信开销，使得天级更新模型成为可能。这篇文章主要的贡献也是在工程实现方面。</p><a id="more"></a><h3 id="背景和动机"><a href="#背景和动机" class="headerlink" title="背景和动机"></a>背景和动机</h3><p>广告 <strong>CTR</strong> 预估是广告系统中至关重要的环节，传统的 (非多模态) 预估模型，主要是使用一些 <strong>ID</strong> 和交叉统计之类的特征，但是由于 <strong>ID</strong> 没有语义，我们无法判断两个 <strong>ID</strong> 是不是有相关性，因此这些模型对于出现频次少或者新出现的 <strong>ID</strong> 无法充分训练，即存在冷启动的问题。</p><p>解决冷启动问题通常会想到引入内容特征，而在电商领域，图片就是能够描述广告/商品的最直观且最受用户关注的内容特征。用户在购买商品的时候，通常会点击、浏览商品的图片，结合商品的描述、评论等其他信息来决定是否购买，因此用户曾经点击过的图片能够在很大程度上表征用户的兴趣。而用户是否点击广告，图片、标题等信息是影响最大的因素。因此，文章就考虑使用用户点击过的图片来建立用户的兴趣模型，再与广告的图片进行匹配，从而估计用户在视觉层面是否对该广告有兴趣；将这方面的估计与传统的基于 <strong>ID</strong> 等特征的估计相结合，来提升 <strong>CTR</strong> 估计的性能。基于这个思路，文章提出了 <strong>DICM</strong> (<em>Deep Image CTR Model</em>)。 </p><p>使用用户图片历史来建立用户视觉偏好主要的问题就是数据传输和存储，如果使用传统的 <strong>PS</strong> 架构，图片数据是保存在 <strong>KV Store</strong> 里（也就是参数服务器），谁用谁来查一下，而图片的数量和数据量都是相对较大的，因此这种方式十分消耗资源，并且这种方式也难以针对 <strong>CTR</strong> 预估任务对预训练的图片特征进行进一步的组合和压缩，即图片数据不是目标相关的。文章针对这个问题，提出了一种扩展 <strong>PS</strong> 架构，称为 <strong>AMS</strong> 架构。下面就详细的介绍这两方面的工作。</p><h3 id="AMS-架构"><a href="#AMS-架构" class="headerlink" title="AMS 架构"></a>AMS 架构</h3><p>如上所述，文章在实现 <strong>DICM</strong> 模型时，实际上是基于 <strong>AMS</strong> 架构的。<strong>AMS</strong> 架构整体如图 1 右图所示：</p><img src="/2019/11/24/paper-2018-ali-dicm/ams-architecture.png" title="图 1. AMS 架构及基于 AMS 架构实现的 DICM 模型"><p><strong>AMS</strong> 将节点分为 <strong>Worker</strong> 和 <strong>Server</strong> 组：</p><ul><li><strong>Server 组</strong>：保存图片原始特征数据（考虑到端到端训练和推理的时延，这里取的是预训练模型的低阶隐层输出），并且负责将图片原始特征数据映射到任务空间的高阶表达，实际上就是学一个 Tower 模型，这个 Tower 模型是所有 Server 共享的。使用这个图片 <strong>EmbedTower</strong>，可以将图片原始特征数据极大的压缩（文章使用 $4096\times 256\times 64\times 12$ 的 Tower，可以将数据量减少 340 多倍），Worker 查询的时候传输数据量就大大减少了。</li><li><strong>Worker 组</strong>：从 <strong>Server 组</strong>查询样本的各维特征（包括 <strong>ID</strong> embedding 和图片的高阶 embedding 等），将特征组合后进行推理；训练时还要将损失梯度传回 Server，用来更新图片 <strong>EmbedTower</strong>。</li></ul><p>这样分与传统 <strong>PS</strong> 架构最大的差别就在于，<strong>Server 组</strong>内的节点也是有通信的，也是需要更新模型的了 (更详细的比较可以参考文献 [1]，说的很清楚)。好处是，当图片的数据量非常大的时候：</p><ol><li>每个图片原始特征只保存在单个 Server 上，节约了存储；</li><li>每个图片的 embedding 只需要计算一次，而且可以通过预计算，缓存以后供多个 Worker 查询；</li><li>压缩后的图片 embedding 数据量小，减小了数据传输消耗；</li></ol><p>文章号称在他们的场景下能节省 31 倍的存储开销和 340 倍的传输开销，而推理的时延仅仅增加了 3 毫秒。不过大家在各自具体场景中可能需要权衡一下性价比。</p><h3 id="DICM-模型"><a href="#DICM-模型" class="headerlink" title="DICM 模型"></a>DICM 模型</h3><p>从图 1 左图来看，<strong>DICM</strong> 模型整体就是一个简单的 Embedding + MLP 架构。其中，最关键的部分实际上就是用户视觉偏好抽取的部分（后面简称为 <strong>VisualPrefExtractor</strong>），也就是图片 <strong>EmbedTower</strong> 和基于用户图片历史和当前广告图片生成兴趣特征向量的部分。</p><p><strong>EmbedTower</strong> 前面简单介绍过了，这里需要说明的是，文章在保存图片原始特征的时候，并不是使用原始的像素值，而是经过预训练的 <strong>VGG16</strong> 第 14 层的 <strong>FC-4096</strong> 作为原始特征（如图 2 所示）。虽然 <strong>VGG16</strong> 的训练目标是图像分类的任务，但是这种任务学到的语义特征有比较好的泛化性能，而且由于是逐层处理，取靠前的参数实际上使用的是图像的一些基础元素的特征，这些特征再进一步通过广告 <strong>CTR</strong> 预估任务进行训练，这样就能够得到有用的高阶特征。文章也尝试了使用其他层的输出作为图片的原始特征：太靠近输出会损失性能；而越靠近输入端，参数越多，并且边际效益递减，因此这也只是一种权衡。另外，淘宝主要是买商品，使用 <strong>ImageNet</strong> 的预训练模型可能比较契合，我们在视频场景下就会发现，<strong>VGG16</strong> 对于人物的识别权重很低，因此可能又不太适用。</p><img src="/2019/11/24/paper-2018-ali-dicm/vgg16.png" title="图 2. 使用配置 D (VGG16) 中第 1 个 FC-4096 作为图片的原始特征，该配置参考文献 [2]"><p>而为了抽取用户的视觉偏好，我们需要从用户图片历史序列中抽取出有效的特征。在用户行为非常丰富的场景，比如淘宝，用户的兴趣是多元化的，用户是不是点击某件 T-恤的广告，主要取决他历史上对衣服款式的喜好，而受他买零食、饮料、矿泉水的影响较小，因此需要引入注意力机制来针对不同的广告从用户图片历史中抽取出不同的特征表达。</p><img src="/2019/11/24/paper-2018-ali-dicm/attentive-pooling.png" title="图 3. 几种 Pooling 方式的比较，文章使用 (d) 所示的 AttentivePooling"><p>文章使用的注意力机制还是比较简单的，如图 3 右图所示，就是将广告图片特征和用户每条历史图片特征拼接后，经过一个 $64\times 16\times 1$ 的 Tower，用来计算每条历史图片的权重，然后再加权对所有历史图片特征计算 sum pooling，得到用户视觉偏好表达。这里的广告图片特征和用户历史图片特征都是经过 <strong>EmbedTower</strong> 映射后的高阶表达。为了增强记忆能力，文章还使用了 <strong>ID</strong> 行为列表来做相似的处理，将得到的 embedding 与图像偏好的 embedding 拼接，即实现了 <strong>MultiQueryAttentivePooling</strong>，两者互为补充，效果得到进一步提升。</p><p>这种方式很容易扩展，比如可以简单的添加 <strong>TextPrefExtractor</strong>、<strong>AudioPrefExtractor</strong> 等其他多模态的偏好模型，而且由于这些多模态数据不与其他特征进行交叉，因此训练与推理都是相对独立的。<strong>VisualPrefExtractor</strong> 也可以作为子模型嵌入到双塔结构里做召回，或者嵌入其他复杂排序模型，如 <strong>DIN</strong> 等，作为特征抽取器。</p><p>根据这篇文章的说明，该模型至少在当时是承接了淘宝的主流量，因此在多模态方面还是十分值得借鉴的。</p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] 一图胜千言: 解读阿里的Deep Image CTR Model. <a href="https://zhuanlan.zhihu.com/p/57056588" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/57056588</a>.</p><p>[2] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556 (2014).</p>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;note success&quot;&gt;&lt;p&gt;&lt;strong&gt;论文引用:&lt;/strong&gt; Ge, Tiezheng , et al. “Image Matters: Visually modeling user behaviors using Advanced Model Server.” (2018). &lt;/p&gt;&lt;/div&gt;
&lt;p&gt;本文是阿里发表在 &lt;strong&gt;CIKM 2018&lt;/strong&gt; 上的文章，主要思路是将用户历史有过行为 (文章实际使用了点击行为) 的图片来对用户视觉兴趣进行建模，在广告 &lt;strong&gt;CTR&lt;/strong&gt; 预估时就能够估计用户对广告图片的喜好，从而提升 &lt;strong&gt;CTR&lt;/strong&gt; 预估的准确率。由于用户在商品页面行为历史通常较为丰富，因此训练样本中会包含大量的图片特征，这些特征使用传统的 &lt;strong&gt;PS&lt;/strong&gt; 架构无法有效训练，因此文章提出了 &lt;strong&gt;AMS&lt;/strong&gt; (&lt;em&gt;Advanced Model Server&lt;/em&gt;) 架构，能够平衡存储和通信开销，使得天级更新模型成为可能。这篇文章主要的贡献也是在工程实现方面。&lt;/p&gt;
    
    </summary>
    
      <category term="论文精读" scheme="https://guyuecanhui.github.io/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/"/>
    
    
      <category term="推荐" scheme="https://guyuecanhui.github.io/tags/%E6%8E%A8%E8%8D%90/"/>
    
      <category term="排序" scheme="https://guyuecanhui.github.io/tags/%E6%8E%92%E5%BA%8F/"/>
    
      <category term="多模态" scheme="https://guyuecanhui.github.io/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/"/>
    
      <category term="预排序" scheme="https://guyuecanhui.github.io/tags/%E9%A2%84%E6%8E%92%E5%BA%8F/"/>
    
      <category term="图片" scheme="https://guyuecanhui.github.io/tags/%E5%9B%BE%E7%89%87/"/>
    
      <category term="分布式" scheme="https://guyuecanhui.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="注意力" scheme="https://guyuecanhui.github.io/tags/%E6%B3%A8%E6%84%8F%E5%8A%9B/"/>
    
  </entry>
  
  <entry>
    <title>MMoE-PosBias 论文精读</title>
    <link href="https://guyuecanhui.github.io/2019/11/16/paper-2019-google-mmoe-bias/"/>
    <id>https://guyuecanhui.github.io/2019/11/16/paper-2019-google-mmoe-bias/</id>
    <published>2019-11-16T14:19:16.000Z</published>
    <updated>2020-06-10T13:46:31.045Z</updated>
    
    <content type="html"><![CDATA[<div class="note success"><p><strong>论文引用:</strong> “Recommending what video to watch next: a multitask ranking system.” <em>Proceedings of the 13th ACM Conference on Recommender Systems</em>. ACM, 2019.  </p></div><p>本文是 Youtube 发表在 <strong>RecSys</strong> <strong>2019</strong> 上的文章，主要解决的问题是提升用户的总体满意度，同时减少推荐造成的用户选择偏差对推荐系统的影响。解决这些问题主要的挑战在于：</p><ol><li><strong>视频推荐中包含多个可能互相冲突的目标，难以权衡</strong>。视频推荐的目标大体可以分为 <strong>engagement objectives</strong> (例如点击、播放等)、<strong>satistaction objective</strong> (例如点赞、收藏、不喜欢等)，这两类目标可能有冲突，例如用户点赞的视频可能是他比较喜欢的严肃的视频，但是用户真正播放的视频可能是一些娱乐性比较强的。</li><li><strong>推荐系统会引入一些隐式的偏差，尤其是推荐位置导致的用户选择偏差</strong>。用户往往倾向于点位置靠前的视频，而这些视频可能并不是用户真实喜欢的视频。如果推荐模型使用带偏差的用户行为日志进行训练，会进一步强化这种偏差，导致恶性循环。</li><li><strong>多模态特征</strong>。多模态特征包括语音、视频 、图像、文本、ID 类特征、连续型特征等。使用多模态的特征有助于信息互补，例如我们希望对低层次内容特征进行映射来跨越语义鸿沟、用于基于内容的过滤；同时将稀疏分布的 ID 类特征用于协同过滤等。</li><li><strong>可扩展性</strong>。模型需要考虑线下训练和线上服务的性能，因此在保证学习效果的情况下，尽可能使用简单易扩展的网络架构。</li></ol><a id="more"></a><p>为了应对这些挑战，文章提出了如下图所示的排序网络架构。该网络接收用户当前播放的视频信息和上下文信息，对数百个召回视频进行排序。这里的召回需要是从不同的角度进行召回，例如基于内容相似的召回、基于协同过滤的召回等，文章使用了 <strong>Deep Candidate Generation</strong> 模型$^{[1]}$等来生成召回。</p><img src="/2019/11/16/paper-2019-google-mmoe-bias/overview.png" title="MMoE with PosBias 整体架构"><p>排序的整体架构服从 <strong>Wide &amp; Deep</strong> 架构，如上图所示。其中，左边的 <strong>wide</strong> 层是一个浅层的 <strong>tower</strong> 网络，用于学习选择偏差，这个偏差在上层会与 <strong>user engagement</strong> 的输出相加，用于抵消选择偏差；右边的 <strong>deep</strong> 层是一个 <strong>MMoE</strong> 的多目标网络（<strong>MMoE</strong> 的解读可以参考 [2]），用于从不同模态特征中学习不同的专家网络，并学习多个 <strong>Gate</strong> 来对多个目标进行预测，最后再对多个目标进行权衡，这里不同的目标使用不同的损失函数，对于目标是连续值的，使用 <strong>MSE</strong> 进行回归，对于目标是离散值的，使用 <strong>logLoss</strong> 进行分类，最终多个目标的结果使用线性加权的方式计算出最终的得分，权重目标是作者手调的。从训练和预测的工程效率角度出发，文章选择了最简单的 <strong>point-wise ranking</strong> 方案。</p><img src="/2019/11/16/paper-2019-google-mmoe-bias/mmoe.png" title="MMoE 架构拆解"><p>多目标的深度网络是整体架构的主要核心，文章先将所有原始的输入压缩成了一个共享的隐含层，再基于该隐含层构建了 <strong>MMoE</strong> 的网络，基于这些网络再进一步学习多个目标。其中：</p><ol><li><p>隐含层的设置主要是为了提高训练的效率。直接用原始特征来训练 <strong>MMoE</strong> 网络可能对多模态特征的学习更有利，但是由于原始特征的维度过高，直接基于原始特征进行训练代价过高。在学习 <strong>Gate</strong> 的时候，作者也尝试过直接用原始特征作为输入，但是比用共享隐含层作为输入没有显著提升。</p></li><li><p>使用 <strong>MoE</strong> 层比使用 <strong>shared-bottom</strong> 策略更有助于学习多模态特征，文章使用了少量的 <strong>Expert</strong> 网络，这样可以在不同的 <strong>Gate</strong> 中充分共享 <strong>Expert</strong> 网络参数，并且工程上效率更高。</p></li><li><p>每个目标使用一个 <strong>Gate</strong> 来对原始特征和专家网络进行激活，每个 task 预测结果的变换函数如下：</p><script type="math/tex; mode=display">\begin{cases}y_k=h^k(f^k(x)) \\f^k(x)=\sum_{i=1}^n g_i^k(x)\cdot f_i(x) \\g^k(x) = \text{softmax}(W_{g^k}\cdot x)\end{cases}</script><p>其中，<script type="math/tex">x</script> 为共享隐含层，<script type="math/tex">f_i(x)</script> 为第 $i$ 个专家网络的输出，$n$ 为专家网络的个数，<script type="math/tex">W_{g^k}</script> 为第 $k$ 个 <strong>Gate</strong> 的网络参数，<script type="math/tex">h^k(x)</script> 为第 $k$ 个目标的隐含层。</p></li></ol><img src="/2019/11/16/paper-2019-google-mmoe-bias/bias.png" title="PosBias 架构拆解"><p>为了减少由于推荐产生的用户选择偏差，文章又增加了一个浅层网络，如上图所示，输入是与偏差相关的特征（简称偏差特征），主要包括物品展示的位置特征和用户的设备信息。学习的时候，为了减少过位置的过分依赖，对所有偏差特征扫行 10% 的 <strong>dropout</strong>。</p><p>学习选择偏差的其他策略包括：直接把偏差特征作为输入的一部分进行训练，这种方式主要用于线性网络，在深度网络里效果不好；使用 <strong>Adversarial Learning</strong>，即将位置作为一个辅助的学习目标来预测。文章的实验结果也表明还是使用浅层网络的效果最好，直接将偏差特征作为输入的效果还不如不加偏差特征。</p><p>以上关于模型的部分其实简洁明了，没有太多的花招。但是特征层就难以企及了，而且在工程效率上必然也是困难重重，文章中工程的部分以后在应用的时候可能还需要再细细品读。</p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ol><li>Covington, Paul , J. Adams , and E. Sargin . “<strong>Deep Neural Networks for YouTube Recommendations.</strong>“ <em>Acm Conference on Recommender Systems</em> ACM, 2016:191-198.</li><li><strong>MMoE 论文精读</strong>. <a href="https://guyuecanhui.github.io/2019/11/16/paper-2018-google-mmoe/">https://guyuecanhui.github.io/2019/11/16/paper-2018-google-mmoe/</a>.</li><li><strong>YouTube 多目标排序系统：如何推荐接下来收看的视频</strong>. <a href="https://www.infoq.cn/article/cZNdKS5ssPiqhjCyKQZ6" target="_blank" rel="noopener">https://www.infoq.cn/article/cZNdKS5ssPiqhjCyKQZ6</a>.</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;note success&quot;&gt;&lt;p&gt;&lt;strong&gt;论文引用:&lt;/strong&gt; “Recommending what video to watch next: a multitask ranking system.” &lt;em&gt;Proceedings of the 13th ACM Conference on Recommender Systems&lt;/em&gt;. ACM, 2019.  &lt;/p&gt;&lt;/div&gt;
&lt;p&gt;本文是 Youtube 发表在 &lt;strong&gt;RecSys&lt;/strong&gt; &lt;strong&gt;2019&lt;/strong&gt; 上的文章，主要解决的问题是提升用户的总体满意度，同时减少推荐造成的用户选择偏差对推荐系统的影响。解决这些问题主要的挑战在于：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;视频推荐中包含多个可能互相冲突的目标，难以权衡&lt;/strong&gt;。视频推荐的目标大体可以分为 &lt;strong&gt;engagement objectives&lt;/strong&gt; (例如点击、播放等)、&lt;strong&gt;satistaction objective&lt;/strong&gt; (例如点赞、收藏、不喜欢等)，这两类目标可能有冲突，例如用户点赞的视频可能是他比较喜欢的严肃的视频，但是用户真正播放的视频可能是一些娱乐性比较强的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;推荐系统会引入一些隐式的偏差，尤其是推荐位置导致的用户选择偏差&lt;/strong&gt;。用户往往倾向于点位置靠前的视频，而这些视频可能并不是用户真实喜欢的视频。如果推荐模型使用带偏差的用户行为日志进行训练，会进一步强化这种偏差，导致恶性循环。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多模态特征&lt;/strong&gt;。多模态特征包括语音、视频 、图像、文本、ID 类特征、连续型特征等。使用多模态的特征有助于信息互补，例如我们希望对低层次内容特征进行映射来跨越语义鸿沟、用于基于内容的过滤；同时将稀疏分布的 ID 类特征用于协同过滤等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可扩展性&lt;/strong&gt;。模型需要考虑线下训练和线上服务的性能，因此在保证学习效果的情况下，尽可能使用简单易扩展的网络架构。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="论文精读" scheme="https://guyuecanhui.github.io/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/"/>
    
    
      <category term="推荐" scheme="https://guyuecanhui.github.io/tags/%E6%8E%A8%E8%8D%90/"/>
    
      <category term="排序" scheme="https://guyuecanhui.github.io/tags/%E6%8E%92%E5%BA%8F/"/>
    
      <category term="多任务" scheme="https://guyuecanhui.github.io/tags/%E5%A4%9A%E4%BB%BB%E5%8A%A1/"/>
    
      <category term="MoE" scheme="https://guyuecanhui.github.io/tags/MoE/"/>
    
      <category term="选择偏差" scheme="https://guyuecanhui.github.io/tags/%E9%80%89%E6%8B%A9%E5%81%8F%E5%B7%AE/"/>
    
  </entry>
  
  <entry>
    <title>MMoE 论文精读</title>
    <link href="https://guyuecanhui.github.io/2019/11/16/paper-2018-google-mmoe/"/>
    <id>https://guyuecanhui.github.io/2019/11/16/paper-2018-google-mmoe/</id>
    <published>2019-11-16T01:42:59.000Z</published>
    <updated>2020-06-10T13:45:37.513Z</updated>
    
    <content type="html"><![CDATA[<div class="note success"><p><strong>论文引用:</strong> Ma, Jiaqi , et al. “Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts.” <em>the 24th ACM SIGKDD International Conference</em> ACM, 2018. </p></div><p>本文是 Google 发表在 <strong>KDD 2018</strong> 的论文，不过感觉少了一些工程的加持，内容略显单薄。文章主要提出了一种多专家子网的结构，显式的从数据中学习多个任务之间的关系，并能够通过门限网络对每个任务进行单独的优化。与传统的 <strong>share-bottom</strong> 结构相比，这种结构在任务之间关联较弱时，仍然能够取得比较好的效果。</p><a id="more"></a><p>近年来，在推荐领域逐渐引入多任务学习来减轻一些使用单个模型指标可能带来的负面影响。例如在视频推荐中，只考虑点击转化率时，会倾向推荐包含标题党、擦边海报的视频；只考虑完成度时，会倾向推荐时间比较短的视频等等。而这些倾向都会影响用户体验，并且可能导致业务长期目标的下降。因此，大家开始尝试引入多个相互关联但又不一致的目标来进行综合考虑建模，并且实践表示，多任务学习在推荐系统中能够提升上下文推荐的效果。</p><p>传统的基于神经网络的多任务学习大致分为两类，一共是底层参数共享，即共享输入到中间层的参数，上层再分别对各个任务建模；一类是参数软共享，并不显式的共享底层参数，而是通过正则等对多个任务的参数进行相互约束。目前看到的比较多的是第一种，如下图 (a) 所示。而这种方式一般都假设多个任务的数据分布和目标都是相似的，当任务间差异变大时，对某些任务的预测性能就会产生较大的影响。然而实际任务的相关性都是难以度量的，因此效果实际上无法事先评估，只能靠不断尝试。</p><img src="/2019/11/16/paper-2018-google-mmoe/mmoe.png" title="MMOE 架构比较"><p>本文的作者受到 <strong>MoE</strong> 网络$^{[1]}$的启发，在多任务学习中引入 <strong>MoE</strong> 层，来显式的对多个任务的关系进行建模，或者理解成学习所有任务的不同方面；再对每个任务学习一个门限网络，这个门限网络可以理解成这个任务在各个方面的特点。整体结构如上图 (c) 所示。其中，每个共享的子网称为一个 <strong>Expert</strong>，文章中的 <strong>Expert</strong> 都使用前馈网络，它的输入是原始特征（也可以是一个共享的隐含层，直接使用原始特征效果会更好，但是维度可能过高），输出为各个 <strong>Gate</strong> 的权重分布（<strong>softmax</strong>），可以理解成是这个 <strong>Expert</strong> 对不同任务的影响程度。研究已经表明在 <strong>DNN</strong> 中，使用这种集成模型和集成子网络的方式有助于提高模型的性能。</p><p>文章在公开数据集和 Google 数据上进行了大量的对比实验，结果表明：</p><ol><li><strong>MMoE</strong> 在任务相关性变弱的情况下，性能影响较小，因此实用性也更强；</li><li><strong>MMoE</strong> 的训练误差收敛更快更稳定，即可训练性更好；这也与近年研究得出的结论一致，即 <em>Modulation and gating mechanisms can improve the trainability in training non-convex deep nurual networks</em>。</li></ol><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ol><li>Jacobs, Robert A. , et al. “<strong>Adaptive Mixtures of Local Experts.</strong>“ <em>Neural Computation</em> 3.1(1991):79-87.</li><li><strong>keras-mmoe</strong>: <a href="https://github.com/drawbridge/keras-mmoe" target="_blank" rel="noopener">https://github.com/drawbridge/keras-mmoe</a>.</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;note success&quot;&gt;&lt;p&gt;&lt;strong&gt;论文引用:&lt;/strong&gt; Ma, Jiaqi , et al. “Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts.” &lt;em&gt;the 24th ACM SIGKDD International Conference&lt;/em&gt; ACM, 2018. &lt;/p&gt;&lt;/div&gt;
&lt;p&gt;本文是 Google 发表在 &lt;strong&gt;KDD 2018&lt;/strong&gt; 的论文，不过感觉少了一些工程的加持，内容略显单薄。文章主要提出了一种多专家子网的结构，显式的从数据中学习多个任务之间的关系，并能够通过门限网络对每个任务进行单独的优化。与传统的 &lt;strong&gt;share-bottom&lt;/strong&gt; 结构相比，这种结构在任务之间关联较弱时，仍然能够取得比较好的效果。&lt;/p&gt;
    
    </summary>
    
      <category term="论文精读" scheme="https://guyuecanhui.github.io/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/"/>
    
    
      <category term="推荐" scheme="https://guyuecanhui.github.io/tags/%E6%8E%A8%E8%8D%90/"/>
    
      <category term="排序" scheme="https://guyuecanhui.github.io/tags/%E6%8E%92%E5%BA%8F/"/>
    
      <category term="多任务" scheme="https://guyuecanhui.github.io/tags/%E5%A4%9A%E4%BB%BB%E5%8A%A1/"/>
    
      <category term="MoE" scheme="https://guyuecanhui.github.io/tags/MoE/"/>
    
  </entry>
  
  <entry>
    <title>ESMM 论文精读</title>
    <link href="https://guyuecanhui.github.io/2019/11/09/paper-2018-ali-esmm/"/>
    <id>https://guyuecanhui.github.io/2019/11/09/paper-2018-ali-esmm/</id>
    <published>2019-11-09T12:16:34.000Z</published>
    <updated>2020-06-10T13:44:59.463Z</updated>
    
    <content type="html"><![CDATA[<div class="note success"><p><strong>论文引用:</strong> Ma, Xiao, et al. “Entire space multi-task model: An effective approach for estimating post-click conversion rate.” The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval. ACM, 2018. </p></div><p>本文是阿里发表在 <strong>SIGIR 2018</strong> 年的短文，主要解决了精确预估 <strong>CVR</strong> 的问题。</p><a id="more"></a><p><strong>CVR</strong> 预估是最大化场景商品交易总额 (<strong>GMV</strong>=<code>流量×点击率×转化率×客单价</code>) 的重要因子，它可以用于 <strong>OCPC</strong> 模式下动态调整出价来使平台和广告主共同受益；并且从用户体验的角度来说，准确预估的 <strong>CVR</strong> 被用来平衡用户的点击偏好与购买偏好。文章认为当前的 <strong>CVR</strong> 预估主要存在两个问题：</p><ol><li><strong>Sample Selection Bias (SSB)</strong>：当前 <strong>CVR</strong> 预估是基于 <code>点击-&gt;转化</code> 数据进行训练的，而有点击的展示数据只是所有展示数据中的一小部分 (如下图所示)，这部分数据的分布与整体的分布通常并不一致。而在实际 serving 的时候，模型又是对整个空间中的所有样本进行预测，因此模型的泛化效果会受到影响。</li><li><strong>Data Sparsity (DS)</strong>：与前一个问题的根因相同，只使用点击数据会存在严重的数据稀疏问题。</li></ol><img src="/2019/11/09/paper-2018-ali-esmm/esmm-ssb.png" title="用户展示-点击-转化行为关系示意"><p>业界也提出过一些解决这两个问题的方案：</p><ol><li><strong>SSB Solution</strong>：<strong>AMAN 方法</strong> 将所有展示未点击的数据也作为负样本进行训练，但是这种方法天然会导致 CVR 被低估 (因为对于一些展示未点击的物品，可能是因为用户并没有关注到，或者用户已经点击了其他的条目而遗漏，并非是真正不会产生转化的物品)；<strong>无偏估计方法</strong> 通过拒绝采样的方法来保证预估的 CVR 与真实的观察一致，但是这种方法在计算过程中会除以一个很小的数，因此可能导致数值不稳定的问题。</li><li><strong>DS Solution</strong>：<strong>分层建模方法</strong>使用不同的特征构建多个预估模型，然后使用 <strong>LR</strong> 等模型将这些模型的结果汇总，这种方法需要比较可靠的先验知识来构建分层模型，在数据量大的推荐场景下难以实现；<strong>过采样方法</strong>将数据量少的类别样本进行过采样，但是对采样参数十分敏感。</li></ol><p>文章在已有工作的基础上，提出使用多任务学习的框架，使用所有 <code>展示-&gt;点击-&gt;转化</code> 数据进行训练，将 <strong>CVR</strong> 预测问题转变为同时预测 <strong>CTR</strong> 和 <strong>CTCVR</strong> 的问题。由于使用所有展示样本，因此不存在 <strong>SSB</strong> 问题；在多任务学习下共享 embedding 向量，实际上是一种参数迁移学习，可以有效的解决 <strong>DS</strong> 问题。</p><p>具体来讲，将一个样本记为 $(\boldsymbol{x},y\rightarrow z)$，其中，$\boldsymbol{x}$ 表示样本特征，$y$ 表示是否点击，$z$ 表示是否转化。则：</p><script type="math/tex; mode=display">\begin{cases}pCTCVR = p(z=1,y=1|\boldsymbol{x}) = pCTR\times pCVR \\pCTR = p(y=1|\boldsymbol{x})\\pCVR = p(z=1|\boldsymbol{x},y=1)\end{cases}</script><p>由于这三个变量的自由度为 2，因此损失函数只需要计算其中两个即可。文章将损失函数设计为 <strong>CTR</strong> 和 <strong>CTCVR</strong> 的预测损失，如下所示：</p><script type="math/tex; mode=display">L(\theta_{cvr},\theta_{ctr}) = \sum_{i=1}^N l(y_i, f(\boldsymbol{x}_i;\theta_{ctr})) + \sum_{i=1}^N l(y_i\&z_i, f(\boldsymbol{x}_i;\theta_{ctr})\times f(\boldsymbol{x}_i;\theta_{cvr}))</script><p>整体网络架构如下图所示：</p><img src="/2019/11/09/paper-2018-ali-esmm/esmm-architect.png" title="ESMM 网络整体架构"><p>可以看到，两个任务共享底层 embedding，同时通过顶层的 <strong>Dot</strong> 算子进行关联。文章没有将 <strong>pCVR</strong> 作为最终输出的结果，是因为 $pCVR = \frac{pCTCVR}{pCTR}$，如果将 <strong>pCVR</strong> 作为最终输出，则最后一步为除法算子，而除法具有数值不稳定性，可能会得出 $pCVR&gt;1$ 的情况，因此将 <strong>pCTCVR</strong> 作为最终输出的结果，这样能够保证 <strong>pCVR</strong> 的结果在 $[0,1]$ 范围内，避免了数值不稳定的问题。</p><p>文章在淘宝数据上与现有解决 <strong>SSB</strong> 和 <strong>DS</strong> 问题的几个策略进行了对比验证，发现基于 <strong>ESSM</strong> 模型的 <strong>CVR</strong> 和 <strong>CTCVR</strong> 预估任务的 <strong>AUC</strong> 是最高的。而且文章还发表了一个 mini 公开数据集，诚意满满~</p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ol><li><strong>XDL ESSM</strong>: <a href="https://github.com/alibaba/x-deeplearning/tree/master/xdl-algorithm-solution/ESMM" target="_blank" rel="noopener">https://github.com/alibaba/x-deeplearning/tree/master/xdl-algorithm-solution/ESMM</a></li><li><strong>完整空间多任务模型：CVR预估的有效方法</strong>: <a href="http://xudongyang.coding.me/esmm/" target="_blank" rel="noopener">http://xudongyang.coding.me/esmm/</a></li><li><strong>构建分布式Tensorflow模型系列之CVR预估案例ESMM模型</strong>: <a href="http://xudongyang.coding.me/esmm-1/" target="_blank" rel="noopener">http://xudongyang.coding.me/esmm-1/</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;note success&quot;&gt;&lt;p&gt;&lt;strong&gt;论文引用:&lt;/strong&gt; Ma, Xiao, et al. “Entire space multi-task model: An effective approach for estimating post-click conversion rate.” The 41st International ACM SIGIR Conference on Research &amp;amp; Development in Information Retrieval. ACM, 2018. &lt;/p&gt;&lt;/div&gt;
&lt;p&gt;本文是阿里发表在 &lt;strong&gt;SIGIR 2018&lt;/strong&gt; 年的短文，主要解决了精确预估 &lt;strong&gt;CVR&lt;/strong&gt; 的问题。&lt;/p&gt;
    
    </summary>
    
      <category term="论文精读" scheme="https://guyuecanhui.github.io/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/"/>
    
    
      <category term="推荐" scheme="https://guyuecanhui.github.io/tags/%E6%8E%A8%E8%8D%90/"/>
    
      <category term="排序" scheme="https://guyuecanhui.github.io/tags/%E6%8E%92%E5%BA%8F/"/>
    
      <category term="多任务" scheme="https://guyuecanhui.github.io/tags/%E5%A4%9A%E4%BB%BB%E5%8A%A1/"/>
    
      <category term="样本偏差" scheme="https://guyuecanhui.github.io/tags/%E6%A0%B7%E6%9C%AC%E5%81%8F%E5%B7%AE/"/>
    
      <category term="数据稀疏" scheme="https://guyuecanhui.github.io/tags/%E6%95%B0%E6%8D%AE%E7%A8%80%E7%96%8F/"/>
    
  </entry>
  
  <entry>
    <title>效率提升 10 倍的各种配置</title>
    <link href="https://guyuecanhui.github.io/2019/08/28/jupyter-config/"/>
    <id>https://guyuecanhui.github.io/2019/08/28/jupyter-config/</id>
    <published>2019-08-28T14:36:04.000Z</published>
    <updated>2020-06-10T13:17:42.028Z</updated>
    
    <content type="html"><![CDATA[<p>由于工作经常会更换机器、更换环境，有时候一个机器用惯了，换了一台机器都不记得自己之前是怎么配置的了。为了防止老年痴呆阻止我配置好看的工作环境，我决定把所有喜欢的配置都记录在这里，可能有点乱。</p><a id="more"></a><h3 id="Jupyter-Notebook"><a href="#Jupyter-Notebook" class="headerlink" title="Jupyter Notebook"></a>Jupyter Notebook</h3><p>这个应该很常用了，大家第一件事应该就是设置主题吧，我试过各种主题，都无法满足我的诉求，所以就自己配置了一下 <code>~/.jupyter/custom/custom.css</code>，感觉下面这个配置简单又好看~</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-class">.introspection</span>, <span class="selector-class">.input_prompt</span>, <span class="selector-class">.output_prompt</span>, <span class="selector-class">.output</span>, <span class="selector-class">.CodeMirror</span> <span class="selector-tag">pre</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">"Microsoft YaHei Mono"</span>, Consolas, <span class="string">"Liberation Mono"</span>, Menlo, Courier, monospace;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">15px</span>;</span><br><span class="line">    <span class="attribute">line-height</span>: <span class="number">22px</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">div</span><span class="selector-class">.output_area</span> <span class="selector-tag">pre</span> &#123;</span><br><span class="line"> <span class="attribute">font-family</span>: <span class="string">"Microsoft YaHei Mono"</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">div</span><span class="selector-class">.text_cell</span>,</span><br><span class="line"><span class="selector-tag">div</span><span class="selector-class">.text_cell_render</span> <span class="selector-tag">pre</span>,</span><br><span class="line"><span class="selector-tag">div</span><span class="selector-class">.text_cell_render</span> &#123;</span><br><span class="line"> <span class="attribute">font-family</span>: sans-serif;</span><br><span class="line"> <span class="attribute">font-size</span>: <span class="number">11pt</span>;</span><br><span class="line"> <span class="attribute">line-height</span>: <span class="number">20pt</span>;</span><br><span class="line"> <span class="attribute">color</span>: <span class="number">#353535</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">div</span><span class="selector-class">.rendered_html</span> <span class="selector-tag">code</span> &#123;</span><br><span class="line"> <span class="attribute">font-family</span>: <span class="string">"Microsoft YaHei Mono"</span>;</span><br><span class="line"> <span class="attribute">font-size</span>: <span class="number">11pt</span>;</span><br><span class="line"> <span class="attribute">padding-top</span>: <span class="number">3px</span>;</span><br><span class="line"> <span class="attribute">padding-left</span>: <span class="number">6px</span>;</span><br><span class="line"> <span class="attribute">padding-right</span>: <span class="number">6px</span>;</span><br><span class="line"> <span class="attribute">color</span>: <span class="number">#a3be8c</span>;</span><br><span class="line"> <span class="attribute">background</span>: <span class="number">#efefef</span>;</span><br><span class="line"> <span class="attribute">background-color</span>: <span class="number">#efefef</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.rendered_html</span> <span class="selector-tag">thead</span> &#123;</span><br><span class="line"> <span class="attribute">font-family</span>: <span class="string">"Microsoft YaHei Mono"</span>;</span><br><span class="line"> <span class="attribute">font-size</span>: <span class="number">10.5pt</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.rendered_html</span> <span class="selector-tag">td</span> &#123;</span><br><span class="line"> <span class="attribute">font-family</span>: <span class="string">"Microsoft YaHei Mono"</span>;</span><br><span class="line"> <span class="attribute">font-size</span>: <span class="number">10pt</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.rendered_html</span> <span class="selector-tag">h1</span>,</span><br><span class="line"><span class="selector-class">.text_cell_render</span> <span class="selector-tag">h1</span> &#123;</span><br><span class="line"> <span class="attribute">color</span>: <span class="number">#126dce</span> <span class="meta">!important</span>;</span><br><span class="line"> <span class="attribute">font-size</span>: <span class="number">160%</span>;</span><br><span class="line"> <span class="attribute">text-align</span>: left;</span><br><span class="line"> <span class="attribute">font-style</span>: normal;</span><br><span class="line"> <span class="attribute">font-weight</span>: bold;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.rendered_html</span> <span class="selector-tag">h2</span>,</span><br><span class="line"><span class="selector-class">.text_cell_render</span> <span class="selector-tag">h2</span> &#123;</span><br><span class="line"> <span class="attribute">color</span>: <span class="number">#126dce</span> <span class="meta">!important</span>;</span><br><span class="line"> <span class="attribute">font-size</span>: <span class="number">140%</span>;</span><br><span class="line"> <span class="attribute">font-style</span>: normal;</span><br><span class="line"> <span class="attribute">font-weight</span>: bold;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.rendered_html</span> <span class="selector-tag">h3</span>,</span><br><span class="line"><span class="selector-class">.text_cell_render</span> <span class="selector-tag">h3</span> &#123;</span><br><span class="line"> <span class="attribute">color</span>: <span class="number">#126dce</span> <span class="meta">!important</span>;</span><br><span class="line"> <span class="attribute">font-size</span>: <span class="number">120%</span>;</span><br><span class="line"> <span class="attribute">font-style</span>: normal;</span><br><span class="line"> <span class="attribute">font-weight</span>: bold;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-class">.CodeMirror-linenumber</span> &#123;</span><br><span class="line"> <span class="attribute">font-family</span>: <span class="string">"Microsoft YaHei Mono"</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.cm-s-ipython</span><span class="selector-class">.CodeMirror</span> &#123;<span class="attribute">background</span>: <span class="number">#2b303b</span>; <span class="attribute">color</span>: <span class="number">#dfe1e8</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">div</span><span class="selector-class">.CodeMirror-selected</span> &#123;<span class="attribute">background</span>: <span class="number">#343d46</span> <span class="meta">!important</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-class">.CodeMirror-gutters</span> &#123;<span class="attribute">background</span>: <span class="number">#2b303b</span>; <span class="attribute">border-right</span>: <span class="number">0px</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-class">.CodeMirror-linenumber</span> &#123;<span class="attribute">color</span>: <span class="number">#65737e</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-class">.CodeMirror-cursor</span> &#123;<span class="attribute">border-left</span>: <span class="number">1px</span> solid <span class="number">#a7adba</span> <span class="meta">!important</span>;&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-comment</span> &#123;<span class="attribute">color</span>: <span class="number">#A3BE72</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-atom</span> &#123;<span class="attribute">color</span>: <span class="number">#b48ead</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-number</span> &#123;<span class="attribute">color</span>: <span class="number">#b48ead</span>;&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-property</span>, <span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-attribute</span> &#123;<span class="attribute">color</span>: <span class="number">#c0c5ce</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-keyword</span> &#123;<span class="attribute">color</span>: <span class="number">#DDD7A3</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-string</span> &#123;<span class="attribute">color</span>: <span class="number">#94C273</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-operator</span> &#123;<span class="attribute">color</span>: <span class="number">#ab7967</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-builtin</span> &#123;<span class="attribute">color</span>: <span class="number">#EA8080</span>;&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-variable</span> &#123;<span class="attribute">color</span>: <span class="number">#c0c5ce</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-variable-2</span> &#123;<span class="attribute">color</span>: <span class="number">#8fa1b3</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-def</span> &#123;<span class="attribute">color</span>: <span class="number">#61AFEF</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-error</span> &#123;<span class="attribute">background</span>: <span class="number">#bf616a</span>; <span class="attribute">color</span>: <span class="number">#a7adba</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-bracket</span> &#123;<span class="attribute">color</span>: <span class="number">#c0c5ce</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-tag</span> &#123;<span class="attribute">color</span>: <span class="number">#bf616a</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-link</span> &#123;<span class="attribute">color</span>: <span class="number">#b48ead</span>;&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-class">.CodeMirror-matchingbracket</span> &#123; <span class="attribute">text-decoration</span>: underline; <span class="attribute">color</span>: <span class="number">#dfe1e8</span> <span class="meta">!important</span>;&#125;</span><br></pre></td></tr></table></figure><p>另外，在 linux 上安装 jupyter notebook 的话，第一次启动时会报 `` 的错，需要修改以下文件：</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;由于工作经常会更换机器、更换环境，有时候一个机器用惯了，换了一台机器都不记得自己之前是怎么配置的了。为了防止老年痴呆阻止我配置好看的工作环境，我决定把所有喜欢的配置都记录在这里，可能有点乱。&lt;/p&gt;
    
    </summary>
    
      <category term="安装部署" scheme="https://guyuecanhui.github.io/categories/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="jupyter" scheme="https://guyuecanhui.github.io/tags/jupyter/"/>
    
  </entry>
  
  <entry>
    <title>例解共轭分布之视频质量评估</title>
    <link href="https://guyuecanhui.github.io/2019/08/18/conjugate-priors-video-quality/"/>
    <id>https://guyuecanhui.github.io/2019/08/18/conjugate-priors-video-quality/</id>
    <published>2019-08-18T02:47:06.000Z</published>
    <updated>2020-06-10T13:16:46.043Z</updated>
    
    <content type="html"><![CDATA[<p>在推荐领域阅读文献的时候，我们常常会遇到共轭分布、共轭先验 (<strong>conjugate prior</strong>) 之类的概念。由于共轭这个翻译实在不太直观，因此这些概念也很难理解，我想结合两个视频推荐中的例子来尝试说明这些概念。今天先介绍视频质量评估的例子。</p><a id="more"></a><h3 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h3><p>如何评估一个视频的质量是视频推荐中非常重要但是又很让人头疼的事情。尤其是在短视频场景下，每天新增大量的短视频，我们需要迅速判断一个新短视频的质量：如果质量很好，我们可以将它向更多的人推荐；如果质量不好，我们可能不再主动推荐该视频。这里判断的时效很重要，因为如果没有及时发现一个垃圾视频，它可能就会通过推荐系统祸害很多的用户 =.=!</p><p>由于视频非常多，我们无法人工对每个视频进行准确的质量评估，而且用户在短视频的观看行为呈现出更加多元的兴趣，因此小编们也无法代表所有用户的口味。因此，要评估一个短视频好不好，还是得看它在用户中的表现 (可以用完播率、点赞率、分享率等统计指标来度量)。</p><p>假设我们只考虑用完播率 $r$ 来度量一个视频的质量 (后面交替使用完播率和视频质量)，它表示一个视频被播放完 (或者播放超过一定比例) 的数量 $m$ 与它展现给用户的次数 $n$ 的比例：</p><script type="math/tex; mode=display">r=\frac{m}{n} \qquad(1)</script><p>这个指标的优点是计算非常方便，而且能够在一定程度上表达业务诉求。但是实际应用的时候，往往会因为视频的展示次数过少而对某个视频进行错误的评价。例如，视频 $v_1$ 只展示了 $10$ 次，有 $5$ 次完播；视频 $v_2$ 展示了 $10000$ 次，有 $4900$ 次完播，相较而言，$v_1$ 和 $v_2$ 哪个质量更好呢？</p><p>很难说！我们只是比较确信 $v_2$ 的完播率稳定在了 $49\%$ 左右，而对于 $v_1$ 的评估就非常不确定了：有可能它再展示 $10$ 次以后，一次都没人看；也有可能它再展示 $10$ 次每次都完播了。这两种情况下我们对视频质量的评估将发生非常大的变化。</p><h3 id="模型假设-先验分布"><a href="#模型假设-先验分布" class="headerlink" title="模型假设 (先验分布)"></a>模型假设 (先验分布)</h3><p>从根本上来讲，我们简单的用式 $(1)$ 来计算完播率忽略了事件过少时候的不确定性。为了引入这种不确定性，我们可以用一个概率分布来表示视频的质量 (这就是贝叶斯学派的观点，$r$ 并不是一个固定的值，而是满足一定的概率分布)，也就是说，给定 $m$ 和 $n$，我们要来估计这个视频的质量呈现一个什么样的分布。这个分布的形状是我们在看到数据之前<strong>根据经验</strong>去假定的，因此我们也叫它<strong>先验分布</strong>。</p><p>我们的直观想法是，如果一个视频的完播率为 $r=\frac{m}{n}$，那么它质量的真实分布 $\theta$ 中，概率最大的点也应该是 $\frac{m}{n}$，并且与 $\frac{m}{n}$ 相差越多概率也越小。</p><p>根据这个想法，我们可以用 <strong>Beta</strong> 分布来进行建模，将 $\alpha=m$ 和 $\beta=n-m$ 作为 <strong>Beta</strong> 分布的参数 (<strong>Beta</strong> 分布的详细介绍可以参考 Wiki)。在我们的例子中，随着 $n$ 的增加，<strong>Beta</strong> 分布的概率密度越集中于 $r=\frac{m}{n}$。下图表示随着 $m$ 和 $n$ 变化，保持 $r=0.5$ 不变的情况下，<strong>Beta</strong> 分布的概率密度函数：</p><img src="/2019/08/18/conjugate-priors-video-quality/beta-pdf.png" title="图 1. 不同参数下 Beta 分布的形状"><p>可以看到，当 $n$ 很小的时候，视频的质量是高度不确定的；而当 $n$ 很大的时候，视频的质量已经集中分布于 $r=\frac{m}{n}$ 附近了。因此，我们选的这个先验分布是能够满足我们的直观想法和假设要求的。这样，我们用式 $(2)$ 来代替式 $(1)$ 对视频质量进行初步的评估：</p><script type="math/tex; mode=display">\begin{align}p(\theta;\alpha,\beta)=Beta(\theta;\alpha,\beta)&=\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}\\&=\frac{1}{B(\alpha,\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}\end{align} \qquad(2)</script><p>其中，$\Gamma(n)=(n-1)!$ 表示伽玛函数 (这个场景下参数都为整数)；$B(\alpha,\beta)$ 可以看成是归一化项，使得所有概率累加和为 $1$。</p><h3 id="更新模型-后验分布"><a href="#更新模型-后验分布" class="headerlink" title="更新模型 (后验分布)"></a>更新模型 (后验分布)</h3><p>问题才解决了一半，由于视频在不断的推荐给用户，我们的统计数据也在发生变化。因此另外一个至关重要的问题是，我们怎么根据新增的数据来更新我们对视频质量的评估。</p><p>例如，对于某个视频 $v$，假设我们已经收集到一些反馈数据，并统计出 $\alpha=m$，$\beta=n-m$，我们根据式 $(2)$ 对视频质量分布 $\theta$ 有了一个初步的估计。现在我们又将这个视频推荐给其他用户，并想看看放量以后，视频质量评估是否准确。假设这个视频又展示了 $b$ 次，完播了 $a$ 次，则我们根据先验假设，视频的质量应该是围绕 $r’=\frac{m+a}{n+b}$ 的钟形分布，并且比之前的分布更陡峭一些。为了实现这个过程，我们需要对模型进行更新。</p><p>由于用户的反馈只包含完播和未完播两类，因此很容易想到用二项分布的似然估计来估计这 $b$ 次展示中有 $a$ 次会完播的概率：</p><script type="math/tex; mode=display">p(x=a|\theta)=C_b^a\theta^{a}(1-\theta)^{(b-a)} \qquad(3)</script><p>由于式 $(3)$ 中的 $\theta$ 实际上是满足式 $(2)$ 中的分布 (<em>注意，这里 $\theta$ 虽然仍然是一个分布，但是我们在这一步假设它是已知的</em>)，代入后可以算出 $a$ 次完播的概率为 $\theta$ 取所有可能值时式 $(3)$ 的积分：</p><script type="math/tex; mode=display">p(x=a)=\int_0^1 p(x=a;\theta)p(\theta)d\theta \qquad(4)</script><p>这里我们要用最基础的贝叶斯公式，来基于初始的视频质量评估和增量收集来的统计数据，去修正我们在式 $(2)$ 中做出的视频质量评估，得到一个更加可靠的估计。贝叶斯公式如下：</p><script type="math/tex; mode=display">p(\theta;X)=\frac{p(X;\theta)p(\theta)}{p(X)} \qquad(5)</script><p>其中，$p(\theta)$ 是我们对这个视频质量的初始评估，即先验分布，用式 $(2)$ 来计算；$p(X;\theta)$ 表示我们基于初始的评估结果，进一步估计事件 $X$ 发生的概率，即似然估计，用式 $(3)$ 来计算；$p(X)$ 表示 $\theta$ 取不同值时事件 $X$ 发生的概率之和，主要是用于做归一化，用式 $(4)$ 来计算；$p(\theta;X)$ 则表示基于先验分布和似然估计，得到的后验分布。</p><p>全部代入后，我们可以得到下面的简单推导：</p><script type="math/tex; mode=display">\begin{align}p(\theta;x=a)&=\frac{p(x=a;\theta)p(\theta)}{\int_0^1 p(x=a;\theta)p(\theta)d(\theta)}\\&=\frac{C_b^a\theta^{a}(1-\theta)^{(b-a)} \frac{1}{B(\alpha,\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}}{\int_0^1 C_b^a\theta^{a}(1-\theta)^{(b-a)}\frac{1}{B(\alpha,\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}d\theta}\\&=\frac{\theta^{\alpha+a-1}(1-\theta)^{\beta+b-a-1}}{\int_0^1\theta^{\alpha+a-1}(1-\theta)^{\beta+b-a-1}d\theta}\\&=\frac{1}{B(\alpha+a,\beta+b-a)}\theta^{\alpha+a-1}(1-\theta)^{\beta+b-a-1}\\&=Beta(\theta;\alpha+a,\beta+b-a)\end{align} \qquad(6)</script><p>也就是说，经过了这一轮的推荐以后，我们对这个视频的质量评估仅仅使模型的参数发了变化，而模型的形式不变，仍然为 <strong>Beta</strong> 分布！至此，我们终于触及本文的核心概念：共轭性。</p><blockquote><p> <strong>模型的先验分布与后验分布具有相同的函数形式，这个性质就叫做共轭性。</strong></p></blockquote><h3 id="共轭性"><a href="#共轭性" class="headerlink" title="共轭性"></a>共轭性</h3><p>共轭性给我们带来了什么样的好处呢？比较式 $(6)$ 和式 $(2)$，我们发现，在观察到 $b$ 次推荐中有 $a$ 次完播事件后，我们可以简单的将模型从 $Beta(\theta;\alpha,\beta)$ 更新为 $Beta(\theta;\alpha+a,\beta+b-a)$，即我们只需要更新如下模型参数：</p><script type="math/tex; mode=display">\begin{cases}\begin{align}\alpha&=\alpha+a \\\beta&=\beta+b-a\end{align}\end{cases}</script><p>它的最大意义在于简化了模型更新的过程，使得模型更新的实时性得到了保证。</p><p>一开始，我们基于先验知识对视频质量进行建模，但是由于数据量较少，我们对视频质量的估计置信度较低；随着用户反馈的数据越来越多，我们可以直接基于这些新增的数据去快速更新模型的参数；随着参数数值的增大，我们对视频质量的估计置信度越来越高，直到我们已经有充足的把握认定这个视频是不是高质量视频。</p><p>这里的置信度还体现在，当数据量较少的时候，少量的观测结果就会导致我们对视频质量评估发生巨大的变化；而当数据量充足的时候，即使再收集到很多数据，也很难改变我们的评估。</p><h3 id="Take-aways"><a href="#Take-aways" class="headerlink" title="Take-aways"></a>Take-aways</h3><p>至此，我们用视频质量评估的例子说明了共轭性和共轭分布是什么含义。一些关键点总结如下：</p><ol><li>共轭性是指模型的先验分布和后验分布有相同的形式，满足共轭性的分布称为共轭分布。例如：<strong>Beta</strong> 分布与二项分布是共轭分布，且 <strong>Beta</strong> 分布是 $\theta$ 的共轭先验；</li><li>共轭性极大的方便了我们基于增量观测的数据对模型进行更新；</li><li>在推导共轭性的时候，我们使用了贝叶斯公式，总结起来就是：后验分布=先验分布*似然函数/归一化因子；</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在推荐领域阅读文献的时候，我们常常会遇到共轭分布、共轭先验 (&lt;strong&gt;conjugate prior&lt;/strong&gt;) 之类的概念。由于共轭这个翻译实在不太直观，因此这些概念也很难理解，我想结合两个视频推荐中的例子来尝试说明这些概念。今天先介绍视频质量评估的例子。&lt;/p&gt;
    
    </summary>
    
      <category term="数学" scheme="https://guyuecanhui.github.io/categories/%E6%95%B0%E5%AD%A6/"/>
    
    
      <category term="统计" scheme="https://guyuecanhui.github.io/tags/%E7%BB%9F%E8%AE%A1/"/>
    
      <category term="概率" scheme="https://guyuecanhui.github.io/tags/%E6%A6%82%E7%8E%87/"/>
    
      <category term="分布" scheme="https://guyuecanhui.github.io/tags/%E5%88%86%E5%B8%83/"/>
    
      <category term="贝叶斯" scheme="https://guyuecanhui.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/"/>
    
      <category term="先验" scheme="https://guyuecanhui.github.io/tags/%E5%85%88%E9%AA%8C/"/>
    
      <category term="后验" scheme="https://guyuecanhui.github.io/tags/%E5%90%8E%E9%AA%8C/"/>
    
      <category term="共轭" scheme="https://guyuecanhui.github.io/tags/%E5%85%B1%E8%BD%AD/"/>
    
      <category term="Beta分布" scheme="https://guyuecanhui.github.io/tags/Beta%E5%88%86%E5%B8%83/"/>
    
      <category term="二项分布" scheme="https://guyuecanhui.github.io/tags/%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83/"/>
    
  </entry>
  
  <entry>
    <title>常用的特征选择方法之 Kendall 秩相关系数</title>
    <link href="https://guyuecanhui.github.io/2019/08/10/feature-selection-kendall/"/>
    <id>https://guyuecanhui.github.io/2019/08/10/feature-selection-kendall/</id>
    <published>2019-08-10T14:44:41.000Z</published>
    <updated>2020-06-10T13:16:55.321Z</updated>
    
    <content type="html"><![CDATA[<p>前面我们已经讨论了 <a href="https://guyuecanhui.github.io/2019/07/20/feature-selection-pearson/"><strong>Pearson</strong> 相关系数</a>和 <a href="https://guyuecanhui.github.io/2019/07/28/feature-selection-spearman/"><strong>Spearman</strong> 秩相关系数</a>，它们可以检测连续变量间的相关性，并且 <strong>Spearman</strong> 秩相关系数还能够检测有序的离散变量间的相关系数。今天我们再讨论一个能够检测有序变量相关性的系数：<strong>Kendall</strong> 秩相关系数。这里有序变量既包括实数变量，也包括可以排序的类别变量，比如名次、年龄段等。</p><a id="more"></a><h3 id="Kendall-秩相关系数的定义"><a href="#Kendall-秩相关系数的定义" class="headerlink" title="Kendall 秩相关系数的定义"></a>Kendall 秩相关系数的定义</h3><p><strong>Kendall</strong> 秩相关系数是一个非参数性质（与分布无关）的秩统计参数，是用来度量两个<strong>有序变量</strong>之间<strong>单调关系</strong>强弱的相关系数，它的取值范围是 $[-1,1]$，绝对值越大，表示单调相关性越强，取值为 $0$ 时表示完全不相关。</p><p>原始的 <strong>Kendall</strong> 秩相关系数定义在<strong>一致对</strong> (<strong>concordant pairs</strong>) 和<strong>分歧对</strong> (<strong>discordant pairs</strong>) 的概念上。所谓一致对，就是两个变量取值的相对关系一致；分歧对则是指它们的相对关系不一致。这么说有点难以理解，我们举个例子。</p><p>假设我们为很多不同年龄的用户推送了一条社保相关的视频，然后回收了这些用户的播放完成度，如下表所示：</p><img src="/2019/08/10/feature-selection-kendall/age-value-pairs.png" title="图 1. 用户年龄与播放完成度的关系"><p>我们想用 <strong>Kendall</strong> 秩相关系数来分析用户年龄与该社保视频的播放情况是否相关。为此，我们将年龄和播放完成度分别排序后，对样本中取值进行排序和编号，分别得到 <code>年龄序号</code> 和 <code>播放序号</code>。这时，对于样本 $3$ 和样本 $4$，它们的年龄序号是 $[3,4]$，播放序号是 $[2,4]$，虽然序号不同，但是变化趋势是相同的，因此它们是一致的；对于样本 $2$ 和样本 $3$，它们的年龄序号是 $[2,3]$，播放序号是 $[5,2]$，它们的变化趋势是相反的，因此它们是分歧的。</p><p>进一步的，我们观察可以发现，当样本已经按年龄升序排列后，对于每个样本，我们可以简单的数一下该样本后续样本中播放序号大于该样本的样本数量，作为该样本引入的一致对数 (该样本之前的样本与该样本也可能一致，但是已经算过一次了)，将所有样本引入的一致对数加起来就能得到所有样本的一致对数，记为 $c$。</p><p>同样的，对于每个样本，我们可以简单的数一下该样本后续样本中播放序号小于该样本的样本数量，作为该样本引入的分歧对数，累加后得到所有样本的分歧对数，记为 $d$。</p><p>则原始的 <strong>Kendall</strong> 秩相关系数定义为：</p><script type="math/tex; mode=display">\tau_a=\frac{c-d}{c+d}=\frac{c-d}{\frac{1}{2}\cdot n\cdot (n-1)}\qquad (1)</script><p>其中，$m=\frac{n\cdot (n-1)}{2}$ 表示所有样本两两组合的数量，在变量没有重复取值的情况下，$m=c+d$。定义 $(1)$ 也被称为 <a href="https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient" target="_blank" rel="noopener"><strong>Tau-a</strong></a>，从定义也容易看出，它不能处理变量有相同取值的情况。</p><p>为了处理变量有相同取值的情况，我们还要将每个变量中相同取值的数量考虑进来，从而得到扩展的定义：</p><script type="math/tex; mode=display">\tau_b=\frac{c-d}{\sqrt{(c+d+t_x)(c+d+t_y)}}\qquad (2)</script><p>其中，$c$ 在计算的时候只能算 <script type="math/tex">a_i<a_j</script> 且 <script type="math/tex">b_i<b_j</script> 的对数，$d$ 也只能算 <script type="math/tex">a_i<a_j</script> 且 <script type="math/tex">b_i>b_j</script> 的对数 (<script type="math/tex">i<j</script>)；$t_x$，$t_y$ 分别表示变量 $x$，$y$ 取值中序号相同的样本对数排除共同平局的部分 (在下一小节举例说明)。式 <script type="math/tex">(2)</script> 通常又被称为 <strong>Tau-b</strong>，是实际中应用最广泛的定义 (另外还有 <strong>Tau-c</strong> 的变种这里就不介绍了)。在 <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kendalltau.html" target="_blank" rel="noopener"><strong>scipy 1.3.0</strong></a> 版本的实现中，同时支持式 $(1)$ 和式 $(2)$。</p><h3 id="举例说明"><a href="#举例说明" class="headerlink" title="举例说明"></a>举例说明</h3><p>首先，我们根据式 $(1)$ 算一下图 $1$ 中年龄与播放的相关度。</p><ol><li>将样本按年龄升序排列，将播放完成度按从小到大的顺序编号，如图 $1$ 所示；</li><li>分别计算每个样本新引入的一致对数和分歧对数，如图 $1$ 所示，进而算出 $c=40$，$d=5$；</li><li>根据式 $(1)$ 得到 $\tau_a=\frac{40-5}{40+5}=0.778$；</li></ol><p>因此，年龄与播放社保视频的时长呈现强相关性，基于这个分析我们就可以尝试对更多年龄大一些的用户推送此视频。</p><p>在工程实现的时候，用户的年龄通常会被划分成不同的区间，而播放完成度只有超过一定阈值 (如 $0.3$) 我们才算作有效播放。因此，图 $1$ 的数据我们又可以转换成下面的离散情况：</p><img src="/2019/08/10/feature-selection-kendall/age-discrete-pairs.png" title="图 2. 离散化的用户年龄与播放完成度的关系"><p>可以发现，年龄段序号和有效播放序号存在大量的重复数据，因此我们基于式 $(2)$ 来计算：</p><ol><li>将样本按年龄段升序排列，相同的年龄段按是否有效播放排序，对年龄段和是否有效播放进行编号，如图 $2$ 所示；</li><li>计算每个样本引入的一致对数和分歧对数，如图 $2$ 所示 (例如样本 $4$ 与 样本 $8\sim 10$ 一致)，进而算出 $c=21$，$d=0$；</li><li>计算公共平局的数量 $t_c$，公共平局是指 $a_i=a_j$ 且 $b_i=b_j$ 的情况 (例如样本 $1\sim 3$ 互为平局，样本 $4,5,7$ 互为平局，样本 $8,9$ 互为平局)，根据图 $2$ 易知：$t_c=\frac{3\cdot (3-1)}{2}+\frac{3\cdot (3-1)}{2}+\frac{2\cdot (2-1)}{2}=7$；</li><li>计算只在年龄段平局的数量 $t_x=\frac{3\cdot (3-1)}{2}+\frac{4\cdot (4-1)}{2}+\frac{2\cdot (2-1)}{2}-t_c=10-7=3$；</li><li>计算只在有效播放平均局的数量 $t_y=\frac{6\cdot (6-1)}{2}+\frac{4\cdot (4-1)}{2}-t_c=21-7=14$；</li><li>根据式 $(2)$ 得到 $\tau_b=\frac{21}{\sqrt{(21+3)(21+14)}}=0.725$；</li></ol><p>对比发现，离散化后，我们发现这两个因素之间仍然是强相关的。</p><blockquote><p>附示例的 python 代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> kendalltau</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y=[<span class="number">1</span>,<span class="number">5</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">7</span>,<span class="number">6</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>kendalltau(x,y)</span><br><span class="line">(<span class="number">0.7777777777777779</span>, <span class="number">0.0017451191944018172</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x=[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y=[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>kendalltau(x,y)</span><br><span class="line">(<span class="number">0.72456883730947197</span>, <span class="number">0.0035417200011750309</span>)</span><br></pre></td></tr></table></figure></p><p>其中，<code>kendalltau</code> 返回的第二个结果是 p-value，其具体含义可参考<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kendalltau.html" target="_blank" rel="noopener">官方文档</a>。</p></blockquote><h3 id="Take-aways"><a href="#Take-aways" class="headerlink" title="Take-aways"></a>Take-aways</h3><ol><li><strong>Kendall</strong> 秩相关系数可以用于度量有序变量间相关性，只要求变量取值之间可比，对变量的分布和数据的距离不作假设；</li><li>能用 <strong>Pearson</strong> 相关系数和 <strong>Spearman</strong> 秩相关系数的地方都能用 <strong>Kendall</strong> 秩相关系数，但是 <strong>Spearman</strong> 和 <strong>Kendall</strong> 秩相关系数要对数据排序，复杂度远高于 <strong>Pearson</strong> 相关系数，因此能用 <strong>Pearson</strong> 相关系数的时候优先考虑 <strong>Pearson</strong> 相关系数；</li><li><strong>Kendall</strong> 秩相关系数依赖一致对和分歧对的计数，这里需要注意数据中是否有重复取值的情况，来选择使用 <strong>Tau-a</strong> 还是 <strong>Tau-b</strong> 进行计算。</li></ol><hr><blockquote><h4 id="这是特征选择系列文章的第三篇，其他文章可参考："><a href="#这是特征选择系列文章的第三篇，其他文章可参考：" class="headerlink" title="这是特征选择系列文章的第三篇，其他文章可参考："></a>这是特征选择系列文章的第三篇，其他文章可参考：</h4><ol><li><a href="https://guyuecanhui.github.io/2019/07/20/feature-selection-pearson/">常用的特征选择方法之 Pearson 相关系数</a></li><li><a href="https://guyuecanhui.github.io/2019/07/28/feature-selection-spearman/">常用的特征选择方法之 Spearman 相关系数</a></li><li><a href="https://guyuecanhui.github.io/2019/07/28/feature-selection-kendall/">常用的特征选择方法之 Kendall 秩相关系数</a></li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前面我们已经讨论了 &lt;a href=&quot;https://guyuecanhui.github.io/2019/07/20/feature-selection-pearson/&quot;&gt;&lt;strong&gt;Pearson&lt;/strong&gt; 相关系数&lt;/a&gt;和 &lt;a href=&quot;https://guyuecanhui.github.io/2019/07/28/feature-selection-spearman/&quot;&gt;&lt;strong&gt;Spearman&lt;/strong&gt; 秩相关系数&lt;/a&gt;，它们可以检测连续变量间的相关性，并且 &lt;strong&gt;Spearman&lt;/strong&gt; 秩相关系数还能够检测有序的离散变量间的相关系数。今天我们再讨论一个能够检测有序变量相关性的系数：&lt;strong&gt;Kendall&lt;/strong&gt; 秩相关系数。这里有序变量既包括实数变量，也包括可以排序的类别变量，比如名次、年龄段等。&lt;/p&gt;
    
    </summary>
    
      <category term="特征工程" scheme="https://guyuecanhui.github.io/categories/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"/>
    
    
      <category term="特征" scheme="https://guyuecanhui.github.io/tags/%E7%89%B9%E5%BE%81/"/>
    
      <category term="特征选择" scheme="https://guyuecanhui.github.io/tags/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/"/>
    
      <category term="特征过滤" scheme="https://guyuecanhui.github.io/tags/%E7%89%B9%E5%BE%81%E8%BF%87%E6%BB%A4/"/>
    
      <category term="Kendall" scheme="https://guyuecanhui.github.io/tags/Kendall/"/>
    
  </entry>
  
  <entry>
    <title>常用的特征选择方法之 Spearman 秩相关系数</title>
    <link href="https://guyuecanhui.github.io/2019/07/28/feature-selection-spearman/"/>
    <id>https://guyuecanhui.github.io/2019/07/28/feature-selection-spearman/</id>
    <published>2019-07-28T02:36:03.000Z</published>
    <updated>2020-06-10T13:17:11.340Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://guyuecanhui.github.io/2019/07/20/feature-selection-pearson/">上一篇</a>里，我们简单的介绍了基于 <strong>Pearson</strong> 相关系数的特征选择方法，本篇介绍另一种使用更加广泛的相关系数：<strong>Spearman</strong> 秩相关系数，简称 <strong>Spearman</strong> 相关系数。<strong>Spearman</strong> 相关系数与 <strong>Pearson</strong> 相关系数、<strong>Kendall</strong> 相关系数并称统计学三大相关系数，足见其重要性。</p><p>有了 <strong>Pearson</strong> 相关系数，为什么还要用 <strong>Spearman</strong> 相关系数呢，主要是 <strong>Pearson</strong> 系数只能度量两个服从正态分布的变量之间线性相关性的强弱 (如果不熟悉可以回顾一下上一篇的介绍)，而 <strong>Spearman</strong> 系数只度量<strong>单调关系</strong>，而不考虑具体数值的影响，因此 <strong>Spearman</strong> 相关系数的应用范围更广，不仅对数据分布不作任何假设，能够容忍异常值，也不需要数据的取值是等距的（例如比赛中，第 1 名和第 2 名的距离与第 2 名和第 3 名的距离是不等的），因此除非是考虑性能的影响，能用 <strong>Pearson</strong> 系数的地方都能用 <strong>Spearman</strong> 系数。</p><a id="more"></a><h3 id="Spearman-秩相关系数的定义"><a href="#Spearman-秩相关系数的定义" class="headerlink" title="Spearman 秩相关系数的定义"></a>Spearman 秩相关系数的定义</h3><p><a href="https://blog.csdn.net/liuyuan_jq/article/details/52542211" target="_blank" rel="noopener"><strong>Spearman</strong> 秩相关系数</a>是一个非参数性质（与分布无关）的秩统计参数，是用来度量两个<strong>连续型变量</strong>之间<strong>单调关系</strong>强弱的相关系数，取值范围也是 $[-1,1]$。在没有重复数据的情况下，如果一个变量是另外一个变量的严格单调函数，则 <strong>Spearman</strong> 秩相关系数就是 $1$ 或 $-1$，称变量完全 <strong>Spearman</strong> 秩相关。</p><p>这里的秩相关 (<strong>Rank Correlation</strong>)，又称等级相关，是将两变量的样本值按数据的大小顺序排列位次，以各要素样本值的位次代替实际数据而求得的一种统计量。排序不论从大到小还是从小到大排都无所谓，只要保证大家排序的标准一致即可。</p><p>用 $\rho_s$ 来表示 <strong>Spearman</strong> 相关系数 (用 $\rho_p$ 表示 <strong>Pearson</strong> 相关系数)。如果每个变量都没有相同的取值 (即没有相同的秩次)，则 <strong>Spearman</strong> 相关系数可由下式计算：</p><script type="math/tex; mode=display">\rho_s=1-\frac{6\sum{d_i^2}}{n(n^2-1)}</script><p>其中，$n$ 表示数据点的个数；<script type="math/tex">d_i</script> 表示数据点 <script type="math/tex">(x_i,y_i)</script> 的秩次 <script type="math/tex">(r_{x_i},r_{y_i})</script> 之差：<script type="math/tex">d_i=r_{x_i}-r_{y_i}</script>。</p><p>如果某个变量有重复数据，则计算变量之间的 <strong>Spearman</strong> 相关系数就是计算变量数据秩次之间的 <strong>Pearson</strong> 相关系数：</p><script type="math/tex; mode=display">\rho_s=\rho_{r_x,r_y}=\frac{\text{cov}(r_x,r_y)}{\sigma_{r_x}\sigma_{r_y}}</script><p>其中，$r_x$ 表示变量 $\boldsymbol{x}$ 转换后的秩次。从这个定义可以看出来，<strong>Spearman</strong> 相关系数实际上就是对数据做了秩次变换后的 <strong>Pearson</strong> 相关系数。</p><h3 id="举例说明"><a href="#举例说明" class="headerlink" title="举例说明"></a>举例说明</h3><p>我们还是拿上一篇的例子来说明。首先将样本进行秩次变换，样本升序排列后的位次如图 1 所示：</p><img src="/2019/07/28/feature-selection-spearman/rank-correlation.png" title="图 1. 将变量 $x$, $y$ 用其排序的位次 $r_x$, $r_y$ 来代替"><p>需要说明的是，这里变量 $y$ 有两个重复数据 $0.1$，在排序的时候它们的位次相同，此时可以用相同位次的数据所占的位次之和除以数据的数量 (即 $\frac{1+2}{2}=1.5$) 来作为这些重复数据的位次。</p><p>根据定义，当存在重复数据的时候，我们计算秩次 (即 $r_x$, $r_y$) 的 <strong>Pearson</strong> 相关系数 (过程省略)，得到结果 $\rho_s=0.994$，几乎是单调相关了，其数值比直接计算原始数据的 <strong>Pearson</strong> 相关系数 $\rho_p=0.972$ 还要大一些。</p><p>实际上，当 <strong>Pearson</strong> 相关系数比较大的时候，<strong>Spearman</strong> 相关系数也比较大；而当 <strong>Pearson</strong> 相关系数比较小的时候，<strong>Spearman</strong> 相关系数仍然可能较大，例如变量之间是指数相关 ($y=e^x$，如图 2 所示) 时，它们的 <strong>Pearson</strong> 相关系数和 <strong>Spearman</strong> 相关系数分别是 $0.7758$ 和 $1.0$。</p><img src="/2019/07/28/feature-selection-spearman/pearson-vs-spearman.png" title="图 2. 变量 $x$, $y$ 之间的 Pearson 相关系数为 $0.7758$，Spearman 相关系数为 $1.0$"><p>最后，我们看看<a href="https://guyuecanhui.github.io/2019/07/20/feature-selection-pearson/">上一篇图 3</a> 所示的异常数据对 <strong>Spearman</strong> 相关系数的影响，引入异常点 $(0.9,-1.0)$ 后，变量 $x$, $y$ 的 <strong>Pearson</strong> 相关系数降为了 $\rho_p=-0.0556$，它们的 <strong>Spearman</strong> 相关系数也受到了较大的影响，降到了 $\rho_s=0.3234$，也就是较弱的正相关性。但是从这个例子仍然可以看出，与 <strong>Pearson</strong> 相关系数相比，<strong>Spearman</strong> 相关系数对异常值容忍度更高一些。</p><blockquote><p>附示例的 python 代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> spearmanr, pearsonr</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x=[<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y=[<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>, <span class="number">1.0</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>spearmanr(x,y)</span><br><span class="line">(<span class="number">0.99402979738800479</span>, <span class="number">5.2961535156451228e-07</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rx=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ry=[<span class="number">1.5</span>, <span class="number">1.5</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pearsonr(rx,ry)</span><br><span class="line">(<span class="number">0.99402979738800501</span>, <span class="number">5.2961535156445373e-07</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z=[<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>, <span class="number">-1.0</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>spearmanr(x,z)</span><br><span class="line">(<span class="number">0.32335909071657992</span>, <span class="number">0.43463944855085729</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z=[<span class="number">0.1</span>, <span class="number">0.12</span>, <span class="number">0.2</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>, <span class="number">-1.0</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>spearmanr(x,z)</span><br><span class="line">(<span class="number">0.32335909071657992</span>, <span class="number">0.43463944855085729</span>)</span><br></pre></td></tr></table></figure><p>这里，<code>spearmanr</code> 返回的第二个结果是 p-value，其具体含义可参考<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html" target="_blank" rel="noopener">官方文档</a>。</p></blockquote><h3 id="Take-aways"><a href="#Take-aways" class="headerlink" title="Take-aways"></a>Take-aways</h3><p>本文简单介绍了 Spearman 相关系数，主要注意点总结如下：</p><ol><li><strong>Spearman</strong> 相关系数是度量两个<strong>连续型变量</strong>之间<strong>单调关系</strong>强弱的相关系数，它对数据的分布不作任何假设，能够容忍异常值，也不需要数据的取值是等距的；</li><li><strong>Spearman</strong> 相关系数实际上就是对数据做了秩次变换后的 <strong>Pearson</strong> 相关系数，只要能用 <strong>Pearson</strong> 相关系数的地方就能使用 <strong>Spearman</strong> 相关系数；</li><li><strong>Spearman</strong> 相关系数还需要对原始数据进行排序，因此计算复杂度高于 <strong>Pearson</strong> 相关系数，当数据满足 <strong>Pearson​</strong> 相关系数的使用条件时，优先考虑使用 <strong>Pearson</strong> 相关系数。</li></ol><hr><blockquote><h4 id="这是特征选择系列文章的第二篇，其他文章可参考："><a href="#这是特征选择系列文章的第二篇，其他文章可参考：" class="headerlink" title="这是特征选择系列文章的第二篇，其他文章可参考："></a>这是特征选择系列文章的第二篇，其他文章可参考：</h4><ol><li><a href="https://guyuecanhui.github.io/2019/07/20/feature-selection-pearson/">常用的特征选择方法之 Pearson 相关系数</a></li><li><a href="https://guyuecanhui.github.io/2019/07/28/feature-selection-spearman/">常用的特征选择方法之 Spearman 相关系数</a></li><li><a href="https://guyuecanhui.github.io/2019/07/28/feature-selection-kendall/">常用的特征选择方法之 Kendall 秩相关系数</a></li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://guyuecanhui.github.io/2019/07/20/feature-selection-pearson/&quot;&gt;上一篇&lt;/a&gt;里，我们简单的介绍了基于 &lt;strong&gt;Pearson&lt;/strong&gt; 相关系数的特征选择方法，本篇介绍另一种使用更加广泛的相关系数：&lt;strong&gt;Spearman&lt;/strong&gt; 秩相关系数，简称 &lt;strong&gt;Spearman&lt;/strong&gt; 相关系数。&lt;strong&gt;Spearman&lt;/strong&gt; 相关系数与 &lt;strong&gt;Pearson&lt;/strong&gt; 相关系数、&lt;strong&gt;Kendall&lt;/strong&gt; 相关系数并称统计学三大相关系数，足见其重要性。&lt;/p&gt;
&lt;p&gt;有了 &lt;strong&gt;Pearson&lt;/strong&gt; 相关系数，为什么还要用 &lt;strong&gt;Spearman&lt;/strong&gt; 相关系数呢，主要是 &lt;strong&gt;Pearson&lt;/strong&gt; 系数只能度量两个服从正态分布的变量之间线性相关性的强弱 (如果不熟悉可以回顾一下上一篇的介绍)，而 &lt;strong&gt;Spearman&lt;/strong&gt; 系数只度量&lt;strong&gt;单调关系&lt;/strong&gt;，而不考虑具体数值的影响，因此 &lt;strong&gt;Spearman&lt;/strong&gt; 相关系数的应用范围更广，不仅对数据分布不作任何假设，能够容忍异常值，也不需要数据的取值是等距的（例如比赛中，第 1 名和第 2 名的距离与第 2 名和第 3 名的距离是不等的），因此除非是考虑性能的影响，能用 &lt;strong&gt;Pearson&lt;/strong&gt; 系数的地方都能用 &lt;strong&gt;Spearman&lt;/strong&gt; 系数。&lt;/p&gt;
    
    </summary>
    
      <category term="特征工程" scheme="https://guyuecanhui.github.io/categories/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"/>
    
    
      <category term="特征" scheme="https://guyuecanhui.github.io/tags/%E7%89%B9%E5%BE%81/"/>
    
      <category term="特征选择" scheme="https://guyuecanhui.github.io/tags/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/"/>
    
      <category term="特征过滤" scheme="https://guyuecanhui.github.io/tags/%E7%89%B9%E5%BE%81%E8%BF%87%E6%BB%A4/"/>
    
      <category term="Spearman" scheme="https://guyuecanhui.github.io/tags/Spearman/"/>
    
  </entry>
  
  <entry>
    <title>常用的特征选择方法之 Pearson 相关系数</title>
    <link href="https://guyuecanhui.github.io/2019/07/20/feature-selection-pearson/"/>
    <id>https://guyuecanhui.github.io/2019/07/20/feature-selection-pearson/</id>
    <published>2019-07-20T14:36:03.000Z</published>
    <updated>2020-06-10T13:17:06.400Z</updated>
    
    <content type="html"><![CDATA[<p>众所周知，特征选择是机器学习活动至关重要的一步。最理想的情况下，我们把所有影响目标的独立因素给找出来，然后使用合适的量化手段，就能够得到完美描述目标问题的特征列表，用这些特征去建立合适容量的模型，这样的模型能够完美的匹配我们要解决的任务。</p><p>但是实际上这种想法太难实现了，我们往往只能从已有的数据出发，通过一些特征变换和组合得到一些原始特征，然后从这些原始特征中选出与目标相关的特征。</p><p>随着深度网络的崛起，越来越多的未经复杂变换的原始特征被加入到了深度网络中，大家期待有用的特征能够被自动的抽取和组合出来。但是这并不意味着特征工程就不需要了，推荐系统的大牛 Xavier 在技术博客《Rules of Machine Learning: Best Practices for ML Engineering》中提到很多关于特征工程的建议，非常值得一读，其中包含的思想就是特征是随着系统的优化进程而逐步添加的，并非一蹴而就，要始终保证特征的简单、直观、可复用、可监控和可靠性，这意味着我们需要时常对系统中存量特征做测试和筛选。</p><p>特征选择通常有过滤法（Filter）、打包法（Wrap）和嵌入法（Embed），其中，后两者都是与模型相关的，需要具体问题具体对待，而过滤法是指对特征进行预处理，提前过滤掉一些对目标无益（即对模型无益）的特征，它只考虑任务目标，而与模型无关。</p><a id="more"></a><p>我打算把常用的特征选择方法都再回顾一遍，力争把每种方法都讲得通俗易懂。这篇文章先介绍 <strong>Pearson</strong> 相关系数。</p><h3 id="Pearson-相关系数的定义"><a href="#Pearson-相关系数的定义" class="headerlink" title="Pearson 相关系数的定义"></a>Pearson 相关系数的定义</h3><p><strong>Pearson</strong> 相关系数是用来检测两个<strong>连续型变量</strong>之间<strong>线性相关</strong>的程度，取值范围为 $[-1,1]$，正值表示正相关，负值表示负相关，绝对值越大表示线性相关程度越高。在实际做特征工程时候，如果两个变量的相关系数取值为负，可以将特征变量取负号，使之与目标变量正相关，这样来保证所有特征与目标之间都是正相关。</p><p>两个变量之间的 <strong>Pearson</strong> 相关系数定义为两个变量之间的协方差和标准差的商：</p><script type="math/tex; mode=display">\rho_{\boldsymbol{x},\boldsymbol{y}}=\frac{\text{cov}(\boldsymbol{x},\boldsymbol{y})}{\sigma_\boldsymbol{x}\sigma_\boldsymbol{y}}=\frac{E[(\boldsymbol{x}-\mu_\boldsymbol{x},\boldsymbol{y}-\mu_\boldsymbol{y})]}{\sigma_\boldsymbol{x}\sigma_\boldsymbol{y}} \qquad(1)</script><p>上式定义了<strong>总体</strong>相关系数，常用希腊小写字母 $\rho$ 作为代表符号。估算样本的协方差和标准差，可得到<strong>样本 Pearson 相关系数</strong>，用英文小写字母 $r$ 表示：</p><script type="math/tex; mode=display">r_{\boldsymbol{x},\boldsymbol{y}}=\frac{\sum ^n _{i=1}(x_i - \overline{x})(y_i - \overline{y})}{\sqrt{\sum ^n _{i=1}(x_i - \overline{x})^2} \sqrt{\sum ^n _{i=1}(y_i - \overline{y})^2}} \qquad(2)</script><p>记 $\boldsymbol{x}’=\boldsymbol{x}-\overline{x}$ 和 $\boldsymbol{y}’=\boldsymbol{y}-\overline{y}$ 表示对变量 $\boldsymbol{x}$ 和 $\boldsymbol{y}$ 进行 $0$ 均值化，则实际上 $\boldsymbol{x}$ 和 $\boldsymbol{y}$ 的 <strong>Pearson</strong> 相关系数就是 $\boldsymbol{x}’$ 和 $\boldsymbol{y}’$ 的 <strong>cosine</strong> 相似度：$r_{\boldsymbol{x},\boldsymbol{y}}=\cos(\boldsymbol{x}’,\boldsymbol{y}’)=\frac{\boldsymbol{x}’\cdot\boldsymbol{y}’}{|\boldsymbol{x}’|\cdot|\boldsymbol{y}’|}$。</p><h3 id="Pearson-相关系数的使用条件"><a href="#Pearson-相关系数的使用条件" class="headerlink" title="Pearson 相关系数的使用条件"></a>Pearson 相关系数的使用条件</h3><p>使用 <strong>Pearson</strong> 相关系数之前需要检查数据是否满足前置条件：</p><ol><li>两个变量间有线性关系；</li><li>变量是连续变量；</li><li>变量均符合正态分布，且二元分布也符合正态分布；</li><li>两变量独立；</li><li>两变量的方差不为 0；</li></ol><p>这些条件在实际中很容易被忽略。</p><p>例如，在视频推荐中，我们可以将用户对视频的播放完成度作为目标变量，检测其他连续型特征与它的相关性，或者将这些连续型特征做特定的变换后，检测其与播放完成度的相关性。</p><p>但是播放完成度实际上不是正态分布的，如下图所示（实际上大多数日志统计特征，如用户播放视频数、视频播放完成度等，也都不服从正态分布），因此实际上是不能使用 <strong>Pearson</strong> 相关系数的，这时候可以用 <strong>Spearman</strong> 或者 <strong>Kendall</strong> 相关系数来代替。</p><img src="/2019/07/20/feature-selection-pearson/play-ratio-distribution.png" title="图 1. 视频播放完成度分布"><p>另外要注意的是，如果两个变量本身就是线性的关系，那么 <strong>Pearson</strong> 相关系数绝对值越大相关性越强，绝对值越小相关性越弱；但在当两个变量关系未知情况下，<strong>Pearson</strong> 相关系数的大小就没有什么指导意义了，它的绝对值大小并不能表征变量间的相关性强弱，这个时候最好能够画图出来看看作为辅助判断。我会在下面的例子里再详细的说明这一点。</p><h3 id="举例说明"><a href="#举例说明" class="headerlink" title="举例说明"></a>举例说明</h3><p>我们举个例子来看如何计算 <strong>Pearson</strong> 相关系数（这里仅仅演示计算过程，实际上数据的分布也不满足使用 <strong>Pearson</strong> 相关系数的条件）。</p><p>考虑视频推荐场景下，假设我们的目标 (之一) 是最大化视频的播放完成度 $y$，播放完成度的取值范围是 $[0,1]$，我们需要分析哪些因素跟 $y$ 相关，例如有一维特征是表示用户对视频的偏好度，记为 $x$，它的取值范围也是 $[0,1]$，我们把几条样本中 $x$ 和 $y$ 的取值计算出来，并画成散点图，如下所示：</p><img src="/2019/07/20/feature-selection-pearson/ratio-preference.png" title="图 2. 用户对视频的偏好度与播放完成度的对应关系"><p>我们可以按照公式 (2) 来计算 $x$ 与 $y$ 的 <strong>Pearson</strong> 相关系数：</p><ol><li>计算变量平均值：$\overline{x} = 0.5,\ \overline{y}=0.55$；</li><li>计算平移后的变量：$\boldsymbol{x}=[-0.4,-0.3,-0.2,-0.1,0.1,0.2,0.3,0.4]$，$\boldsymbol{y}=[-0.45,-0.45,-0.35,0.05,0.15,0.25,0.35,0.45]$；</li><li>计算公式 (2) 的结果：$r=\frac{0.73}{\sqrt{0.6}\cdot\sqrt{ 0.94}}=0.972$； </li></ol><p>通过计算，我们发现，这个特征与目标变量之间的线性相关性非常高，这与我们看图得到的认知是一致的。因此我们可以把这一维特征作为有效特征加入。</p><p>但是，如果我们对这个例子稍加修改，将最后一个数据点 $(0.9,1.0)$ 改为 $(0.9,-1.0)$，如图 3 所示：</p><img src="/2019/07/20/feature-selection-pearson/ratio-preference-abnormal.png" title="图 3. 引入异常数据对 Pearson 相关系数的影响"><p>从我们的观察来看，最后一个数据点可能是噪声或者异常值，对我们判断两个变量的线性相关性应该不造成影响，但是实际上，我们再次计算一下这两个变量的 <strong>Pearson</strong> 相关系数，此时的值仅仅只有 $-0.0556$，可以说是几乎不线性相关了，这说明 <strong>Pearson</strong> 相关系数小并不代表线性相关性一定弱。在这种情况下，我们应该在数据清洗阶段把特征的异常值过滤或者平滑掉以后，再计算它与目标的相关系数。</p><p>反过来，<strong>Pearson</strong> 相关系数大也并不代表线性相关性一定强。<a href="https://en.wikiversity.org/wiki/Correlation" target="_blank" rel="noopener">图 4</a> 列举了几个 <strong>Pearson</strong> 相关系数均为 $0.816$ 的变量数据，其中有些变量间并非明显的线性相关，或者是明显的二次相关，只是 <strong>Pearson</strong> 相关系数恰好较大而已。</p><img src="/2019/07/20/feature-selection-pearson/different-shape-of-same-pearson.png" title="图 4. 几组 Pearson 相关系数为 $0.816$ 的数据"><blockquote><p>附示例的 python 代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = [<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = [<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>, <span class="number">1.0</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pearsonr(x, y)</span><br><span class="line">(<span class="number">0.97203814535663591</span>, <span class="number">5.3516208203873684e-05</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z = [<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>, <span class="number">-1.0</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pearsonr(x, z)</span><br><span class="line">(<span class="number">-0.055618651039326214</span>, <span class="number">0.89592989552025337</span>)</span><br></pre></td></tr></table></figure><p>这里，<code>pearsonr</code> 返回的第二个结果是 p-value，其具体含义可参考<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html" target="_blank" rel="noopener">官方文档</a>。</p></blockquote><h3 id="Take-aways"><a href="#Take-aways" class="headerlink" title="Take-aways"></a>Take-aways</h3><p>本文简单的介绍了基于 <strong>Pearson</strong> 相关系数的特征选择方法，主要注意点总结如下：</p><ol><li><strong>Pearson</strong> 相关系数是用来检测两个<strong>连续型变量</strong>之间<strong>线性相关</strong>的程度，并且要求这两个变量分别分布服从正态分布；</li><li><strong>Pearson</strong> 相关系数仅能度量变量间的线性相关性，如果变量间相关性未知，则 <strong>Pearson</strong> 相关系数的大小没有指导意义，此时需要借助可视化手段辅助判断；</li><li>两变量的 <strong>Pearson</strong> 相关系数实际上是这两个变量 $0$ 均值化后的 <strong>cosine</strong> 相似度；</li><li>如果两个变量是非线性相关，为了使用线性模型，可以先将特征变量进行非线性变换，使之与目标线性相关；</li><li><strong>Pearson</strong> 相关系数对异常值比较敏感，在数据清洗阶段需要将异常值过滤或者平滑处理。</li></ol><hr><blockquote><h4 id="这是特征选择系列文章的第一篇，其他文章可参考："><a href="#这是特征选择系列文章的第一篇，其他文章可参考：" class="headerlink" title="这是特征选择系列文章的第一篇，其他文章可参考："></a>这是特征选择系列文章的第一篇，其他文章可参考：</h4><ol><li><a href="https://guyuecanhui.github.io/2019/07/20/feature-selection-pearson/">常用的特征选择方法之 Pearson 相关系数</a></li><li><a href="https://guyuecanhui.github.io/2019/07/28/feature-selection-spearman/">常用的特征选择方法之 Spearman 相关系数</a></li><li><a href="https://guyuecanhui.github.io/2019/07/28/feature-selection-kendall/">常用的特征选择方法之 Kendall 秩相关系数</a></li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;众所周知，特征选择是机器学习活动至关重要的一步。最理想的情况下，我们把所有影响目标的独立因素给找出来，然后使用合适的量化手段，就能够得到完美描述目标问题的特征列表，用这些特征去建立合适容量的模型，这样的模型能够完美的匹配我们要解决的任务。&lt;/p&gt;
&lt;p&gt;但是实际上这种想法太难实现了，我们往往只能从已有的数据出发，通过一些特征变换和组合得到一些原始特征，然后从这些原始特征中选出与目标相关的特征。&lt;/p&gt;
&lt;p&gt;随着深度网络的崛起，越来越多的未经复杂变换的原始特征被加入到了深度网络中，大家期待有用的特征能够被自动的抽取和组合出来。但是这并不意味着特征工程就不需要了，推荐系统的大牛 Xavier 在技术博客《Rules of Machine Learning: Best Practices for ML Engineering》中提到很多关于特征工程的建议，非常值得一读，其中包含的思想就是特征是随着系统的优化进程而逐步添加的，并非一蹴而就，要始终保证特征的简单、直观、可复用、可监控和可靠性，这意味着我们需要时常对系统中存量特征做测试和筛选。&lt;/p&gt;
&lt;p&gt;特征选择通常有过滤法（Filter）、打包法（Wrap）和嵌入法（Embed），其中，后两者都是与模型相关的，需要具体问题具体对待，而过滤法是指对特征进行预处理，提前过滤掉一些对目标无益（即对模型无益）的特征，它只考虑任务目标，而与模型无关。&lt;/p&gt;
    
    </summary>
    
      <category term="特征工程" scheme="https://guyuecanhui.github.io/categories/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"/>
    
    
      <category term="特征" scheme="https://guyuecanhui.github.io/tags/%E7%89%B9%E5%BE%81/"/>
    
      <category term="特征选择" scheme="https://guyuecanhui.github.io/tags/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/"/>
    
      <category term="特征过滤" scheme="https://guyuecanhui.github.io/tags/%E7%89%B9%E5%BE%81%E8%BF%87%E6%BB%A4/"/>
    
      <category term="Pearson" scheme="https://guyuecanhui.github.io/tags/Pearson/"/>
    
  </entry>
  
  <entry>
    <title>用 FTRL 训练 FM 模型</title>
    <link href="https://guyuecanhui.github.io/2019/07/03/ftrl-fm/"/>
    <id>https://guyuecanhui.github.io/2019/07/03/ftrl-fm/</id>
    <published>2019-07-03T14:45:49.000Z</published>
    <updated>2020-06-10T13:17:22.058Z</updated>
    
    <content type="html"><![CDATA[<p>近期尝试了基于 <strong>FTRL</strong> 来训练 <strong>FM</strong> 模型，用于短视频的排序。这篇博客主要总结一下算法的理论推导和工程化的一些心得。</p><a id="more"></a><h2 id="一、FM-Factorization-Machines-模型推导"><a href="#一、FM-Factorization-Machines-模型推导" class="headerlink" title="一、FM (Factorization Machines) 模型推导"></a>一、FM (Factorization Machines) 模型推导</h2><h3 id="FM-模型简介"><a href="#FM-模型简介" class="headerlink" title="FM 模型简介"></a>FM 模型简介</h3><p>在设计排序模型时，至关重要的步骤就是特征的构造和选择。除了一些简单单特征外，往往要对特征进行组合，例如对用户的年龄、性别组合，对视频的演员、类别进行组合等，更大的特征空间能够增加模型表征能力。对于特征组合来说，业界现在通用的做法主要有两大类：</p><ul><li><strong>FM</strong> 系列，常见的模型包括 <strong>FM</strong>，<strong>FFM</strong>，<strong>DeepFM</strong>，它们对特征的取值范围比较敏感。</li><li><strong>Tree</strong> 系列，常见的模型包括 <strong>GBDT</strong>，它们对特征的取值范围不敏感。</li></ul><p>其中，<strong>FM</strong> 系列由于适合处理大规模稀疏数据，并且易于与深度神经网络结合，因此使用十分广泛，成为大厂居家必备。</p><p><strong>FM</strong> 模型的主要思想是在 <strong>LR</strong> 的基础上，对所有的特征自动做两两组合$^{[1,2]}$。两两组合最直观的方法就是为每对特征组合设置一个参数（例如 <strong>Poly2</strong> 模型），但是这样就需要 $\text{O}(n^2)$ 个参数，当特征数量很多时，需要的样本量也是巨大的，往往不可能所有的参数都有充足的样本训练。因此 <strong>FM</strong> 考虑使用矩阵分解的方式来还原这个 $n\times n$ 的参数矩阵，只需要 $n\times k$ （$k$ 通常是个很小的常数）的参数即可实现特征两两组合的目的。 </p><p>具体来说，给定样本 $z=(\boldsymbol{x},y)$，记 $\boldsymbol{v}_i = (v_i^{(1)},\cdots,v_i^{(d)})^\top$ 为第 $i$ 维特征对应的隐式向量，则 <strong>FM</strong> 模型为：</p><script type="math/tex; mode=display">\begin{align}f(\boldsymbol{x}|\boldsymbol{w})&=w_0+\sum_{i=1}^n w_ix_i+\sum_{i=1}^{n}\sum_{j=i+1}^{n} (\boldsymbol{v}_i^\top \boldsymbol{v}_j)x_ix_j \\&=w_0+\sum_{i=1}^n w_ix_i+\frac{1}{2}\Big(\sum_{i=1}^{n}\sum_{j=1}^{n}\sum_{k=1}^{d} v_i^{(k)} v_j^{(k)}x_ix_j- \sum_{i=1}^{n}\sum_{k=1}^{d} (v_i^{(k)}x_i)^2\Big) \\&=w_0+\sum_{i=1}^n w_ix_i+\frac{1}{2}\sum_{k=1}^{d}\Big(\sum_{i=1}^{n}v_i^{(k)} x_i\sum_{j=1}^{n} v_j^{(k)} x_j- \sum_{i=1}^{n} (v_i^{(k)}x_i)^2\Big) \\&=w_0+\sum_{i=1}^n w_ix_i+\frac{1}{2}\sum_{k=1}^{d}\Big(\big(\sum_{i=1}^{n}v_i^{(k)} x_i \big)^2- \sum_{i=1}^{n} (v_i^{(k)}x_i)^2\Big)\end{align} \qquad (1)</script><p><strong>FM</strong> 的参数包括 $\boldsymbol{w}={w_0,\cdots w_n,v_1^{(1)},\cdots v_n^{(d)}}$，容易得到 <strong>FM</strong> 对各参数的偏导如下：</p><script type="math/tex; mode=display">\frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w}=\begin{cases}\begin{align}1 &, \qquad w=w_0 \\x_i &, \qquad w=w_i,\ i=1,\cdots,n \\x_i\Big(\sum_{j=1}^n v_j^{(k)}x_j - v_i^{(k)}x_i\Big) &, \qquad w=v_i^{(k)},\ i=1,\cdots,n;\ k=1,\cdots,d\end{align}\end{cases} \qquad (2)</script><h3 id="FM-模型求解（回归问题）"><a href="#FM-模型求解（回归问题）" class="headerlink" title="FM 模型求解（回归问题）"></a>FM 模型求解（回归问题）</h3><p>此时直接将 $\hat{y} = f(\boldsymbol{x}|\boldsymbol{w})$ 作为对 $y$ 的预测结果，因此可以将样本 $z=(\boldsymbol{x},y)$ 的损失函数定义为：</p><script type="math/tex; mode=display">l(\boldsymbol{w},z) = \big(\hat{y}-y\big)^2= \big(f(\boldsymbol{x}|\boldsymbol{w})-y\big)^2 \qquad(3)</script><p>损失函数对参数的偏导为：</p><script type="math/tex; mode=display">\begin{align}\frac{\partial l(\boldsymbol{w},z)}{\partial w} &= 2\big(\hat{y}-y\big)\cdot \frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w} \\&= 2 \big(f(\boldsymbol{x}|\boldsymbol{w})-y\big)\cdot \frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w}\end{align}\qquad(4)</script><h3 id="FM-模型求解（二分类问题）"><a href="#FM-模型求解（二分类问题）" class="headerlink" title="FM 模型求解（二分类问题）"></a>FM 模型求解（二分类问题）</h3><p>此时将 $\hat{y} = \pi(f(\boldsymbol{x}|\boldsymbol{w}))=\frac{1}{1+e^{-f(\boldsymbol{x}|\boldsymbol{w})}}$  作为对 $y$ 的预测结果，其中，$\pi(x)$ 为 <strong>Sigmoid</strong> 函数。还是分标签取值来进行讨论（损失函数的推导参考 <strong><a href="https://guyuecanhui.github.io/2019/05/15/lr/">LR 模型</a></strong>）。</p><h4 id="1-Label-为-1-0"><a href="#1-Label-为-1-0" class="headerlink" title="1. Label 为 {1,0}"></a>1. Label 为 {1,0}</h4><p>则将样本 $z=(\boldsymbol{x},y)$ 的损失函数定义为 <strong>LogLoss</strong> 函数：</p><script type="math/tex; mode=display">l(\boldsymbol{w},z) = -yf(\boldsymbol{x}|\boldsymbol{w})+\ln(1+e^{f(\boldsymbol{x}|\boldsymbol{w})})\big)\qquad(5)</script><p>损失函数对参数的偏导为：</p><script type="math/tex; mode=display">\begin{align}\frac{\partial l(\boldsymbol{w},z)}{\partial w} &= -y\cdot\frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w}+\frac{1}{1+e^{f(\boldsymbol{x}|\boldsymbol{w})}}\cdot e^{f(\boldsymbol{x}|\boldsymbol{w})} \cdot\frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w} \\&=\big(\pi(f(\boldsymbol{x}|\boldsymbol{w}))-y\big)\cdot \frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w} \\&=\big(\hat{y}-y\big)\cdot \frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w}\end{align} \qquad (6)</script><h4 id="2-Label-为-1-1"><a href="#2-Label-为-1-1" class="headerlink" title="2. Label 为 {1,-1}"></a>2. Label 为 {1,-1}</h4><p>则将样本 $z=(\boldsymbol{x},y)$ 的损失函数定义为 <strong>SigmoidLoss</strong> 函数：</p><script type="math/tex; mode=display">l(\boldsymbol{w},z) = \ln(1+e^{-yf(\boldsymbol{x}|\boldsymbol{w})})\big)\qquad(7)</script><p>损失函数对参数的偏导为：</p><script type="math/tex; mode=display">\begin{align}\frac{\partial l(\boldsymbol{w},z)}{\partial w} &= \frac{1}{1+e^{-yf(\boldsymbol{x}|\boldsymbol{w})}}\cdot e^{-yf(\boldsymbol{x}|\boldsymbol{w})} \cdot(-y)\cdot\frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w} \\&=y\cdot\big(\frac{1}{1+e^{-yf(\boldsymbol{x}|\boldsymbol{w})}}-1\big)\cdot \frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w} \\&=y\cdot\Big(\pi\big(yf(\boldsymbol{x}|\boldsymbol{w})\big)-1\Big)\cdot \frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w}\end{align} \qquad (8)</script><h2 id="二、FTRL-Optimizer-介绍"><a href="#二、FTRL-Optimizer-介绍" class="headerlink" title="二、FTRL Optimizer 介绍"></a>二、FTRL Optimizer 介绍</h2><p>上面一陀公式实际上是优化算法求梯度的时候用到的。优化算法目前有很多种，在如在线更新模型或者在线排序等对性能有严格要求的场景中，模型的稀疏解十分关键。稀疏的模型意味着只保留最关键特征的参数，意味着更少的存储、查询与计算。为了得到模型的稀疏解，通常的做法是使用 <strong>L1</strong> 正则、基于参数大小或者累积梯度大小的截断等技术。其中，<strong>FTRL</strong> 集众家之长，实现了精度与稀疏性的平衡$^{[3]}$。</p><p><strong>FTRL</strong> 更像是一种启发式的模型组装，其特征权重的更新公式为：</p><script type="math/tex; mode=display">\boldsymbol{w}^{t+1}=\arg \min_\boldsymbol{w}(\boldsymbol{g}^{1:t}\cdot \boldsymbol{w}+\lambda_1 || \boldsymbol{w}||_1+\frac{1}{2}\lambda_2 || \boldsymbol{w}||_2^2 +\frac{1}{2}\sum_{j=1}^t\sigma^j || \boldsymbol{w}-\boldsymbol{w}^j ||_2^2) \qquad(9)</script><p>其中，$\boldsymbol{g}^{1:t}$ 表示 $1\sim t$ 轮迭代中参数梯度的累积和，其中，<strong>L1</strong> 正则化部分是为了生成稀疏解，<strong>L2</strong> 正则化部分是为了使解更平滑（在论文的推导中不包含这一项），而 $\parallel \boldsymbol{w}-\boldsymbol{w}^t\parallel^2_2$ 是为了保证 $\boldsymbol{w}$ 不要离已迭代过的解太远。经过比较复杂的推导（参考文献 [4]），可以得到每一维参数的求解式：</p><script type="math/tex; mode=display">w^{t+1}_i=\begin{cases}\begin{align}0  &, \qquad |z^t_i|<\lambda_1 \\-\Big(\lambda_2+\frac{\beta+\sqrt{s^t_i}}{\alpha}\Big)^{-1}\cdot\big(z^t_i-\lambda_1\cdot \text{sgn}(z^t_i)\big) &, \qquad \text{otherwise}\end{align}\end{cases} \qquad(10)</script><p>其中，令 <script type="math/tex">z_i^t=g^{1:t}-\sum_{s=1}^t\sigma_s\boldsymbol{w}_s, \ s_i^t=\sum_{j=1}^t (g_i^j)^2</script>，主要是方便存储和迭代计算。</p><h2 id="三、基于-FTRL-训练-FM-的算法流程"><a href="#三、基于-FTRL-训练-FM-的算法流程" class="headerlink" title="三、基于 FTRL 训练 FM 的算法流程"></a>三、基于 FTRL 训练 FM 的算法流程</h2><p>用 <strong>FTRL</strong> 来训练 <strong>FM</strong> 模型，由于我们组习惯用 {0,1} 作为样本标签，则根据式 (2), (6), (10)，可以得到如下算法流程：</p><h3 id="Algorithm-Ftrl-FM"><a href="#Algorithm-Ftrl-FM" class="headerlink" title="Algorithm Ftrl+FM"></a><strong>Algorithm</strong> Ftrl+FM</h3><img src="/2019/07/03/ftrl-fm/alg-ftrl-fm.png" title="用 FTRL 算法训练 FM 模型流程"><p><strong>FTRL</strong> 算法特别适合在线更新模型，即基于每条实时样本更新模型。但是出于性能和可靠性考虑，也可以稍加修改应用于离线训练或者近线批量训练。例如，离线训练任务，将每天/每小时的数据作为一个批次用来更新 <strong>FM</strong> 模型：在每轮迭代时，需要将一批次样本的所有梯度、损失等计算结果进行汇总（可以简单的用平均值来代替），再用汇总后的值更新模型。为了训练充分，可以对每个批次的样本迭代训练若干轮。训练完的模型需要将参数 $\boldsymbol{w}, \boldsymbol{s}, \boldsymbol{z}$ 保存起来，下次加载后再增量更新；而在线预测时，只需要加载参数 $\boldsymbol{w}$ 即可。</p><p>另外，由于短视频的标签、UP 主等特征变化较快，因此对于离散特征的编码可以考虑使用特征 Hash，虽然牺牲了一定的可解释性，并且存在一定的编码冲突，但是实测下来效果还是不错的，并且工程上确实能省下很多麻烦，提升不少性能。</p><p>最后，虽然 <strong>FM</strong> 模型具备表征特征两两组合的能力，但是实际上我们发现由于样本、调参等的限制，并不能充分发掘每对特征组合的作用，并且该模型对于三个及以上特征的组合就完全无能为力了。因此，实际应用时还是不能太依赖模型的自动特征组合能力，如果有什么对业务比较有帮助的特征，还是人工生成，再一起丢到模型里去训练吧。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Rendle, S. (2011). Factorization Machines. <em>IEEE International Conference on Data Mining</em>.<br>[2] Rendle, S. (2012). Factorization machines with libfm. <em>Acm Transactions on Intelligent Systems &amp; Technology, 3</em>(3), 1-22.<br>[3] McMahan, H. B., Holt, G., Sculley, D., Young, M., Ebner, D., Grady, J., … &amp; Chikkerur, S. (2013, August). Ad click prediction: a view from the trenches. In <em>Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining</em> (pp. 1222-1230). ACM.<br>[4] 冯扬 (2014). 在线最优化求解.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;近期尝试了基于 &lt;strong&gt;FTRL&lt;/strong&gt; 来训练 &lt;strong&gt;FM&lt;/strong&gt; 模型，用于短视频的排序。这篇博客主要总结一下算法的理论推导和工程化的一些心得。&lt;/p&gt;
    
    </summary>
    
      <category term="推荐系统" scheme="https://guyuecanhui.github.io/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="优化" scheme="https://guyuecanhui.github.io/tags/%E4%BC%98%E5%8C%96/"/>
    
      <category term="FTRL" scheme="https://guyuecanhui.github.io/tags/FTRL/"/>
    
      <category term="模型" scheme="https://guyuecanhui.github.io/tags/%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="FM" scheme="https://guyuecanhui.github.io/tags/FM/"/>
    
  </entry>
  
  <entry>
    <title>二项 Logistic Regression 模型</title>
    <link href="https://guyuecanhui.github.io/2019/05/15/lr/"/>
    <id>https://guyuecanhui.github.io/2019/05/15/lr/</id>
    <published>2019-05-15T14:02:00.000Z</published>
    <updated>2020-06-10T13:18:25.520Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要介绍一下二项 <strong>Logistic Regression</strong> 模型推导。</p><a id="more"></a><h3 id="模型描述"><a href="#模型描述" class="headerlink" title="模型描述"></a>模型描述</h3><p>记 $\pi(x)=\frac{1}{1+e^{-x}}$，二项 <strong>Logistic Regression</strong> 模型是如下的条件概率分布：</p><script type="math/tex; mode=display">\begin{cases}P(y=1|\boldsymbol{x})=\pi(\boldsymbol{wx})=\frac{1}{1+e^{-\boldsymbol{wx}}}=\frac{e^{\boldsymbol{wx}}}{1+e^{\boldsymbol{wx}}} \\P(y\not=1|\boldsymbol{x})=1-\pi(\boldsymbol{wx})=\frac{1}{1+e^{\boldsymbol{wx}}}\end{cases}\qquad(1)</script><h3 id="模型求解（极大似然估计）"><a href="#模型求解（极大似然估计）" class="headerlink" title="模型求解（极大似然估计）"></a>模型求解（极大似然估计）</h3><p>常见的 label 设置有正负样本分别为 {1,0} 或 {1,-1}，下面分别讨论两种设置下的损失函数和梯度的推导。首先要假设训练样本独立同分布并且数量足够，模型中待估计的参数为 $\boldsymbol{w}$，似然函数的目标是 $y_i=1$ 时 $\pi(\boldsymbol{wx}_i)$ 尽可能大，且 $y_i\not =1$ 时 $1-\pi(\boldsymbol{wx}_i)$ 尽可能大。</p><h4 id="1-label-为-1-0"><a href="#1-label-为-1-0" class="headerlink" title="1. label 为 {1,0}"></a>1. label 为 {1,0}</h4><p>此时，可以直接将 $\hat{y}=\pi(\boldsymbol{wx})$ 的结果作为对 $y$ 值的预测（或者说是预测结果为 1 的概率）。根据<a href="https://guyuecanhui.github.io/2019/05/11/terminology/">最大似然估计公式</a>，$p(\boldsymbol{x}_i|\boldsymbol{w})=\big(\pi(\boldsymbol{wx}_i)\big)^{y_i}\cdot\big(1-\pi(\boldsymbol{wx}_i)\big)^{1-y_i}$，对数似然函数可以设计为：</p><script type="math/tex; mode=display">\begin{align}H(\boldsymbol{w}) &=\arg \max_{\boldsymbol{w}}\sum_{i=1}^N \ln\Big(\big(\pi(\boldsymbol{wx}_i)\big)^{y_i}\cdot\big(1-\pi(\boldsymbol{wx}_i)\big)^{1-y_i}\Big) \\&=\arg \max_{\boldsymbol{w}}\sum_{i=1}^N \Big(y_i\cdot \ln\big(\pi(\boldsymbol{wx}_i)\big)+(1-y_i)\cdot\big(1-\pi(\boldsymbol{wx}_i)\big)\Big) \\&=\arg \max_{\boldsymbol{w}}\sum_{i=1}^N \Big(y_i\cdot \ln(\frac{e^{\boldsymbol{wx}_i}}{1+e^{\boldsymbol{wx}_i}})+(1-y_i)\cdot \ln(\frac{1}{1+e^{\boldsymbol{wx}_i}})\Big) \\&=\arg \max_{\boldsymbol{w}}\sum_{i=1}^N \Big(y_i\boldsymbol{wx}_i-\ln(1+e^{\boldsymbol{wx}_i})\Big)\qquad(2)\end{align}</script><p>这里，$l_l(\boldsymbol{x},y)=-\big(y\cdot \ln(\hat{y})+(1-y)\cdot\ln(1-\hat{y})\big)=\ln(1+e^{f(\boldsymbol{x})})-yf(\boldsymbol{x})$ 记作样本 $ (\boldsymbol{x},y)$ 的 <strong>LogLoss</strong>，后面会经常见到。</p><p>根据损失函数 $l_l(\boldsymbol{x},y)$，对每个维度上的参数分别求导：</p><script type="math/tex; mode=display">\begin{align}\frac{\partial l_l(\boldsymbol{x},y)}{\partial w_i}&=\frac{1}{(1+e^{\boldsymbol{wx}})}\cdot e^{\boldsymbol{wx}}\cdot x_i-y\cdot x_i\\&=\big(\pi(\boldsymbol{wx})-y\big)\cdot x_i\\&=(\hat{y}-y)\cdot x_i\qquad(3)\end{align}</script><h4 id="2-label-为-1-1"><a href="#2-label-为-1-1" class="headerlink" title="2. label 为 {1,-1}"></a>2. label 为 {1,-1}</h4><p>此时仍然可以认为 $\pi(\boldsymbol{wx})$ 输出了模型预测样本结果为 1 的概率，但是由于负样本的标签为 -1，因此考虑使用 $p(\boldsymbol{x}_i|\boldsymbol{w})=\frac{1}{1+e^{-y_i\boldsymbol{wx}_i}}$，则对数似然函数可以设计为：</p><script type="math/tex; mode=display">\begin{align}H(\boldsymbol{w}) &=\arg \max_{\boldsymbol{w}}\sum_{i=1}^N \ln(\frac{1}{1+e^{-y_i\boldsymbol{wx}_i}}) \\&=\arg \min_{\boldsymbol{w}}\sum_{i=1}^N \ln(1+e^{-y_i\boldsymbol{wx}_i}) \qquad(4)\\\end{align}</script><p>这里，$l_s(\boldsymbol{x},y)=\ln(1+e^{-y\boldsymbol{wx}})$ 称作样本 $(\boldsymbol{x},y)$ 的 <strong>SigmoidLoss</strong>，后面也会经常看到。</p><p>根据损失函数 $l_s(\boldsymbol{x},y)$，对每个维度上的参数分别求导：</p><script type="math/tex; mode=display">\begin{align}\frac{\partial l_s(\boldsymbol{x},y)}{\partial w_i}&=\frac{1}{1+e^{-y\boldsymbol{wx}}}\cdot e^{-y\boldsymbol{wx}}\cdot (-y\cdot x_i) \\&=y\cdot \big(\pi(y\boldsymbol{wx})-1\big)\cdot x_i\qquad(4)\\\end{align}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要介绍一下二项 &lt;strong&gt;Logistic Regression&lt;/strong&gt; 模型推导。&lt;/p&gt;
    
    </summary>
    
      <category term="数学" scheme="https://guyuecanhui.github.io/categories/%E6%95%B0%E5%AD%A6/"/>
    
    
      <category term="模型" scheme="https://guyuecanhui.github.io/tags/%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="线性模型" scheme="https://guyuecanhui.github.io/tags/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="LR" scheme="https://guyuecanhui.github.io/tags/LR/"/>
    
  </entry>
  
</feed>
