<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[常用的特征选择方法之 Kendall 秩相关系数]]></title>
    <url>%2F2019%2F08%2F10%2Ffeature-selection-kendall%2F</url>
    <content type="text"><![CDATA[前面我们已经讨论了 Pearson 相关系数和 Spearman 秩相关系数，它们可以检测连续变量间的相关性，并且 Spearman 秩相关系数还能够检测有序的离散变量间的相关系数。今天我们再讨论一个能够检测有序变量相关性的系数：Kendall 秩相关系数。这里有序变量既包括实数变量，也包括可以排序的类别变量，比如名次、年龄段等。 Kendall 秩相关系数的定义Kendall 秩相关系数是一个非参数性质（与分布无关）的秩统计参数，是用来度量两个有序变量之间单调关系强弱的相关系数，它的取值范围是 $[-1,1]$，绝对值越大，表示单调相关性越强，取值为 $0$ 时表示完全不相关。 原始的 Kendall 秩相关系数定义在一致对 (concordant pairs) 和分歧对 (discordant pairs) 的概念上。所谓一致对，就是两个变量取值的相对关系一致；分歧对则是指它们的相对关系不一致。这么说有点难以理解，我们举个例子。 假设我们为很多不同年龄的用户推送了一条社保相关的视频，然后回收了这些用户的播放完成度，如下表所示： 我们想用 Kendall 秩相关系数来分析用户年龄与该社保视频的播放情况是否相关。为此，我们将年龄和播放完成度分别排序后，对样本中取值进行排序和编号，分别得到 年龄序号 和 播放序号。这时，对于样本 $3$ 和样本 $4$，它们的年龄序号是 $[3,4]$，播放序号是 $[2,4]$，虽然序号不同，但是变化趋势是相同的，因此它们是一致的；对于样本 $2$ 和样本 $3$，它们的年龄序号是 $[2,3]$，播放序号是 $[5,2]$，它们的变化趋势是相反的，因此它们是分歧的。 进一步的，我们观察可以发现，当样本已经按年龄升序排列后，对于每个样本，我们可以简单的数一下该样本后续样本中播放序号大于该样本的样本数量，作为该样本引入的一致对数 (该样本之前的样本与该样本也可能一致，但是已经算过一次了)，将所有样本引入的一致对数加起来就能得到所有样本的一致对数，记为 $c$。 同样的，对于每个样本，我们可以简单的数一下该样本后续样本中播放序号小于该样本的样本数量，作为该样本引入的分歧对数，累加后得到所有样本的分歧对数，记为 $d$。 则原始的 Kendall 秩相关系数定义为： \tau_a=\frac{c-d}{c+d}=\frac{c-d}{\frac{1}{2}\cdot n\cdot (n-1)}\qquad (1)其中，$m=\frac{n\cdot (n-1)}{2}$ 表示所有样本两两组合的数量，在变量没有重复取值的情况下，$m=c+d$。定义 $(1)$ 也被称为 Tau-a，从定义也容易看出，它不能处理变量有相同取值的情况。 为了处理变量有相同取值的情况，我们还要将每个变量中相同取值的数量考虑进来，从而得到扩展的定义： \tau_b=\frac{c-d}{\sqrt{(c+d+t_x)(c+d+t_y)}}\qquad (2)其中，$c$ 在计算的时候只能算 a_i]]></content>
      <categories>
        <category>特征工程</category>
      </categories>
      <tags>
        <tag>特征</tag>
        <tag>特征选择</tag>
        <tag>特征过滤</tag>
        <tag>Kendall</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用的特征选择方法之 Spearman 秩相关系数]]></title>
    <url>%2F2019%2F07%2F28%2Ffeature-selection-spearman%2F</url>
    <content type="text"><![CDATA[上一篇里，我们简单的介绍了基于 Pearson 相关系数的特征选择方法，本篇介绍另一种使用更加广泛的相关系数：Spearman 秩相关系数，简称 Spearman 相关系数。Spearman 相关系数与 Pearson 相关系数、Kendall 相关系数并称统计学三大相关系数，足见其重要性。 有了 Pearson 相关系数，为什么还要用 Spearman 相关系数呢，主要是 Pearson 系数只能度量两个服从正态分布的变量之间线性相关性的强弱 (如果不熟悉可以回顾一下上一篇的介绍)，而 Spearman 系数只度量单调关系，而不考虑具体数值的影响，因此 Spearman 相关系数的应用范围更广，不仅对数据分布不作任何假设，能够容忍异常值，也不需要数据的取值是等距的（例如比赛中，第 1 名和第 2 名的距离与第 2 名和第 3 名的距离是不等的），因此除非是考虑性能的影响，能用 Pearson 系数的地方都能用 Spearman 系数。 Spearman 秩相关系数的定义Spearman 秩相关系数是一个非参数性质（与分布无关）的秩统计参数，是用来度量两个连续型变量之间单调关系强弱的相关系数，取值范围也是 $[-1,1]$。在没有重复数据的情况下，如果一个变量是另外一个变量的严格单调函数，则 Spearman 秩相关系数就是 $1$ 或 $-1$，称变量完全 Spearman 秩相关。 这里的秩相关 (Rank Correlation)，又称等级相关，是将两变量的样本值按数据的大小顺序排列位次，以各要素样本值的位次代替实际数据而求得的一种统计量。排序不论从大到小还是从小到大排都无所谓，只要保证大家排序的标准一致即可。 用 $\rho_s$ 来表示 Spearman 相关系数 (用 $\rho_p$ 表示 Pearson 相关系数)。如果每个变量都没有相同的取值 (即没有相同的秩次)，则 Spearman 相关系数可由下式计算： \rho_s=1-\frac{6\sum{d_i^2}}{n(n^2-1)}其中，$n$ 表示数据点的个数；d_i 表示数据点 (x_i,y_i) 的秩次 (r_{x_i},r_{y_i}) 之差：d_i=r_{x_i}-r_{y_i}。 如果某个变量有重复数据，则计算变量之间的 Spearman 相关系数就是计算变量数据秩次之间的 Pearson 相关系数： \rho_s=\rho_{r_x,r_y}=\frac{\text{cov}(r_x,r_y)}{\sigma_{r_x}\sigma_{r_y}}其中，$r_x$ 表示变量 $\boldsymbol{x}$ 转换后的秩次。从这个定义可以看出来，Spearman 相关系数实际上就是对数据做了秩次变换后的 Pearson 相关系数。 举例说明我们还是拿上一篇的例子来说明。首先将样本进行秩次变换，样本升序排列后的位次如图 1 所示： 需要说明的是，这里变量 $y$ 有两个重复数据 $0.1$，在排序的时候它们的位次相同，此时可以用相同位次的数据所占的位次之和除以数据的数量 (即 $\frac{1+2}{2}=1.5$) 来作为这些重复数据的位次。 根据定义，当存在重复数据的时候，我们计算秩次 (即 $r_x$, $r_y$) 的 Pearson 相关系数 (过程省略)，得到结果 $\rho_s=0.994$，几乎是单调相关了，其数值比直接计算原始数据的 Pearson 相关系数 $\rho_p=0.972$ 还要大一些。 实际上，当 Pearson 相关系数比较大的时候，Spearman 相关系数也比较大；而当 Pearson 相关系数比较小的时候，Spearman 相关系数仍然可能较大，例如变量之间是指数相关 ($y=e^x$，如图 2 所示) 时，它们的 Pearson 相关系数和 Spearman 相关系数分别是 $0.7758$ 和 $1.0$。 最后，我们看看上一篇图 3 所示的异常数据对 Spearman 相关系数的影响，引入异常点 $(0.9,-1.0)$ 后，变量 $x$, $y$ 的 Pearson 相关系数降为了 $\rho_p=-0.0556$，它们的 Spearman 相关系数也受到了较大的影响，降到了 $\rho_s=0.3234$，也就是较弱的正相关性。但是从这个例子仍然可以看出，与 Pearson 相关系数相比，Spearman 相关系数对异常值容忍度更高一些。 附示例的 python 代码： 123456789101112131415&gt;&gt;&gt; from scipy.stats import spearmanr, pearsonr&gt;&gt;&gt; x=[0.1, 0.2, 0.3, 0.4, 0.6, 0.7, 0.8, 0.9]&gt;&gt;&gt; y=[0.1, 0.1, 0.2, 0.6, 0.7, 0.8, 0.9, 1.0]&gt;&gt;&gt; spearmanr(x,y)(0.99402979738800479, 5.2961535156451228e-07)&gt;&gt;&gt; rx=[1, 2, 3, 4, 5, 6, 7, 8]&gt;&gt;&gt; ry=[1.5, 1.5, 3, 4, 5, 6, 7, 8]&gt;&gt;&gt; pearsonr(rx,ry)(0.99402979738800501, 5.2961535156445373e-07)&gt;&gt;&gt; z=[0.1, 0.1, 0.2, 0.6, 0.7, 0.8, 0.9, -1.0]&gt;&gt;&gt; spearmanr(x,z)(0.32335909071657992, 0.43463944855085729)&gt;&gt;&gt; z=[0.1, 0.12, 0.2, 0.6, 0.7, 0.8, 0.9, -1.0]&gt;&gt;&gt; spearmanr(x,z)(0.32335909071657992, 0.43463944855085729) 这里，spearmanr 返回的第二个结果是 p-value，其具体含义可参考官方文档。 Take-aways本文简单介绍了 Spearman 相关系数，主要注意点总结如下： Spearman 相关系数是度量两个连续型变量之间单调关系强弱的相关系数，它对数据的分布不作任何假设，能够容忍异常值，也不需要数据的取值是等距的； Spearman 相关系数实际上就是对数据做了秩次变换后的 Pearson 相关系数，只要能用 Pearson 相关系数的地方就能使用 Spearman 相关系数； Spearman 相关系数还需要对原始数据进行排序，因此计算复杂度高于 Pearson 相关系数，当数据满足 Pearson​ 相关系数的使用条件时，优先考虑使用 Pearson 相关系数。 这是特征选择系列文章的第二篇，其他文章可参考： 常用的特征选择方法之 Pearson 相关系数 常用的特征选择方法之 Spearman 相关系数 常用的特征选择方法之 Kendall 秩相关系数]]></content>
      <categories>
        <category>特征工程</category>
      </categories>
      <tags>
        <tag>特征</tag>
        <tag>特征选择</tag>
        <tag>特征过滤</tag>
        <tag>Spearman</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用的特征选择方法之 Pearson 相关系数]]></title>
    <url>%2F2019%2F07%2F20%2Ffeature-selection-pearson%2F</url>
    <content type="text"><![CDATA[众所周知，特征选择是机器学习活动至关重要的一步。最理想的情况下，我们把所有影响目标的独立因素给找出来，然后使用合适的量化手段，就能够得到完美描述目标问题的特征列表，用这些特征去建立合适容量的模型，这样的模型能够完美的匹配我们要解决的任务。 但是实际上这种想法太难实现了，我们往往只能从已有的数据出发，通过一些特征变换和组合得到一些原始特征，然后从这些原始特征中选出与目标相关的特征。 随着深度网络的崛起，越来越多的未经复杂变换的原始特征被加入到了深度网络中，大家期待有用的特征能够被自动的抽取和组合出来。但是这并不意味着特征工程就不需要了，推荐系统的大牛 Xavier 在技术博客《Rules of Machine Learning: Best Practices for ML Engineering》中提到很多关于特征工程的建议，非常值得一读，其中包含的思想就是特征是随着系统的优化进程而逐步添加的，并非一蹴而就，要始终保证特征的简单、直观、可复用、可监控和可靠性，这意味着我们需要时常对系统中存量特征做测试和筛选。 特征选择通常有过滤法（Filter）、打包法（Wrap）和嵌入法（Embed），其中，后两者都是与模型相关的，需要具体问题具体对待，而过滤法是指对特征进行预处理，提前过滤掉一些对目标无益（即对模型无益）的特征，它只考虑任务目标，而与模型无关。 我打算把常用的特征选择方法都再回顾一遍，力争把每种方法都讲得通俗易懂。这篇文章先介绍 Pearson 相关系数。 Pearson 相关系数的定义Pearson 相关系数是用来检测两个连续型变量之间线性相关的程度，取值范围为 $[-1,1]$，正值表示正相关，负值表示负相关，绝对值越大表示线性相关程度越高。在实际做特征工程时候，如果两个变量的相关系数取值为负，可以将特征变量取负号，使之与目标变量正相关，这样来保证所有特征与目标之间都是正相关。 两个变量之间的 Pearson 相关系数定义为两个变量之间的协方差和标准差的商： \rho_{\boldsymbol{x},\boldsymbol{y}}=\frac{\text{cov}(\boldsymbol{x},\boldsymbol{y})}{\sigma_\boldsymbol{x}\sigma_\boldsymbol{y}}=\frac{E[(\boldsymbol{x}-\mu_\boldsymbol{x},\boldsymbol{y}-\mu_\boldsymbol{y})]}{\sigma_\boldsymbol{x}\sigma_\boldsymbol{y}} \qquad(1)上式定义了总体相关系数，常用希腊小写字母 $\rho$ 作为代表符号。估算样本的协方差和标准差，可得到样本 Pearson 相关系数，用英文小写字母 $r$ 表示： r_{\boldsymbol{x},\boldsymbol{y}}=\frac{\sum ^n _{i=1}(x_i - \overline{x})(y_i - \overline{y})}{\sqrt{\sum ^n _{i=1}(x_i - \overline{x})^2} \sqrt{\sum ^n _{i=1}(y_i - \overline{y})^2}} \qquad(2)记 $\boldsymbol{x}’=\boldsymbol{x}-\overline{x}$ 和 $\boldsymbol{y}’=\boldsymbol{y}-\overline{y}$ 表示对变量 $\boldsymbol{x}$ 和 $\boldsymbol{y}$ 进行 $0$ 均值化，则实际上 $\boldsymbol{x}$ 和 $\boldsymbol{y}$ 的 Pearson 相关系数就是 $\boldsymbol{x}’$ 和 $\boldsymbol{y}’$ 的 cosine 相似度：$r_{\boldsymbol{x},\boldsymbol{y}}=\cos(\boldsymbol{x}’,\boldsymbol{y}’)=\frac{\boldsymbol{x}’\cdot\boldsymbol{y}’}{|\boldsymbol{x}’|\cdot|\boldsymbol{y}’|}$。 Pearson 相关系数的使用条件使用 Pearson 相关系数之前需要检查数据是否满足前置条件： 两个变量间有线性关系； 变量是连续变量； 变量均符合正态分布，且二元分布也符合正态分布； 两变量独立； 两变量的方差不为 0； 这些条件在实际中很容易被忽略。 例如，在视频推荐中，我们可以将用户对视频的播放完成度作为目标变量，检测其他连续型特征与它的相关性，或者将这些连续型特征做特定的变换后，检测其与播放完成度的相关性。 但是播放完成度实际上不是正态分布的，如下图所示（实际上大多数日志统计特征，如用户播放视频数、视频播放完成度等，也都不服从正态分布），因此实际上是不能使用 Pearson 相关系数的，这时候可以用 Spearman 或者 Kendall 相关系数来代替。 另外要注意的是，如果两个变量本身就是线性的关系，那么 Pearson 相关系数绝对值越大相关性越强，绝对值越小相关性越弱；但在当两个变量关系未知情况下，Pearson 相关系数的大小就没有什么指导意义了，它的绝对值大小并不能表征变量间的相关性强弱，这个时候最好能够画图出来看看作为辅助判断。我会在下面的例子里再详细的说明这一点。 举例说明我们举个例子来看如何计算 Pearson 相关系数（这里仅仅演示计算过程，实际上数据的分布也不满足使用 Pearson 相关系数的条件）。 考虑视频推荐场景下，假设我们的目标 (之一) 是最大化视频的播放完成度 $y$，播放完成度的取值范围是 $[0,1]$，我们需要分析哪些因素跟 $y$ 相关，例如有一维特征是表示用户对视频的偏好度，记为 $x$，它的取值范围也是 $[0,1]$，我们把几条样本中 $x$ 和 $y$ 的取值计算出来，并画成散点图，如下所示： 我们可以按照公式 (2) 来计算 $x$ 与 $y$ 的 Pearson 相关系数： 计算变量平均值：$\overline{x} = 0.5,\ \overline{y}=0.55$； 计算平移后的变量：$\boldsymbol{x}=[-0.4,-0.3,-0.2,-0.1,0.1,0.2,0.3,0.4]$，$\boldsymbol{y}=[-0.45,-0.45,-0.35,0.05,0.15,0.25,0.35,0.45]$； 计算公式 (2) 的结果：$r=\frac{0.73}{\sqrt{0.6}\cdot\sqrt{ 0.94}}=0.972$； 通过计算，我们发现，这个特征与目标变量之间的线性相关性非常高，这与我们看图得到的认知是一致的。因此我们可以把这一维特征作为有效特征加入。 但是，如果我们对这个例子稍加修改，将最后一个数据点 $(0.9,1.0)$ 改为 $(0.9,-1.0)$，如图 3 所示： 从我们的观察来看，最后一个数据点可能是噪声或者异常值，对我们判断两个变量的线性相关性应该不造成影响，但是实际上，我们再次计算一下这两个变量的 Pearson 相关系数，此时的值仅仅只有 $-0.0556$，可以说是几乎不线性相关了，这说明 Pearson 相关系数小并不代表线性相关性一定弱。在这种情况下，我们应该在数据清洗阶段把特征的异常值过滤或者平滑掉以后，再计算它与目标的相关系数。 反过来，Pearson 相关系数大也并不代表线性相关性一定强。图 4 列举了几个 Pearson 相关系数均为 $0.816$ 的变量数据，其中有些变量间并非明显的线性相关，或者是明显的二次相关，只是 Pearson 相关系数恰好较大而已。 附示例的 python 代码： 12345678&gt;&gt;&gt; from scipy.stats import pearsonr&gt;&gt;&gt; x = [0.1, 0.2, 0.3, 0.4, 0.6, 0.7, 0.8, 0.9]&gt;&gt;&gt; y = [0.1, 0.1, 0.2, 0.6, 0.7, 0.8, 0.9, 1.0]&gt;&gt;&gt; pearsonr(x, y)(0.97203814535663591, 5.3516208203873684e-05)&gt;&gt;&gt; z = [0.1, 0.1, 0.2, 0.6, 0.7, 0.8, 0.9, -1.0]&gt;&gt;&gt; pearsonr(x, z)(-0.055618651039326214, 0.89592989552025337) 这里，pearsonr 返回的第二个结果是 p-value，其具体含义可参考官方文档。 Take-aways本文简单的介绍了基于 Pearson 相关系数的特征选择方法，主要注意点总结如下： Pearson 相关系数是用来检测两个连续型变量之间线性相关的程度，并且要求这两个变量分别分布服从正态分布； Pearson 相关系数仅能度量变量间的线性相关性，如果变量间相关性未知，则 Pearson 相关系数的大小没有指导意义，此时需要借助可视化手段辅助判断； 两变量的 Pearson 相关系数实际上是这两个变量 $0$ 均值化后的 cosine 相似度； 如果两个变量是非线性相关，为了使用线性模型，可以先将特征变量进行非线性变换，使之与目标线性相关； Pearson 相关系数对异常值比较敏感，在数据清洗阶段需要将异常值过滤或者平滑处理。 这是特征选择系列文章的第一篇，其他文章可参考： 常用的特征选择方法之 Pearson 相关系数 常用的特征选择方法之 Spearman 相关系数 常用的特征选择方法之 Kendall 秩相关系数]]></content>
      <categories>
        <category>特征工程</category>
      </categories>
      <tags>
        <tag>特征</tag>
        <tag>特征选择</tag>
        <tag>特征过滤</tag>
        <tag>Pearson</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用 FTRL 训练 FM 模型]]></title>
    <url>%2F2019%2F07%2F03%2Fftrl-fm%2F</url>
    <content type="text"><![CDATA[近期尝试了基于 FTRL 来训练 FM 模型，用于短视频的排序。这篇博客主要总结一下算法的理论推导和工程化的一些心得。 一、FM (Factorization Machines) 模型推导FM 模型简介在设计排序模型时，至关重要的步骤就是特征的构造和选择。除了一些简单单特征外，往往要对特征进行组合，例如对用户的年龄、性别组合，对视频的演员、类别进行组合等，更大的特征空间能够增加模型表征能力。对于特征组合来说，业界现在通用的做法主要有两大类： FM 系列，常见的模型包括 FM，FFM，DeepFM，它们对特征的取值范围比较敏感。 Tree 系列，常见的模型包括 GBDT，它们对特征的取值范围不敏感。 其中，FM 系列由于适合处理大规模稀疏数据，并且易于与深度神经网络结合，因此使用十分广泛，成为大厂居家必备。 FM 模型的主要思想是在 LR 的基础上，对所有的特征自动做两两组合$^{[1,2]}$。两两组合最直观的方法就是为每对特征组合设置一个参数（例如 Poly2 模型），但是这样就需要 $\text{O}(n^2)$ 个参数，当特征数量很多时，需要的样本量也是巨大的，往往不可能所有的参数都有充足的样本训练。因此 FM 考虑使用矩阵分解的方式来还原这个 $n\times n$ 的参数矩阵，只需要 $n\times k$ （$k$ 通常是个很小的常数）的参数即可实现特征两两组合的目的。 具体来说，给定样本 $z=(\boldsymbol{x},y)$，记 $\boldsymbol{v}_i = (v_i^{(1)},\cdots,v_i^{(d)})^\top$ 为第 $i$ 维特征对应的隐式向量，则 FM 模型为： \begin{align} f(\boldsymbol{x}|\boldsymbol{w})&=w_0+\sum_{i=1}^n w_ix_i+\sum_{i=1}^{n}\sum_{j=i+1}^{n} (\boldsymbol{v}_i^\top \boldsymbol{v}_j)x_ix_j \\ &=w_0+\sum_{i=1}^n w_ix_i+\frac{1}{2}\Big(\sum_{i=1}^{n}\sum_{j=1}^{n}\sum_{k=1}^{d} v_i^{(k)} v_j^{(k)}x_ix_j- \sum_{i=1}^{n}\sum_{k=1}^{d} (v_i^{(k)}x_i)^2\Big) \\ &=w_0+\sum_{i=1}^n w_ix_i+\frac{1}{2}\sum_{k=1}^{d}\Big(\sum_{i=1}^{n}v_i^{(k)} x_i\sum_{j=1}^{n} v_j^{(k)} x_j- \sum_{i=1}^{n} (v_i^{(k)}x_i)^2\Big) \\ &=w_0+\sum_{i=1}^n w_ix_i+\frac{1}{2}\sum_{k=1}^{d}\Big(\big(\sum_{i=1}^{n}v_i^{(k)} x_i \big)^2- \sum_{i=1}^{n} (v_i^{(k)}x_i)^2\Big) \end{align} \qquad (1)FM 的参数包括 $\boldsymbol{w}={w_0,\cdots w_n,v_1^{(1)},\cdots v_n^{(d)}}$，容易得到 FM 对各参数的偏导如下： \frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w}= \begin{cases} \begin{align} 1 &, \qquad w=w_0 \\ x_i &, \qquad w=w_i,\ i=1,\cdots,n \\ x_i\Big(\sum_{j=1}^n v_j^{(k)}x_j - v_i^{(k)}x_i\Big) &, \qquad w=v_i^{(k)},\ i=1,\cdots,n;\ k=1,\cdots,d \end{align} \end{cases} \qquad (2)FM 模型求解（回归问题）此时直接将 $\hat{y} = f(\boldsymbol{x}|\boldsymbol{w})$ 作为对 $y$ 的预测结果，因此可以将样本 $z=(\boldsymbol{x},y)$ 的损失函数定义为： l(\boldsymbol{w},z) = \big(\hat{y}-y\big)^2= \big(f(\boldsymbol{x}|\boldsymbol{w})-y\big)^2 \qquad(3)损失函数对参数的偏导为： \begin{align} \frac{\partial l(\boldsymbol{w},z)}{\partial w} &= 2\big(\hat{y}-y\big)\cdot \frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w} \\ &= 2 \big(f(\boldsymbol{x}|\boldsymbol{w})-y\big)\cdot \frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w} \end{align}\qquad(4)FM 模型求解（二分类问题）此时将 $\hat{y} = \pi(f(\boldsymbol{x}|\boldsymbol{w}))=\frac{1}{1+e^{-f(\boldsymbol{x}|\boldsymbol{w})}}$ 作为对 $y$ 的预测结果，其中，$\pi(x)$ 为 Sigmoid 函数。还是分标签取值来进行讨论（损失函数的推导参考 LR 模型）。 1. Label 为 {1,0}则将样本 $z=(\boldsymbol{x},y)$ 的损失函数定义为 LogLoss 函数： l(\boldsymbol{w},z) = -yf(\boldsymbol{x}|\boldsymbol{w})+\ln(1+e^{f(\boldsymbol{x}|\boldsymbol{w})})\big)\qquad(5)损失函数对参数的偏导为： \begin{align} \frac{\partial l(\boldsymbol{w},z)}{\partial w} &= -y\cdot\frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w}+\frac{1}{1+e^{f(\boldsymbol{x}|\boldsymbol{w})}}\cdot e^{f(\boldsymbol{x}|\boldsymbol{w})} \cdot\frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w} \\ &=\big(\pi(f(\boldsymbol{x}|\boldsymbol{w}))-y\big)\cdot \frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w} \\ &=\big(\hat{y}-y\big)\cdot \frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w} \end{align} \qquad (6)2. Label 为 {1,-1}则将样本 $z=(\boldsymbol{x},y)$ 的损失函数定义为 SigmoidLoss 函数： l(\boldsymbol{w},z) = \ln(1+e^{-yf(\boldsymbol{x}|\boldsymbol{w})})\big)\qquad(7)损失函数对参数的偏导为： \begin{align} \frac{\partial l(\boldsymbol{w},z)}{\partial w} &= \frac{1}{1+e^{-yf(\boldsymbol{x}|\boldsymbol{w})}}\cdot e^{-yf(\boldsymbol{x}|\boldsymbol{w})} \cdot(-y)\cdot\frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w} \\ &=y\cdot\big(\frac{1}{1+e^{-yf(\boldsymbol{x}|\boldsymbol{w})}}-1\big)\cdot \frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w} \\ &=y\cdot\Big(\pi\big(yf(\boldsymbol{x}|\boldsymbol{w})\big)-1\Big)\cdot \frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w} \end{align} \qquad (8)二、FTRL Optimizer 介绍上面一陀公式实际上是优化算法求梯度的时候用到的。优化算法目前有很多种，在如在线更新模型或者在线排序等对性能有严格要求的场景中，模型的稀疏解十分关键。稀疏的模型意味着只保留最关键特征的参数，意味着更少的存储、查询与计算。为了得到模型的稀疏解，通常的做法是使用 L1 正则、基于参数大小或者累积梯度大小的截断等技术。其中，FTRL 集众家之长，实现了精度与稀疏性的平衡$^{[3]}$。 FTRL 更像是一种启发式的模型组装，其特征权重的更新公式为： \boldsymbol{w}^{t+1}=\arg \min_\boldsymbol{w}(\boldsymbol{g}^{1:t}\cdot \boldsymbol{w}+\lambda_1 || \boldsymbol{w}||_1+\frac{1}{2}\lambda_2 || \boldsymbol{w}||_2^2 +\frac{1}{2}\sum_{j=1}^t\sigma^j || \boldsymbol{w}-\boldsymbol{w}^j ||_2^2) \qquad(9)其中，$\boldsymbol{g}^{1:t}$ 表示 $1\sim t$ 轮迭代中参数梯度的累积和，其中，L1 正则化部分是为了生成稀疏解，L2 正则化部分是为了使解更平滑（在论文的推导中不包含这一项），而 $\parallel \boldsymbol{w}-\boldsymbol{w}^t\parallel^2_2$ 是为了保证 $\boldsymbol{w}$ 不要离已迭代过的解太远。经过比较复杂的推导（参考文献 [4]），可以得到每一维参数的求解式： w^{t+1}_i= \begin{cases} \begin{align} 0 &, \qquad |z^t_i|]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>优化</tag>
        <tag>FTRL</tag>
        <tag>模型</tag>
        <tag>FM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二项 Logistic Regression 模型]]></title>
    <url>%2F2019%2F05%2F15%2Flr%2F</url>
    <content type="text"><![CDATA[二项 Logistic Regression 模型推导模型描述记 $\pi(x)=\frac{1}{1+e^{-x}}$，二项 Logistic Regression 模型是如下的条件概率分布： \begin{cases} P(y=1|\boldsymbol{x})=\pi(\boldsymbol{wx})=\frac{1}{1+e^{-\boldsymbol{wx}}}=\frac{e^{\boldsymbol{wx}}}{1+e^{\boldsymbol{wx}}} \\ P(y\not=1|\boldsymbol{x})=1-\pi(\boldsymbol{wx})=\frac{1}{1+e^{\boldsymbol{wx}}} \end{cases}\qquad(1)模型求解（极大似然估计）常见的 label 设置有正负样本分别为 {1,0} 或 {1,-1}，下面分别讨论两种设置下的损失函数和梯度的推导。首先要假设训练样本独立同分布并且数量足够，模型中待估计的参数为 $\boldsymbol{w}$，似然函数的目标是 $y_i=1$ 时 $\pi(\boldsymbol{wx}_i)$ 尽可能大，且 $y_i\not =1$ 时 $1-\pi(\boldsymbol{wx}_i)$ 尽可能大。 1. label 为 {1,0}此时，可以直接将 $\hat{y}=\pi(\boldsymbol{wx})$ 的结果作为对 $y$ 值的预测（或者说是预测结果为 1 的概率）。根据最大似然估计公式，$p(\boldsymbol{x}_i|\boldsymbol{w})=\big(\pi(\boldsymbol{wx}_i)\big)^{y_i}\cdot\big(1-\pi(\boldsymbol{wx}_i)\big)^{1-y_i}$，对数似然函数可以设计为： \begin{align} H(\boldsymbol{w}) &=\arg \max_{\boldsymbol{w}}\sum_{i=1}^N \ln\Big(\big(\pi(\boldsymbol{wx}_i)\big)^{y_i}\cdot\big(1-\pi(\boldsymbol{wx}_i)\big)^{1-y_i}\Big) \\ &=\arg \max_{\boldsymbol{w}}\sum_{i=1}^N \Big(y_i\cdot \ln\big(\pi(\boldsymbol{wx}_i)\big)+(1-y_i)\cdot\big(1-\pi(\boldsymbol{wx}_i)\big)\Big) \\ &=\arg \max_{\boldsymbol{w}}\sum_{i=1}^N \Big(y_i\cdot \ln(\frac{e^{\boldsymbol{wx}_i}}{1+e^{\boldsymbol{wx}_i}})+(1-y_i)\cdot \ln(\frac{1}{1+e^{\boldsymbol{wx}_i}})\Big) \\ &=\arg \max_{\boldsymbol{w}}\sum_{i=1}^N \Big(y_i\boldsymbol{wx}_i-\ln(1+e^{\boldsymbol{wx}_i})\Big)\qquad(2) \end{align}这里，$l_l(\boldsymbol{x},y)=-\big(y\cdot \ln(\hat{y})+(1-y)\cdot\ln(1-\hat{y})\big)=\ln(1+e^{f(\boldsymbol{x})})-yf(\boldsymbol{x})$ 记作样本 $ (\boldsymbol{x},y)$ 的 LogLoss，后面会经常见到。 根据损失函数 $l_l(\boldsymbol{x},y)$，对每个维度上的参数分别求导： \begin{align} \frac{\partial l_l(\boldsymbol{x},y)}{\partial w_i} &=\frac{1}{(1+e^{\boldsymbol{wx}})}\cdot e^{\boldsymbol{wx}}\cdot x_i-y\cdot x_i\\ &=\big(\pi(\boldsymbol{wx})-y\big)\cdot x_i\\ &=(\hat{y}-y)\cdot x_i\qquad(3) \end{align}2. label 为 {1,-1}此时仍然可以认为 $\pi(\boldsymbol{wx})$ 输出了模型预测样本结果为 1 的概率，但是由于负样本的标签为 -1，因此考虑使用 $p(\boldsymbol{x}_i|\boldsymbol{w})=\frac{1}{1+e^{-y_i\boldsymbol{wx}_i}}$，则对数似然函数可以设计为： \begin{align} H(\boldsymbol{w}) &=\arg \max_{\boldsymbol{w}}\sum_{i=1}^N \ln(\frac{1}{1+e^{-y_i\boldsymbol{wx}_i}}) \\ &=\arg \min_{\boldsymbol{w}}\sum_{i=1}^N \ln(1+e^{-y_i\boldsymbol{wx}_i}) \qquad(4)\\ \end{align}这里，$l_s(\boldsymbol{x},y)=\ln(1+e^{-y\boldsymbol{wx}})$ 称作样本 $(\boldsymbol{x},y)$ 的 SigmoidLoss，后面也会经常看到。 根据损失函数 $l_s(\boldsymbol{x},y)$，对每个维度上的参数分别求导： \begin{align} \frac{\partial l_s(\boldsymbol{x},y)}{\partial w_i} &=\frac{1}{1+e^{-y\boldsymbol{wx}}}\cdot e^{-y\boldsymbol{wx}}\cdot (-y\cdot x_i) \\ &=y\cdot \big(\pi(y\boldsymbol{wx})-1\big)\cdot x_i\qquad(4)\\ \end{align}]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>模型</tag>
        <tag>线性模型</tag>
        <tag>LR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[符号约定与常用公式]]></title>
    <url>%2F2019%2F05%2F11%2Fterminology%2F</url>
    <content type="text"><![CDATA[一、推荐系统常用符号含义 符号表示 含义 $\boldsymbol{x}$ 输入变量，一般为特征向量 $\boldsymbol{x}_i=(x_i^{(1)}, \cdots, x_i^{(n)})^{\top}$ 第 $i$ 个输入变量的取值，在推导损失函数等场景下，由于每次只考虑一条样本，记样本为 $\boldsymbol{x}=(x_1,\cdots,x_n)$，此时 $x_i$ 表示样本的第 $i$ 维特征 \mathcal{X}=\{\boldsymbol{x}_1,\cdots,\boldsymbol{x}_N\} 输入实例集合 (x_j^{(i)})^k 第 $j$ 个输入变量的第 $i$ 维特征取值的 $k$ 次方 $y$ 输出变量，一般为样本标签 $y_i$ 第 $i$ 个输出变量的取值 $\mathcal{Y}={y_1,\cdots,y_N}$ 输出实例集合 $(\boldsymbol{x}_i,y_i)$ 第 $i$ 个样本点 $\mathcal{T}={(\boldsymbol{x}_1,y_1),\cdots,(\boldsymbol{x}_N,y_N)}$ 训练数据集 $\boldsymbol{w}=(w_1,\cdots,w_n)$ 权重向量 $w_i^t$ 第 $i$ 维特征的权重在第 $t$ 轮迭代的取值 $\parallel \boldsymbol{w} \parallel_i^j$ 权重向量 $\boldsymbol{w}$ 的 Li 范数的 $j$ 次方，例如 L1 范数：$\parallel \boldsymbol{w} \parallel_1$，L2 范数： $\parallel \boldsymbol{w} \parallel_2^2$ $\boldsymbol{g}=(g_1,\cdots,g_n)$ 梯度向量 $\psi(\boldsymbol{w})$ 正则化函数 二、常用定理中心极限定理 样本的平均值约等于总体的平均值。 给定一个任意分布的总体，从中随机抽取 $N$ 个样本，抽取 $k$ 次，这 $k$ 组抽样平均值的分布接近正态分布。 经验表明，当每组抽样数量 $N\ge 30$ 时就服从中心极限定理。 极大似然估计前提假设：训练样本的分布能代表样本的真实分布；每个样本集中的样本都是所谓独立同分布的随机变量，且有充分的训练样本。 最大似然估计的目的是：利用已知的样本结果，反推最有可能（最大概率）导致这样结果的参数值。换句话说，极大似然估计提供了一种给定观察数据来评估模型参数的方法，即：模型已定，参数未知。 ML估计的求解方法： \hat{\theta} = \arg \max_{\theta} l(\theta) = \arg \max_{\theta}\prod_{i=1}^N p(\boldsymbol{x}_i|\theta)为了便于分析，定义对数似然函数 $H(\theta) = \ln l(\theta)$，则： \hat{\theta} = \arg \max_{\theta} \ln l(\theta) = \arg \max_{\theta}\sum_{i=1}^N \ln p(\boldsymbol{x}_i|\theta)当 $H(\theta)$ 连续可微的情况下，可以通过求导（单个未知参数）或者求梯度（多个未知参数）的方式求解方程。 三、常用的函数和公式Sigmoid 函数 表达式：$\pi(x)=\frac{1}{1+e^{-x}}=\frac{e^x}{1+e^x}$； 导数：$\pi’(x)=\pi(x)\big(1-\pi(x)\big)$； LogLoss 样本的 $(\boldsymbol{x},y)$ 的 SigmoidLoss 表达式：$l_{l}(\boldsymbol{x},y)=\ln(1+e^{f(\boldsymbol{x})})-yf(\boldsymbol{x})$ 导数：$l_l’(\boldsymbol{x},y)=\Big(\pi\big(f(\boldsymbol{x})\big)-y\Big)\cdot f’(\boldsymbol{x})$ 使用极大似然估计，标签值为 {0,1}，推导参考 LR 模型 SigmoidLoss 样本的 $(\boldsymbol{x},y)$ 的 SigmoidLoss 表达式：$l_s(\boldsymbol{x},y)=\ln(1+e^{-yf(\boldsymbol{x})})$ 导数：$l_s’(\boldsymbol{x},y)=y\Big(\pi\big(y\cdot f(\boldsymbol{x})\big)-1\Big)\cdot f’(\boldsymbol{x})$ 使用极大似然估计，标签值为 {-1,1}，推导参考 LR 模型]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>符号</tag>
        <tag>定理</tag>
        <tag>公式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从 SimRank 到 SimRank++]]></title>
    <url>%2F2019%2F05%2F10%2Fsimrankpp%2F</url>
    <content type="text"><![CDATA[从 SimRank 到 SimRank++上一篇博客《SimRank与视频相似度计算》 介绍了 SimRank$^{[1]}$ 及其在视频推荐中的应用，这一篇再谈谈 SimRank++。顾名思义，SimRank++ 是在 SimRank 的基础上做了一些优化，在文献 [2] 中提出时是为了解决搜索词改写的问题，本质上也就是计算搜索词的相似度。作者发现，当需要考虑二部图的边权信息时，原始的 SimRank 模型难以评估物品间相似度的可信度，这篇博客从视频推荐的角度来阐释作者的优化点。 从用户到用户群由于我们影片的观众量级在千万级，而影片的数量在十万级，因此使用 SimRank 模型来计算视频相似度时，最大的计算和存储瓶颈在于用户相似矩阵、用户-视频转移矩阵及视频-用户转移矩阵。但是从使用场景上来讲，我们在这里实际上并不需要度量用户之间的相似度（尽管它们可以用来做用户协同推荐），用户仅仅是用来传递视频间的相似度。因此，为了减少计算和存储的开销，我们可以对用户进行聚类，使用用户组来代替用户完成视频相似度的传递。 基于这个想法，我们可以使用各种聚类的方法：按用户性别、年龄、地域等；我是直接基于历史行为进行用户聚类。具体的做法是基于用户最近 $N$ 天的播放、收藏、分享等行为生成用户的表征向量（可以用 AutoEncoder、PCA 等方法），然后基于表征向量执行 KMeans（直接 KMeans 可能跑不出来），这里的用户群数量需要根据实际场景调试，我们希望类内最大距离越小越好。然后再将用户的行为聚合到用户组，例如有效播放次数累加、总播放时长的累加、总播放占比的累加、平均 CTR 等。这样我们就从用户-视频二部图切换到了用户组-视频二部图，整个网络的规模降低了 2 个数量级。 SimRank++ 的优化我们将用户聚成了用户组，丢失了大量的网络信息，虽然用户组作为网络中的一个节点，我们看不出它的出边是来自哪些用户，但是好在我们保留了这个组里有多少用户看了某个视频。而由于这一组用户又是相似的，因此我们期望通过充分利用边权来最小化网络信息的丢失。 SimRank++ 正好满足我们的需求，它在 SimRank 的基础上增加了两项优化： 1. 两个节点共同节点越多，则这两个节点相似度的可信度越高这一条很容易理解，如果很多人同时看了两部视频，那这两部视频的相似度也就越可信（注意，共同观看越多并不意味着相似度越高）。例如下图所示，视频 $v_1,v_2$ 与 $v_3,v_4$ 相比同时被更多的用户组同时观看，因此 $v_1,v_2$ 根据 SimRank 模型算出来的相似度应该比 $v_3,v_4$ 的相似度更可信。 我们用 $E(i,j)$ 来表示节点 $i,j$ 相似度的可信度，论文 [2] 中推荐使用 $Ev(v_i,v_j)=\sum{k=1}^{|I(v_i)\cap I(v_j)|} \frac{1}{2^k}$ 或者 $E_v(v_i,v_j)=1-e^{|I(v_i)\cap I(v_j)|}$ 来评估该权重（用户侧的同理），则： \begin{cases} s(u,u')=c_1\cdot E_u(u,u')\cdot \sum_{i\in O(u)}\sum_{j\in O(u')}W_{uv}(u,i)\cdot W_{uv}(u',j)\cdot s(i, j) \\ s(v,v')=c_2\cdot E_v(v,v')\cdot \sum_{i\in I(v)}\sum_{j\in I(v')}W_{vu}(v,i)\cdot W_{vu}(v',j)\cdot s(i, j) \end{cases} \qquad (1)2. 节点边权越大、差异越小，则它的邻居节点相似度的权重越高如下图所示，我们用用户播放数来表示边权（如上所述，并非只有这一种权重表示方法）。不考虑边权时，$s(v_1,v_2)$ 和 $s(v_3,v_4)$ 完全相同。但是实际上，由于用户组 1 中有 100 个人看了 $v_1$ 和 $v_2$，可以认为用户组 1 中很多人都同时喜欢 $v_1,v_2$；而用户组 2 中有 100 个人看了 $v_3$，但只有 1 个人看了 $v_4$，因此 $v_3$ 和 $v_4$ 显然相似度应该比 $v_1,v_2$ 的低。 我们用新的权重 $P(i,j)$ 来表示节点 $i,j$ 的相似度传导权重，则： P(i,j)=e^{-var(j)}\frac{w(i,j)}{\sum_{k\in N(i)}w(i,k)}\quad (2)其中，$e^{-var(i)}$ 用来度量节点 $i$ 的边权差异，边权差异越大，该系数越小；$\frac{w(i,j)}{\sum_{k\in N(i)}w(i,k)}$ 则是用来计算归一化的权重。 SimRank++ 模型的矩阵描述基于式 (1) 和 式 (2)，我们可以写出 SimRank++ 的矩阵描述： \begin{cases} S_u^{k+1} = c_1\cdot E_u\circ P_{vu}^T\cdot S_v^k \cdot P_{vu} + (I - diag(c_1\cdot E_u\circ P_{vu}^T\cdot S_v^k \cdot P_{vu})) \\ S_v^{k+1} = c_2\cdot E_v\circ P_{uv}^T\cdot S_u^k \cdot P_{uv} + (I-diag(c_2\cdot E_v\circ P_{uv}^T\cdot S_u^k \cdot P_{uv})) \end{cases}\quad (3)其中， \begin{cases} E_u(u,u')=1-e^{-|O(u)\cap O(u')|}\\ E_v(v,v')=1-e^{-|I(v)\cap I(v')|} \end{cases}\quad (4) \begin{cases} P_{uv}(u,v)=e^{-var(v)}\frac{w(u,v)}{\sum_{i\in O(u)}w(u,i)} \\ P_{vu}(v,u)=e^{-var(u)}\frac{w(v,u)}{\sum_{i\in I(v)}w(v,i)} \end{cases} \qquad(5)但是使用数据进行验证时，发现该模型对用户聚类的效果和权重的设置十分敏感，这两项没调好的话，很容易导致算出来的视频相似列表趋同或者有其他的问题。具体来说，用户聚类的原则是类内用户的行为越相似越好；权重的话则没有很明显的规律，需要根据业务场景来尝试了。 发散讨论：扩散算法前几天跟其他同学交流的时候，有人提过之前做过用热传导算法来算用户的个性化推荐结果，据说效果也很不错。这里顺便扒一扒热传导算法和 SimRank 算法的区别和联系。 首先，它们都属于扩散算法，都是基于对物理世界现象的观察和模拟。典型的扩散有两类：一类是物质或者能量的扩散，满足守恒律，常称作为物质扩散，最终稳定下来后，总量是不变的；另一类是热的扩散，一般由一个或多个恒温热源驱动，不满足守恒律，常被称作为热传导。SimRank 是属于热传导（物品与自己的相似度恒定为 1）。 相比而言，物质扩散倾向于推荐比较流行的物品，而热传导倾向于推荐比较冷门的物品。更详细的讨论可以参考文献 [3]。 参考文献[1] Jeh, G., &amp; Widom, J. (2002, July). SimRank: a measure of structural-context similarity. In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining (pp. 538-543). ACM. [2] Antonellis, I., Molina, H. G., &amp; Chang, C. C. (2008). Simrank++: query rewriting through link analysis of the click graph. Proceedings of the VLDB Endowment, 1(1), 408-421. [3] 推荐算法整理 — 扩散算法. https://www.zybuluo.com/chanvee/note/21053.]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐</tag>
        <tag>协同过滤</tag>
        <tag>算法</tag>
        <tag>相似度</tag>
        <tag>二部图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SimRank与视频相似度计算]]></title>
    <url>%2F2019%2F04%2F29%2Fsimrank%2F</url>
    <content type="text"><![CDATA[一、应用背景最近需要对视频的相关推荐进行一些优化。之前尝试过 TagSim、AutoEncoder 和 Word2Vec 等方法，无非是基于元数据相似或基于协同相似的思路。但是在实际应用的时候，由于媒资传过来的信息未必是非常准确的，因此基于元数据相似的方法在数据基础上可能就存在一定的不确定性，因此常常会推出来一些虽然实际上很符合算法预期，但是看起来很奇怪的结果。而基于协同相似的推荐，由于需要比较多的行为数据来估计视频之间的相似度，又往往只能覆盖少量的视频。在应用中，我们往往使用的是两者的混合，但是由于混合比较简单粗暴，仍然有很多 VOC 问题。 因此，团队迫切的需要一种能够提升相关推荐效果的模型。而这种相关又是有强业务语义的，需要能够支持灵活的定制，因此在短时间内先不考虑深度网络（可解释性太差）。在调研中，发现有基于热传导的算法，感觉好像挺符合直观感觉，用了协同数据，同时也支持元数据。但是再顺着这个思路往下找的时候，发现 SimRank 是一种十分成熟且常用于相关推荐的模型，粗看了一下，感觉很符合我们的业务诉求，就迫不及待尝试了一下。 二、SimRank 基本模型2.1 核心思想由于 SimRank 提出的时间比较早，网上的材料很多，而且大多长的也差不多，可以参考文献 [1, 2] ，这里只简单的搬个砖。 文献 [1] 最早提出 SimRank 模型，核心的思想是 “two objects are similar if they are related to similar objects“（这跟 PageRank 的思路完全一致，只是 PageRank 是用来评估每个链接的重要性，而 SimRank 是用来评估每两个物品间的相似度）。 SimRank 既支持计算所有节点对之间的相似度（如输入数据为文章引用记录），也支持计算二部图中每一部分节点间的相似度（如输入数据为用户行为记录）。由于我们是做视频推荐，主要用的是用户行为数据，因此这里只介绍基于二部图的模型。 举个简单的例子：如下图所示，用户 $u_1$ 观看了视频 $v_1,v_2,v_3$；用户 $u_2$ 观看了视频 $v_2,v_3,v_4$，则可以用二部图来表示这种观影关系（二部图是因为用户 $u_1,u_2$ 之间无联系，且视频 $v_1,v_2,v_3,v_4$ 间无联系，只有用户-视频间存在有向边）： 为了评估视频 $v_1,v_4$ 之间的相似度，需要看看哪些人看了 $v_1,v_4$ ，以及这些用户的相似度。这是一个典型的递归逻辑，递归的起点在于：每个节点（包括这里的用户/视频）与自己的相似度为 1；没有关联的节点间相似度为 0（一种情况是这两个节点没有与其他节点的联系，还有一种情况是在迭代的初始状态时，所有节点对间的相似度为 0）。值得注意的是，如果用 ItemCF 算法来计算 $v_1,v_4$ 的相似度，由于它们没有共同观看的用户，相似度为 0，具体对比可以参考我之前的博客：可能是最好懂的ItemCF解释了。 2.2 基于二部图的描述最直观和容易理解的是基于图的描述。用数学语言来表达上面的思路： \begin{cases} s(u,u')=\frac{c_1}{|O(u)|\cdot|O(u')|}\sum_{i\in O(u)}\sum_{j\in O(u')}s(i, j) \\ s(v,v')=\frac{c_2}{|I(v)|\cdot|I(v')|}\sum_{i\in I(v)}\sum_{j\in I(v')}s(i, j) \end{cases} \quad (1)其中，$u$ 表示用户，$v$ 表示视频，$O(u)$ 表示用户 $u$ 观看过的视频集合，$I(v)$ 表示视频的观看用户集合，$s(i,j)$ 表示两个节点的相似度，$c_i$ 为常数系数。式 (1) 中累加相似度的部分不是很好理解，实际上就是对两个节点所有关联的节点进行两两组合计算相似度之和。$c_1, c_2$ 可以理解成相似度的传导率，传导率越大，受到相邻节点影响也就越大，每轮迭代相似度的传播也就越快，表现为迭代若干轮后，节点间的相似度越高（文献 [1] 中建议的是0.8）。如果使用随机游走的方法，则传导率越大，下一个状态转移到相邻节点的概率越大，即下一个状态保持原来节点概率越小。 在实现模型的时候，可以直接在图上按公式 (1) 进行计算，但是需要注意缓存中间结果$^{[3]}$，否则存在很多重复计算，实测中，不做什么优化的话，超过 $10000\times10000$ 的二部图单机基本就几个小时都算不出来了。 2.3 基于矩阵的描述另外一种等价的描述是将图转化成矩阵，比如原来的二部图是 $G = (U, V, E)$，即共 $n_u + n_v$ 个节点，可以转化成 $(n_u + n_v) \times (n_u + n_v)$ 的状态转移矩阵 $W$。根据公式 (1) 的描述，图中的每一条边对应于转移矩阵的一个元素（这里实现的时候用户和视频一般是分开连续编号的），从而可以设置转移矩阵为： \begin{cases} w(u,v)=\frac{1}{|O(u)|} \\ w(v,u)=\frac{1}{|I(v)|} \end{cases}转移矩阵中其他元素为 0。而根据定义，相似度矩阵 $S$ 中对角线始终为 1，其他元素初始化为 0。则基于矩阵的迭代过程可以用下式来表达： S = C\cdot W^T\cdot S\cdot W + (I-diag(C\cdot W^T\cdot S\cdot W)) \quad (2)其中，矩阵 $C$ 的对角线元素为 c_1 或 c_2，如果 c_1=c_2=c，那 $C$ 可以直接用系数 $c$ 来代替。公式 (2) 的前一部分就是公式 (1) 的矩阵描述，后一部分实际上是为了设置每轮迭代时，相似矩阵的对角线为 1，即 s_{i,i}=1。 注意到，在二部图的情况下，用户-视频的相似度必然是 0，同时，用户-用户 / 视频-视频的转移矩阵也必然是 0。因此相似矩阵和转移矩阵可以简单的拆成用户-用户相似矩阵 S_u、视频-视频 S_v 相似矩阵以及用户-视频转移矩阵 W_{uv}、视频-用户转移矩阵 $W_{vu}$，并做分块乘法。简单的推导一下： \begin{equation}\begin{aligned} W^T\cdot S\cdot W &= \left[ \begin{array}{cc} 0 & W_{vu}^T \\ W_{uv}^T & 0 \end{array} \right] \cdot \left[ \begin{array}{cc} S_u & 0 \\ 0 & S_v \end{array} \right] \cdot \left[ \begin{array}{cc} 0 & W_{uv} \\ W_{vu} & 0 \end{array} \right] \\ &=\left[ \begin{array}{cc} 0 & W_{vu}^T\cdot S_v \cdot W_{vu} \\ W_{uv}^T\cdot S_u \cdot W_{uv} & 0 \end{array} \right] \end{aligned}\end{equation}仔细品味一下这个公式，能更直观的了解相似度的传递过程。因此，迭代计算公式为： \begin{cases} S_u^{k+1} = c_1 \cdot W_{vu}^T\cdot S_v^k \cdot W_{vu} + (I - diag(c_1 \cdot W_{vu}^T\cdot S_v^k \cdot W_{vu})) \\ S_v^{k+1} = c_2 \cdot W_{uv}^T\cdot S_u^k \cdot W_{uv} + (I-diag(c_2\cdot W_{uv}^T\cdot S_u^k \cdot W_{uv})) \end{cases}\quad (3)2.4 扩展用户/视频属性以上描述了经典的基于二部图的 SimRank 算法，但是其实我们可以将视频的元数据/用户的属性数据作为辅助节点加入到图中来，并添加视频元数据$\rightarrow$视频和用户画像$\rightarrow$用户的单向边（表示用户/视频的相似度不会反向传播给画像/元数据），同时初始化不同维度的视频元数据/用户画像的相似度，以达到运营干预的目的。具体的分块乘法就不推导了，跟 2.3 节差不多，这里只举一个例子： 上图中，本来 $u_1,u_2$ 之间是没有边相连的，因此相似度为 0，但是由于他们同属男性，因此由男性这个画像向这两个用户传播了一定的相似度；同样的，本来 $v_1,v_2$ 之间的相似度也为 0，但是由于它们都是搞笑的视频，因此搞笑这个元数据也向它们传播了一定的相似度。加入用户维度和视频维度的辅助节点以后，有助于解决由于行为较少而无法准确评估相似度的情况。 三、模型实现与优化讨论我在 spark 2 和在 python 中分别实现了上述过程，使用图遍历的方式优点是代码简单，但是对于大规模的图优化比较麻烦，速度很慢；使用矩阵计算的时候，主要的问题又在于矩阵的优化计算。下面简单讲下一些可行的优化思路。 a. 基于 spark 的精确计算如果使用 mllib 的 BlockMatrix 来计算，会强制将稀疏矩阵转成稠密矩阵来计算，因此开销比实际需要的大很多，因此一定要使用公式 (3) 来替代公式 (2)。但是即使这样，也不能从根本上解决问题，根本上是需要自己实现一套高效的分布式稀疏矩阵的计算方法，网上有一些开源项目可参考。 b. 基于 python 的精确计算使用 python 进行计算时，由于相似度的精度要求不高，因此使用 np.float16 就足够了，并且每轮迭代完，要将小于一定阈值的相似项置 0（如果只需要计算 topN相似的话，每轮可以只保留系数最大的 topN 项）。另外，构建矩阵用 csr_matrix 比较方便，计算的时候还是得用 li_matrix。 c. 迭代近似由于我们只需要算视频的相似度，有一种解决上面问题的思路是将用户随机分成若干份，用这些用户的数据来计算视频的相似矩阵，然后将这些相似矩阵加起来求平均，但是效果不是很好。 d. 矩阵分析针对矩阵运算，可以预先分析矩阵的特点，然后再采用一定的手段来减少总计算量。这里涉及一些矩阵分解的优化方法，以后有机会再仔细研究研究。 参考文献[1] Jeh, G., &amp; Widom, J. (2002, July). SimRank: a measure of structural-context similarity. In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining (pp. 538-543). ACM. [2] SimRank协同过滤推荐算法: http://www.cnblogs.com/pinard/p/6362647.html. [3] Lizorkin, D., Velikhov, P., Grinev, M., &amp; Turdakov, D. (2008). Accuracy estimate and optimization techniques for simrank computation. Proceedings of the VLDB Endowment, 1(1), 422-433.]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐</tag>
        <tag>协同过滤</tag>
        <tag>算法</tag>
        <tag>相似度</tag>
        <tag>二部图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo+NexT+github 配置指南]]></title>
    <url>%2F2019%2F04%2F14%2Fhexo-next-github%2F</url>
    <content type="text"><![CDATA[这两天在网络各位大神的帖子指导下完成了 Hexo+Next 在 github 上的部署，记录一下全过程，以供后来者参考。 进入正题前，需要安装 Node.js 和 Git，并创建 github 帐号，可以参考其他帖子，这里就不详述了。 安装使用 Hexo安装 HexoHexo 安装过程很简单，只需要选择一个项目的名称和目录（如 project），然后输入以下代码即可在当前目录创建一个 project 的目录，同时初始化该工程： 123456npm install hexo-cli -ghexo init projectcd projectnpm installhexo ghexo s 如果打开 [http://localhost:4000](http://localhost:4000/) 能够看到 Hello World，说明安装已经成功了。 Hexo 常用命令Hexo 常用的命令不多，而且很容易记，按一般使用顺序记录如下： 1234hexo n "new post" # 创建新博客，名为 new posthexo g # 生成静态文件hexo s # 在本地起一个服务，可以查看效果，默认路径为 http://localhost:4000hexo d # 将本地文件部署到远端，本文将使用 github 托管 部署到 github创建新仓库首先需要创建一个新的仓库，例如我的用户名为 guyuecanhui，则我需要创建的仓库名为 guyuecanhui.github.io。注意：仓库的名字一定要按照规范命名，即 用户名.github.io，否则无法通过该路径访问博客。 配置 Hexo 的 deploy 选项配置 project 根目录下的 _config.yml，在最后添加如下代码： 1234deploy: type: git repository: http://github.com/guyuecanhui/guyuecanhui.github.io.git branch: master 注意仓库的路径按照参考代码设置，把用户名改成自己的即可。 配置完后执行（这两步后面简称重新部署）： 12hexo ghexo d 即可把本地的博客发布到 github 上了。可以通过 用户名.github.io 来访问主页了。 安装和配置 NexT 主题我使用 Hexo 的目的之一是使用网络大神们提供的各种养眼的主题。这里推荐安装 NexT 主题，也是当前使用比较广泛的一种。 下载并使用 NexT 主题首先定位到博客根目录下，然后下载 NexT 源码： 1git clone https://github.com/theme-next/hexo-theme-next themes/next 然后修改根目录下的 _config.yml 的 theme 选项，修改为： 1theme: next 然后重新部署博客即可看到主题变成了 NexT。NextT 提供了四种模式，在 themes/next/_config.yml 中可以修改，每次修改后需要重新部署才能生效： 12345# Schemes#scheme: Muse # 默认风格#scheme: Mist#scheme: Piscesscheme: Gemini # 选择 gemini 风格 常用选项设置只要记住，跟主题相关的所有设置基本都可以在 themes/next/_config.yml 里面找到。 访问统计使用不蒜子统计博客访问的人数，首先要引入 busuanzi.js。先在 themes/next/_config.yml 中启用并配置 busuanzi_count 插件： 123456789101112131415busuanzi_count: # count values only if the other configs are false enable: true # custom uv span for the whole site site_uv: true site_uv_header: &lt;i class="fa fa-user"&gt;&lt;/i&gt; 访问人数 site_uv_footer: 人 # custom pv span for the whole site site_pv: true site_pv_header: &lt;i class="fa fa-eye"&gt;&lt;/i&gt; 总访问量 site_pv_footer: 次 # custom pv span for one page only page_pv: true page_pv_header: &lt;i class="fa fa-file-o"&gt;&lt;/i&gt; 阅读数 page_pv_footer: 然后在 themes/next/layout/_partial/footer.swig 中添加以下代码： 12&lt;script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"&gt;&lt;/script&gt; 重新部署后，就能看到博客的访问统计数据啦！ 其他 Latex 支持 添加分类、标签页面 添加关于页面 添加图片支持 添加评论]]></content>
      <categories>
        <category>安装部署</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>github</tag>
        <tag>next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[可能是最好懂的ItemCF解释了]]></title>
    <url>%2F2019%2F04%2F12%2Fitemcf%2F</url>
    <content type="text"><![CDATA[说到推荐系统，可能最为人熟知的算法就是协同过滤，特别是其中的 ItemCF，自亚马逊文章发表以后，得到了广泛而成功的应用。这篇文章主要谈谈我的理解。 ItemCF 推导过程首先，ItemCF 依赖一个隐含的假设：就是每个用户的兴趣都局限在某几个方面，因此如果两个物品属于一个用户的兴趣列表，那么这两个物品可能就属于有限的几个领域，而如果两个物品属于很多用户的兴趣列表，那么它们就可能属于同一个领域，因而有很大的相似度。 从这个假设出发，我们可以认为两个视频相似表现在它们被很多用户同时观看，两个物品共同观看的人数越多，说明它们的相似度越高，用公式来表达就是： s_{i,j}=|N(i)\cap N(j)| \qquad (1)其中，$N(i)$ 表示观看视频 $i$ 的人群集合，$|N(i)\cap N(j)|$ 表示同时播放过 $i,j$ 的人数。但是由于热点视频可能并不代表用户的真实兴趣（有可能是运营推送，或者仅仅是由于追热心理），因此需要惩罚那些热点的视频，可以通过将共同观看人数除以与视频总观看数相关的系数来实现，例如使用以下方式： s_{i,j}=\frac{|N(i)\cap N(j)|}{\sqrt{|N(i)|\cdot|N(j)|}} \qquad (2)但是仅仅惩罚热点视频也还不够，有些人就是闲的无聊，有什么看什么，这种情况下他表现出来的就未必是真实的兴趣了（就不满足我们的隐含假设），他的行为也就不太能作为我们的协同的依据，因此需要对这种人做降权，例如使用以下方式： s_{i,j}=\frac{\sum_{u\in N(i)\cap N(j)}\frac{1}{log(1+|M(u)|)}}{\sqrt{|N(i)|\cdot|N(j)|}} \qquad (3)其中，$M(u)$ 表示用户 $u$ 观看的视频集合。另外，如果用户对视频 $i$ 观看了 80%，而对视频 $j$ 只看了 10%，那用户对这两个视频的喜欢程度也是不相同的，因此我们还可以对用户对两个视频观看的完成度差异做降权，差异越大，相似度也越低，例如使用以下方式： s_{i,j}=\frac{\sum_{u\in N(i)\cap N(j)}\frac{\cos(r_u(i),r_u(j))}{log(1+|M(u)|)}}{\sqrt{|N(i)|\cdot|N(j)|}} \qquad (4)其中，$r_u(i)$ 表示用户 $u$ 对视频 $i$ 的观看完成度。最后，将所有视频与其他视频的相似度做 $max$ 归一化，得到： s_{i,j}'=\frac{s_{i,j}}{\max_j s_{i,j}} \qquad (5)归一化使得所有物品的相似度取值都在 (0,1] 之间，这个相似度已经可以直接用于相关推荐场景。另外，有研究表明，这种归一化可以提高 ItemCF 用于个性化推荐时的准确度、覆盖率和多样性。 那基于 ItemCF 如何进行个性化推荐呢？主要是考虑推荐与用户的观看历史最相似的视频，即计算每个视频与用户观看视频集合的相似度作为作为是否观看该视频的预测值： p_u(i)=\frac{\sum_{j\in M(u)} s_{i,j}\cdot r_u(j)}{\sum_{j\in M(u)} s_{i,j}} \qquad (6)最后，再根据预测值从大到小选取 TopN 个视频作为推荐结果。 优化与讨论其实从第 1 部分的介绍来看，基于 ItemCF 的思想可以做很多改进。例如： 如果感觉算出来的结果仍然偏向热门视频时，可以增加式 (4) 的分母大小； 如果觉得用户只有观看完完成度很高时才是真实兴趣，那可以将式 (4) 的 $cos(\cdot)$ 部分改成类似 $r_u(i)\cdot r_u(j)$ 的形式； 如果觉得需要更多的考虑用户的短期兴趣，做即时的推荐，那可以将式 (6) 中的用户观看历史限制在最近几次，甚至一次； 如果把用户-视频考虑成一个二部图，ItemCF 实际上是基于图的结构，执行了一次从用户到视频的兴趣扩散过程。可以考虑下图中的视频 $v_1,v_3$，它们没有直接的共同观看，因此用 ItemCF 算出来的相似度为 0，但是实际上 $u_1,u_2$ 都观看了 $v_2$，因此可以认为用户 $u_1,u_2$ 存在一定的相似性，因此如果执行一次视频-用户-视频的兴趣扩散过程就能够捕获 $v_1,v_3$ 的相似度了。 后面一种思路实际上就是 SimRank，但是由于需要执行多次兴趣扩散（即对二部图做多次迭代计算），SimRank 的计算复杂度相当高，在业务数据量大的情况下需要强大的算力支持，以后会再讨论下我在 SimRank 模型上的尝试。]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐</tag>
        <tag>协同过滤</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[置信区间在推荐中的应用]]></title>
    <url>%2F2019%2F02%2F10%2Fconfidence-interval%2F</url>
    <content type="text"><![CDATA[学过统计的同学都对置信区间的概念非常熟悉，实际上，离开置信区间谈统计值没啥意义，或者说经常会造成很大的误导。简单来讲，置信区间是指基于观测样本来估计一个未知参数（如均值）时，我们相当确定（用置信度来度量）参数可能的取值范围。如果不考虑置信区间的概念，在我们观察到有 2 个用户喜欢一个视频、1 个用户不喜欢一个视频时，会估计该视频的推荐度为 66%，而认为它是一个高质量的视频，如果一旦将它进行大规模推荐时，很可能发现这个视频的实际转化率低的可怜。 因此在推荐里，置信区间是需要密切关注的概念。在推荐领域实践中，我从 3 个简单的算法来分别介绍置信区间的应用。 Wilson 区间法来判断视频质量在引言的例子中，我们组的海威同学利用 Wilson 区间法来估计视频的推荐度，或者说，来建立视频质量评估模型（模型的一部分）。利用视频播放行为数据来统计视频的播放转化率时，假设视频展示的总数为 $n$，用户实际播放的总数为 $m$，则直接计算出来的播放转化率为 $p=\frac{m}{n}$。如果 $n$ 越大，说明 $p$ 的估计置信度越高，否则置信度越低。由于视频质量直接决定了我们是否会大规模推荐这个视频，因此在估计 $p$ 时采用的是宁缺毋滥的策略，这个时候可以巧妙的用置信区间的下界来代替 $p$ 作为播放转化率的估计。 具体到 Wilson 区间的计算公式，可以参考wiki（基于正态分布假设），这里只搬个公式： p_w = \max(0, \frac{p+\frac{z^2}{2n}}{1+\frac{z^2}{n}}-\frac{z}{1+\frac{z^2}{n}}\sqrt{\frac{p(1-p)}{n}+\frac{z^2}{4n^2}})其中，$z$ 为某置信度（如 95% 置信度）下查表可得，$n$ 在实际代入时，需要加上平滑因子（如 0.1），防止展示数据丢失导致 $n=0$。从公式可知，基于 Wilson 区间估计的播放转化率最小接近于 0（$n$ 在实际时很可能取到平滑因子），最大接近于 $p$。 UCB算法来平衡探索与应用（E&amp;E）Wilson区间法是用置信区间的下限来减少数据量不足时误判的可能，主要是用来选出精品视频用来广泛推荐。但是一直这样保守推荐，会导致有些视频得不到充分的曝光，就难以评估其实际的转化率，导致推荐出来的所谓精品只是次优的选择。因此，在应用（Expoit）目前已知比较好的视频进行推荐的同时，也要保持一定比例的探索（Explore），即尝试一下那些曝光较少的视频。EE算法里一个常用的算法是 LinUCB，由于涉及特征构造，这里只介绍一个简化版本 UCB，大致思路是一样的。 UCB（Upper Confidence Bound）是一种多臂老虎机算法（MAB），也勉强算一种简化的强化学习算法，调性十足。同样以估计播放转化率为例，它的思路是利用置信区间的上界来代替 $p$ 作为估计值，实际上是提高了曝光不足视频（即长尾视频）的估计值。 UCB 主要解决的问题在于，如何计算置信区间的上界，既能保证随着曝光总量的增加，那些未被探索的视频越来越少，又能保证长久来看，能选到精品的视频。为了实现这个目标，一个常用的启发式公式如下： p_u=\max_{i}(p_i+\sqrt{\frac{2\ln t}{n_i}})其中，$p_i$ 为某个视频 $n_i$ 次曝光计算的平均转化率，$t$ 表示所有视频总共的曝光数。可以看到，随着曝光总数的增加，曝光很少的视频第二项值会很大，因此所有视频都会得到保底的曝光（t=100000 时至少有 28 次）。但是随着 $n_i$ 继续增加，主要决定因素又变成了 $p_i$，即历史平均转化率高的视频更可能被选中。 Thompson 采样来进行随机长尾推荐UCB 算法在实际于新物品增加快的场景（例如短视频推荐，平均每天新增几万部短视频）时，由于计算过程是确定性的，存在一直只推新物品的问题。为了增加一些随机性，可以考虑用 Thompson 采样算法。它既不使用置信区间的上界，也不使用下界，而是每次基于 Beta(m, n-m) 分布进行采样（注意，这里的 m 和 n 是每个视频单独维护的参数）。 我们知道，Beta 分布实际上是“白努力”过程的成功率，曝光数 $n$ 越大，Beta 分布的曲线越像是一个倒钟的形状，且钟的开口越窄，最后收于期望：$p=\frac{m}{n}$。反过来说，当使用 Thompson 采样来选择推荐的视频时，虽然每个视频长期来选中的概率取决于其转化率，但是当曝光数量少时，Beta 分布开口很大，也更容易得到比期望大或者小的采样结果，从而引入了随机性。不过从实际应用来看，当媒资库时的视频数量很多时，大部分选中的视频还是新视频。 本文简单的介绍了统计区间在推荐中的一些简单应用，既有利用置信区间的下界来选精品，也有利用置信区间的上界来探索，还有利用整个分布来引入随机性。所有算法都是用简单的数学公式就能达到我们期望的效果，是比人工规则优美的多的形式。当然，举的示例都是推荐的核心问题，没有这么简单就能讲清楚，涉及大量的数据处理和参数调优，需要不断尝试和改进。]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐</tag>
        <tag>统计</tag>
        <tag>置信区间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[特征组合之FFM]]></title>
    <url>%2F2018%2F10%2F04%2Fffm%2F</url>
    <content type="text"><![CDATA[前段时间搞 LR 的特征优化，切身体会到人工特征工程实在太费劲了，一方面发掘高价值的特征十分困难，另一方面某些特征之间需要组合才能有效，比如用户对视频的某个特征的偏好，就必须将视频的特征和用户的特征进行组合。LR 是线性模型，没法自动做特征组合，只能人工搞，但人工来干这事就相当麻烦了。自然而然的，就会想到用可以自动组合特征的模型。现在了解的包括 FM、FFM 等基于矩阵分解的模型、基于 GBDT 之类的树模型和基于 DNN 的网络模型。这篇文章先介绍下 FFM 模型。 FFM 模型简介FFM (Field-aware Factorization Machines)$^{[1]}$是 Yuchin Juan 等人在台大期间提出的用于 CTR 预估的模型。它是对 FM 模型的推广，提到 FM 又不得不提到 Poly2 模型，好在它们三个的关系十分简单和明确： Poly2 模型是将所有特征进行两两组合，也就是当特征有 $n$ 个的时候，需要 $O(n^2)$ 个参数，而且这些参数之间是相互独立的，意味着每个参数都需要足够的样本来训练，也就是每对特征都同时出现在足够多的样本里。因此如果无法满足海量样本的要求时，这个模型很难训练出来。它的模型如下（其中 $h(i,j)$ 作用是将 $i,j$ 映射成一个自然数）： \phi_{poly2}(\mathcal{w},\mathcal{x}) = \sum_{j_1=1}^n\sum_{j_2=j_1+1}^n w_{h(j_1,j_2)}x_{j_1}x_{j_2} \qquad (1) FM 模型是为每个特征训练一个隐向量，而特征组合的权重就是这两个特征的隐向量点积，假设隐向量的长度为 $k$，那么需要 $O(nk)$ 个参数，因此参数的规模要比 Poly2 小很多（这里可以认为 Poly2 为每个特征生成的向量长度为 $n$），训练数据量要求也就没那么高了。它的原始形态 (2) 和简化计算形态 (3) 分别如下： \phi_{FM}(\mathcal{w},\mathcal{x})= \sum_{j_1=1}^n\sum_{j_2=j_1+1}^n (\mathcal{w}_{j_1}\cdot\mathcal{w}_{j_2})x_{j_1}x_{j_2} \qquad (2) \phi_{FM}(\mathcal{w},\mathcal{x})=\frac{1}{2}\sum_{j=1}^n(\mathcal{s}-\mathcal{w}_j x_j), \quad \mathcal{s}=\sum_{j'=1}^n\mathcal{w}_{j'} x_{j'} \qquad (3) FFM 模型是为每个特征对每一个 Field 学习一个隐向量，一个 Field 可以认为是特征所属的属性，比如用户的常驻地可以看成是一个 Field、视频的分类可以看成是另一个 Field，假设有 $f$ 个 Field，每个隐向量长度为 $k$，则FFM模型需要 $O(nfk)$ 个参数，看起来比 FM 多很多，但是实际上由于每个特征对不同 Field 的作用都是单独学习的，因此 FFM 的 $k$ 往往比 FM 的 $k$ 小很多。它的模型如下： \phi_{FFM}(\mathcal{w},\mathcal{x})= \sum_{j_1=1}^n\sum_{j_2=j_1+1}^n (\mathcal{w}_{j_1,f_2}\cdot\mathcal{w}_{j_2,f_1})x_{j_1}x_{j_2} \qquad (4)FFM 为什么要把 Field 拎出来考虑呢？举个例子，还是在视频推荐里，假设只考虑用户的年龄特征、视频的分类特征和演员特征，FM 在学用户年龄特征的时候是综合考虑视频分类和演员来得到的，然而从直观上来看，年龄对分类的影响和对演员的影响是不同的，因此更自然的想法是对分类和演员各学一个隐向量，效果应该会更好。 换句话说，如果特征有明显的 Field 划分，用 FFM 模型理论上是优于 FM 的；但是如果不满足这个条件，例如在 NLP 领域，所有特征都属于一个 Field，FFM 模型的优势就不明显了。另外，Field 很容易对应到一个类别，因此 FFM 特别适合处理类别特征，对于连续特征，如果离散化处理效果比较好也还OK，否则优势也不明显。因此，FFM 主要适合处理类别特征，并且喜欢稀疏数据，而不适合处理连续特征，不适合处理 Field 数量很少的数据。 FFM 模型实现由于官方只提供了 FFM 模型的 C++ 实现$^{[2]}$，而我们主要是基于 Spark 的，因此需要一份 scala 实现。网上也找了一下，发现 Vince Shieh 实现的一份代码$^{[3]}$，但是 review 以后发现参数有点问题，因此考虑自己实现一份。实现的 FFM 的核心就在于如何计算梯度，如何更新模型。论文的模型 (4) 是简化处理，在实现的时候还需要带上全局偏置和线性部分，完整的模型如下： \phi_{FFM}(\mathcal{w},\mathcal{x})= w_0 + \sum_{j=1}^n w_jx_j+ \sum_{j_1=1}^n\sum_{j_2=j_1+1}^n (\mathcal{w}_{j_1,f_2}\cdot\mathcal{w}_{j_2,f_1})x_{j_1}x_{j_2} \qquad (5)而 FFM 用于 CTR 预估时，目标优化函数定义成： \mathcal{L}=\min_{\mathcal{w}} \frac{\lambda}{2}||\mathcal{w}||^2_2+\sum_{i=1}^m \log(1+e^{-y_i\phi(\mathcal{w},\mathcal{x})}) \qquad (6)使用 SGD 的方式进行更新，即每次使用一个样本 $(y,\mathcal{x})$ 来更新模型，其中，$\mathcal{x}$ 的格式为 \mathcal{x}=[f_{i_1}j_{i_1}x_{i_1},\cdots,f_{i_t}j_{i_t}x_{i_t}]，表示该样本中 $t$ 个非零特征，$f$ 表示特征的域编号，$j$ 表示特征编号，$x$ 表示特征取值（对于 one-hot 编码，$x=1$）。首先对式 (6) 中各权重计算梯度： \begin{cases} g_0=\lambda w_0+\kappa \\ g_j=\lambda w_j+\kappa w_j \\ \mathcal{g}_{j_1,f_2}=\lambda \mathcal{w}_{j_1,f_2}+\kappa \mathcal{w}_{j_2,f_1} \\ \mathcal{g}_{j_2,f_1}=\lambda \mathcal{w}_{j_2,f_1}+\kappa \mathcal{w}_{j_1,f_2} \end{cases}, \quad \kappa=\frac{-y_ie^{-y_i\phi(\mathcal{w},\mathcal{x})}}{1+e^{-y_i\phi(\mathcal{w},\mathcal{x})}} \qquad (7)然后使用 AdaGrad 对累积梯度进行更新（这里也可以不用 AdaGrad，直接使用 GD，或者用 Adam 等其他方法更新）： \begin{cases} G_i=G_i+g_i^2 \\ w_i=w_i-\frac{\eta}{\sqrt{G_i}} g_i \end{cases}, \quad i=0, i_1, \cdots, i_t \qquad (8) \begin{cases} (G_{j_1,f_2})_d=(G_{j_1,f_2})_d+(g_{j_1,f_2})_d^2 \\ (G_{j_2,f_1})_d=(G_{j_2,f_1})_d+(g_{j_2,f_1})_d^2 \\ (w_{j_1,f_2})_d=(w_{j_1,f_2})_d-\frac{\eta}{\sqrt{(G_{j_1,f_2})_d}} (g_{j_1,f_2})_d \\ (w_{j_2,f_1})_d=(w_{j_2,f_1})_d-\frac{\eta}{\sqrt{(G_{j_2,f_1})_d}} (g_{j_2,f_1})_d \end{cases}, \quad d=1,\cdots, k,\qquad (9)基于以上各式，可以很容易把算法写出来了：12345678910Algorithm: Train FFM using SG init G = ones(n,f,k) init g = rand(n,f,k)[0,1/sqrt(k)] for epoch = 1 to t: for i = 1 to m: sample a data point (y,x) calculate kappa by (7) for xi, xj in x: calculate gradients by (7) update weights by (8)(9) 论文中指出，FFM 特别容易过拟合，其中，正则化系数 $\lambda$ 越小，效果越好但越容易过拟合；学习率 $\eta$ 越大，学习速度越快也越容易过拟合。我自己试了几个数据集，使用 $\lambda=0.00002,\ \eta=0.1,\ k=4$，一般 1~4 轮都差不多OK了，再多就容易过拟合。为了防止过拟合，论文提出使用 early stopping 技术，即将训练数据进一步划分成训练集和验证集，每一轮用训练集更新完模型后，用验证集计算 logloss，并记录验证集 logloss 开始上升的轮数 $r$，最后再用整个数据集训练 $r$ 轮。但是实际在用的时候，可以线下调一个比较好的参数，然后直接放到线上去用，等数据发生变化，或者定时去重新评估这些参数。 自己用 scala 实现的 FFM 模型没有使用指令集加速，只是将训练数据划分成多个 partition 并行训练，然后将参数合并（求平均），效果差一些。我拿 libFFM 做了一个性能的比较……完败……唉，Spark 做数值计算还是不太行啊！ References[1] Juan, Yuchin, et al. “Field-aware Factorization Machines for CTR Prediction.” ACM Conference on Recommender Systems ACM, 2016:43-50.[2] https://github.com/guestwalk/libffm[3] https://github.com/VinceShieh/spark-ffm]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐</tag>
        <tag>排序</tag>
        <tag>特征工程</tag>
        <tag>特征组合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Submodular函数]]></title>
    <url>%2F2018%2F08%2F16%2Fsub-modular%2F</url>
    <content type="text"><![CDATA[Submodular 函数的定义与性质最近在看一些计算学习理论的时候，发现很多文章是基于 Submodular 函数做的，就去了解了一下。所谓 Submodular 函数，是指满足如下定义的集合函数$^{[1]}$： 记 $[n]={1,2,\cdots,n}$ 为 Ground Set，记 $f:2^{[n]}\to\mathbb{R}$ 为一个集合函数，该函数是 submudular当： f(A)+f(B)\ge f(A\cup B)+f(A\cap B), \quad \forall A,B\subseteq[n] \qquad(1) 它是对 Modular 函数的条件进行放松，而 Modular 函数是指满足如下定义的函数： f(A)+f(B)=f(A\cup B)+f(A\cap B), \quad \forall A,B\subseteq[n] \qquad(2)看定义，Submodular 函数与凹函数有些相似，不同的在于它并不限定元素的顺序！Submodular 函数还有一种等价式，更能体现它的一个核心特点： f(A\cup \{i\})-f(A)\ge f(B\cup \{i\})-f(B), \quad \forall A\subseteq B\subseteq [n],\ i\not \in B \qquad(3)通俗的来讲，这个特点就是边际效用递减，即增加一个元素对整体的收益贡献递减。这种边际效用递减的程度可以用曲率 $\kappa$（Curvature）来度量：$f_S(i)\ge (1-\kappa)f(i)$，其中，$0\le\kappa\le1$。 举两个跟推荐有关系的 Submodular 函数的例子： 视频推荐多样性：对于一个可推荐的视频集合 $S$，假设每个视频有一个分类 $g_i$，则一个推荐列表中不同类别的总数 $f(S)=\sum_i \mathbb{I}(g_i)$ 就是一个 Submodular 函数，其中，$\mathbb{I}(x)$ 表示元素 $x$ 是否存在。 商品推广用户选择：对于一个社交网络的用户集合 $S$，如果某用户看过一个物品，则他有可能向他的朋友推荐和分享。假设某个物品在推广期时给 $k$ 个用户 $S_k$ 展示了，则最终该物品会展示给多少用户 $m=f(S_k)$ 是一个 Submodular 函数。 最后简单介绍下它的一些性质。Submodular 函数首先是集合函数，因此满足如下性质： 非负性：$f(A)\ge 0$ 单调性：可以是单调增或单调减 正则化：$f(\phi)=0$ 另外，根据定义，可以证明它还满足： 若 $f_1,f_2,\cdots,f_k$ 是 Submodular 函数，给定 $w_1,w_2,\cdots,w_k\ge 0$，则 $g(S)=\sum_iw_if_i(S)$ 也是 Submodular 函数 若 $f$ 在 $X$ 集合上是 Submodular 函数，给定 $T\subseteq X$ 则 $f(S\cup T)$、$f(S\cap T)$、$f(X\setminus S)$ 都是 Submodular 函数 由于 Submodular 函数性质好、易证明，它在机器学习、博弈论等领域的理论研究方面获得了广泛的应用$^{[1,2]}$。特别的，文献$[1]$基于 Submodular 目标提出了 PMAC 理论，是对 PAC 理论的扩展；文献$[2]$基于 Submodular 函数提出一种 AdaptiveSampling 的算法，可以在理论保证的前提下，将样本数大大减少，这里就不展开了。 Reference[1] Balcan, Maria Florina, and N. J. A. Harvey. “Learning submodular functions.” ACM Symposium on Theory of Computing ACM, 2011:793-802.[2] Balkanski, Eric and Singer, Yaron. “Approximation Guarantees for Adaptive Sampling.” Proceedings of the 35th International Conference on Machine Learning, 2018:393-402.]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>优化</tag>
        <tag>计算学习理论</tag>
        <tag>函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[柯里化 (Currying) 及其应用]]></title>
    <url>%2F2018%2F07%2F20%2Fcurrying%2F</url>
    <content type="text"><![CDATA[柯里化（Currying，以逻辑学家 Haskell Brooks Curry 的名字命名）指的是将原来接受两个参数的函数变成新的接受一个参数的函数的过程。新的函数返回一个以原有第二个参数作为参数的函数。乍一看不容易理解，我们结合几个例子来看看，在 scala 中，currying 是什么样的，以及什么时候我们可以考虑使用它。 样例一：加法从最简单的开始，我们看一下 currying 是怎么把一个接受两个参数的函数改造成每次只接受一个参数的函数： 1234567891011121314151617181920// uncurrydef add1(x: Int, y: Int): Int = &#123; x + y&#125;// shorthanddef add2(x: Int)(y: Int): Int = &#123; x + y&#125;add2(2) _add2(2)(3)// longhanddef add3(x: Int): (Int =&gt; Int) = &#123; (y: Int) =&gt; &#123; x + y &#125;&#125;add3(2)add3(2)(5) 输出结果： 1234res0: Int =&gt; Int = $$Lambda$1120/855429058@4702faeeres1: Int = 5res2: Int =&gt; Int = $$Lambda$1119/1771691170@f6b85c3res3: Int = 7 从这里，我们可以看出，实际上 add2(2) 已经变成了一个 method，而 add3(2) 则变成了一个 function（method 和 function 的差别参考我之前的博客），它们都可以将任何接受的参数加上 2 得到输出的结果。 样例二：foldLeft上面的例子实际上已经很清楚的说明了 currying 的特点，即固定一个参数作为函数的一部分，然后接受剩下的参数进行处理。下面这个例子是 scala 内置的代码 foldLeft，我们平时也经常会用到，它将对一个列表的操作转换成了依次对列表中每个元素的操作： 12345678910def foldLeft[B](z: B)(op: (B, A) =&gt; B): B = &#123; var acc = z var these = this while (!these.isEmpty) &#123; acc = op(acc, these.head) these = these.tail &#125; acc&#125;List(1,2,3).foldLeft("res:")((x: String, y:Int) =&gt; x + y) 输出结果：1res:123 样例三：人群分析报告最后，我们再举一个例子，尝试着说明一下在什么情况下可以考虑使用 currying。考虑我们有一个函数能够接受用户的各种属性和待分析的视频 ID，输出具备指定属性的用户对该视频的详细分析报告（好希望有），它的非 currying 形式如下： 1def godView(age: String, gender: String, city: String, netType: String, videoID: String): Unit = &#123; /** whoCanWhoUp **/ &#125; 每天业务都会根据数据分析去定向 push 一些视频，但是有些 push 的效果不好，就需要分析为啥给某群用户推荐这个视频不好，我们借助这个 godView 函数来进行分析。假设我们有几个人被分到了不同的人群和一些视频列表，每个人都得仔细根据函数的输出的报告进行分析。比如我分到了使用 wifi 的中年上海男性，那我每次分析都需要把这些参数全都传进去： 1234godView("35-45", "male", "shanghai", "wifi", "video1")godView("35-45", "male", "shanghai", "wifi", "video2")godView("35-45", "male", "shanghai", "wifi", "video3")... 对于我来说，多希望不需要每次传这些相同的参数，让我专心分析视频 ID 就好了，那我就希望把这个函数改造一下： 1def godView(age: String)(gender: String)(city: String)(netType: String)(videoID: String): Unit = &#123; /** whoCanWhoUp **/ &#125; 然后我只把我关注的人群提取出来，再进行分析，就简洁多了： 12345val myView = godView("35-45")("male")("shanghai")("wifi") _myView("video1")myView("video2")myView("video3")... Take-aways从以上三个例子中，我们可以窥见 currying 的几个特点： Currying 是把接受多个参数的函数变换成接受一个单一参数的函数，并且返回接受余下的参数且返回结果的新函数的技术； Currying 其实只是复用代码的一种思路，它并非不可替代； 当你发现你要调用一个函数，并且调用参数都是一样的情况下，这个参数就可以进行 currying，以便更好的完成任务； Currying 允许你写出来的代码更干净、更有表达力。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>curry</tag>
        <tag>柯里化</tag>
        <tag>scala</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scala 中函数与方法的差别]]></title>
    <url>%2F2018%2F07%2F17%2Fmethod-vs-function%2F</url>
    <content type="text"><![CDATA[1. 引子在 Spark 开发过程中，我们经常会定义一些 udf 函数，用于对 DataFrame 的列进行变换，例如： 123val thres = 3.0val log10Udf = udf &#123; x: Long =&gt; math.min(math.log10(x + 2.0), thres) &#125;df.withColumn("newColumn", log10Udf($"oldColumn")).show 这里的 log10Udf 是个啥呢？我们去看 udf 的定义，会发现它返回的是一个 UserDefinedFunction 对象： 1234def udf[RT: TypeTag, A1: TypeTag](f: Function1[A1, RT]): UserDefinedFunction = &#123; val inputTypes = Try(ScalaReflection.schemaFor(typeTag[A1]).dataType :: Nil).toOption UserDefinedFunction(f, ScalaReflection.schemaFor(typeTag[RT]).dataType, inputTypes)&#125; 可以确认一下： 12345scala&gt; log10Udf.getClassres1: Class[_ &lt;: org.apache.spark.sql.expressions.UserDefinedFunction] = class org.apache.spark.sql.expressions.UserDefinedFunctionscala&gt; log10Udf.isInstanceOf[java.lang.Object]res2: Boolean = true 这里就引出了一个小小的疑问，我们平时 def 的东西也是个对象吗？例如我们尝试一下： 123456789scala&gt; def inc(x:Int) = x + 1inc: (x: Int)Intscala&gt; inc.isInstanceOf[java.lang.Object]&lt;console&gt;:13: error: missing argument list for method incUnapplied methods are only converted to functions when a function type is expected.You can make this conversion explicit by writing `inc _` or `inc(_)` instead of `inc`. inc.isInstanceOf[java.lang.Object] ^ 从上面的报错信息我们可以分析出来两点： def 的结果并不是一个对象，而是一个 method； 可以通过 _ 操作符将一个 method 转成一个 function； 确认一下： 12345scala&gt; (inc _).isInstanceOf[java.lang.Object]res3: Boolean = truescala&gt; (inc _).getClassres4: Class[_ &lt;: Int =&gt; Int] = class $$Lambda$1421/1772552470 2. method vs. function一个很自然的问题就提出来了：method 和 function 有啥差别呢？可以去官方文档上查询关键字 function： A function can be invoked with a list of arguments to produce a result. A function has a parameter list, a body, and a result type. Functions that are members of a class, trait, or singleton object are called methods. Functions defined inside other functions are called local functions. Functions with the result type of Unit are called procedures. Anonymous functions in source code are called function literals. At run time, function literals are instantiated into objects called function values. 简单的来讲，method 是定义在 class, trait 或者 object 里的 function，而匿名函数（Anonymous functions）会在运行时被实例化成 object。所谓的匿名函数就是没有名字的函数（-_-!），例如：(x: Int) =&gt; x + 2 就是一个匿名函数，我们可以将它赋值给一个变量： 1val inc2 = (x: Int) =&gt; x + 2 把它写到一个类定义里，再尝试着编译一下，会得到这个匿名函数的定义： 1public final class test$$anonfun$1 extends java.lang.Object implements scala.Function1,scala.ScalaObject 其中，值得关注的是这个匿名函数实现了 trait scala.Function1（实际上，scala 包里定义了 Function0 ~ Function22 表示接受 0 ~ 22 个参数的函数），它的代码如下： 12345678910@annotation.implicitNotFound(msg = "No implicit view available from $&#123;T1&#125; =&gt; $&#123;R&#125;.")trait Function1[@specialized(scala.Int, scala.Long, scala.Float, scala.Double) -T1, @specialized(scala.Unit, scala.Boolean, scala.Int, scala.Float, scala.Long, scala.Double) +R] extends AnyRef &#123; self =&gt; /** Apply the body of this function to the argument. * @return the result of function application. */ def apply(v1: T1): R @annotation.unspecialized def compose[A](g: A =&gt; T1): A =&gt; R = &#123; x =&gt; apply(g(x)) &#125; @annotation.unspecialized def andThen[A](g: R =&gt; A): T1 =&gt; A = &#123; x =&gt; g(apply(x)) &#125; override def toString() = "&lt;function1&gt;"&#125; 根据注释推测，这个匿名函数实际上就是定义了 apply 方法；当我们调用 inc2(3) 时，我们实际上是调用了这个对象的 apply 方法。确认一下： 12345val inc2 = (x: Int) =&gt; x + 2val anonfun = new Function1[Int, Int] &#123; def apply(x: Int): Int = x + 2&#125;assert(inc2(0) == anonfun(0)) 嗯，终于理顺了 ~ 好了，我们再用这个例子串一下： 12345678910111213141516171819202122232425scala&gt; def inc(x: Int) = x + 1inc: (x: Int)Intscala&gt; val inc2 = (x: Int) =&gt; x + 2inc2: Int =&gt; Int = $$Lambda$1035/948692477@8f2e3e6scala&gt; val inc3 = inc _inc3: Int =&gt; Int = $$Lambda$1042/1739111611@1bb96449scala&gt; inc2.toStringres0: String = $$Lambda$1035/948692477@8f2e3e6scala&gt; inc.toString&lt;console&gt;:13: error: missing argument list for method incUnapplied methods are only converted to functions when a function type is expected.You can make this conversion explicit by writing `inc _` or `inc(_)` instead of `inc`. inc.toString ^scala&gt; val inc4 = inc&lt;console&gt;:12: error: missing argument list for method incUnapplied methods are only converted to functions when a function type is expected.You can make this conversion explicit by writing `inc _` or `inc(_)` instead of `inc`. val inc4 = inc ^ 3. Take-aways这篇短文主要比较了之前容易忽略的两个概念：method 和 function 的联系和细微的差别： method 是定义在 class, trait 或者 object 里的 function； 在运行时，匿名函数会被实例化成 object，因此可以把匿名函数赋值给一个变量，调用匿名函数实际上是调用这个对象的 apply 方法； method 本身只是一段代码，并不会被实例化，也不能对它进行赋值等操作，但是 method 通过 _ 操作符可以转换成一个 function 类型；]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>scala</tag>
        <tag>method</tag>
        <tag>function</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SVD++ 论文精读]]></title>
    <url>%2F2018%2F02%2F24%2Fsvdpp%2F</url>
    <content type="text"><![CDATA[论文引用：Koren, Y. . (2008). Factorization meets the neighborhood : a multifaceted collaborative filtering model. Proceedings of the 14th ACM SIGKDD International Conference of Knowledge Discovery and Data Mining, 2008. ACM Press. 本文对协同过滤中最主要的两种方法（基于邻域的方法和基于隐特征模型的方法）分别提出了优化方案，并且设计了一个联合模型将两种方法统一，从而达到更好的效果。为了进行区分，本文将对 SVD 进行优化的方案称为 SVD+，将联合模型的方法称为 SVD++。 研究背景Koren 在做 Netflix 的比赛过程中，发现基于邻域的方法和基于隐特征模型的方法各有所长： 比较 基于邻域的方法 基于隐特征模型的方法 主要思想 核心在于计算用户/物品的相似度，将相似用户的喜好推荐给用户，或将用户喜欢物品的相似仿物品推荐给用户 假设真正描述用户评分矩阵性质的内存特征（可能未知）其实只有少数几个，将用户和物品都映射到这些隐特征层，从而使得用户和物品直接关联起来 挖掘信息特征 能够对局部强相关的关系更敏感，而无法捕捉全局弱相关的关系 能够估计关联所有物品/用户的整体结构，但是难以反映局部强相关的关系 因此，这两种方法存在天然的互补关系。另外，Koren 还发现，使用隐式反馈的数据能够提高推荐的准确性，而这两种方法都不支持使用隐式反馈的数据。基于这些发现，Koren 先分别将隐式反馈集成到两个模型中去，得到两个优化的模型，再提出一种联合模型，将这两个优化的模型进一步融合，从而得到更好的效果。 模型推导文章从 Baseline 的模型，通过加入各种考虑因素，推导出基于邻域和基于隐特征的两个模型，再推导出联合模型。 1、Baseline模型Baseline 模型就是基于历史数据的简单统计，主要看用户 $u$ 的平均评分 $b_u$、电影 $i$ 的平均评分 $b_i$ 和所有电影的平均评分 $\mu$： b_{ui} = \mu + b_u + b_i所有后面的模型都是对这个基准模型的修正。这个基准模型中的参数都是可以离线计算的，用的方法也是本文通用的参数估计方法，先定义损失函数 $l(P)$： l(p_1,p_2,\cdots) = \sum_{(u,i)\in \kappa} (r_{ui} - \hat{r_{ui}})^2 + \lambda(\sum_{p_1} p_1^2 + \sum_{p_2} p_2^2 + \cdots)其中，P=\{p_1,p_2,\cdots\} 表示待估计的参数，$\kappa$ 表示所有显式反馈的组合（即用户 $u$ 对物品 $i$ 进行过评分），r_{ui} 表示评分的实际值，\hat{r_{ui}} 表示评分的预测值，$\lambda$ 为超参，根据经验设置，然后求最小化 $l(P)$ 下各参数的值，通常使用最小二乘法，或者文中使用的梯度下降法（效率更高）。比如这个地方，参数就 $b_u$ 和 $b_i$，可以根据下式进行参数估计： \min_{b_*}\sum_{(u,i)\in \kappa} (r_{ui} - \hat{r_{ui}})^2 + \lambda(\sum_{p_1} p_1^2 + \sum_{p_2} p_2^2 + \cdots)2、推广到基于邻域的模型本文主要考虑 ItemCF，对于两个物品 $i$ 和 $j$，它们的相似性 s_{ij} 是基于 Pearson 相关系数 \rho_{ij} 计算得到： s_{ij} = \frac{n_{ij}}{n_{ij}+\lambda_2}\rho_{ij}, \\ \rho_{ij}=\frac{E((x-\mu_x)(y-\mu_y))}{\sigma_x\sigma_y}其中，$n_{ij}$ 表示同时对 $i$ 和 $j$ 进行评分的用户数，$\lambda_2$ 应该是防止 $i$ 和 $j$ 比较冷门的情况下，恰好有个别用户同时对它们进行了评分，这时候它们的相关性实际是看不出来的，属于偶然情况，通常 $\lambda_2=100$。之前的 ItemCF 进一步利用用户 $u$ 评过分的与 $i$ 最相关的 $k$ 个物品 $S^k(i;u)$ 来估计用户 $u$ 对 $i$ 的评分： \hat{r_{ui}} = b_{ui} + \frac{\sum_{j\in S^k(i;u)} s_{ij}(r_{uj} - b_{uj})}{\sum_{j\in S^k(i;u)} s_{ij}}但是如果 $u$ 没有对与 $i$ 相似的物品评过分，那上式就主要取决于 b_{ui} 了。为了解决这个小问题，有方案先计算插值权重 $\theta_{ij}^u$ 来取代实际的评分： \hat{r_{ui}} = b_{ui} + \sum_{j\in S^k(i;u)} \theta_{ij}^u (r_{uj} - b_{uj})但是以上模型都只考虑了用户 $u$，而对全局结构没有一个很好的理解，因此 Koren 提出不仅仅使用用户 $u$ 的对 $i$ 最相关的 $k$ 个物品的评分数据，而是使用所有 $u$ 的评分数据，因此引入一个参数 \omega_{ij} 来表示 $j$ 的评分对 $i$ 评分的影响，并且这个 $\omega_{ij}$ 是基于所有用户对 $i$ 和 $j$ 评分估计出来的： \hat{r_{ui}} = b_{ui} + \sum_{j\in R(u)} (r_{uj} - b_{uj})\omega_{ij}分析这个式子，当 $i$ 和 $j$ 越相关，说明 $j$ 对 $i$ 的影响越大，即 w_{ij} 越大，这时候如果 (r_{uj} - b_{uj}) 较大，则估计的评分相对于 b_{ui} 的偏移也就越多；反之，当 w_{ij} 较小时，无论 $j$ 的评分如何都对偏移影响不大。 在此基础上，进一步引入隐式反馈的数据： \hat{r_{ui}} = b_{ui} + \sum_{j\in R(u)} (r_{uj} - b_{uj})\omega_{ij} +\sum_{j\in N(u)} c_{ij}其中，c_{ij} 表示隐式反馈对基准估计的偏移影响，当 $j$ 与 $i$ 的评分强相关时，$c_{ij}$ 较大。这个式子的主要问题是，它对重度用户的推荐和对轻度用户的推荐结果相差较大，因为重度用户的显式反馈和隐式反馈都很多，因此偏移项值较大。Koren 发现，做一下正则化以后，效果会更好： \hat{r_{ui}} = b_{ui} + \mid R(u)\mid ^{-1/2}\sum_{j\in R(u)} (r_{uj} - b_{uj})\omega_{ij} +\mid N(u)\mid ^{-1/2}\sum_{j\in N(u)} c_{ij}为了降低上式的计算复杂度，可以只考虑对 $i$ 影响最大的 $k$ 个物品，记 $R^k(i;u)=R(u)\cap S^k(i)$ 表示 $u$ 评分过的物品中属于 $i$ 最相似的 TopK 物品，类似的，记 $N^k(i;u)=N(u)\cap S^k(i)$，这两个集合的元素个数通常是小于 $k$ 的（而如果 $u$ 对至少 $k$ 个物品评过分的话，$\mid S^k(i;u)\mid = k$）。则最终的模型为： \hat{r_{ui}} = b_{ui} + \mid R^k(i;u)\mid ^{-1/2}\sum_{j\in R(u)} (r_{uj} - b_{uj})\omega_{ij} +\mid N^k(i;u)\mid ^{-1/2}\sum_{j\in N(u)} c_{ij}使用之前提到的最小化 f(b_u, b_i, w_{ij}, c_{ij}) 的方法来估计这些参数的取值。记 e_{ui}=r_{ui} - \hat{r_{ui}}，则使用梯度下降法得到的迭代公式如下： \begin{cases} b_u \leftarrow b_u+\gamma\cdot (e_{ui} - \lambda_4\cdot b_u) \\ b_i \leftarrow b_i+\gamma\cdot (e_{ui} - \lambda_4\cdot b_i) \\ \omega_{ij} \leftarrow \omega_{ij} + \gamma\cdot(\mid R^k(i;u)\mid ^{-1/2}\cdot e_{ui}\cdot (r_{uj} - b_{uj})-\lambda_4\cdot \omega_{ij}), \forall j \in R^k(i;u) \\ c_{ij} \leftarrow c_{ij} + \gamma\cdot(\mid N^k(i;u)\mid ^{-1/2}\cdot e_{ui}-\lambda_4\cdot c_{ij}), \forall j \in N^k(i;u) \end{cases}对于 Netflix 数据集，Koren 推荐取 $\gamma=0.005$，$\lambda_4=0.002$，对所有数据集进行 15 轮训练。从实际效果来看 $k$ 越大，推荐的效果越好。这个模型的计算主要集中在参数训练上，一旦模型训练出来了，就可以快速的进行在线的预测。 3、推广到基于隐特征的模型原始的 SVD 是将用户和物品映射到一个隐特征集合： \hat{r_{ui}} = b_{ui} + p_u^T\cdot q_i由于用户的规模通常远大于物品的规模，因此考虑用 $u$ 喜欢的物品来对 $u$ 进行建模，再加上隐式反馈的数据，可以得到 Asymmetric-SVD 模型： \hat{r_{ui}} = b_{ui} + q_i^T(\mid R(u)\mid ^{-1/2}\sum_{j\in R(u)} (r_{uj} - b_{uj})x_j +\mid N(u)\mid ^{-1/2}\sum_{j\in N(u)} y_j)其中，x_j 和 y_j 是用来控制显式反馈和隐式反馈重要性比例的参数。用最小化 f(b_u,b_i,q_i,x_j,y_j) 来估计这些参数值。由于这里用 (r_{uj} - b_{uj})x_j 来替代原来的用户隐特征，因此数据量少了很多。该模型具有比较好的可解释性，并且对于新用户来讲，只要他做了一些反馈，即更新了 r_{uj} 后，就可以立即算出估计值；但是如果新上线一个物品，由于 q_i^T 需要重新估计，因此对新物品的冷启动需要一定的反应时间。 如果对于计算不是很 care 的话，当然可以不用这种简化处理，还是对用户直接进行建模（$p_u$），这样的效果会更好一些，但是可解释性之类的就要差一些： \hat{r_{ui}} = b_{ui} + q_i^T(p_u +\mid N(u)\mid ^{-1/2}\sum_{j\in N(u)} y_j)4、联合模型如果把上面两个模型看成是 预测值=基准估计+偏移量 的话，那么这两个模型就可以混合到一起，变成： \begin{align} \hat{r_{ui}} &= b_{ui} \\ &+ q_i^T(p_u +\mid N(u)\mid ^{-1/2}\sum_{j\in N(u)} y_j) \\ &+ \mid R^k(i;u)\mid ^{-1/2}\sum_{j\in R(u)} (r_{uj} - b_{uj})\omega_{ij} +\mid N^k(i;u)\mid ^{-1/2}\sum_{j\in N(u)} c_{ij} \end{align}其中，第一项为基准估计，第二项 provides the interaction between the user profile and the item profile. In our example, it may find that “The Sixth Sense” and Joe are rated high on the Psychological Thrillers scale. 第三项 contributes fine grained adjustments that are hard to profile, such as the fact that Joe rated low the related movie “Signs”. 使用梯度下降法得到的迭代公式如下： \begin{cases} b_u \leftarrow b_u+\gamma_1\cdot (e_{ui} - \lambda_6\cdot b_u) \\ b_i \leftarrow b_i+\gamma_1\cdot (e_{ui} - \lambda_6\cdot b_i) \\ q_i \leftarrow q_i+ \gamma_2\cdot(e_{ui}\cdot(p_u+\mid N(u)\mid ^{-1/2}\sum_{j\in N(u)} y_j)-\lambda_7\cdot q_i) \\ p_u \leftarrow p_u + \gamma_2\cdot(e_{ui}\cdot q_i - \lambda_7\cdot p_u) \\ y_j \leftarrow y_j+\gamma_2\cdot(e_{ui} \cdot\mid N(u)\mid ^{-1/2} \cdot q_i - \lambda_7\cdot y_j) \\ \omega_{ij} \leftarrow \omega_{ij} + \gamma_3\cdot(\mid R^k(i;u)\mid ^{-1/2}\cdot e_{ui}\cdot (r_{uj} - b_{uj})-\lambda_8\cdot \omega_{ij}),\ \forall j \in R^k(i;u) \\ c_{ij} \leftarrow c_{ij} + \gamma_3\cdot(\mid N^k(i;u)\mid ^{-1/2}\cdot e_{ui}-\lambda_8\cdot c_{ij}),\ \forall j \in N^k(i;u) \end{cases}在 Netflix 的数据集上，建议参数为 \gamma_1=\gamma_2=0.007，\gamma_3=0.001，\lambda_6=0.005，\lambda_7=\lambda_8=0.015，整体迭代约 30 轮收敛，每一轮训练时，可以将 \gamma_* 减少 10%。而 $k=300$，再大也不会有明显的性能提升。 最后，Koren 还设计了一个比较巧妙的实验，解答了我一直以来一个疑问：RMSE 的提升是否也意味着推荐效果的提升。他们设计了一个针对 TopN 推荐的测试，主要的思想是先找出所有 5-star 的评分，认为这些评分意味着该用户喜欢这部电影，然后对所有这些 $(u,i)$，随机再选 1000 部电影，估计 $u$ 对这些电影的评分，看用户对这些电影里所有的 5-star 电影排名情况，然后对不同的算法进行比较，发现 RMSE 越小的算法，将 5-star 排到前面的概率也越大，从而说明了在这种情况下，RMSE 的提升也意味着推荐效果的提升。]]></content>
      <categories>
        <category>论文精读</category>
      </categories>
      <tags>
        <tag>推荐</tag>
        <tag>协同过滤</tag>
        <tag>算法</tag>
        <tag>召回</tag>
        <tag>矩阵分解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[白话 Word2Vec]]></title>
    <url>%2F2018%2F02%2F21%2Fword2vec%2F</url>
    <content type="text"><![CDATA[这两天学习了下Word2Vector的理论和实现，原理什么的网上很多，就不搬运了，推荐看参考文献[1-3]，这里主要讲下我对几个关键点的理解。 1、词向量的意义为什么要生成词向量，或者说词向量解决原来哪个领域什么方法的哪些不足？我的理解是这玩意主要就是为了解决如何让计算机理解自然语言中单词含义的问题。当然，现在随着 word2vec 用法的推广，这里已经不仅仅是自然语言中单词的理解了，还可以是各种现实生活中计算机本来没有办法理解的概念，比如用户的观影行为、图片的主题等等，把这些计算机一脸蒙逼的东西转换为它们最喜欢的浮点向量，然后把理解这个计算机一脸蒙逼的行为转换成向量的运算，这样实际就是完成了人类世界各种概念向计算机世界的映射/翻译，为人工智能占领世界打下了坚实的基础（扯远了）。那词向量比之前的方法好在哪呢？给我印象最深的就是含义相近的词能用距离相近的向量来表示！至于其他的一些数学处理上的好处，感觉只是副产品。文献 [1-2] 提供了一种能专门训练词向量的方法，一份好的词向量是可以直接用于翻译等应用的，所以感觉当我们自己数据量不足的时候，可以考虑直接用别人训练出来的词向量。 2、训练过程Mikolov 等人提出了两种模型（CBOW 和 Skip-gram）、两种目标函数（Hierarchical Softmax, HS 和 Negative Sampling, NS），所以乘一下就是4个训练过程，但是其实理解起来都是差不多的。 先整体讲一下它们的关系，CBOW 模型是根据一个词 $w$ 的上下文 $U$ 来预测 $w$，Skip-gram是 根据一个词 $w$ 来预测上下文 $U$。初看时我是一脸蒙逼的，预测啥？后来才发现，实际上这里讲预测有点歧义，就是一个训练网络参数的过程。下文的理解需要有点基础知识，比如Huffman 编码之类的。 基于 HS 的 CBOW 模型和 Skip-gram 模型基于HS的CBOW模型实际上就是给定一个词 $w$ 的上下文 $U$ 中所有词的词向量 $v_u$ （$u \in U$），输出一个 Huffman 树，使得网络根据这些 $v_u$ 的和 $x_U$ 能顺着这个 Huffman 树一路找到词 $w$。这里的 Huffman 树是根据所有词的词频生成的，它的每个叶节点表示一个词 $i$，并记录该词的词向量 $v_i$，非叶节点针对每个单词 $w$ 都会生成一个参数向量 $\theta_w$）。那什么叫顺着 Huffman 树一路找到词 $w$呢？我们知道 Huffman 树是一棵二叉树，在任何一个非叶节点 $j$ 决定是往左走还是往右走的时候，实际上是用 $x_U^T\cdot \theta_w^j$ 来决定的，这类似于二分类问题，因此需要加一个激活函数（用的是 sigmoid 函数），但是这不重要，重要的是它要根据 $x_U^T\cdot \theta_w^j$ 来判断是往左走还是往右走。因此，整个 CBOW 模型实际上就是在计算如何给定 $x_U$ 来在 Huffman 树上一步一步找到 $w$ 所在的叶节点。这个框架定了，剩下就是把这个思路转换成优化方程，然后用 GD 的方法来迭代求解，求解的过程中会不断更新 $\theta_w$ 和 $v_u$。注意，CBOW 模型虽然说是根据 $w$ 的上下文 $U$ 来预测 $w$，但是它更新的是 $w$ 的上下文 $U$ 中词的词向量。 基于 HS 的 Skip-gram 模型也是一样的道理，但是它的输入是 $v_w$，目标是在 Huffman 树中找到 $w$ 的所有上下文 $u$ 所在的叶节点（把每次查找都乘起来就 OK 了）。然后又是一堆计算，得到一个迭代方程组，来更新 $\theta_u$ 和 $v_w$（跟上面的类似，$\theta_u^j$ 是用来控制根据 $v_w$ 决定在每个非叶节点 $j$ 是往左走还是往右走才能找到 $u$ 所在的叶节点）。 基于 HS 的目标函数有一个小问题，就是所有非叶节点 $i$ 会对所有的词 $w$ 训练参数向量 $\theta_w^i$，因此需要很大的数据量，而且存储量也很大。基于 NS 的目标函数就能大大减少参数的个数，下面详细讨论下。 基于 NS 的 CBOW 模型和 Skip-gram 模型前面讲了，基于 HS 的模型生成的是 Huffman 树，每次训练是最大化找到某个词（根据上下文找一个词，或者根据词找它的上下文）的概率。而基于 NS 的模型则是最大化正确分类某个词的概率。前面提到了，在 Huffman 树上往下走的时候，相当于是一个二分类问题，那为什么不用更加直观的分类呢？ 什么是更直观的分类呢？给定一个样本，比如说一个词 $w$ 及其上下文 $U$，这时候再从词库里随便挑一些小伙伴出来，目标就是区分 $w$ 和这些新伙伴谁是 $U$ 的那个他（CBOW 模型），或者区分 $U$ 和这些新伙伴，谁是 $w$ 的上下文（Skip-gram 模型）？当然，这些小伙伴也不是随机选的，用的是随机负采样（所以叫 Negtive Sampling），本质上就是一种带权采样，也就是出现次数越多的词采到的概率越大。 基于 NS 的 CBOW 模型输入还是一个词 $w$ 的上下文 $U$ 中所有词的词向量之和 $x_U$，以及随机选的小伙伴们 $F$，分类是对每个 $p\in {w} \cup F$，训练一个参数向量 $\theta_p$，然后根据 $x_U^T\cdot \theta_p$（借助 sigmoid 函数分类）来判断 $p$ 到底是不是 $w$？因此设置的目标函数就是最大化分对的概率同时最小化分错的概率，然后再用 GD 列出一堆迭代方程来求解。从这里可以看到，HS 是对 Huffman 树上到 $w$ 的每个非叶节点训练一个参数向量，而这里是对 $p\in {w} \cup F$ 训练参数向量，参数向量的个数少了很多（$(N-1)\cdot N$ vs. $N$），但是训练时间却不一定。文献 [2] 给出的数据是 $\mid F\mid=5$ 时，NS 方法快，$\mid F\mid=15$ 时，HS 方法快。 基于 NS 的 Skip-gram 模型也是类似，就是给定 $w$ 的词向量及其上下文，再选一群小伙伴，最大化把 $w$ 的上下文正确分出来并且最小化分错的概率。 3、词向量的应用参考文献[1] Mikolov T, Chen K, Corrado G, et al. Efficient estimation of word representations in vector space[J]. arXiv preprint arXiv:1301.3781, 2013.[2] Mikolov T, Sutskever I, Chen K, et al. Distributed representations of words and phrases and their compositionality[C]//Advances in neural information processing systems. 2013: 3111-3119.[3] peghoty. word2vec 中的数学原理详解. http://www.cnblogs.com/peghoty/p/3857839.html.]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>表征向量</tag>
      </tags>
  </entry>
</search>
