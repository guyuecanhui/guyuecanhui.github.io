{"meta":{"title":"Looping","subtitle":"Watch, learn and practise","description":"总结心得","author":"胡诚","url":"https://guyuecanhui.github.io","root":"/"},"pages":[{"title":"关于我自己","date":"2019-04-13T05:51:57.000Z","updated":"2019-04-13T06:22:46.422Z","comments":true,"path":"about/index.html","permalink":"https://guyuecanhui.github.io/about/index.html","excerpt":"","text":"我叫胡诚，本博就读于东南大学计算机系，研究方向为分布式计算，传感器网络，云计算。目前主要兴趣为推荐系统、大数据、机器学习技术和传统算法。 欢迎大家通过邮箱与我交流：guyuecanhui@icloud.com。"},{"title":"tags","date":"2019-04-13T05:44:53.000Z","updated":"2019-04-13T05:54:54.764Z","comments":true,"path":"tags/index.html","permalink":"https://guyuecanhui.github.io/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-04-13T05:44:08.000Z","updated":"2019-04-13T05:54:55.762Z","comments":true,"path":"categories/index.html","permalink":"https://guyuecanhui.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"可能是最好懂的ItemCF解释了","slug":"itemcf","date":"2019-04-12T05:56:07.000Z","updated":"2019-04-13T07:08:36.074Z","comments":true,"path":"2019/04/12/itemcf/","link":"","permalink":"https://guyuecanhui.github.io/2019/04/12/itemcf/","excerpt":"","text":"说到推荐系统，可能最为人熟知的算法就是协同过滤，特别是其中的 ItemCF，自亚马逊文章发表以后，得到了广泛而成功的应用。这篇文章主要谈谈我的理解。 ItemCF 推导过程首先，ItemCF 依赖一个隐含的假设：就是每个用户的兴趣都局限在某几个方面，因此如果两个物品属于一个用户的兴趣列表，那么这两个物品可能就属于有限的几个领域，而如果两个物品属于很多用户的兴趣列表，那么它们就可能属于同一个领域，因而有很大的相似度。 从这个假设出发，我们可以认为两个视频相似表现在它们被很多用户同时观看，两个物品共同观看的人数越多，说明它们的相似度越高，用公式来表达就是： s_{i,j}=|N(i)\\cap N(j)| \\qquad (1)其中，$N(i)$ 表示观看视频 $i$ 的人群集合，$|N(i)\\cap N(j)|$ 表示同时播放过 $i,j$ 的人数。但是由于热点视频可能并不代表用户的真实兴趣（有可能是运营推送，或者仅仅是由于追热心理），因此需要惩罚那些热点的视频，可以通过将共同观看人数除以与视频总观看数相关的系数来实现，例如使用以下方式： s_{i,j}=\\frac{|N(i)\\cap N(j)|}{\\sqrt{|N(i)|\\cdot|N(j)|}} \\qquad (2)但是仅仅惩罚热点视频也还不够，有些人就是闲的无聊，有什么看什么，这种情况下他表现出来的就未必是真实的兴趣了（就不满足我们的隐含假设），他的行为也就不太能作为我们的协同的依据，因此需要对这种人做降权，例如使用以下方式： s_{i,j}=\\frac{\\sum_{u\\in N(i)\\cap N(j)}\\frac{1}{log(1+|M(u)|)}}{\\sqrt{|N(i)|\\cdot|N(j)|}} \\qquad (3)其中，$M(u)$ 表示用户 $u$ 观看的视频集合。另外，如果用户对视频 $i$ 观看了 80%，而对视频 $j$ 只看了 10%，那用户对这两个视频的喜欢程度也是不相同的，因此我们还可以对用户对两个视频观看的完成度差异做降权，差异越大，相似度也越低，例如使用以下方式： s_{i,j}=\\frac{\\sum_{u\\in N(i)\\cap N(j)}\\frac{\\cos(r_u(i),r_u(j))}{log(1+|M(u)|)}}{\\sqrt{|N(i)|\\cdot|N(j)|}} \\qquad (4)其中，$r_u(i)$ 表示用户 $u$ 对视频 $i$ 的观看完成度。最后，将所有视频与其他视频的相似度做 $max$ 归一化，得到： s_{i,j}'=\\frac{s_{i,j}}{\\max_j s_{i,j}} \\qquad (5)归一化使得所有物品的相似度取值都在 (0,1] 之间，这个相似度已经可以直接用于相关推荐场景。另外，有研究表明，这种归一化可以提高 ItemCF 用于个性化推荐时的准确度、覆盖率和多样性。 那基于 ItemCF 如何进行个性化推荐呢？主要是考虑推荐与用户的观看历史最相似的视频，即计算每个视频与用户观看视频集合的相似度作为作为是否观看该视频的预测值： p_u(i)=\\frac{\\sum_{j\\in M(u)} s_{i,j}\\cdot r_u(j)}{\\sum_{j\\in M(u)} s_{i,j}} \\qquad (6)最后，再根据预测值从大到小选取 TopN 个视频作为推荐结果。 优化与讨论其实从第1部分的介绍来看，基于 ItemCF 的思想可以做很多改进。例如： 如果感觉算出来的结果仍然偏向热门视频时，可以增加式 (4) 的分母大小； 如果觉得用户只有观看完完成度很高时才是真实兴趣，那可以将式 (4) 的 $cos(\\cdot)$ 部分改成类似 $r_u(i)\\cdot r_u(j)$ 的形式； 如果觉得需要更多的考虑用户的短期兴趣，做即时的推荐，那可以将式 (6) 中的用户观看历史限制在最近几次，甚至一次； 如果把用户-视频考虑成一个二部图，ItemCF 实际上是基于图的结构，执行了一次从用户到视频的兴趣扩散过程。可以考虑下图中的视频 $v_1,v_3​$，它们没有直接的共同观看，因此用 ItemCF 算出来的相似度为 0，但是实际上 $u_1,u_2​$ 都观看了 $v_2​$，因此可以认为用户 $u_1,u_2​$ 存在一定的相似性，因此如果执行一次视频-用户-视频的兴趣扩散过程就能够捕获 $v_1,v_3​$ 的相似度了。 后面一种思路实际上就是 SimRank，但是由于需要执行多次兴趣扩散（即对二部图做多次迭代计算），SimRank 的计算复杂度相当高，在业务数据量大的情况下需要强大的算力支持，以后会再讨论下我在 SimRank 模型上的尝试。","categories":[{"name":"推荐系统","slug":"推荐系统","permalink":"https://guyuecanhui.github.io/categories/推荐系统/"}],"tags":[{"name":"推荐","slug":"推荐","permalink":"https://guyuecanhui.github.io/tags/推荐/"},{"name":"协同过滤","slug":"协同过滤","permalink":"https://guyuecanhui.github.io/tags/协同过滤/"},{"name":"算法","slug":"算法","permalink":"https://guyuecanhui.github.io/tags/算法/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-04-10T13:57:37.514Z","updated":"2019-04-10T13:57:37.514Z","comments":true,"path":"2019/04/10/hello-world/","link":"","permalink":"https://guyuecanhui.github.io/2019/04/10/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"置信区间在推荐中的应用","slug":"confidence-interval","date":"2019-02-10T05:22:05.000Z","updated":"2019-04-13T12:13:47.051Z","comments":true,"path":"2019/02/10/confidence-interval/","link":"","permalink":"https://guyuecanhui.github.io/2019/02/10/confidence-interval/","excerpt":"","text":"学过统计的同学都对置信区间的概念非常熟悉，实际上，离开置信区间谈统计值没啥意义，或者说经常会造成很大的误导。简单来讲，置信区间是指基于观测样本来估计一个未知参数（如均值）时，我们相当确定（用置信度来度量）参数可能的取值范围。如果不考虑置信区间的概念，在我们观察到有 2 个用户喜欢一个视频、1 个用户不喜欢一个视频时，会估计该视频的推荐度为 66%，而认为它是一个高质量的视频，如果一旦将它进行大规模推荐时，很可能发现这个视频的实际转化率低的可怜。 因此在推荐里，置信区间是需要密切关注的概念。在推荐领域实践中，我从 3 个简单的算法来分别介绍置信区间的应用。 Wilson 区间法来判断视频质量在引言的例子中，我们组的海威同学利用 Wilson 区间法来估计视频的推荐度，或者说，来建立视频质量评估模型（模型的一部分）。利用视频播放行为数据来统计视频的播放转化率时，假设视频展示的总数为 $n$，用户实际播放的总数为 $m$，则直接计算出来的播放转化率为 $p=\\frac{m}{n}$。如果 $n$ 越大，说明 $p$ 的估计置信度越高，否则置信度越低。由于视频质量直接决定了我们是否会大规模推荐这个视频，因此在估计 $p$ 时采用的是宁缺毋滥的策略，这个时候可以巧妙的用置信区间的下界来代替 $p$ 作为播放转化率的估计。 具体到 Wilson 区间的计算公式，可以参考wiki（基于正态分布假设），这里只搬个公式： p_w = \\max(0, \\frac{p+\\frac{z^2}{2n}}{1+\\frac{z^2}{n}}-\\frac{z}{1+\\frac{z^2}{n}}\\sqrt{\\frac{p(1-p)}{n}+\\frac{z^2}{4n^2}})其中，$z$ 为某置信度（如 95% 置信度）下查表可得，$n$ 在实际代入时，需要加上平滑因子（如 0.1），防止展示数据丢失导致 $n=0$。从公式可知，基于 Wilson 区间估计的播放转化率最小接近于 0（$n$ 在实际时很可能取到平滑因子），最大接近于 $p$。 UCB算法来平衡探索与应用（E&amp;E）Wilson区间法是用置信区间的下限来减少数据量不足时误判的可能，主要是用来选出精品视频用来广泛推荐。但是一直这样保守推荐，会导致有些视频得不到充分的曝光，就难以评估其实际的转化率，导致推荐出来的所谓精品只是次优的选择。因此，在应用（Expoit）目前已知比较好的视频进行推荐的同时，也要保持一定比例的探索（Explore），即尝试一下那些曝光较少的视频。EE算法里一个常用的算法是 LinUCB，由于涉及特征构造，这里只介绍一个简化版本 UCB，大致思路是一样的。 UCB（Upper Confidence Bound）是一种多臂老虎机算法（MAB），也勉强算一种简化的强化学习算法，调性十足。同样以估计播放转化率为例，它的思路是利用置信区间的上界来代替 $p$ 作为估计值，实际上是提高了曝光不足视频（即长尾视频）的估计值。 UCB 主要解决的问题在于，如何计算置信区间的上界，既能保证随着曝光总量的增加，那些未被探索的视频越来越少，又能保证长久来看，能选到精品的视频。为了实现这个目标，一个常用的启发式公式如下： p_u=\\max_{i}(p_i+\\sqrt{\\frac{2\\ln t}{n_i}})其中，$p_i$ 为某个视频 $n_i$ 次曝光计算的平均转化率，$t$ 表示所有视频总共的曝光数。可以看到，随着曝光总数的增加，曝光很少的视频第二项值会很大，因此所有视频都会得到保底的曝光（t=100000 时至少有 28 次）。但是随着 $n_i$ 继续增加，主要决定因素又变成了 $p_i$，即历史平均转化率高的视频更可能被选中。 Thompson 采样来进行随机长尾推荐UCB 算法在实际于新物品增加快的场景（例如短视频推荐，平均每天新增几万部短视频）时，由于计算过程是确定性的，存在一直只推新物品的问题。为了增加一些随机性，可以考虑用 Thompson 采样算法。它既不使用置信区间的上界，也不使用下界，而是每次基于 Beta(m, n-m) 分布进行采样（注意，这里的 m 和 n 是每个视频单独维护的参数）。 我们知道，Beta 分布实际上是“白努力”过程的成功率，曝光数 $n$ 越大，Beta 分布的曲线越像是一个倒钟的形状，且钟的开口越窄，最后收于期望：$p=\\frac{m}{n}$。反过来说，当使用 Thompson 采样来选择推荐的视频时，虽然每个视频长期来选中的概率取决于其转化率，但是当曝光数量少时，Beta 分布开口很大，也更容易得到比期望大或者小的采样结果，从而引入了随机性。不过从实际应用来看，当媒资库时的视频数量很多时，大部分选中的视频还是新视频。 本文简单的介绍了统计区间在推荐中的一些简单应用，既有利用置信区间的下界来选精品，也有利用置信区间的上界来探索，还有利用整个分布来引入随机性。所有算法都是用简单的数学公式就能达到我们期望的效果，是比人工规则优美的多的形式。当然，举的示例都是推荐的核心问题，没有这么简单就能讲清楚，涉及大量的数据处理和参数调优，需要不断尝试和改进。","categories":[{"name":"推荐系统","slug":"推荐系统","permalink":"https://guyuecanhui.github.io/categories/推荐系统/"}],"tags":[{"name":"推荐","slug":"推荐","permalink":"https://guyuecanhui.github.io/tags/推荐/"},{"name":"统计","slug":"统计","permalink":"https://guyuecanhui.github.io/tags/统计/"},{"name":"置信区间","slug":"置信区间","permalink":"https://guyuecanhui.github.io/tags/置信区间/"}]},{"title":"特征组合之FFM","slug":"ffm","date":"2018-10-04T06:43:50.000Z","updated":"2019-04-13T07:08:32.023Z","comments":true,"path":"2018/10/04/ffm/","link":"","permalink":"https://guyuecanhui.github.io/2018/10/04/ffm/","excerpt":"","text":"前段时间搞 LR 的特征优化，切身体会到人工特征工程实在太费劲了，一方面发掘高价值的特征十分困难，另一方面某些特征之间需要组合才能有效，比如用户对视频的某个特征的偏好，就必须将视频的特征和用户的特征进行组合。LR 是线性模型，没法自动做特征组合，只能人工搞，但人工来干这事就相当麻烦了。自然而然的，就会想到用可以自动组合特征的模型。现在了解的包括 FM、FFM 等基于矩阵分解的模型、基于 GBDT 之类的树模型和基于 DNN 的网络模型。这篇文章先介绍下 FFM 模型。 FFM 模型简介FFM (Field-aware Factorization Machines)$^{[1]}$是 Yuchin Juan 等人在台大期间提出的用于 CTR 预估的模型。它是对 FM 模型的推广，提到 FM 又不得不提到 Poly2 模型，好在它们三个的关系十分简单和明确： Poly2 模型是将所有特征进行两两组合，也就是当特征有 $n$ 个的时候，需要 $O(n^2)$ 个参数，而且这些参数之间是相互独立的，意味着每个参数都需要足够的样本来训练，也就是每对特征都同时出现在足够多的样本里。因此如果无法满足海量样本的要求时，这个模型很难训练出来。它的模型如下（其中 $h(i,j)$ 作用是将 $i,j$ 映射成一个自然数）： \\phi_{poly2}(\\mathcal{w},\\mathcal{x}) = \\sum_{j_1=1}^n\\sum_{j_2=j_1+1}^n w_{h(j_1,j_2)}x_{j_1}x_{j_2} \\qquad (1) FM 模型是为每个特征训练一个隐向量，而特征组合的权重就是这两个特征的隐向量点积，假设隐向量的长度为 $k$，那么需要 $O(nk)$ 个参数，因此参数的规模要比 Poly2 小很多（这里可以认为 Poly2 为每个特征生成的向量长度为 $n$），训练数据量要求也就没那么高了。它的原始形态 (2) 和简化计算形态 (3) 分别如下： \\phi_{FM}(\\mathcal{w},\\mathcal{x})= \\sum_{j_1=1}^n\\sum_{j_2=j_1+1}^n (\\mathcal{w}_{j_1}\\cdot\\mathcal{w}_{j_2})x_{j_1}x_{j_2} \\qquad (2) \\phi_{FM}(\\mathcal{w},\\mathcal{x})=\\frac{1}{2}\\sum_{j=1}^n(\\mathcal{s}-\\mathcal{w}_j x_j), \\quad \\mathcal{s}=\\sum_{j'=1}^n\\mathcal{w}_{j'} x_{j'} \\qquad (3) FFM 模型是为每个特征对每一个 Field 学习一个隐向量，一个 Field 可以认为是特征所属的属性，比如用户的常驻地可以看成是一个 Field、视频的分类可以看成是另一个 Field，假设有 $f$ 个 Field，每个隐向量长度为 $k$，则FFM模型需要 $O(nfk)$ 个参数，看起来比 FM 多很多，但是实际上由于每个特征对不同 Field 的作用都是单独学习的，因此 FFM 的 $k$ 往往比 FM 的 $k$ 小很多。它的模型如下： \\phi_{FFM}(\\mathcal{w},\\mathcal{x})= \\sum_{j_1=1}^n\\sum_{j_2=j_1+1}^n (\\mathcal{w}_{j_1,f_2}\\cdot\\mathcal{w}_{j_2,f_1})x_{j_1}x_{j_2} \\qquad (4)FFM 为什么要把Field拎出来考虑呢？举个例子，还是在视频推荐里，假设只考虑用户的年龄特征、视频的分类特征和演员特征，FM 在学用户年龄特征的时候是综合考虑视频分类和演员来得到的，然而从直观上来看，年龄对分类的影响和对演员的影响是不同的，因此更自然的想法是对分类和演员各学一个隐向量，效果应该会更好。 换句话说，如果特征有明显的 Field 划分，用 FFM 模型理论上是优于 FM 的；但是如果不满足这个条件，例如在 NLP 领域，所有特征都属于一个 Field，FFM 模型的优势就不明显了。另外，Field 很容易对应到一个类别，因此 FFM 特别适合处理类别特征，对于连续特征，如果离散化处理效果比较好也还OK，否则优势也不明显。因此，FFM 主要适合处理类别特征，并且喜欢稀疏数据，而不适合处理连续特征，不适合处理 Field 数量很少的数据。 FFM 模型实现由于官方只提供了 FFM 模型的 C++ 实现$^{[2]}$，而我们主要是基于 Spark 的，因此需要一份 scala 实现。网上也找了一下，发现 Vince Shieh 实现的一份代码$^{[3]}$，但是 review 以后发现参数有点问题，因此考虑自己实现一份。实现的 FFM 的核心就在于如何计算梯度，如何更新模型。论文的模型 (4) 是简化处理，在实现的时候还需要带上全局偏置和线性部分，完整的模型如下： \\phi_{FFM}(\\mathcal{w},\\mathcal{x})= w_0 + \\sum_{j=1}^n w_jx_j+ \\sum_{j_1=1}^n\\sum_{j_2=j_1+1}^n (\\mathcal{w}_{j_1,f_2}\\cdot\\mathcal{w}_{j_2,f_1})x_{j_1}x_{j_2} \\qquad (5)而 FFM 用于 CTR 预估时，目标优化函数定义成： \\mathcal{L}=\\min_{\\mathcal{w}} \\frac{\\lambda}{2}||\\mathcal{w}||^2_2+\\sum_{i=1}^m \\log(1+e^{-y_i\\phi(\\mathcal{w},\\mathcal{x})}) \\qquad (6)使用 SG 的方式进行更新，即每次使用一个样本 $(y,\\mathcal{x})$ 来更新模型，其中，$\\mathcal{x}$ 的格式为 $\\mathcal{x}=[f{i_1}j{i1}x{i1},\\cdots,f{it}j{it}x{i_t}]$，表示该样本中 $t$ 个非零特征，$f$ 表示特征的域编号，$j$ 表示特征编号，$x$ 表示特征取值（对于 one-hot 编码，$x=1$）。首先对式 (6) 中各权重计算梯度： \\begin{cases} g_0=\\lambda w_0+\\kappa \\\\ g_j=\\lambda w_j+\\kappa w_j \\\\ \\mathcal{g}_{j_1,f_2}=\\lambda \\mathcal{w}_{j_1,f_2}+\\kappa \\mathcal{w}_{j_2,f_1} \\\\ \\mathcal{g}_{j_2,f_1}=\\lambda \\mathcal{w}_{j_2,f_1}+\\kappa \\mathcal{w}_{j_1,f_2} \\end{cases}, \\quad \\kappa=\\frac{-y_ie^{-y_i\\phi(\\mathcal{w},\\mathcal{x})}}{1+e^{-y_i\\phi(\\mathcal{w},\\mathcal{x})}} \\qquad (7)然后使用 AdaGrad 对累积梯度进行更新（这里也可以不用 AdaGrad，直接使用 GD，或者用 Adam 等其他方法更新）： \\begin{cases} G_i=G_i+g_i^2 \\\\ w_i=w_i-\\frac{\\eta}{\\sqrt{G_i}} g_i \\end{cases}, \\quad i=0, i_1, \\cdots, i_t \\qquad (8) \\begin{cases} (G_{j_1,f_2})_d=(G_{j_1,f_2})_d+(g_{j_1,f_2})_d^2 \\\\ (G_{j_2,f_1})_d=(G_{j_2,f_1})_d+(g_{j_2,f_1})_d^2 \\\\ (w_{j_1,f_2})_d=(w_{j_1,f_2})_d-\\frac{\\eta}{\\sqrt{(G_{j_1,f_2})_d}} (g_{j_1,f_2})_d \\\\ (w_{j_2,f_1})_d=(w_{j_2,f_1})_d-\\frac{\\eta}{\\sqrt{(G_{j_2,f_1})_d}} (g_{j_2,f_1})_d \\end{cases}, \\quad d=1,\\cdots, k,\\qquad (9)基于以上各式，可以很容易把算法写出来了：12345678910Algorithm: Train FFM using SG init G = ones(n,f,k) init g = rand(n,f,k)[0,1/sqrt(k)] for epoch = 1 to t: for i = 1 to m: sample a data point (y,x) calculate kappa by (7) for xi, xj in x: calculate gradients by (7) update weights by (8)(9) 论文中指出，FFM 特别容易过拟合，其中，正则化系数 $\\lambda$ 越小，效果越好但越容易过拟合；学习率 $\\eta$ 越大，学习速度越快也越容易过拟合。我自己试了几个数据集，使用 $\\lambda=0.00002,\\ \\eta=0.1,\\ k=4$，一般 1~4 轮都差不多OK了，再多就容易过拟合。为了防止过拟合，论文提出使用 early stopping 技术，即将训练数据进一步划分成训练集和验证集，每一轮用训练集更新完模型后，用验证集计算 logloss，并记录验证集 logloss 开始上升的轮数 $r$，最后再用整个数据集训练 $r$ 轮。但是实际在用的时候，可以线下调一个比较好的参数，然后直接放到线上去用，等数据发生变化，或者定时去重新评估这些参数。 自己用 scala 实现的 FFM 模型没有使用指令集加速，只是将训练数据划分成多个 partition 并行训练，然后将参数合并（求平均），效果差一些。我拿 libFFM 做了一个性能的比较……完败……唉，Spark 做数值计算还是不太行啊！ References[1] Juan, Yuchin, et al. “Field-aware Factorization Machines for CTR Prediction.” ACM Conference on Recommender Systems ACM, 2016:43-50.[2] https://github.com/guestwalk/libffm[3] https://github.com/VinceShieh/spark-ffm","categories":[{"name":"推荐系统","slug":"推荐系统","permalink":"https://guyuecanhui.github.io/categories/推荐系统/"}],"tags":[{"name":"推荐","slug":"推荐","permalink":"https://guyuecanhui.github.io/tags/推荐/"},{"name":"排序","slug":"排序","permalink":"https://guyuecanhui.github.io/tags/排序/"},{"name":"特征工程","slug":"特征工程","permalink":"https://guyuecanhui.github.io/tags/特征工程/"},{"name":"特征组合","slug":"特征组合","permalink":"https://guyuecanhui.github.io/tags/特征组合/"}]},{"title":"Submodular函数","slug":"sub-modular","date":"2018-08-16T12:14:44.000Z","updated":"2019-04-13T12:27:55.260Z","comments":true,"path":"2018/08/16/sub-modular/","link":"","permalink":"https://guyuecanhui.github.io/2018/08/16/sub-modular/","excerpt":"","text":"Submodular 函数的定义与性质最近在看一些计算学习理论的时候，发现很多文章是基于 Submodular 函数做的，就去了解了一下。所谓 Submodular 函数，是指满足如下定义的集合函数$^{[1]}$： 记 $[n]={1,2,\\cdots,n}​$ 为 Ground Set，记 $f:2^{[n]}\\to\\mathbb{R}​$ 为一个集合函数，该函数是 submudular当： f(A)+f(B)\\ge f(A\\cup B)+f(A\\cap B), \\quad \\forall A,B\\subseteq[n] \\qquad(1)​ 它是对 Modular 函数的条件进行放松，而 Modular 函数是指满足如下定义的函数： f(A)+f(B)=f(A\\cup B)+f(A\\cap B), \\quad \\forall A,B\\subseteq[n] \\qquad(2)看定义，Submodular 函数与凹函数有些相似，不同的在于它并不限定元素的顺序！Submodular 函数还有一种等价式，更能体现它的一个核心特点： f(A\\cup \\{i\\})-f(A)\\ge f(B\\cup \\{i\\})-f(B), \\quad \\forall A\\subseteq B\\subseteq [n],\\ i\\not \\in B \\qquad(3)通俗的来讲，这个特点就是边际效用递减，即增加一个元素对整体的收益贡献递减。这种边际效用递减的程度可以用曲率 $\\kappa$（Curvature）来度量：$f_S(i)\\ge (1-\\kappa)f(i)$，其中，$0\\le\\kappa\\le1$。 举两个跟推荐有关系的 Submodular 函数的例子： 视频推荐多样性：对于一个可推荐的视频集合 $S$，假设每个视频有一个分类 $g_i$，则一个推荐列表中不同类别的总数 $f(S)=\\sum_i \\mathbb{I}(g_i)$ 就是一个 Submodular 函数，其中，$\\mathbb{I}(x)$ 表示元素 $x$ 是否存在。 商品推广用户选择：对于一个社交网络的用户集合 $S$，如果某用户看过一个物品，则他有可能向他的朋友推荐和分享。假设某个物品在推广期时给 $k$ 个用户 $S_k$ 展示了，则最终该物品会展示给多少用户 $m=f(S_k)$ 是一个 Submodular 函数。 最后简单介绍下它的一些性质。Submodular 函数首先是集合函数，因此满足如下性质： 非负性：$f(A)\\ge 0$ 单调性：可以是单调增或单调减 正则化：$f(\\phi)=0$ 另外，根据定义，可以证明它还满足： 若 $f_1,f_2,\\cdots,f_k$ 是 Submodular 函数，给定 $w_1,w_2,\\cdots,w_k\\ge 0$，则 $g(S)=\\sum_iw_if_i(S)$ 也是 Submodular 函数 若 $f$ 在 $X$ 集合上是 Submodular 函数，给定 $T\\subseteq X$ 则 $f(S\\cup T)$、$f(S\\cap T)$、$f(X\\setminus S)$ 都是 Submodular 函数 由于 Submodular 函数性质好、易证明，它在机器学习、博弈论等领域的理论研究方面获得了广泛的应用$^{[1,2]}​$。特别的，文献$[1]​$基于 Submodular 目标提出了 PMAC 理论，是对 PAC 理论的扩展；文献$[2]​$基于 Submodular 函数提出一种 AdaptiveSampling 的算法，可以在理论保证的前提下，将样本数大大减少，这里就不展开了。 Reference[1] Balcan, Maria Florina, and N. J. A. Harvey. “Learning submodular functions.” ACM Symposium on Theory of Computing ACM, 2011:793-802.[2] Balkanski, Eric and Singer, Yaron. “Approximation Guarantees for Adaptive Sampling.” Proceedings of the 35th International Conference on Machine Learning, 2018:393-402.","categories":[{"name":"数学","slug":"数学","permalink":"https://guyuecanhui.github.io/categories/数学/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://guyuecanhui.github.io/tags/优化/"},{"name":"计算学习理论","slug":"计算学习理论","permalink":"https://guyuecanhui.github.io/tags/计算学习理论/"},{"name":"函数","slug":"函数","permalink":"https://guyuecanhui.github.io/tags/函数/"}]}]}