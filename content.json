{"meta":{"title":"Looping","subtitle":"Watch, learn and practise","description":"总结心得","author":"胡诚","url":"https://guyuecanhui.github.io","root":"/"},"pages":[{"title":"categories","date":"2019-04-13T05:44:08.000Z","updated":"2019-04-13T05:54:55.762Z","comments":true,"path":"categories/index.html","permalink":"https://guyuecanhui.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-04-13T05:44:53.000Z","updated":"2019-04-13T05:54:54.764Z","comments":true,"path":"tags/index.html","permalink":"https://guyuecanhui.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"可能是最好懂的ItemCF解释了","slug":"可能是最好懂的ItemCF解释了","date":"2019-04-13T05:56:07.000Z","updated":"2019-04-13T06:18:08.145Z","comments":true,"path":"2019/04/13/可能是最好懂的ItemCF解释了/","link":"","permalink":"https://guyuecanhui.github.io/2019/04/13/可能是最好懂的ItemCF解释了/","excerpt":"","text":"说到推荐系统，可能最为人熟知的算法就是协同过滤，特别是其中的 ItemCF，自亚马逊文章发表以后，得到了广泛而成功的应用。这篇文章主要谈谈我的理解。 ItemCF 推导过程首先，ItemCF 依赖一个隐含的假设：就是每个用户的兴趣都局限在某几个方面，因此如果两个物品属于一个用户的兴趣列表，那么这两个物品可能就属于有限的几个领域，而如果两个物品属于很多用户的兴趣列表，那么它们就可能属于同一个领域，因而有很大的相似度。 从这个假设出发，我们可以认为两个视频相似表现在它们被很多用户同时观看，两个物品共同观看的人数越多，说明它们的相似度越高，用公式来表达就是： s_{i,j}=|N(i)\\cap N(j)| \\qquad (1)其中，$N(i)$ 表示观看视频 $i$ 的人群集合，$|N(i)\\cap N(j)|$ 表示同时播放过 $i,j$ 的人数。但是由于热点视频可能并不代表用户的真实兴趣（有可能是运营推送，或者仅仅是由于追热心理），因此需要惩罚那些热点的视频，可以通过将共同观看人数除以与视频总观看数相关的系数来实现，例如使用以下方式： s_{i,j}=\\frac{|N(i)\\cap N(j)|}{\\sqrt{|N(i)|\\cdot|N(j)|}} \\qquad (2)但是仅仅惩罚热点视频也还不够，有些人就是闲的无聊，有什么看什么，这种情况下他表现出来的就未必是真实的兴趣了（就不满足我们的隐含假设），他的行为也就不太能作为我们的协同的依据，因此需要对这种人做降权，例如使用以下方式： s_{i,j}=\\frac{\\sum_{u\\in N(i)\\cap N(j)}\\frac{1}{log(1+|M(u)|)}}{\\sqrt{|N(i)|\\cdot|N(j)|}} \\qquad (3)其中，$M(u)$ 表示用户 $u$ 观看的视频集合。另外，如果用户对视频 $i$ 观看了 80%，而对视频 $j$ 只看了 10%，那用户对这两个视频的喜欢程度也是不相同的，因此我们还可以对用户对两个视频观看的完成度差异做降权，差异越大，相似度也越低，例如使用以下方式： s_{i,j}=\\frac{\\sum_{u\\in N(i)\\cap N(j)}\\frac{\\cos(r_u(i),r_u(j))}{log(1+|M(u)|)}}{\\sqrt{|N(i)|\\cdot|N(j)|}} \\qquad (4)其中，$r_u(i)$ 表示用户 $u$ 对视频 $i$ 的观看完成度。最后，将所有视频与其他视频的相似度做 $max$ 归一化，得到： s_{i,j}'=\\frac{s_{i,j}}{\\max_j s_{i,j}} \\qquad (5)归一化使得所有物品的相似度取值都在 (0,1] 之间，这个相似度已经可以直接用于相关推荐场景。另外，有研究表明，这种归一化可以提高 ItemCF 用于个性化推荐时的准确度、覆盖率和多样性。 那基于 ItemCF 如何进行个性化推荐呢？主要是考虑推荐与用户的观看历史最相似的视频，即计算每个视频与用户观看视频集合的相似度作为作为是否观看该视频的预测值： p_u(i)=\\frac{\\sum_{j\\in M(u)} s_{i,j}\\cdot r_u(j)}{\\sum_{j\\in M(u)} s_{i,j}} \\qquad (6)最后，再根据预测值从大到小选取 TopN 个视频作为推荐结果。 优化与讨论其实从第1部分的介绍来看，基于 ItemCF 的思想可以做很多改进。例如： 如果感觉算出来的结果仍然偏向热门视频时，可以增加式 (4) 的分母大小； 如果觉得用户只有观看完完成度很高时才是真实兴趣，那可以将式 (4) 的 $cos(\\cdot)$ 部分改成类似 $r_u(i)\\cdot r_u(j)$ 的形式； 如果觉得需要更多的考虑用户的短期兴趣，做即时的推荐，那可以将式 (6) 中的用户观看历史限制在最近几次，甚至一次； 如果把用户-视频考虑成一个二部图，ItemCF 实际上是基于图的结构，执行了一次从用户到视频的兴趣扩散过程。可以考虑下图中的视频 $v_1,v_3$，它们没有直接的共同观看，因此用 ItemCF 算出来的相似度为 0，但是实际上 $u_1,u_2$ 都观看了 $v_2$，因此可以认为用户 $u_1,u_2$ 存在一定的相似性，因此如果执行一次视频-用户-视频的兴趣扩散过程就能够捕获 $v_1,v_3​$ 的相似度了。 后面一种思路实际上就是 SimRank，但是由于需要执行多次兴趣扩散（即对二部图做多次迭代计算），SimRank 的计算复杂度相当高，在业务数据量大的情况下需要强大的算力支持，以后会再讨论下我在 SimRank 模型上的尝试。","categories":[{"name":"推荐系统","slug":"推荐系统","permalink":"https://guyuecanhui.github.io/categories/推荐系统/"}],"tags":[{"name":"推荐","slug":"推荐","permalink":"https://guyuecanhui.github.io/tags/推荐/"},{"name":"协同过滤","slug":"协同过滤","permalink":"https://guyuecanhui.github.io/tags/协同过滤/"},{"name":"算法","slug":"算法","permalink":"https://guyuecanhui.github.io/tags/算法/"}]},{"title":"关于我自己","slug":"about","date":"2019-04-13T05:51:57.000Z","updated":"2019-04-13T05:54:51.557Z","comments":true,"path":"2019/04/13/about/","link":"","permalink":"https://guyuecanhui.github.io/2019/04/13/about/","excerpt":"","text":"我叫胡诚，本博就读于东南大学计算机系，研究方向为分布式计算，传感器网络，云计算。目前主要兴趣为推荐系统、大数据、机器学习技术和传统算法。 欢迎大家与我交流。","categories":[],"tags":[]},{"title":"置信区间在推荐中的应用","slug":"置信区间在推荐中的应用","date":"2019-04-13T05:22:05.000Z","updated":"2019-04-13T06:17:03.764Z","comments":true,"path":"2019/04/13/置信区间在推荐中的应用/","link":"","permalink":"https://guyuecanhui.github.io/2019/04/13/置信区间在推荐中的应用/","excerpt":"","text":"学过统计的同学都对置信区间的概念非常熟悉，实际上，离开置信区间谈统计值没啥意义，或者说经常会造成很大的误导。简单来讲，置信区间是指基于观测样本来估计一个未知参数（如均值）时，我们相当确定（用置信度来度量）参数可能的取值范围。如果不考虑置信区间的概念，在我们观察到有 2 个用户喜欢一个视频、1 个用户不喜欢一个视频时，会估计该视频的推荐度为 66%，而认为它是一个高质量的视频，如果一旦将它进行大规模推荐时，很可能发现这个视频的实际转化率低的可怜。 因此在推荐里，置信区间是需要密切关注的概念。在推荐领域实践中，我从 3 个简单的算法来分别介绍置信区间的应用。 Wilson 区间法来判断视频质量在引言的例子中，我们组的海威同学利用 Wilson 区间法来估计视频的推荐度，或者说，来建立视频质量评估模型（模型的一部分）。利用视频播放行为数据来统计视频的播放转化率时，假设视频展示的总数为 $n$，用户实际播放的总数为 $m$，则直接计算出来的播放转化率为 $p=\\frac{m}{n}$。如果 $n$ 越大，说明 $p$ 的估计置信度越高，否则置信度越低。由于视频质量直接决定了我们是否会大规模推荐这个视频，因此在估计 $p$ 时采用的是宁缺毋滥的策略，这个时候可以巧妙的用置信区间的下界来代替 $p$ 作为播放转化率的估计。 具体到 Wilson 区间的计算公式，可以参考wiki（基于正态分布假设），这里只搬个公式： p_w = \\max(0, \\frac{p+\\frac{z^2}{2n}}{1+\\frac{z^2}{n}}-\\frac{z}{1+\\frac{z^2}{n}}\\sqrt{\\frac{p(1-p)}{n}+\\frac{z^2}{4n^2}})其中，$z$ 为某置信度（如 95% 置信度）下查表可得，$n$ 在实际代入时，需要加上平滑因子（如 0.1），防止展示数据丢失导致 $n=0$。从公式可知，基于 Wilson 区间估计的播放转化率最小接近于 0（$n$ 在实际时很可能取到平滑因子），最大接近于 $p$。 UCB算法来平衡探索与应用（E&amp;E）Wilson区间法是用置信区间的下限来减少数据量不足时误判的可能，主要是用来选出精品视频用来广泛推荐。但是一直这样保守推荐，会导致有些视频得不到充分的曝光，就难以评估其实际的转化率，导致推荐出来的所谓精品只是次优的选择。因此，在应用（Expoit）目前已知比较好的视频进行推荐的同时，也要保持一定比例的探索（Explore），即尝试一下那些曝光较少的视频。EE算法里一个常用的算法是 LinUCB，由于涉及特征构造，这里只介绍一个简化版本 UCB，大致思路是一样的。 UCB（Upper Confidence Bound）是一种多臂老虎机算法（MAB），也勉强算一种简化的强化学习算法，调性十足。同样以估计播放转化率为例，它的思路是利用置信区间的上界来代替 $p$ 作为估计值，实际上是提高了曝光不足视频（即长尾视频）的估计值。 UCB 主要解决的问题在于，如何计算置信区间的上界，既能保证随着曝光总量的增加，那些未被探索的视频越来越少，又能保证长久来看，能选到精品的视频。为了实现这个目标，一个常用的启发式公式如下： p_u=\\max_{i}(p_i+\\sqrt{\\frac{2\\ln t}{n_i}})其中，$p_i$ 为某个视频 $n_i$ 次曝光计算的平均转化率，$t$ 表示所有视频总共的曝光数。可以看到，随着曝光总数的增加，曝光很少的视频第二项值会很大，因此所有视频都会得到保底的曝光（t=100000 时至少有 28 次）。但是随着 $n_i$ 继续增加，主要决定因素又变成了 $p_i$，即历史平均转化率高的视频更可能被选中。 Thompson 采样来进行随机长尾推荐UCB 算法在实际于新物品增加快的场景（例如短视频推荐，平均每天新增几万部短视频）时，由于计算过程是确定性的，存在一直只推新物品的问题。为了增加一些随机性，可以考虑用 Thompson 采样算法。它既不使用置信区间的上界，也不使用下界，而是每次基于 Beta(m, n-m) 分布进行采样（注意，这里的 m 和 n 是每个视频单独维护的参数）。 我们知道，Beta 分布实际上是“白努力”过程的成功率，曝光数 $n$ 越大，Beta 分布的曲线越像是一个倒钟的形状，且钟的开口越窄，最后收于期望：$p=\\frac{m}{n}$。反过来说，当使用 Thompson 采样来选择推荐的视频时，虽然每个视频长期来选中的概率取决于其转化率，但是当曝光数量少时，Beta 分布开口很大，也更容易得到比期望大或者小的采样结果，从而引入了随机性。不过从实际应用来看，当媒资库时的视频数量很多时，大部分选中的视频还是新视频。 本文简单的介绍了统计区间在推荐中的一些简单应用，既有利用置信区间的下界来选精品，也有利用置信区间的上界来探索，还有利用整个分布来引入随机性。所有算法都是用简单的数学公式就能达到我们期望的效果，是比人工规则优美的多的形式。当然，举的示例都是推荐的核心问题，没有这么简单就能讲清楚，涉及大量的数据处理和参数调优，需要不断尝试和改进。","categories":[{"name":"推荐系统","slug":"推荐系统","permalink":"https://guyuecanhui.github.io/categories/推荐系统/"}],"tags":[{"name":"推荐","slug":"推荐","permalink":"https://guyuecanhui.github.io/tags/推荐/"},{"name":"统计","slug":"统计","permalink":"https://guyuecanhui.github.io/tags/统计/"},{"name":"置信区间","slug":"置信区间","permalink":"https://guyuecanhui.github.io/tags/置信区间/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-04-10T13:57:37.514Z","updated":"2019-04-10T13:57:37.514Z","comments":true,"path":"2019/04/10/hello-world/","link":"","permalink":"https://guyuecanhui.github.io/2019/04/10/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}