{"meta":{"title":"Looping","subtitle":"Watch, learn and practise","description":"总结心得","author":"胡诚","url":"https://guyuecanhui.github.io","root":"/"},"pages":[{"title":"文章分类","date":"2019-04-13T05:44:08.000Z","updated":"2019-04-13T14:44:46.943Z","comments":true,"path":"categories/index.html","permalink":"https://guyuecanhui.github.io/categories/index.html","excerpt":"","text":""},{"title":"关于胡诚","date":"2019-04-13T05:51:57.000Z","updated":"2019-04-13T14:43:11.849Z","comments":true,"path":"about/index.html","permalink":"https://guyuecanhui.github.io/about/index.html","excerpt":"","text":"我叫胡诚，本博就读于东南大学计算机系，研究方向为分布式计算，传感器网络，云计算。目前主要兴趣为推荐系统、大数据、机器学习技术和传统算法。 欢迎大家通过邮箱与我交流：guyuecanhui@icloud.com。"},{"title":"标签云","date":"2019-04-13T05:44:53.000Z","updated":"2019-04-13T14:43:43.276Z","comments":true,"path":"tags/index.html","permalink":"https://guyuecanhui.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"用 FTRL 训练 FM 模型","slug":"ftrl-fm","date":"2019-07-03T14:45:49.000Z","updated":"2019-07-03T14:28:24.710Z","comments":true,"path":"2019/07/03/ftrl-fm/","link":"","permalink":"https://guyuecanhui.github.io/2019/07/03/ftrl-fm/","excerpt":"","text":"近期尝试了基于 FTRL 来训练 FM 模型，用于短视频的排序。这篇博客主要总结一下算法的理论推导和工程化的一些心得。 一、FM (Factorization Machines) 模型推导FM 模型简介在设计排序模型时，至关重要的步骤就是特征的构造和选择。除了一些简单单特征外，往往要对特征进行组合，例如对用户的年龄、性别组合，对视频的演员、类别进行组合等，更大的特征空间能够增加模型表征能力。对于特征组合来说，业界现在通用的做法主要有两大类： FM 系列，常见的模型包括 FM，FFM，DeepFM，它们对特征的取值范围比较敏感。 Tree 系列，常见的模型包括 GBDT，它们对特征的取值范围不敏感。 其中，FM 系列由于适合处理大规模稀疏数据，并且易于与深度神经网络结合，因此使用十分广泛，成为大厂居家必备。 FM 模型的主要思想是在 LR 的基础上，对所有的特征自动做两两组合$^{[1,2]}$。两两组合最直观的方法就是为每对特征组合设置一个参数（例如 Poly2 模型），但是这样就需要 $\\text{O}(n^2)$ 个参数，当特征数量很多时，需要的样本量也是巨大的，往往不可能所有的参数都有充足的样本训练。因此 FM 考虑使用矩阵分解的方式来还原这个 $n\\times n$ 的参数矩阵，只需要 $n\\times k$ （$k$ 通常是个很小的常数）的参数即可实现特征两两组合的目的。 具体来说，给定样本 $z=(\\boldsymbol{x},y)$，记 $\\boldsymbol{v}_i = (v_i^{(1)},\\cdots,v_i^{(d)})^\\top$ 为第 $i$ 维特征对应的隐式向量，则 FM 模型为： \\begin{align} f(\\boldsymbol{x}|\\boldsymbol{w})&=w_0+\\sum_{i=1}^n w_ix_i+\\sum_{i=1}^{n}\\sum_{j=i+1}^{n} (\\boldsymbol{v}_i^\\top \\boldsymbol{v}_j)x_ix_j \\\\ &=w_0+\\sum_{i=1}^n w_ix_i+\\frac{1}{2}\\Big(\\sum_{i=1}^{n}\\sum_{j=1}^{n}\\sum_{k=1}^{d} v_i^{(k)} v_j^{(k)}x_ix_j- \\sum_{i=1}^{n}\\sum_{k=1}^{d} (v_i^{(k)}x_i)^2\\Big) \\\\ &=w_0+\\sum_{i=1}^n w_ix_i+\\frac{1}{2}\\sum_{k=1}^{d}\\Big(\\sum_{i=1}^{n}v_i^{(k)} x_i\\sum_{j=1}^{n} v_j^{(k)} x_j- \\sum_{i=1}^{n} (v_i^{(k)}x_i)^2\\Big) \\\\ &=w_0+\\sum_{i=1}^n w_ix_i+\\frac{1}{2}\\sum_{k=1}^{d}\\Big(\\big(\\sum_{i=1}^{n}v_i^{(k)} x_i \\big)^2- \\sum_{i=1}^{n} (v_i^{(k)}x_i)^2\\Big) \\end{align} \\qquad (1)FM 的参数包括 $\\boldsymbol{w}={w_0,\\cdots w_n,v_1^{(1)},\\cdots v_n^{(d)}}$，容易得到 FM 对各参数的偏导如下： \\frac{\\partial f(\\boldsymbol{x}|\\boldsymbol{w})}{\\partial w}= \\begin{cases} \\begin{align} 1 &, \\qquad w=w_0 \\\\ x_i &, \\qquad w=w_i,\\ i=1,\\cdots,n \\\\ x_i\\Big(\\sum_{j=1}^n v_j^{(k)}x_j - v_i^{(k)}x_i\\Big) &, \\qquad w=v_i^{(k)},\\ i=1,\\cdots,n;\\ k=1,\\cdots,d \\end{align} \\end{cases} \\qquad (2)FM 模型求解（回归问题）此时直接将 $\\hat{y} = f(\\boldsymbol{x}|\\boldsymbol{w})$ 作为对 $y$ 的预测结果，因此可以将样本 $z=(\\boldsymbol{x},y)$ 的损失函数定义为： l(\\boldsymbol{w},z) = \\big(\\hat{y}-y\\big)^2= \\big(f(\\boldsymbol{x}|\\boldsymbol{w})-y\\big)^2 \\qquad(3)损失函数对参数的偏导为： \\begin{align} \\frac{\\partial l(\\boldsymbol{w},z)}{\\partial w} &= 2\\big(\\hat{y}-y\\big)\\cdot \\frac{\\partial f(\\boldsymbol{x}|\\boldsymbol{w})}{\\partial w} \\\\ &= 2 \\big(f(\\boldsymbol{x}|\\boldsymbol{w})-y\\big)\\cdot \\frac{\\partial f(\\boldsymbol{x}|\\boldsymbol{w})}{\\partial w} \\end{align}\\qquad(4)FM 模型求解（二分类问题）此时将 $\\hat{y} = \\pi(f(\\boldsymbol{x}|\\boldsymbol{w}))=\\frac{1}{1+e^{-f(\\boldsymbol{x}|\\boldsymbol{w})}}$ 作为对 $y$ 的预测结果，其中，$\\pi(x)$ 为 Sigmoid 函数。还是分标签取值来进行讨论（损失函数的推导参考 LR 模型）。 1. Label 为 {1,0}则将样本 $z=(\\boldsymbol{x},y)$ 的损失函数定义为 LogLoss 函数： l(\\boldsymbol{w},z) = -yf(\\boldsymbol{x}|\\boldsymbol{w})+\\ln(1+e^{f(\\boldsymbol{x}|\\boldsymbol{w})})\\big)\\qquad(5)损失函数对参数的偏导为： \\begin{align} \\frac{\\partial l(\\boldsymbol{w},z)}{\\partial w} &= -y\\cdot\\frac{\\partial f(\\boldsymbol{x}|\\boldsymbol{w})}{\\partial w}+\\frac{1}{1+e^{f(\\boldsymbol{x}|\\boldsymbol{w})}}\\cdot e^{f(\\boldsymbol{x}|\\boldsymbol{w})} \\cdot\\frac{\\partial f(\\boldsymbol{x}|\\boldsymbol{w})}{\\partial w} \\\\ &=\\big(\\pi(f(\\boldsymbol{x}|\\boldsymbol{w}))-y\\big)\\cdot \\frac{\\partial f(\\boldsymbol{x}|\\boldsymbol{w})}{\\partial w} \\\\ &=\\big(\\hat{y}-y\\big)\\cdot \\frac{\\partial f(\\boldsymbol{x}|\\boldsymbol{w})}{\\partial w} \\end{align} \\qquad (6)2. Label 为 {1,-1}则将样本 $z=(\\boldsymbol{x},y)$ 的损失函数定义为 SigmoidLoss 函数： l(\\boldsymbol{w},z) = \\ln(1+e^{-yf(\\boldsymbol{x}|\\boldsymbol{w})})\\big)\\qquad(7)损失函数对参数的偏导为： \\begin{align} \\frac{\\partial l(\\boldsymbol{w},z)}{\\partial w} &= \\frac{1}{1+e^{-yf(\\boldsymbol{x}|\\boldsymbol{w})}}\\cdot e^{-yf(\\boldsymbol{x}|\\boldsymbol{w})} \\cdot(-y)\\cdot\\frac{\\partial f(\\boldsymbol{x}|\\boldsymbol{w})}{\\partial w} \\\\ &=y\\cdot\\big(\\frac{1}{1+e^{-yf(\\boldsymbol{x}|\\boldsymbol{w})}}-1\\big)\\cdot \\frac{\\partial f(\\boldsymbol{x}|\\boldsymbol{w})}{\\partial w} \\\\ &=y\\cdot\\Big(\\pi\\big(yf(\\boldsymbol{x}|\\boldsymbol{w})\\big)-1\\Big)\\cdot \\frac{\\partial f(\\boldsymbol{x}|\\boldsymbol{w})}{\\partial w} \\end{align} \\qquad (8)二、FTRL Optimizer 介绍上面一陀公式实际上是优化算法求梯度的时候用到的。优化算法目前有很多种，在如在线更新模型或者在线排序等对性能有严格要求的场景中，模型的稀疏解十分关键。稀疏的模型意味着只保留最关键特征的参数，意味着更少的存储、查询与计算。为了得到模型的稀疏解，通常的做法是使用 L1 正则、基于参数大小或者累积梯度大小的截断等技术。其中，FTRL 集众家之长，实现了精度与稀疏性的平衡$^{[3]}$。 FTRL 更像是一种启发式的模型组装，其特征权重的更新公式为： \\boldsymbol{w}^{t+1}=\\arg \\min_\\boldsymbol{w}(\\boldsymbol{g}^{1:t}\\cdot \\boldsymbol{w}+\\lambda_1 || \\boldsymbol{w}||_1+\\frac{1}{2}\\lambda_2 || \\boldsymbol{w}||_2^2 +\\frac{1}{2}\\sum_{j=1}^t\\sigma^j || \\boldsymbol{w}-\\boldsymbol{w}^j ||_2^2) \\qquad(9)其中，$\\boldsymbol{g}^{1:t}$ 表示 $1\\sim t$ 轮迭代中参数梯度的累积和，其中，L1 正则化部分是为了生成稀疏解，L2 正则化部分是为了使解更平滑（在论文的推导中不包含这一项），而 $\\parallel \\boldsymbol{w}-\\boldsymbol{w}^t\\parallel^2_2$ 是为了保证 $\\boldsymbol{w}$ 不要离已迭代过的解太远。经过比较复杂的推导（参考文献 [4]），可以得到每一维参数的求解式： w^{t+1}_i= \\begin{cases} \\begin{align} 0 &, \\qquad |z^t_i|","categories":[{"name":"推荐系统","slug":"推荐系统","permalink":"https://guyuecanhui.github.io/categories/推荐系统/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://guyuecanhui.github.io/tags/优化/"},{"name":"FTRL","slug":"FTRL","permalink":"https://guyuecanhui.github.io/tags/FTRL/"},{"name":"模型","slug":"模型","permalink":"https://guyuecanhui.github.io/tags/模型/"},{"name":"FM","slug":"FM","permalink":"https://guyuecanhui.github.io/tags/FM/"}]},{"title":"二项 Logistic Regression 模型","slug":"lr","date":"2019-05-15T14:02:00.000Z","updated":"2019-05-18T05:44:10.328Z","comments":true,"path":"2019/05/15/lr/","link":"","permalink":"https://guyuecanhui.github.io/2019/05/15/lr/","excerpt":"","text":"二项 Logistic Regression 模型推导模型描述记 $\\pi(x)=\\frac{1}{1+e^{-x}}$，二项 Logistic Regression 模型是如下的条件概率分布： \\begin{cases} P(y=1|\\boldsymbol{x})=\\pi(\\boldsymbol{wx})=\\frac{1}{1+e^{-\\boldsymbol{wx}}}=\\frac{e^{\\boldsymbol{wx}}}{1+e^{\\boldsymbol{wx}}} \\\\ P(y\\not=1|\\boldsymbol{x})=1-\\pi(\\boldsymbol{wx})=\\frac{1}{1+e^{\\boldsymbol{wx}}} \\end{cases}\\qquad(1)模型求解（极大似然估计）常见的 label 设置有正负样本分别为 {1,0} 或 {1,-1}，下面分别讨论两种设置下的损失函数和梯度的推导。首先要假设训练样本独立同分布并且数量足够，模型中待估计的参数为 $\\boldsymbol{w}$，似然函数的目标是 $y_i=1$ 时 $\\pi(\\boldsymbol{wx}_i)$ 尽可能大，且 $y_i\\not =1$ 时 $1-\\pi(\\boldsymbol{wx}_i)$ 尽可能大。 1. label 为 {1,0}此时，可以直接将 $\\hat{y}=\\pi(\\boldsymbol{wx})$ 的结果作为对 $y$ 值的预测（或者说是预测结果为 1 的概率）。根据最大似然估计公式，$p(\\boldsymbol{x}_i|\\boldsymbol{w})=\\big(\\pi(\\boldsymbol{wx}_i)\\big)^{y_i}\\cdot\\big(1-\\pi(\\boldsymbol{wx}_i)\\big)^{1-y_i}$，对数似然函数可以设计为： \\begin{align} H(\\boldsymbol{w}) &=\\arg \\max_{\\boldsymbol{w}}\\sum_{i=1}^N \\ln\\Big(\\big(\\pi(\\boldsymbol{wx}_i)\\big)^{y_i}\\cdot\\big(1-\\pi(\\boldsymbol{wx}_i)\\big)^{1-y_i}\\Big) \\\\ &=\\arg \\max_{\\boldsymbol{w}}\\sum_{i=1}^N \\Big(y_i\\cdot \\ln\\big(\\pi(\\boldsymbol{wx}_i)\\big)+(1-y_i)\\cdot\\big(1-\\pi(\\boldsymbol{wx}_i)\\big)\\Big) \\\\ &=\\arg \\max_{\\boldsymbol{w}}\\sum_{i=1}^N \\Big(y_i\\cdot \\ln(\\frac{e^{\\boldsymbol{wx}_i}}{1+e^{\\boldsymbol{wx}_i}})+(1-y_i)\\cdot \\ln(\\frac{1}{1+e^{\\boldsymbol{wx}_i}})\\Big) \\\\ &=\\arg \\max_{\\boldsymbol{w}}\\sum_{i=1}^N \\Big(y_i\\boldsymbol{wx}_i-\\ln(1+e^{\\boldsymbol{wx}_i})\\Big)\\qquad(2) \\end{align}这里，$l_l(\\boldsymbol{x},y)=-\\big(y\\cdot \\ln(\\hat{y})+(1-y)\\cdot\\ln(1-\\hat{y})\\big)=\\ln(1+e^{f(\\boldsymbol{x})})-yf(\\boldsymbol{x})$ 记作样本 $ (\\boldsymbol{x},y)$ 的 LogLoss，后面会经常见到。 根据损失函数 $l_l(\\boldsymbol{x},y)$，对每个维度上的参数分别求导： \\begin{align} \\frac{\\partial l_l(\\boldsymbol{x},y)}{\\partial w_i} &=\\frac{1}{(1+e^{\\boldsymbol{wx}})}\\cdot e^{\\boldsymbol{wx}}\\cdot x_i-y\\cdot x_i\\\\ &=\\big(\\pi(\\boldsymbol{wx})-y\\big)\\cdot x_i\\\\ &=(\\hat{y}-y)\\cdot x_i\\qquad(3) \\end{align}2. label 为 {1,-1}此时仍然可以认为 $\\pi(\\boldsymbol{wx})$ 输出了模型预测样本结果为 1 的概率，但是由于负样本的标签为 -1，因此考虑使用 $p(\\boldsymbol{x}_i|\\boldsymbol{w})=\\frac{1}{1+e^{-y_i\\boldsymbol{wx}_i}}$，则对数似然函数可以设计为： \\begin{align} H(\\boldsymbol{w}) &=\\arg \\max_{\\boldsymbol{w}}\\sum_{i=1}^N \\ln(\\frac{1}{1+e^{-y_i\\boldsymbol{wx}_i}}) \\\\ &=\\arg \\min_{\\boldsymbol{w}}\\sum_{i=1}^N \\ln(1+e^{-y_i\\boldsymbol{wx}_i}) \\qquad(4)\\\\ \\end{align}这里，$l_s(\\boldsymbol{x},y)=\\ln(1+e^{-y\\boldsymbol{wx}})$ 称作样本 $(\\boldsymbol{x},y)$ 的 SigmoidLoss，后面也会经常看到。 根据损失函数 $l_s(\\boldsymbol{x},y)$，对每个维度上的参数分别求导： \\begin{align} \\frac{\\partial l_s(\\boldsymbol{x},y)}{\\partial w_i} &=\\frac{1}{1+e^{-y\\boldsymbol{wx}}}\\cdot e^{-y\\boldsymbol{wx}}\\cdot (-y\\cdot x_i) \\\\ &=y\\cdot \\big(\\pi(y\\boldsymbol{wx})-1\\big)\\cdot x_i\\qquad(4)\\\\ \\end{align}","categories":[{"name":"数学","slug":"数学","permalink":"https://guyuecanhui.github.io/categories/数学/"}],"tags":[{"name":"模型","slug":"模型","permalink":"https://guyuecanhui.github.io/tags/模型/"},{"name":"线性模型","slug":"线性模型","permalink":"https://guyuecanhui.github.io/tags/线性模型/"},{"name":"LR","slug":"LR","permalink":"https://guyuecanhui.github.io/tags/LR/"}]},{"title":"符号约定与常用公式","slug":"terminology","date":"2019-05-11T13:51:23.000Z","updated":"2019-05-18T05:43:43.507Z","comments":true,"path":"2019/05/11/terminology/","link":"","permalink":"https://guyuecanhui.github.io/2019/05/11/terminology/","excerpt":"","text":"一、推荐系统常用符号含义 符号表示 含义 $\\boldsymbol{x}$ 输入变量，一般为特征向量 $\\boldsymbol{x}_i=(x_i^{(1)}, \\cdots, x_i^{(n)})^{\\top}$ 第 $i$ 个输入变量的取值，在推导损失函数等场景下，由于每次只考虑一条样本，记样本为 $\\boldsymbol{x}=(x_1,\\cdots,x_n)$，此时 $x_i$ 表示样本的第 $i$ 维特征 \\mathcal{X}=\\{\\boldsymbol{x}_1,\\cdots,\\boldsymbol{x}_N\\} 输入实例集合 (x_j^{(i)})^k 第 $j$ 个输入变量的第 $i$ 维特征取值的 $k$ 次方 $y$ 输出变量，一般为样本标签 $y_i$ 第 $i$ 个输出变量的取值 $\\mathcal{Y}={y_1,\\cdots,y_N}$ 输出实例集合 $(\\boldsymbol{x}_i,y_i)$ 第 $i$ 个样本点 $\\mathcal{T}={(\\boldsymbol{x}_1,y_1),\\cdots,(\\boldsymbol{x}_N,y_N)}$ 训练数据集 $\\boldsymbol{w}=(w_1,\\cdots,w_n)$ 权重向量 $w_i^t$ 第 $i$ 维特征的权重在第 $t$ 轮迭代的取值 $\\parallel \\boldsymbol{w} \\parallel_i^j$ 权重向量 $\\boldsymbol{w}$ 的 Li 范数的 $j$ 次方，例如 L1 范数：$\\parallel \\boldsymbol{w} \\parallel_1$，L2 范数： $\\parallel \\boldsymbol{w} \\parallel_2^2$ $\\boldsymbol{g}=(g_1,\\cdots,g_n)$ 梯度向量 $\\psi(\\boldsymbol{w})$ 正则化函数 二、常用定理中心极限定理 样本的平均值约等于总体的平均值。 给定一个任意分布的总体，从中随机抽取 $N$ 个样本，抽取 $k$ 次，这 $k$ 组抽样平均值的分布接近正态分布。 经验表明，当每组抽样数量 $N\\ge 30$ 时就服从中心极限定理。 极大似然估计前提假设：训练样本的分布能代表样本的真实分布；每个样本集中的样本都是所谓独立同分布的随机变量，且有充分的训练样本。 最大似然估计的目的是：利用已知的样本结果，反推最有可能（最大概率）导致这样结果的参数值。换句话说，极大似然估计提供了一种给定观察数据来评估模型参数的方法，即：模型已定，参数未知。 ML估计的求解方法： \\hat{\\theta} = \\arg \\max_{\\theta} l(\\theta) = \\arg \\max_{\\theta}\\prod_{i=1}^N p(\\boldsymbol{x}_i|\\theta)为了便于分析，定义对数似然函数 $H(\\theta) = \\ln l(\\theta)$，则： \\hat{\\theta} = \\arg \\max_{\\theta} \\ln l(\\theta) = \\arg \\max_{\\theta}\\sum_{i=1}^N \\ln p(\\boldsymbol{x}_i|\\theta)当 $H(\\theta)$ 连续可微的情况下，可以通过求导（单个未知参数）或者求梯度（多个未知参数）的方式求解方程。 三、常用的函数和公式Sigmoid 函数 表达式：$\\pi(x)=\\frac{1}{1+e^{-x}}=\\frac{e^x}{1+e^x}$； 导数：$\\pi’(x)=\\pi(x)\\big(1-\\pi(x)\\big)$； LogLoss 样本的 $(\\boldsymbol{x},y)$ 的 SigmoidLoss 表达式：$l_{l}(\\boldsymbol{x},y)=\\ln(1+e^{f(\\boldsymbol{x})})-yf(\\boldsymbol{x})$ 导数：$l_l’(\\boldsymbol{x},y)=\\Big(\\pi\\big(f(\\boldsymbol{x})\\big)-y\\Big)\\cdot f’(\\boldsymbol{x})$ 使用极大似然估计，标签值为 {0,1}，推导参考 LR 模型 SigmoidLoss 样本的 $(\\boldsymbol{x},y)$ 的 SigmoidLoss 表达式：$l_s(\\boldsymbol{x},y)=\\ln(1+e^{-yf(\\boldsymbol{x})})$ 导数：$l_s’(\\boldsymbol{x},y)=y\\Big(\\pi\\big(y\\cdot f(\\boldsymbol{x})\\big)-1\\Big)\\cdot f’(\\boldsymbol{x})$ 使用极大似然估计，标签值为 {-1,1}，推导参考 LR 模型","categories":[{"name":"数学","slug":"数学","permalink":"https://guyuecanhui.github.io/categories/数学/"}],"tags":[{"name":"符号","slug":"符号","permalink":"https://guyuecanhui.github.io/tags/符号/"},{"name":"定理","slug":"定理","permalink":"https://guyuecanhui.github.io/tags/定理/"},{"name":"公式","slug":"公式","permalink":"https://guyuecanhui.github.io/tags/公式/"}]},{"title":"从 SimRank 到 SimRank++","slug":"simrankpp","date":"2019-05-10T14:42:18.000Z","updated":"2019-05-12T14:48:49.603Z","comments":true,"path":"2019/05/10/simrankpp/","link":"","permalink":"https://guyuecanhui.github.io/2019/05/10/simrankpp/","excerpt":"","text":"从 SimRank 到 SimRank++上一篇博客《SimRank与视频相似度计算》 介绍了 SimRank$^{[1]}$ 及其在视频推荐中的应用，这一篇再谈谈 SimRank++。顾名思义，SimRank++ 是在 SimRank 的基础上做了一些优化，在文献 [2] 中提出时是为了解决搜索词改写的问题，本质上也就是计算搜索词的相似度。作者发现，当需要考虑二部图的边权信息时，原始的 SimRank 模型难以评估物品间相似度的可信度，这篇博客从视频推荐的角度来阐释作者的优化点。 从用户到用户群由于我们影片的观众量级在千万级，而影片的数量在十万级，因此使用 SimRank 模型来计算视频相似度时，最大的计算和存储瓶颈在于用户相似矩阵、用户-视频转移矩阵及视频-用户转移矩阵。但是从使用场景上来讲，我们在这里实际上并不需要度量用户之间的相似度（尽管它们可以用来做用户协同推荐），用户仅仅是用来传递视频间的相似度。因此，为了减少计算和存储的开销，我们可以对用户进行聚类，使用用户组来代替用户完成视频相似度的传递。 基于这个想法，我们可以使用各种聚类的方法：按用户性别、年龄、地域等；我是直接基于历史行为进行用户聚类。具体的做法是基于用户最近 $N$ 天的播放、收藏、分享等行为生成用户的表征向量（可以用 AutoEncoder、PCA 等方法），然后基于表征向量执行 KMeans（直接 KMeans 可能跑不出来），这里的用户群数量需要根据实际场景调试，我们希望类内最大距离越小越好。然后再将用户的行为聚合到用户组，例如有效播放次数累加、总播放时长的累加、总播放占比的累加、平均 CTR 等。这样我们就从用户-视频二部图切换到了用户组-视频二部图，整个网络的规模降低了 2 个数量级。 SimRank++ 的优化我们将用户聚成了用户组，丢失了大量的网络信息，虽然用户组作为网络中的一个节点，我们看不出它的出边是来自哪些用户，但是好在我们保留了这个组里有多少用户看了某个视频。而由于这一组用户又是相似的，因此我们期望通过充分利用边权来最小化网络信息的丢失。 SimRank++ 正好满足我们的需求，它在 SimRank 的基础上增加了两项优化： 1. 两个节点共同节点越多，则这两个节点相似度的可信度越高这一条很容易理解，如果很多人同时看了两部视频，那这两部视频的相似度也就越可信（注意，共同观看越多并不意味着相似度越高）。例如下图所示，视频 $v_1,v_2$ 与 $v_3,v_4$ 相比同时被更多的用户组同时观看，因此 $v_1,v_2$ 根据 SimRank 模型算出来的相似度应该比 $v_3,v_4$ 的相似度更可信。 我们用 $E(i,j)$ 来表示节点 $i,j$ 相似度的可信度，论文 [2] 中推荐使用 $Ev(v_i,v_j)=\\sum{k=1}^{|I(v_i)\\cap I(v_j)|} \\frac{1}{2^k}$ 或者 $E_v(v_i,v_j)=1-e^{|I(v_i)\\cap I(v_j)|}$ 来评估该权重（用户侧的同理），则： \\begin{cases} s(u,u')=c_1\\cdot E_u(u,u')\\cdot \\sum_{i\\in O(u)}\\sum_{j\\in O(u')}W_{uv}(u,i)\\cdot W_{uv}(u',j)\\cdot s(i, j) \\\\ s(v,v')=c_2\\cdot E_v(v,v')\\cdot \\sum_{i\\in I(v)}\\sum_{j\\in I(v')}W_{vu}(v,i)\\cdot W_{vu}(v',j)\\cdot s(i, j) \\end{cases} \\qquad (1)2. 节点边权越大、差异越小，则它的邻居节点相似度的权重越高如下图所示，我们用用户播放数来表示边权（如上所述，并非只有这一种权重表示方法）。不考虑边权时，$s(v_1,v_2)$ 和 $s(v_3,v_4)$ 完全相同。但是实际上，由于用户组 1 中有 100 个人看了 $v_1$ 和 $v_2$，可以认为用户组 1 中很多人都同时喜欢 $v_1,v_2$；而用户组 2 中有 100 个人看了 $v_3$，但只有 1 个人看了 $v_4$，因此 $v_3$ 和 $v_4$ 显然相似度应该比 $v_1,v_2$ 的低。 我们用新的权重 $P(i,j)$ 来表示节点 $i,j$ 的相似度传导权重，则： P(i,j)=e^{-var(j)}\\frac{w(i,j)}{\\sum_{k\\in N(i)}w(i,k)}\\quad (2)其中，$e^{-var(i)}$ 用来度量节点 $i$ 的边权差异，边权差异越大，该系数越小；$\\frac{w(i,j)}{\\sum_{k\\in N(i)}w(i,k)}$ 则是用来计算归一化的权重。 SimRank++ 模型的矩阵描述基于式 (1) 和 式 (2)，我们可以写出 SimRank++ 的矩阵描述： \\begin{cases} S_u^{k+1} = c_1\\cdot E_u\\circ P_{vu}^T\\cdot S_v^k \\cdot P_{vu} + (I - diag(c_1\\cdot E_u\\circ P_{vu}^T\\cdot S_v^k \\cdot P_{vu})) \\\\ S_v^{k+1} = c_2\\cdot E_v\\circ P_{uv}^T\\cdot S_u^k \\cdot P_{uv} + (I-diag(c_2\\cdot E_v\\circ P_{uv}^T\\cdot S_u^k \\cdot P_{uv})) \\end{cases}\\quad (3)其中， \\begin{cases} E_u(u,u')=1-e^{-|O(u)\\cap O(u')|}\\\\ E_v(v,v')=1-e^{-|I(v)\\cap I(v')|} \\end{cases}\\quad (4) \\begin{cases} P_{uv}(u,v)=e^{-var(v)}\\frac{w(u,v)}{\\sum_{i\\in O(u)}w(u,i)} \\\\ P_{vu}(v,u)=e^{-var(u)}\\frac{w(v,u)}{\\sum_{i\\in I(v)}w(v,i)} \\end{cases} \\qquad(5)但是使用数据进行验证时，发现该模型对用户聚类的效果和权重的设置十分敏感，这两项没调好的话，很容易导致算出来的视频相似列表趋同或者有其他的问题。具体来说，用户聚类的原则是类内用户的行为越相似越好；权重的话则没有很明显的规律，需要根据业务场景来尝试了。 发散讨论：扩散算法前几天跟其他同学交流的时候，有人提过之前做过用热传导算法来算用户的个性化推荐结果，据说效果也很不错。这里顺便扒一扒热传导算法和 SimRank 算法的区别和联系。 首先，它们都属于扩散算法，都是基于对物理世界现象的观察和模拟。典型的扩散有两类：一类是物质或者能量的扩散，满足守恒律，常称作为物质扩散，最终稳定下来后，总量是不变的；另一类是热的扩散，一般由一个或多个恒温热源驱动，不满足守恒律，常被称作为热传导。SimRank 是属于热传导（物品与自己的相似度恒定为 1）。 相比而言，物质扩散倾向于推荐比较流行的物品，而热传导倾向于推荐比较冷门的物品。更详细的讨论可以参考文献 [3]。 参考文献[1] Jeh, G., &amp; Widom, J. (2002, July). SimRank: a measure of structural-context similarity. In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining (pp. 538-543). ACM. [2] Antonellis, I., Molina, H. G., &amp; Chang, C. C. (2008). Simrank++: query rewriting through link analysis of the click graph. Proceedings of the VLDB Endowment, 1(1), 408-421. [3] 推荐算法整理 — 扩散算法. https://www.zybuluo.com/chanvee/note/21053.","categories":[{"name":"推荐系统","slug":"推荐系统","permalink":"https://guyuecanhui.github.io/categories/推荐系统/"}],"tags":[{"name":"推荐","slug":"推荐","permalink":"https://guyuecanhui.github.io/tags/推荐/"},{"name":"协同过滤","slug":"协同过滤","permalink":"https://guyuecanhui.github.io/tags/协同过滤/"},{"name":"算法","slug":"算法","permalink":"https://guyuecanhui.github.io/tags/算法/"},{"name":"相似度","slug":"相似度","permalink":"https://guyuecanhui.github.io/tags/相似度/"},{"name":"二部图","slug":"二部图","permalink":"https://guyuecanhui.github.io/tags/二部图/"}]},{"title":"SimRank与视频相似度计算","slug":"simrank","date":"2019-04-29T01:09:50.000Z","updated":"2019-05-10T14:44:49.781Z","comments":true,"path":"2019/04/29/simrank/","link":"","permalink":"https://guyuecanhui.github.io/2019/04/29/simrank/","excerpt":"","text":"一、应用背景最近需要对视频的相关推荐进行一些优化。之前尝试过 TagSim、AutoEncoder 和 Word2Vec 等方法，无非是基于元数据相似或基于协同相似的思路。但是在实际应用的时候，由于媒资传过来的信息未必是非常准确的，因此基于元数据相似的方法在数据基础上可能就存在一定的不确定性，因此常常会推出来一些虽然实际上很符合算法预期，但是看起来很奇怪的结果。而基于协同相似的推荐，由于需要比较多的行为数据来估计视频之间的相似度，又往往只能覆盖少量的视频。在应用中，我们往往使用的是两者的混合，但是由于混合比较简单粗暴，仍然有很多 VOC 问题。 因此，团队迫切的需要一种能够提升相关推荐效果的模型。而这种相关又是有强业务语义的，需要能够支持灵活的定制，因此在短时间内先不考虑深度网络（可解释性太差）。在调研中，发现有基于热传导的算法，感觉好像挺符合直观感觉，用了协同数据，同时也支持元数据。但是再顺着这个思路往下找的时候，发现 SimRank 是一种十分成熟且常用于相关推荐的模型，粗看了一下，感觉很符合我们的业务诉求，就迫不及待尝试了一下。 二、SimRank 基本模型2.1 核心思想由于 SimRank 提出的时间比较早，网上的材料很多，而且大多长的也差不多，可以参考文献 [1, 2] ，这里只简单的搬个砖。 文献 [1] 最早提出 SimRank 模型，核心的思想是 “two objects are similar if they are related to similar objects“（这跟 PageRank 的思路完全一致，只是 PageRank 是用来评估每个链接的重要性，而 SimRank 是用来评估每两个物品间的相似度）。 SimRank 既支持计算所有节点对之间的相似度（如输入数据为文章引用记录），也支持计算二部图中每一部分节点间的相似度（如输入数据为用户行为记录）。由于我们是做视频推荐，主要用的是用户行为数据，因此这里只介绍基于二部图的模型。 举个简单的例子：如下图所示，用户 $u_1$ 观看了视频 $v_1,v_2,v_3$；用户 $u_2$ 观看了视频 $v_2,v_3,v_4$，则可以用二部图来表示这种观影关系（二部图是因为用户 $u_1,u_2$ 之间无联系，且视频 $v_1,v_2,v_3,v_4$ 间无联系，只有用户-视频间存在有向边）： 为了评估视频 $v_1,v_4$ 之间的相似度，需要看看哪些人看了 $v_1,v_4$ ，以及这些用户的相似度。这是一个典型的递归逻辑，递归的起点在于：每个节点（包括这里的用户/视频）与自己的相似度为 1；没有关联的节点间相似度为 0（一种情况是这两个节点没有与其他节点的联系，还有一种情况是在迭代的初始状态时，所有节点对间的相似度为 0）。值得注意的是，如果用 ItemCF 算法来计算 $v_1,v_4$ 的相似度，由于它们没有共同观看的用户，相似度为 0，具体对比可以参考我之前的博客：可能是最好懂的ItemCF解释了。 2.2 基于二部图的描述最直观和容易理解的是基于图的描述。用数学语言来表达上面的思路： \\begin{cases} s(u,u')=\\frac{c_1}{|O(u)|\\cdot|O(u')|}\\sum_{i\\in O(u)}\\sum_{j\\in O(u')}s(i, j) \\\\ s(v,v')=\\frac{c_2}{|I(v)|\\cdot|I(v')|}\\sum_{i\\in I(v)}\\sum_{j\\in I(v')}s(i, j) \\end{cases} \\quad (1)其中，$u$ 表示用户，$v$ 表示视频，$O(u)$ 表示用户 $u$ 观看过的视频集合，$I(v)$ 表示视频的观看用户集合，$s(i,j)$ 表示两个节点的相似度，$c_i$ 为常数系数。式 (1) 中累加相似度的部分不是很好理解，实际上就是对两个节点所有关联的节点进行两两组合计算相似度之和。$c_1, c_2$ 可以理解成相似度的传导率，传导率越大，受到相邻节点影响也就越大，每轮迭代相似度的传播也就越快，表现为迭代若干轮后，节点间的相似度越高（文献 [1] 中建议的是0.8）。如果使用随机游走的方法，则传导率越大，下一个状态转移到相邻节点的概率越大，即下一个状态保持原来节点概率越小。 在实现模型的时候，可以直接在图上按公式 (1) 进行计算，但是需要注意缓存中间结果$^{[3]}$，否则存在很多重复计算，实测中，不做什么优化的话，超过 $10000\\times10000$ 的二部图单机基本就几个小时都算不出来了。 2.3 基于矩阵的描述另外一种等价的描述是将图转化成矩阵，比如原来的二部图是 $G = (U, V, E)$，即共 $n_u + n_v$ 个节点，可以转化成 $(n_u + n_v) \\times (n_u + n_v)$ 的状态转移矩阵 $W$。根据公式 (1) 的描述，图中的每一条边对应于转移矩阵的一个元素（这里实现的时候用户和视频一般是分开连续编号的），从而可以设置转移矩阵为： \\begin{cases} w(u,v)=\\frac{1}{|O(u)|} \\\\ w(v,u)=\\frac{1}{|I(v)|} \\end{cases}转移矩阵中其他元素为 0。而根据定义，相似度矩阵 $S$ 中对角线始终为 1，其他元素初始化为 0。则基于矩阵的迭代过程可以用下式来表达： S = C\\cdot W^T\\cdot S\\cdot W + (I-diag(C\\cdot W^T\\cdot S\\cdot W)) \\quad (2)其中，矩阵 $C$ 的对角线元素为 c_1 或 c_2，如果 c_1=c_2=c，那 $C$ 可以直接用系数 $c$ 来代替。公式 (2) 的前一部分就是公式 (1) 的矩阵描述，后一部分实际上是为了设置每轮迭代时，相似矩阵的对角线为 1，即 s_{i,i}=1。 注意到，在二部图的情况下，用户-视频的相似度必然是 0，同时，用户-用户 / 视频-视频的转移矩阵也必然是 0。因此相似矩阵和转移矩阵可以简单的拆成用户-用户相似矩阵 S_u、视频-视频 S_v 相似矩阵以及用户-视频转移矩阵 W_{uv}、视频-用户转移矩阵 $W_{vu}$，并做分块乘法。简单的推导一下： \\begin{equation}\\begin{aligned} W^T\\cdot S\\cdot W &= \\left[ \\begin{array}{cc} 0 & W_{vu}^T \\\\ W_{uv}^T & 0 \\end{array} \\right] \\cdot \\left[ \\begin{array}{cc} S_u & 0 \\\\ 0 & S_v \\end{array} \\right] \\cdot \\left[ \\begin{array}{cc} 0 & W_{uv} \\\\ W_{vu} & 0 \\end{array} \\right] \\\\ &=\\left[ \\begin{array}{cc} 0 & W_{vu}^T\\cdot S_v \\cdot W_{vu} \\\\ W_{uv}^T\\cdot S_u \\cdot W_{uv} & 0 \\end{array} \\right] \\end{aligned}\\end{equation}仔细品味一下这个公式，能更直观的了解相似度的传递过程。因此，迭代计算公式为： \\begin{cases} S_u^{k+1} = c_1 \\cdot W_{vu}^T\\cdot S_v^k \\cdot W_{vu} + (I - diag(c_1 \\cdot W_{vu}^T\\cdot S_v^k \\cdot W_{vu})) \\\\ S_v^{k+1} = c_2 \\cdot W_{uv}^T\\cdot S_u^k \\cdot W_{uv} + (I-diag(c_2\\cdot W_{uv}^T\\cdot S_u^k \\cdot W_{uv})) \\end{cases}\\quad (3)2.4 扩展用户/视频属性以上描述了经典的基于二部图的 SimRank 算法，但是其实我们可以将视频的元数据/用户的属性数据作为辅助节点加入到图中来，并添加视频元数据$\\rightarrow$视频和用户画像$\\rightarrow$用户的单向边（表示用户/视频的相似度不会反向传播给画像/元数据），同时初始化不同维度的视频元数据/用户画像的相似度，以达到运营干预的目的。具体的分块乘法就不推导了，跟 2.3 节差不多，这里只举一个例子： 上图中，本来 $u_1,u_2$ 之间是没有边相连的，因此相似度为 0，但是由于他们同属男性，因此由男性这个画像向这两个用户传播了一定的相似度；同样的，本来 $v_1,v_2$ 之间的相似度也为 0，但是由于它们都是搞笑的视频，因此搞笑这个元数据也向它们传播了一定的相似度。加入用户维度和视频维度的辅助节点以后，有助于解决由于行为较少而无法准确评估相似度的情况。 三、模型实现与优化讨论我在 spark 2 和在 python 中分别实现了上述过程，使用图遍历的方式优点是代码简单，但是对于大规模的图优化比较麻烦，速度很慢；使用矩阵计算的时候，主要的问题又在于矩阵的优化计算。下面简单讲下一些可行的优化思路。 a. 基于 spark 的精确计算如果使用 mllib 的 BlockMatrix 来计算，会强制将稀疏矩阵转成稠密矩阵来计算，因此开销比实际需要的大很多，因此一定要使用公式 (3) 来替代公式 (2)。但是即使这样，也不能从根本上解决问题，根本上是需要自己实现一套高效的分布式稀疏矩阵的计算方法，网上有一些开源项目可参考。 b. 基于 python 的精确计算使用 python 进行计算时，由于相似度的精度要求不高，因此使用 np.float16 就足够了，并且每轮迭代完，要将小于一定阈值的相似项置 0（如果只需要计算 topN相似的话，每轮可以只保留系数最大的 topN 项）。另外，构建矩阵用 csr_matrix 比较方便，计算的时候还是得用 li_matrix。 c. 迭代近似由于我们只需要算视频的相似度，有一种解决上面问题的思路是将用户随机分成若干份，用这些用户的数据来计算视频的相似矩阵，然后将这些相似矩阵加起来求平均，但是效果不是很好。 d. 矩阵分析针对矩阵运算，可以预先分析矩阵的特点，然后再采用一定的手段来减少总计算量。这里涉及一些矩阵分解的优化方法，以后有机会再仔细研究研究。 参考文献[1] Jeh, G., &amp; Widom, J. (2002, July). SimRank: a measure of structural-context similarity. In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining (pp. 538-543). ACM. [2] SimRank协同过滤推荐算法: http://www.cnblogs.com/pinard/p/6362647.html. [3] Lizorkin, D., Velikhov, P., Grinev, M., &amp; Turdakov, D. (2008). Accuracy estimate and optimization techniques for simrank computation. Proceedings of the VLDB Endowment, 1(1), 422-433.","categories":[{"name":"推荐系统","slug":"推荐系统","permalink":"https://guyuecanhui.github.io/categories/推荐系统/"}],"tags":[{"name":"推荐","slug":"推荐","permalink":"https://guyuecanhui.github.io/tags/推荐/"},{"name":"协同过滤","slug":"协同过滤","permalink":"https://guyuecanhui.github.io/tags/协同过滤/"},{"name":"算法","slug":"算法","permalink":"https://guyuecanhui.github.io/tags/算法/"},{"name":"相似度","slug":"相似度","permalink":"https://guyuecanhui.github.io/tags/相似度/"},{"name":"二部图","slug":"二部图","permalink":"https://guyuecanhui.github.io/tags/二部图/"}]},{"title":"Hexo+NexT+github 配置指南","slug":"hexo-next-github","date":"2019-04-14T06:43:50.000Z","updated":"2019-04-14T14:02:49.468Z","comments":true,"path":"2019/04/14/hexo-next-github/","link":"","permalink":"https://guyuecanhui.github.io/2019/04/14/hexo-next-github/","excerpt":"","text":"这两天在网络各位大神的帖子指导下完成了 Hexo+Next 在 github 上的部署，记录一下全过程，以供后来者参考。 进入正题前，需要安装 Node.js 和 Git，并创建 github 帐号，可以参考其他帖子，这里就不详述了。 安装使用 Hexo安装 HexoHexo 安装过程很简单，只需要选择一个项目的名称和目录（如 project），然后输入以下代码即可在当前目录创建一个 project 的目录，同时初始化该工程： 123456npm install hexo-cli -ghexo init projectcd projectnpm installhexo ghexo s 如果打开 [http://localhost:4000](http://localhost:4000/) 能够看到 Hello World，说明安装已经成功了。 Hexo 常用命令Hexo 常用的命令不多，而且很容易记，按一般使用顺序记录如下： 1234hexo n \"new post\" # 创建新博客，名为 new posthexo g # 生成静态文件hexo s # 在本地起一个服务，可以查看效果，默认路径为 http://localhost:4000hexo d # 将本地文件部署到远端，本文将使用 github 托管 部署到 github创建新仓库首先需要创建一个新的仓库，例如我的用户名为 guyuecanhui，则我需要创建的仓库名为 guyuecanhui.github.io。注意：仓库的名字一定要按照规范命名，即 用户名.github.io，否则无法通过该路径访问博客。 配置 Hexo 的 deploy 选项配置 project 根目录下的 _config.yml，在最后添加如下代码： 1234deploy: type: git repository: http://github.com/guyuecanhui/guyuecanhui.github.io.git branch: master 注意仓库的路径按照参考代码设置，把用户名改成自己的即可。 配置完后执行（这两步后面简称重新部署）： 12hexo ghexo d 即可把本地的博客发布到 github 上了。可以通过 用户名.github.io 来访问主页了。 安装和配置 NexT 主题我使用 Hexo 的目的之一是使用网络大神们提供的各种养眼的主题。这里推荐安装 NexT 主题，也是当前使用比较广泛的一种。 下载并使用 NexT 主题首先定位到博客根目录下，然后下载 NexT 源码： 1git clone https://github.com/theme-next/hexo-theme-next themes/next 然后修改根目录下的 _config.yml 的 theme 选项，修改为： 1theme: next 然后重新部署博客即可看到主题变成了 NexT。NextT 提供了四种模式，在 themes/next/_config.yml 中可以修改，每次修改后需要重新部署才能生效： 12345# Schemes#scheme: Muse # 默认风格#scheme: Mist#scheme: Piscesscheme: Gemini # 选择 gemini 风格 常用选项设置只要记住，跟主题相关的所有设置基本都可以在 themes/next/_config.yml 里面找到。 访问统计使用不蒜子统计博客访问的人数，首先要引入 busuanzi.js。先在 themes/next/_config.yml 中启用并配置 busuanzi_count 插件： 123456789101112131415busuanzi_count: # count values only if the other configs are false enable: true # custom uv span for the whole site site_uv: true site_uv_header: &lt;i class=\"fa fa-user\"&gt;&lt;/i&gt; 访问人数 site_uv_footer: 人 # custom pv span for the whole site site_pv: true site_pv_header: &lt;i class=\"fa fa-eye\"&gt;&lt;/i&gt; 总访问量 site_pv_footer: 次 # custom pv span for one page only page_pv: true page_pv_header: &lt;i class=\"fa fa-file-o\"&gt;&lt;/i&gt; 阅读数 page_pv_footer: 然后在 themes/next/layout/_partial/footer.swig 中添加以下代码： 12&lt;script async src=\"//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js\"&gt;&lt;/script&gt; 重新部署后，就能看到博客的访问统计数据啦！ 其他 Latex 支持 添加分类、标签页面 添加关于页面 添加图片支持 添加评论","categories":[{"name":"安装部署","slug":"安装部署","permalink":"https://guyuecanhui.github.io/categories/安装部署/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://guyuecanhui.github.io/tags/hexo/"},{"name":"github","slug":"github","permalink":"https://guyuecanhui.github.io/tags/github/"},{"name":"next","slug":"next","permalink":"https://guyuecanhui.github.io/tags/next/"}]},{"title":"可能是最好懂的ItemCF解释了","slug":"itemcf","date":"2019-04-12T05:56:07.000Z","updated":"2019-05-04T13:33:58.679Z","comments":true,"path":"2019/04/12/itemcf/","link":"","permalink":"https://guyuecanhui.github.io/2019/04/12/itemcf/","excerpt":"","text":"说到推荐系统，可能最为人熟知的算法就是协同过滤，特别是其中的 ItemCF，自亚马逊文章发表以后，得到了广泛而成功的应用。这篇文章主要谈谈我的理解。 ItemCF 推导过程首先，ItemCF 依赖一个隐含的假设：就是每个用户的兴趣都局限在某几个方面，因此如果两个物品属于一个用户的兴趣列表，那么这两个物品可能就属于有限的几个领域，而如果两个物品属于很多用户的兴趣列表，那么它们就可能属于同一个领域，因而有很大的相似度。 从这个假设出发，我们可以认为两个视频相似表现在它们被很多用户同时观看，两个物品共同观看的人数越多，说明它们的相似度越高，用公式来表达就是： s_{i,j}=|N(i)\\cap N(j)| \\qquad (1)其中，$N(i)$ 表示观看视频 $i$ 的人群集合，$|N(i)\\cap N(j)|$ 表示同时播放过 $i,j$ 的人数。但是由于热点视频可能并不代表用户的真实兴趣（有可能是运营推送，或者仅仅是由于追热心理），因此需要惩罚那些热点的视频，可以通过将共同观看人数除以与视频总观看数相关的系数来实现，例如使用以下方式： s_{i,j}=\\frac{|N(i)\\cap N(j)|}{\\sqrt{|N(i)|\\cdot|N(j)|}} \\qquad (2)但是仅仅惩罚热点视频也还不够，有些人就是闲的无聊，有什么看什么，这种情况下他表现出来的就未必是真实的兴趣了（就不满足我们的隐含假设），他的行为也就不太能作为我们的协同的依据，因此需要对这种人做降权，例如使用以下方式： s_{i,j}=\\frac{\\sum_{u\\in N(i)\\cap N(j)}\\frac{1}{log(1+|M(u)|)}}{\\sqrt{|N(i)|\\cdot|N(j)|}} \\qquad (3)其中，$M(u)$ 表示用户 $u$ 观看的视频集合。另外，如果用户对视频 $i$ 观看了 80%，而对视频 $j$ 只看了 10%，那用户对这两个视频的喜欢程度也是不相同的，因此我们还可以对用户对两个视频观看的完成度差异做降权，差异越大，相似度也越低，例如使用以下方式： s_{i,j}=\\frac{\\sum_{u\\in N(i)\\cap N(j)}\\frac{\\cos(r_u(i),r_u(j))}{log(1+|M(u)|)}}{\\sqrt{|N(i)|\\cdot|N(j)|}} \\qquad (4)其中，$r_u(i)$ 表示用户 $u$ 对视频 $i$ 的观看完成度。最后，将所有视频与其他视频的相似度做 $max$ 归一化，得到： s_{i,j}'=\\frac{s_{i,j}}{\\max_j s_{i,j}} \\qquad (5)归一化使得所有物品的相似度取值都在 (0,1] 之间，这个相似度已经可以直接用于相关推荐场景。另外，有研究表明，这种归一化可以提高 ItemCF 用于个性化推荐时的准确度、覆盖率和多样性。 那基于 ItemCF 如何进行个性化推荐呢？主要是考虑推荐与用户的观看历史最相似的视频，即计算每个视频与用户观看视频集合的相似度作为作为是否观看该视频的预测值： p_u(i)=\\frac{\\sum_{j\\in M(u)} s_{i,j}\\cdot r_u(j)}{\\sum_{j\\in M(u)} s_{i,j}} \\qquad (6)最后，再根据预测值从大到小选取 TopN 个视频作为推荐结果。 优化与讨论其实从第 1 部分的介绍来看，基于 ItemCF 的思想可以做很多改进。例如： 如果感觉算出来的结果仍然偏向热门视频时，可以增加式 (4) 的分母大小； 如果觉得用户只有观看完完成度很高时才是真实兴趣，那可以将式 (4) 的 $cos(\\cdot)$ 部分改成类似 $r_u(i)\\cdot r_u(j)$ 的形式； 如果觉得需要更多的考虑用户的短期兴趣，做即时的推荐，那可以将式 (6) 中的用户观看历史限制在最近几次，甚至一次； 如果把用户-视频考虑成一个二部图，ItemCF 实际上是基于图的结构，执行了一次从用户到视频的兴趣扩散过程。可以考虑下图中的视频 $v_1,v_3$，它们没有直接的共同观看，因此用 ItemCF 算出来的相似度为 0，但是实际上 $u_1,u_2$ 都观看了 $v_2$，因此可以认为用户 $u_1,u_2$ 存在一定的相似性，因此如果执行一次视频-用户-视频的兴趣扩散过程就能够捕获 $v_1,v_3$ 的相似度了。 后面一种思路实际上就是 SimRank，但是由于需要执行多次兴趣扩散（即对二部图做多次迭代计算），SimRank 的计算复杂度相当高，在业务数据量大的情况下需要强大的算力支持，以后会再讨论下我在 SimRank 模型上的尝试。","categories":[{"name":"推荐系统","slug":"推荐系统","permalink":"https://guyuecanhui.github.io/categories/推荐系统/"}],"tags":[{"name":"推荐","slug":"推荐","permalink":"https://guyuecanhui.github.io/tags/推荐/"},{"name":"协同过滤","slug":"协同过滤","permalink":"https://guyuecanhui.github.io/tags/协同过滤/"},{"name":"算法","slug":"算法","permalink":"https://guyuecanhui.github.io/tags/算法/"}]},{"title":"置信区间在推荐中的应用","slug":"confidence-interval","date":"2019-02-10T05:22:05.000Z","updated":"2019-04-13T12:13:47.051Z","comments":true,"path":"2019/02/10/confidence-interval/","link":"","permalink":"https://guyuecanhui.github.io/2019/02/10/confidence-interval/","excerpt":"","text":"学过统计的同学都对置信区间的概念非常熟悉，实际上，离开置信区间谈统计值没啥意义，或者说经常会造成很大的误导。简单来讲，置信区间是指基于观测样本来估计一个未知参数（如均值）时，我们相当确定（用置信度来度量）参数可能的取值范围。如果不考虑置信区间的概念，在我们观察到有 2 个用户喜欢一个视频、1 个用户不喜欢一个视频时，会估计该视频的推荐度为 66%，而认为它是一个高质量的视频，如果一旦将它进行大规模推荐时，很可能发现这个视频的实际转化率低的可怜。 因此在推荐里，置信区间是需要密切关注的概念。在推荐领域实践中，我从 3 个简单的算法来分别介绍置信区间的应用。 Wilson 区间法来判断视频质量在引言的例子中，我们组的海威同学利用 Wilson 区间法来估计视频的推荐度，或者说，来建立视频质量评估模型（模型的一部分）。利用视频播放行为数据来统计视频的播放转化率时，假设视频展示的总数为 $n$，用户实际播放的总数为 $m$，则直接计算出来的播放转化率为 $p=\\frac{m}{n}$。如果 $n$ 越大，说明 $p$ 的估计置信度越高，否则置信度越低。由于视频质量直接决定了我们是否会大规模推荐这个视频，因此在估计 $p$ 时采用的是宁缺毋滥的策略，这个时候可以巧妙的用置信区间的下界来代替 $p$ 作为播放转化率的估计。 具体到 Wilson 区间的计算公式，可以参考wiki（基于正态分布假设），这里只搬个公式： p_w = \\max(0, \\frac{p+\\frac{z^2}{2n}}{1+\\frac{z^2}{n}}-\\frac{z}{1+\\frac{z^2}{n}}\\sqrt{\\frac{p(1-p)}{n}+\\frac{z^2}{4n^2}})其中，$z$ 为某置信度（如 95% 置信度）下查表可得，$n$ 在实际代入时，需要加上平滑因子（如 0.1），防止展示数据丢失导致 $n=0$。从公式可知，基于 Wilson 区间估计的播放转化率最小接近于 0（$n$ 在实际时很可能取到平滑因子），最大接近于 $p$。 UCB算法来平衡探索与应用（E&amp;E）Wilson区间法是用置信区间的下限来减少数据量不足时误判的可能，主要是用来选出精品视频用来广泛推荐。但是一直这样保守推荐，会导致有些视频得不到充分的曝光，就难以评估其实际的转化率，导致推荐出来的所谓精品只是次优的选择。因此，在应用（Expoit）目前已知比较好的视频进行推荐的同时，也要保持一定比例的探索（Explore），即尝试一下那些曝光较少的视频。EE算法里一个常用的算法是 LinUCB，由于涉及特征构造，这里只介绍一个简化版本 UCB，大致思路是一样的。 UCB（Upper Confidence Bound）是一种多臂老虎机算法（MAB），也勉强算一种简化的强化学习算法，调性十足。同样以估计播放转化率为例，它的思路是利用置信区间的上界来代替 $p$ 作为估计值，实际上是提高了曝光不足视频（即长尾视频）的估计值。 UCB 主要解决的问题在于，如何计算置信区间的上界，既能保证随着曝光总量的增加，那些未被探索的视频越来越少，又能保证长久来看，能选到精品的视频。为了实现这个目标，一个常用的启发式公式如下： p_u=\\max_{i}(p_i+\\sqrt{\\frac{2\\ln t}{n_i}})其中，$p_i$ 为某个视频 $n_i$ 次曝光计算的平均转化率，$t$ 表示所有视频总共的曝光数。可以看到，随着曝光总数的增加，曝光很少的视频第二项值会很大，因此所有视频都会得到保底的曝光（t=100000 时至少有 28 次）。但是随着 $n_i$ 继续增加，主要决定因素又变成了 $p_i$，即历史平均转化率高的视频更可能被选中。 Thompson 采样来进行随机长尾推荐UCB 算法在实际于新物品增加快的场景（例如短视频推荐，平均每天新增几万部短视频）时，由于计算过程是确定性的，存在一直只推新物品的问题。为了增加一些随机性，可以考虑用 Thompson 采样算法。它既不使用置信区间的上界，也不使用下界，而是每次基于 Beta(m, n-m) 分布进行采样（注意，这里的 m 和 n 是每个视频单独维护的参数）。 我们知道，Beta 分布实际上是“白努力”过程的成功率，曝光数 $n$ 越大，Beta 分布的曲线越像是一个倒钟的形状，且钟的开口越窄，最后收于期望：$p=\\frac{m}{n}$。反过来说，当使用 Thompson 采样来选择推荐的视频时，虽然每个视频长期来选中的概率取决于其转化率，但是当曝光数量少时，Beta 分布开口很大，也更容易得到比期望大或者小的采样结果，从而引入了随机性。不过从实际应用来看，当媒资库时的视频数量很多时，大部分选中的视频还是新视频。 本文简单的介绍了统计区间在推荐中的一些简单应用，既有利用置信区间的下界来选精品，也有利用置信区间的上界来探索，还有利用整个分布来引入随机性。所有算法都是用简单的数学公式就能达到我们期望的效果，是比人工规则优美的多的形式。当然，举的示例都是推荐的核心问题，没有这么简单就能讲清楚，涉及大量的数据处理和参数调优，需要不断尝试和改进。","categories":[{"name":"推荐系统","slug":"推荐系统","permalink":"https://guyuecanhui.github.io/categories/推荐系统/"}],"tags":[{"name":"推荐","slug":"推荐","permalink":"https://guyuecanhui.github.io/tags/推荐/"},{"name":"统计","slug":"统计","permalink":"https://guyuecanhui.github.io/tags/统计/"},{"name":"置信区间","slug":"置信区间","permalink":"https://guyuecanhui.github.io/tags/置信区间/"}]},{"title":"特征组合之FFM","slug":"ffm","date":"2018-10-04T06:43:50.000Z","updated":"2019-05-04T13:37:20.601Z","comments":true,"path":"2018/10/04/ffm/","link":"","permalink":"https://guyuecanhui.github.io/2018/10/04/ffm/","excerpt":"","text":"前段时间搞 LR 的特征优化，切身体会到人工特征工程实在太费劲了，一方面发掘高价值的特征十分困难，另一方面某些特征之间需要组合才能有效，比如用户对视频的某个特征的偏好，就必须将视频的特征和用户的特征进行组合。LR 是线性模型，没法自动做特征组合，只能人工搞，但人工来干这事就相当麻烦了。自然而然的，就会想到用可以自动组合特征的模型。现在了解的包括 FM、FFM 等基于矩阵分解的模型、基于 GBDT 之类的树模型和基于 DNN 的网络模型。这篇文章先介绍下 FFM 模型。 FFM 模型简介FFM (Field-aware Factorization Machines)$^{[1]}$是 Yuchin Juan 等人在台大期间提出的用于 CTR 预估的模型。它是对 FM 模型的推广，提到 FM 又不得不提到 Poly2 模型，好在它们三个的关系十分简单和明确： Poly2 模型是将所有特征进行两两组合，也就是当特征有 $n$ 个的时候，需要 $O(n^2)$ 个参数，而且这些参数之间是相互独立的，意味着每个参数都需要足够的样本来训练，也就是每对特征都同时出现在足够多的样本里。因此如果无法满足海量样本的要求时，这个模型很难训练出来。它的模型如下（其中 $h(i,j)$ 作用是将 $i,j$ 映射成一个自然数）： \\phi_{poly2}(\\mathcal{w},\\mathcal{x}) = \\sum_{j_1=1}^n\\sum_{j_2=j_1+1}^n w_{h(j_1,j_2)}x_{j_1}x_{j_2} \\qquad (1) FM 模型是为每个特征训练一个隐向量，而特征组合的权重就是这两个特征的隐向量点积，假设隐向量的长度为 $k$，那么需要 $O(nk)$ 个参数，因此参数的规模要比 Poly2 小很多（这里可以认为 Poly2 为每个特征生成的向量长度为 $n$），训练数据量要求也就没那么高了。它的原始形态 (2) 和简化计算形态 (3) 分别如下： \\phi_{FM}(\\mathcal{w},\\mathcal{x})= \\sum_{j_1=1}^n\\sum_{j_2=j_1+1}^n (\\mathcal{w}_{j_1}\\cdot\\mathcal{w}_{j_2})x_{j_1}x_{j_2} \\qquad (2) \\phi_{FM}(\\mathcal{w},\\mathcal{x})=\\frac{1}{2}\\sum_{j=1}^n(\\mathcal{s}-\\mathcal{w}_j x_j), \\quad \\mathcal{s}=\\sum_{j'=1}^n\\mathcal{w}_{j'} x_{j'} \\qquad (3) FFM 模型是为每个特征对每一个 Field 学习一个隐向量，一个 Field 可以认为是特征所属的属性，比如用户的常驻地可以看成是一个 Field、视频的分类可以看成是另一个 Field，假设有 $f$ 个 Field，每个隐向量长度为 $k$，则FFM模型需要 $O(nfk)$ 个参数，看起来比 FM 多很多，但是实际上由于每个特征对不同 Field 的作用都是单独学习的，因此 FFM 的 $k$ 往往比 FM 的 $k$ 小很多。它的模型如下： \\phi_{FFM}(\\mathcal{w},\\mathcal{x})= \\sum_{j_1=1}^n\\sum_{j_2=j_1+1}^n (\\mathcal{w}_{j_1,f_2}\\cdot\\mathcal{w}_{j_2,f_1})x_{j_1}x_{j_2} \\qquad (4)FFM 为什么要把 Field 拎出来考虑呢？举个例子，还是在视频推荐里，假设只考虑用户的年龄特征、视频的分类特征和演员特征，FM 在学用户年龄特征的时候是综合考虑视频分类和演员来得到的，然而从直观上来看，年龄对分类的影响和对演员的影响是不同的，因此更自然的想法是对分类和演员各学一个隐向量，效果应该会更好。 换句话说，如果特征有明显的 Field 划分，用 FFM 模型理论上是优于 FM 的；但是如果不满足这个条件，例如在 NLP 领域，所有特征都属于一个 Field，FFM 模型的优势就不明显了。另外，Field 很容易对应到一个类别，因此 FFM 特别适合处理类别特征，对于连续特征，如果离散化处理效果比较好也还OK，否则优势也不明显。因此，FFM 主要适合处理类别特征，并且喜欢稀疏数据，而不适合处理连续特征，不适合处理 Field 数量很少的数据。 FFM 模型实现由于官方只提供了 FFM 模型的 C++ 实现$^{[2]}$，而我们主要是基于 Spark 的，因此需要一份 scala 实现。网上也找了一下，发现 Vince Shieh 实现的一份代码$^{[3]}$，但是 review 以后发现参数有点问题，因此考虑自己实现一份。实现的 FFM 的核心就在于如何计算梯度，如何更新模型。论文的模型 (4) 是简化处理，在实现的时候还需要带上全局偏置和线性部分，完整的模型如下： \\phi_{FFM}(\\mathcal{w},\\mathcal{x})= w_0 + \\sum_{j=1}^n w_jx_j+ \\sum_{j_1=1}^n\\sum_{j_2=j_1+1}^n (\\mathcal{w}_{j_1,f_2}\\cdot\\mathcal{w}_{j_2,f_1})x_{j_1}x_{j_2} \\qquad (5)而 FFM 用于 CTR 预估时，目标优化函数定义成： \\mathcal{L}=\\min_{\\mathcal{w}} \\frac{\\lambda}{2}||\\mathcal{w}||^2_2+\\sum_{i=1}^m \\log(1+e^{-y_i\\phi(\\mathcal{w},\\mathcal{x})}) \\qquad (6)使用 SGD 的方式进行更新，即每次使用一个样本 $(y,\\mathcal{x})$ 来更新模型，其中，$\\mathcal{x}$ 的格式为 \\mathcal{x}=[f_{i_1}j_{i_1}x_{i_1},\\cdots,f_{i_t}j_{i_t}x_{i_t}]，表示该样本中 $t$ 个非零特征，$f$ 表示特征的域编号，$j$ 表示特征编号，$x$ 表示特征取值（对于 one-hot 编码，$x=1$）。首先对式 (6) 中各权重计算梯度： \\begin{cases} g_0=\\lambda w_0+\\kappa \\\\ g_j=\\lambda w_j+\\kappa w_j \\\\ \\mathcal{g}_{j_1,f_2}=\\lambda \\mathcal{w}_{j_1,f_2}+\\kappa \\mathcal{w}_{j_2,f_1} \\\\ \\mathcal{g}_{j_2,f_1}=\\lambda \\mathcal{w}_{j_2,f_1}+\\kappa \\mathcal{w}_{j_1,f_2} \\end{cases}, \\quad \\kappa=\\frac{-y_ie^{-y_i\\phi(\\mathcal{w},\\mathcal{x})}}{1+e^{-y_i\\phi(\\mathcal{w},\\mathcal{x})}} \\qquad (7)然后使用 AdaGrad 对累积梯度进行更新（这里也可以不用 AdaGrad，直接使用 GD，或者用 Adam 等其他方法更新）： \\begin{cases} G_i=G_i+g_i^2 \\\\ w_i=w_i-\\frac{\\eta}{\\sqrt{G_i}} g_i \\end{cases}, \\quad i=0, i_1, \\cdots, i_t \\qquad (8) \\begin{cases} (G_{j_1,f_2})_d=(G_{j_1,f_2})_d+(g_{j_1,f_2})_d^2 \\\\ (G_{j_2,f_1})_d=(G_{j_2,f_1})_d+(g_{j_2,f_1})_d^2 \\\\ (w_{j_1,f_2})_d=(w_{j_1,f_2})_d-\\frac{\\eta}{\\sqrt{(G_{j_1,f_2})_d}} (g_{j_1,f_2})_d \\\\ (w_{j_2,f_1})_d=(w_{j_2,f_1})_d-\\frac{\\eta}{\\sqrt{(G_{j_2,f_1})_d}} (g_{j_2,f_1})_d \\end{cases}, \\quad d=1,\\cdots, k,\\qquad (9)基于以上各式，可以很容易把算法写出来了：12345678910Algorithm: Train FFM using SG init G = ones(n,f,k) init g = rand(n,f,k)[0,1/sqrt(k)] for epoch = 1 to t: for i = 1 to m: sample a data point (y,x) calculate kappa by (7) for xi, xj in x: calculate gradients by (7) update weights by (8)(9) 论文中指出，FFM 特别容易过拟合，其中，正则化系数 $\\lambda$ 越小，效果越好但越容易过拟合；学习率 $\\eta$ 越大，学习速度越快也越容易过拟合。我自己试了几个数据集，使用 $\\lambda=0.00002,\\ \\eta=0.1,\\ k=4$，一般 1~4 轮都差不多OK了，再多就容易过拟合。为了防止过拟合，论文提出使用 early stopping 技术，即将训练数据进一步划分成训练集和验证集，每一轮用训练集更新完模型后，用验证集计算 logloss，并记录验证集 logloss 开始上升的轮数 $r$，最后再用整个数据集训练 $r$ 轮。但是实际在用的时候，可以线下调一个比较好的参数，然后直接放到线上去用，等数据发生变化，或者定时去重新评估这些参数。 自己用 scala 实现的 FFM 模型没有使用指令集加速，只是将训练数据划分成多个 partition 并行训练，然后将参数合并（求平均），效果差一些。我拿 libFFM 做了一个性能的比较……完败……唉，Spark 做数值计算还是不太行啊！ References[1] Juan, Yuchin, et al. “Field-aware Factorization Machines for CTR Prediction.” ACM Conference on Recommender Systems ACM, 2016:43-50.[2] https://github.com/guestwalk/libffm[3] https://github.com/VinceShieh/spark-ffm","categories":[{"name":"推荐系统","slug":"推荐系统","permalink":"https://guyuecanhui.github.io/categories/推荐系统/"}],"tags":[{"name":"推荐","slug":"推荐","permalink":"https://guyuecanhui.github.io/tags/推荐/"},{"name":"排序","slug":"排序","permalink":"https://guyuecanhui.github.io/tags/排序/"},{"name":"特征工程","slug":"特征工程","permalink":"https://guyuecanhui.github.io/tags/特征工程/"},{"name":"特征组合","slug":"特征组合","permalink":"https://guyuecanhui.github.io/tags/特征组合/"}]},{"title":"Submodular函数","slug":"sub-modular","date":"2018-08-16T12:14:44.000Z","updated":"2019-05-10T14:41:11.981Z","comments":true,"path":"2018/08/16/sub-modular/","link":"","permalink":"https://guyuecanhui.github.io/2018/08/16/sub-modular/","excerpt":"","text":"Submodular 函数的定义与性质最近在看一些计算学习理论的时候，发现很多文章是基于 Submodular 函数做的，就去了解了一下。所谓 Submodular 函数，是指满足如下定义的集合函数$^{[1]}$： 记 $[n]={1,2,\\cdots,n}$ 为 Ground Set，记 $f:2^{[n]}\\to\\mathbb{R}$ 为一个集合函数，该函数是 submudular当： f(A)+f(B)\\ge f(A\\cup B)+f(A\\cap B), \\quad \\forall A,B\\subseteq[n] \\qquad(1) 它是对 Modular 函数的条件进行放松，而 Modular 函数是指满足如下定义的函数： f(A)+f(B)=f(A\\cup B)+f(A\\cap B), \\quad \\forall A,B\\subseteq[n] \\qquad(2)看定义，Submodular 函数与凹函数有些相似，不同的在于它并不限定元素的顺序！Submodular 函数还有一种等价式，更能体现它的一个核心特点： f(A\\cup \\{i\\})-f(A)\\ge f(B\\cup \\{i\\})-f(B), \\quad \\forall A\\subseteq B\\subseteq [n],\\ i\\not \\in B \\qquad(3)通俗的来讲，这个特点就是边际效用递减，即增加一个元素对整体的收益贡献递减。这种边际效用递减的程度可以用曲率 $\\kappa$（Curvature）来度量：$f_S(i)\\ge (1-\\kappa)f(i)$，其中，$0\\le\\kappa\\le1$。 举两个跟推荐有关系的 Submodular 函数的例子： 视频推荐多样性：对于一个可推荐的视频集合 $S$，假设每个视频有一个分类 $g_i$，则一个推荐列表中不同类别的总数 $f(S)=\\sum_i \\mathbb{I}(g_i)$ 就是一个 Submodular 函数，其中，$\\mathbb{I}(x)$ 表示元素 $x$ 是否存在。 商品推广用户选择：对于一个社交网络的用户集合 $S$，如果某用户看过一个物品，则他有可能向他的朋友推荐和分享。假设某个物品在推广期时给 $k$ 个用户 $S_k$ 展示了，则最终该物品会展示给多少用户 $m=f(S_k)$ 是一个 Submodular 函数。 最后简单介绍下它的一些性质。Submodular 函数首先是集合函数，因此满足如下性质： 非负性：$f(A)\\ge 0$ 单调性：可以是单调增或单调减 正则化：$f(\\phi)=0$ 另外，根据定义，可以证明它还满足： 若 $f_1,f_2,\\cdots,f_k$ 是 Submodular 函数，给定 $w_1,w_2,\\cdots,w_k\\ge 0$，则 $g(S)=\\sum_iw_if_i(S)$ 也是 Submodular 函数 若 $f$ 在 $X$ 集合上是 Submodular 函数，给定 $T\\subseteq X$ 则 $f(S\\cup T)$、$f(S\\cap T)$、$f(X\\setminus S)$ 都是 Submodular 函数 由于 Submodular 函数性质好、易证明，它在机器学习、博弈论等领域的理论研究方面获得了广泛的应用$^{[1,2]}$。特别的，文献$[1]$基于 Submodular 目标提出了 PMAC 理论，是对 PAC 理论的扩展；文献$[2]$基于 Submodular 函数提出一种 AdaptiveSampling 的算法，可以在理论保证的前提下，将样本数大大减少，这里就不展开了。 Reference[1] Balcan, Maria Florina, and N. J. A. Harvey. “Learning submodular functions.” ACM Symposium on Theory of Computing ACM, 2011:793-802.[2] Balkanski, Eric and Singer, Yaron. “Approximation Guarantees for Adaptive Sampling.” Proceedings of the 35th International Conference on Machine Learning, 2018:393-402.","categories":[{"name":"数学","slug":"数学","permalink":"https://guyuecanhui.github.io/categories/数学/"}],"tags":[{"name":"优化","slug":"优化","permalink":"https://guyuecanhui.github.io/tags/优化/"},{"name":"计算学习理论","slug":"计算学习理论","permalink":"https://guyuecanhui.github.io/tags/计算学习理论/"},{"name":"函数","slug":"函数","permalink":"https://guyuecanhui.github.io/tags/函数/"}]},{"title":"SVD++ 论文精读","slug":"svdpp","date":"2018-02-24T12:16:34.000Z","updated":"2019-07-03T14:28:09.414Z","comments":true,"path":"2018/02/24/svdpp/","link":"","permalink":"https://guyuecanhui.github.io/2018/02/24/svdpp/","excerpt":"","text":"论文引用：Koren, Y. . (2008). Factorization meets the neighborhood : a multifaceted collaborative filtering model. Proceedings of the 14th ACM SIGKDD International Conference of Knowledge Discovery and Data Mining, 2008. ACM Press. 本文对协同过滤中最主要的两种方法（基于邻域的方法和基于隐特征模型的方法）分别提出了优化方案，并且设计了一个联合模型将两种方法统一，从而达到更好的效果。为了进行区分，本文将对 SVD 进行优化的方案称为 SVD+，将联合模型的方法称为 SVD++。 研究背景Koren 在做 Netflix 的比赛过程中，发现基于邻域的方法和基于隐特征模型的方法各有所长： 比较 基于邻域的方法 基于隐特征模型的方法 主要思想 核心在于计算用户/物品的相似度，将相似用户的喜好推荐给用户，或将用户喜欢物品的相似仿物品推荐给用户 假设真正描述用户评分矩阵性质的内存特征（可能未知）其实只有少数几个，将用户和物品都映射到这些隐特征层，从而使得用户和物品直接关联起来 挖掘信息特征 能够对局部强相关的关系更敏感，而无法捕捉全局弱相关的关系 能够估计关联所有物品/用户的整体结构，但是难以反映局部强相关的关系 因此，这两种方法存在天然的互补关系。另外，Koren 还发现，使用隐式反馈的数据能够提高推荐的准确性，而这两种方法都不支持使用隐式反馈的数据。基于这些发现，Koren 先分别将隐式反馈集成到两个模型中去，得到两个优化的模型，再提出一种联合模型，将这两个优化的模型进一步融合，从而得到更好的效果。 模型推导文章从 Baseline 的模型，通过加入各种考虑因素，推导出基于邻域和基于隐特征的两个模型，再推导出联合模型。 1、Baseline模型Baseline 模型就是基于历史数据的简单统计，主要看用户 $u$ 的平均评分 $b_u$、电影 $i$ 的平均评分 $b_i$ 和所有电影的平均评分 $\\mu$： b_{ui} = \\mu + b_u + b_i所有后面的模型都是对这个基准模型的修正。这个基准模型中的参数都是可以离线计算的，用的方法也是本文通用的参数估计方法，先定义损失函数 $l(P)$： l(p_1,p_2,\\cdots) = \\sum_{(u,i)\\in \\kappa} (r_{ui} - \\hat{r_{ui}})^2 + \\lambda(\\sum_{p_1} p_1^2 + \\sum_{p_2} p_2^2 + \\cdots)其中，P=\\{p_1,p_2,\\cdots\\} 表示待估计的参数，$\\kappa$ 表示所有显式反馈的组合（即用户 $u$ 对物品 $i$ 进行过评分），r_{ui} 表示评分的实际值，\\hat{r_{ui}} 表示评分的预测值，$\\lambda$ 为超参，根据经验设置，然后求最小化 $l(P)$ 下各参数的值，通常使用最小二乘法，或者文中使用的梯度下降法（效率更高）。比如这个地方，参数就 $b_u$ 和 $b_i$，可以根据下式进行参数估计： \\min_{b_*}\\sum_{(u,i)\\in \\kappa} (r_{ui} - \\hat{r_{ui}})^2 + \\lambda(\\sum_{p_1} p_1^2 + \\sum_{p_2} p_2^2 + \\cdots)2、推广到基于邻域的模型本文主要考虑 ItemCF，对于两个物品 $i$ 和 $j$，它们的相似性 s_{ij} 是基于 Pearson 相关系数 \\rho_{ij} 计算得到： s_{ij} = \\frac{n_{ij}}{n_{ij}+\\lambda_2}\\rho_{ij}, \\\\ \\rho_{ij}=\\frac{E((x-\\mu_x)(y-\\mu_y))}{\\sigma_x\\sigma_y}其中，$n_{ij}$ 表示同时对 $i$ 和 $j$ 进行评分的用户数，$\\lambda_2$ 应该是防止 $i$ 和 $j$ 比较冷门的情况下，恰好有个别用户同时对它们进行了评分，这时候它们的相关性实际是看不出来的，属于偶然情况，通常 $\\lambda_2=100$。之前的 ItemCF 进一步利用用户 $u$ 评过分的与 $i$ 最相关的 $k$ 个物品 $S^k(i;u)$ 来估计用户 $u$ 对 $i$ 的评分： \\hat{r_{ui}} = b_{ui} + \\frac{\\sum_{j\\in S^k(i;u)} s_{ij}(r_{uj} - b_{uj})}{\\sum_{j\\in S^k(i;u)} s_{ij}}但是如果 $u$ 没有对与 $i$ 相似的物品评过分，那上式就主要取决于 b_{ui} 了。为了解决这个小问题，有方案先计算插值权重 $\\theta_{ij}^u$ 来取代实际的评分： \\hat{r_{ui}} = b_{ui} + \\sum_{j\\in S^k(i;u)} \\theta_{ij}^u (r_{uj} - b_{uj})但是以上模型都只考虑了用户 $u$，而对全局结构没有一个很好的理解，因此 Koren 提出不仅仅使用用户 $u$ 的对 $i$ 最相关的 $k$ 个物品的评分数据，而是使用所有 $u$ 的评分数据，因此引入一个参数 \\omega_{ij} 来表示 $j$ 的评分对 $i$ 评分的影响，并且这个 $\\omega_{ij}$ 是基于所有用户对 $i$ 和 $j$ 评分估计出来的： \\hat{r_{ui}} = b_{ui} + \\sum_{j\\in R(u)} (r_{uj} - b_{uj})\\omega_{ij}分析这个式子，当 $i$ 和 $j$ 越相关，说明 $j$ 对 $i$ 的影响越大，即 w_{ij} 越大，这时候如果 (r_{uj} - b_{uj}) 较大，则估计的评分相对于 b_{ui} 的偏移也就越多；反之，当 w_{ij} 较小时，无论 $j$ 的评分如何都对偏移影响不大。 在此基础上，进一步引入隐式反馈的数据： \\hat{r_{ui}} = b_{ui} + \\sum_{j\\in R(u)} (r_{uj} - b_{uj})\\omega_{ij} +\\sum_{j\\in N(u)} c_{ij}其中，c_{ij} 表示隐式反馈对基准估计的偏移影响，当 $j$ 与 $i$ 的评分强相关时，$c_{ij}$ 较大。这个式子的主要问题是，它对重度用户的推荐和对轻度用户的推荐结果相差较大，因为重度用户的显式反馈和隐式反馈都很多，因此偏移项值较大。Koren 发现，做一下正则化以后，效果会更好： \\hat{r_{ui}} = b_{ui} + \\mid R(u)\\mid ^{-1/2}\\sum_{j\\in R(u)} (r_{uj} - b_{uj})\\omega_{ij} +\\mid N(u)\\mid ^{-1/2}\\sum_{j\\in N(u)} c_{ij}为了降低上式的计算复杂度，可以只考虑对 $i$ 影响最大的 $k$ 个物品，记 $R^k(i;u)=R(u)\\cap S^k(i)$ 表示 $u$ 评分过的物品中属于 $i$ 最相似的 TopK 物品，类似的，记 $N^k(i;u)=N(u)\\cap S^k(i)$，这两个集合的元素个数通常是小于 $k$ 的（而如果 $u$ 对至少 $k$ 个物品评过分的话，$\\mid S^k(i;u)\\mid = k$）。则最终的模型为： \\hat{r_{ui}} = b_{ui} + \\mid R^k(i;u)\\mid ^{-1/2}\\sum_{j\\in R(u)} (r_{uj} - b_{uj})\\omega_{ij} +\\mid N^k(i;u)\\mid ^{-1/2}\\sum_{j\\in N(u)} c_{ij}使用之前提到的最小化 f(b_u, b_i, w_{ij}, c_{ij}) 的方法来估计这些参数的取值。记 e_{ui}=r_{ui} - \\hat{r_{ui}}，则使用梯度下降法得到的迭代公式如下： \\begin{cases} b_u \\leftarrow b_u+\\gamma\\cdot (e_{ui} - \\lambda_4\\cdot b_u) \\\\ b_i \\leftarrow b_i+\\gamma\\cdot (e_{ui} - \\lambda_4\\cdot b_i) \\\\ \\omega_{ij} \\leftarrow \\omega_{ij} + \\gamma\\cdot(\\mid R^k(i;u)\\mid ^{-1/2}\\cdot e_{ui}\\cdot (r_{uj} - b_{uj})-\\lambda_4\\cdot \\omega_{ij}), \\forall j \\in R^k(i;u) \\\\ c_{ij} \\leftarrow c_{ij} + \\gamma\\cdot(\\mid N^k(i;u)\\mid ^{-1/2}\\cdot e_{ui}-\\lambda_4\\cdot c_{ij}), \\forall j \\in N^k(i;u) \\end{cases}对于 Netflix 数据集，Koren 推荐取 $\\gamma=0.005$，$\\lambda_4=0.002$，对所有数据集进行 15 轮训练。从实际效果来看 $k$ 越大，推荐的效果越好。这个模型的计算主要集中在参数训练上，一旦模型训练出来了，就可以快速的进行在线的预测。 3、推广到基于隐特征的模型原始的 SVD 是将用户和物品映射到一个隐特征集合： \\hat{r_{ui}} = b_{ui} + p_u^T\\cdot q_i由于用户的规模通常远大于物品的规模，因此考虑用 $u$ 喜欢的物品来对 $u$ 进行建模，再加上隐式反馈的数据，可以得到 Asymmetric-SVD 模型： \\hat{r_{ui}} = b_{ui} + q_i^T(\\mid R(u)\\mid ^{-1/2}\\sum_{j\\in R(u)} (r_{uj} - b_{uj})x_j +\\mid N(u)\\mid ^{-1/2}\\sum_{j\\in N(u)} y_j)其中，x_j 和 y_j 是用来控制显式反馈和隐式反馈重要性比例的参数。用最小化 f(b_u,b_i,q_i,x_j,y_j) 来估计这些参数值。由于这里用 (r_{uj} - b_{uj})x_j 来替代原来的用户隐特征，因此数据量少了很多。该模型具有比较好的可解释性，并且对于新用户来讲，只要他做了一些反馈，即更新了 r_{uj} 后，就可以立即算出估计值；但是如果新上线一个物品，由于 q_i^T 需要重新估计，因此对新物品的冷启动需要一定的反应时间。 如果对于计算不是很 care 的话，当然可以不用这种简化处理，还是对用户直接进行建模（$p_u$），这样的效果会更好一些，但是可解释性之类的就要差一些： \\hat{r_{ui}} = b_{ui} + q_i^T(p_u +\\mid N(u)\\mid ^{-1/2}\\sum_{j\\in N(u)} y_j)4、联合模型如果把上面两个模型看成是 预测值=基准估计+偏移量 的话，那么这两个模型就可以混合到一起，变成： \\begin{align} \\hat{r_{ui}} &= b_{ui} \\\\ &+ q_i^T(p_u +\\mid N(u)\\mid ^{-1/2}\\sum_{j\\in N(u)} y_j) \\\\ &+ \\mid R^k(i;u)\\mid ^{-1/2}\\sum_{j\\in R(u)} (r_{uj} - b_{uj})\\omega_{ij} +\\mid N^k(i;u)\\mid ^{-1/2}\\sum_{j\\in N(u)} c_{ij} \\end{align}其中，第一项为基准估计，第二项 provides the interaction between the user profile and the item profile. In our example, it may find that “The Sixth Sense” and Joe are rated high on the Psychological Thrillers scale. 第三项 contributes fine grained adjustments that are hard to profile, such as the fact that Joe rated low the related movie “Signs”. 使用梯度下降法得到的迭代公式如下： \\begin{cases} b_u \\leftarrow b_u+\\gamma_1\\cdot (e_{ui} - \\lambda_6\\cdot b_u) \\\\ b_i \\leftarrow b_i+\\gamma_1\\cdot (e_{ui} - \\lambda_6\\cdot b_i) \\\\ q_i \\leftarrow q_i+ \\gamma_2\\cdot(e_{ui}\\cdot(p_u+\\mid N(u)\\mid ^{-1/2}\\sum_{j\\in N(u)} y_j)-\\lambda_7\\cdot q_i) \\\\ p_u \\leftarrow p_u + \\gamma_2\\cdot(e_{ui}\\cdot q_i - \\lambda_7\\cdot p_u) \\\\ y_j \\leftarrow y_j+\\gamma_2\\cdot(e_{ui} \\cdot\\mid N(u)\\mid ^{-1/2} \\cdot q_i - \\lambda_7\\cdot y_j) \\\\ \\omega_{ij} \\leftarrow \\omega_{ij} + \\gamma_3\\cdot(\\mid R^k(i;u)\\mid ^{-1/2}\\cdot e_{ui}\\cdot (r_{uj} - b_{uj})-\\lambda_8\\cdot \\omega_{ij}),\\ \\forall j \\in R^k(i;u) \\\\ c_{ij} \\leftarrow c_{ij} + \\gamma_3\\cdot(\\mid N^k(i;u)\\mid ^{-1/2}\\cdot e_{ui}-\\lambda_8\\cdot c_{ij}),\\ \\forall j \\in N^k(i;u) \\end{cases}在 Netflix 的数据集上，建议参数为 \\gamma_1=\\gamma_2=0.007，\\gamma_3=0.001，\\lambda_6=0.005，\\lambda_7=\\lambda_8=0.015，整体迭代约 30 轮收敛，每一轮训练时，可以将 \\gamma_* 减少 10%。而 $k=300$，再大也不会有明显的性能提升。 最后，Koren 还设计了一个比较巧妙的实验，解答了我一直以来一个疑问：RMSE 的提升是否也意味着推荐效果的提升。他们设计了一个针对 TopN 推荐的测试，主要的思想是先找出所有 5-star 的评分，认为这些评分意味着该用户喜欢这部电影，然后对所有这些 $(u,i)$，随机再选 1000 部电影，估计 $u$ 对这些电影的评分，看用户对这些电影里所有的 5-star 电影排名情况，然后对不同的算法进行比较，发现 RMSE 越小的算法，将 5-star 排到前面的概率也越大，从而说明了在这种情况下，RMSE 的提升也意味着推荐效果的提升。","categories":[{"name":"论文精读","slug":"论文精读","permalink":"https://guyuecanhui.github.io/categories/论文精读/"}],"tags":[{"name":"推荐","slug":"推荐","permalink":"https://guyuecanhui.github.io/tags/推荐/"},{"name":"协同过滤","slug":"协同过滤","permalink":"https://guyuecanhui.github.io/tags/协同过滤/"},{"name":"算法","slug":"算法","permalink":"https://guyuecanhui.github.io/tags/算法/"},{"name":"召回","slug":"召回","permalink":"https://guyuecanhui.github.io/tags/召回/"},{"name":"矩阵分解","slug":"矩阵分解","permalink":"https://guyuecanhui.github.io/tags/矩阵分解/"}]},{"title":"白话 Word2Vec","slug":"word2vec","date":"2018-02-21T14:00:53.000Z","updated":"2019-04-24T14:15:24.933Z","comments":true,"path":"2018/02/21/word2vec/","link":"","permalink":"https://guyuecanhui.github.io/2018/02/21/word2vec/","excerpt":"","text":"这两天学习了下Word2Vector的理论和实现，原理什么的网上很多，就不搬运了，推荐看参考文献[1-3]，这里主要讲下我对几个关键点的理解。 1、词向量的意义为什么要生成词向量，或者说词向量解决原来哪个领域什么方法的哪些不足？我的理解是这玩意主要就是为了解决如何让计算机理解自然语言中单词含义的问题。当然，现在随着 word2vec 用法的推广，这里已经不仅仅是自然语言中单词的理解了，还可以是各种现实生活中计算机本来没有办法理解的概念，比如用户的观影行为、图片的主题等等，把这些计算机一脸蒙逼的东西转换为它们最喜欢的浮点向量，然后把理解这个计算机一脸蒙逼的行为转换成向量的运算，这样实际就是完成了人类世界各种概念向计算机世界的映射/翻译，为人工智能占领世界打下了坚实的基础（扯远了）。那词向量比之前的方法好在哪呢？给我印象最深的就是含义相近的词能用距离相近的向量来表示！至于其他的一些数学处理上的好处，感觉只是副产品。文献 [1-2] 提供了一种能专门训练词向量的方法，一份好的词向量是可以直接用于翻译等应用的，所以感觉当我们自己数据量不足的时候，可以考虑直接用别人训练出来的词向量。 2、训练过程Mikolov 等人提出了两种模型（CBOW 和 Skip-gram）、两种目标函数（Hierarchical Softmax, HS 和 Negative Sampling, NS），所以乘一下就是4个训练过程，但是其实理解起来都是差不多的。 先整体讲一下它们的关系，CBOW 模型是根据一个词 $w$ 的上下文 $U$ 来预测 $w$，Skip-gram是 根据一个词 $w$ 来预测上下文 $U$。初看时我是一脸蒙逼的，预测啥？后来才发现，实际上这里讲预测有点歧义，就是一个训练网络参数的过程。下文的理解需要有点基础知识，比如Huffman 编码之类的。 基于 HS 的 CBOW 模型和 Skip-gram 模型基于HS的CBOW模型实际上就是给定一个词 $w$ 的上下文 $U$ 中所有词的词向量 $v_u$ （$u \\in U$），输出一个 Huffman 树，使得网络根据这些 $v_u$ 的和 $x_U$ 能顺着这个 Huffman 树一路找到词 $w$。这里的 Huffman 树是根据所有词的词频生成的，它的每个叶节点表示一个词 $i$，并记录该词的词向量 $v_i$，非叶节点针对每个单词 $w$ 都会生成一个参数向量 $\\theta_w$）。那什么叫顺着 Huffman 树一路找到词 $w$呢？我们知道 Huffman 树是一棵二叉树，在任何一个非叶节点 $j$ 决定是往左走还是往右走的时候，实际上是用 $x_U^T\\cdot \\theta_w^j$ 来决定的，这类似于二分类问题，因此需要加一个激活函数（用的是 sigmoid 函数），但是这不重要，重要的是它要根据 $x_U^T\\cdot \\theta_w^j$ 来判断是往左走还是往右走。因此，整个 CBOW 模型实际上就是在计算如何给定 $x_U$ 来在 Huffman 树上一步一步找到 $w$ 所在的叶节点。这个框架定了，剩下就是把这个思路转换成优化方程，然后用 GD 的方法来迭代求解，求解的过程中会不断更新 $\\theta_w$ 和 $v_u$。注意，CBOW 模型虽然说是根据 $w$ 的上下文 $U$ 来预测 $w$，但是它更新的是 $w$ 的上下文 $U$ 中词的词向量。 基于 HS 的 Skip-gram 模型也是一样的道理，但是它的输入是 $v_w$，目标是在 Huffman 树中找到 $w$ 的所有上下文 $u$ 所在的叶节点（把每次查找都乘起来就 OK 了）。然后又是一堆计算，得到一个迭代方程组，来更新 $\\theta_u$ 和 $v_w$（跟上面的类似，$\\theta_u^j$ 是用来控制根据 $v_w$ 决定在每个非叶节点 $j$ 是往左走还是往右走才能找到 $u$ 所在的叶节点）。 基于 HS 的目标函数有一个小问题，就是所有非叶节点 $i$ 会对所有的词 $w$ 训练参数向量 $\\theta_w^i$，因此需要很大的数据量，而且存储量也很大。基于 NS 的目标函数就能大大减少参数的个数，下面详细讨论下。 基于 NS 的 CBOW 模型和 Skip-gram 模型前面讲了，基于 HS 的模型生成的是 Huffman 树，每次训练是最大化找到某个词（根据上下文找一个词，或者根据词找它的上下文）的概率。而基于 NS 的模型则是最大化正确分类某个词的概率。前面提到了，在 Huffman 树上往下走的时候，相当于是一个二分类问题，那为什么不用更加直观的分类呢？ 什么是更直观的分类呢？给定一个样本，比如说一个词 $w$ 及其上下文 $U$，这时候再从词库里随便挑一些小伙伴出来，目标就是区分 $w$ 和这些新伙伴谁是 $U$ 的那个他（CBOW 模型），或者区分 $U$ 和这些新伙伴，谁是 $w$ 的上下文（Skip-gram 模型）？当然，这些小伙伴也不是随机选的，用的是随机负采样（所以叫 Negtive Sampling），本质上就是一种带权采样，也就是出现次数越多的词采到的概率越大。 基于 NS 的 CBOW 模型输入还是一个词 $w$ 的上下文 $U$ 中所有词的词向量之和 $x_U$，以及随机选的小伙伴们 $F$，分类是对每个 $p\\in {w} \\cup F$，训练一个参数向量 $\\theta_p$，然后根据 $x_U^T\\cdot \\theta_p$（借助 sigmoid 函数分类）来判断 $p$ 到底是不是 $w$？因此设置的目标函数就是最大化分对的概率同时最小化分错的概率，然后再用 GD 列出一堆迭代方程来求解。从这里可以看到，HS 是对 Huffman 树上到 $w$ 的每个非叶节点训练一个参数向量，而这里是对 $p\\in {w} \\cup F$ 训练参数向量，参数向量的个数少了很多（$(N-1)\\cdot N$ vs. $N$），但是训练时间却不一定。文献 [2] 给出的数据是 $\\mid F\\mid=5$ 时，NS 方法快，$\\mid F\\mid=15$ 时，HS 方法快。 基于 NS 的 Skip-gram 模型也是类似，就是给定 $w$ 的词向量及其上下文，再选一群小伙伴，最大化把 $w$ 的上下文正确分出来并且最小化分错的概率。 3、词向量的应用参考文献[1] Mikolov T, Chen K, Corrado G, et al. Efficient estimation of word representations in vector space[J]. arXiv preprint arXiv:1301.3781, 2013.[2] Mikolov T, Sutskever I, Chen K, et al. Distributed representations of words and phrases and their compositionality[C]//Advances in neural information processing systems. 2013: 3111-3119.[3] peghoty. word2vec 中的数学原理详解. http://www.cnblogs.com/peghoty/p/3857839.html.","categories":[{"name":"推荐系统","slug":"推荐系统","permalink":"https://guyuecanhui.github.io/categories/推荐系统/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://guyuecanhui.github.io/tags/算法/"},{"name":"表征向量","slug":"表征向量","permalink":"https://guyuecanhui.github.io/tags/表征向量/"}]}]}