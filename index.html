<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">





  <link rel="alternate" href="/atom.xml" title="HCigmoid" type="application/atom+xml">






<meta name="description" content="总结心得">
<meta name="keywords" content="feature, model, algorithm">
<meta property="og:type" content="website">
<meta property="og:title" content="HCigmoid">
<meta property="og:url" content="https://guyuecanhui.github.io/index.html">
<meta property="og:site_name" content="HCigmoid">
<meta property="og:description" content="总结心得">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="HCigmoid">
<meta name="twitter:description" content="总结心得">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://guyuecanhui.github.io/">





  <title>HCigmoid</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">HCigmoid</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Watch, learn and practise</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2020/05/09/paper-2019-pku-autoint/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/05/09/paper-2019-pku-autoint/" itemprop="url">AutoInt 论文精读</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-09T23:46:32+08:00">
                2020-05-09
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文精读/" itemprop="url" rel="index">
                    <span itemprop="name">论文精读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/05/09/paper-2019-pku-autoint/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2020/05/09/paper-2019-pku-autoint/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.4k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  9
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p><strong>论文引用:</strong> Song, Weiping, et al. “Autoint: Automatic feature interaction learning via self-attentive neural networks.” <em>Proceedings of the 28th ACM International Conference on Information and Knowledge Management</em>. 2019.</p>
</blockquote>
<p>这是一篇北京大学发表在 <strong>CIKM 2019</strong> 的文章，看作者列表没有企业背景，主要还是提供一些理论思路。文章的核心也是想通过自动挖掘特征间的高阶交互关系来提升减少人工特征工程，但是与前面的 <strong>DeepFM</strong>、<strong>DCN</strong> 等能够提供显式特征交叉能力的模型最大的差别在于：本文是通过不同 field 间特征做 <strong>Self-Attention</strong> 来实现特征的交互，也因此获得了一定的特征组合的可视化能力（<em>即文章中声称提供了较好的可解释性</em>）。</p>
<h3 id="背景与动机"><a href="#背景与动机" class="headerlink" title="背景与动机"></a>背景与动机</h3><p>其实已有的深度模型的相关工作基本核心都是在做高阶的特征交叉，但是诸如 <strong>PNN</strong>、<strong>FNN</strong>、<strong>DeepCrossing</strong>、<strong>Wide&amp;Deep</strong>、<strong>DeepFM</strong> 等模型，主要是依赖前馈网络来实现高阶特征交叉，主要的问题是特征交叉过程是隐式的，很难解释是哪些特征间的组合起到了关键作用，这个问题也存在于 <strong>DCN</strong>、<strong>xDeepFM</strong> 等提供显式特征交叉能力的模型中。</p>
<p>另外一些提供显式特征交叉能力的模型和算法也存在各种各样的问题，比如基于树+embedding 的$^{[1,2,3]}$，会将训练过程分裂成几个部分；比如显式做所有特征的高阶组合的 <strong>HOFM</strong> 模型$^{[4]}$，参数量过大，高于 5 阶的组合基本不可用（<em>实际上根据张俊林的说法，高于 4 阶的特征组合就已经收益很低了，这在 <strong>DCN</strong> 的测试中也得到了一定的验证</em>）。</p>
<p>基于这个背景，文章的目标是想找到一种特征自动进行高阶交叉的方法，既能弥补 <strong>MLP</strong> 对乘性特征组合捕获能力不强的弱点，又能够较好的解释哪些特征组合比较有效。</p>
<h3 id="AutoInt-网络设计"><a href="#AutoInt-网络设计" class="headerlink" title="AutoInt 网络设计"></a>AutoInt 网络设计</h3><h4 id="模型概览"><a href="#模型概览" class="headerlink" title="模型概览"></a>模型概览</h4><p><strong>AutoInt</strong> 网络内部主要包括两块，如下图所示：</p>
<img src="/2020/05/09/paper-2019-pku-autoint/autoint.png" title="AutoInt 整体架构">
<p><strong>AutoInt</strong> 底层是 embedding 层，类似于 <strong>DeepFM</strong> 的设计，将所有的离散、连续特征都映射成一个等长的 embedding 向量，其中，离散特征是直接 lookup embedding 表，多值的离散特征使用 average pooling；连续特征则相当于乘以一个不含 bias 的 <strong>Dense</strong> 层。</p>
<p><strong>AutoInt</strong> 核心是上面的交互层，使用 <strong>Multi-head Self-Attention</strong> 来实现，并且可以叠加多层，实现特征的高阶交叉。作者认为，特征组合的关键是知道哪些特征组合在一起有强大的表征能力，这个实际上相当于在人工特征工程中进行特征选择，那么在深度网络里怎么自动去实现特征组合的选择呢？作者受到 <strong>Self-Attention</strong> 的启发，考虑让每个 field 的特征与其他 field 的特征分别做 attention，根据 attention 的权重来判断该 field 特征与其他 field 特征组合的重要性，越重要的组合给予的权重越高，最后生成加权后的 sum pooling 作为该 field 特征与所有其他 field 特征组合的结果。</p>
<h4 id="Self-Attention-层计算流程详解"><a href="#Self-Attention-层计算流程详解" class="headerlink" title="Self-Attention 层计算流程详解"></a>Self-Attention 层计算流程详解</h4><p>关于 <strong>Self-Attention</strong> 相关的理论和应用，后面还会再单独介绍，感觉这一块是后面网络发展的重点。下面仅仅结合计算过程再详细的说明一下上面的思路，使用的符号与文章略有不同。</p>
<ol>
<li>假设输入特征一共有 $m$ 个 field，每个 field 的特征记为 $\boldsymbol{x}_i$，对应的 embedding 向量记为 $\boldsymbol{e}_i$；所有 field 拼接起来的 embedding 记为 $\boldsymbol{e}$；</li>
<li>考虑第 $i$ 个 field 的特征 $\boldsymbol{x}_i$ 对应的 embedding 向量 $\boldsymbol{e}_i$，首先计算它经过单层 Self-Attention 后生成的特征组合向量 $\tilde{\boldsymbol{e}}_i$（<em>其他 field 的计算过程完全相同</em>）；</li>
<li>对于 head $h$，根据该 head 中的 query、key、value 矩阵，计算第 $i$ 个 field 特征的 query 向量和所有其他 field 特征的 key、value 向量：<script type="math/tex; mode=display">
\begin{cases}\boldsymbol{q}_i^{(h)} = \boldsymbol{W}_q^{(h)}\boldsymbol{e}_i \\\boldsymbol{k}_j^{(h)} = \boldsymbol{W}_k^{(h)}\boldsymbol{e}_j \\\boldsymbol{v}_j^{(h)} = \boldsymbol{W}_v^{(h)}\boldsymbol{e}_j\end{cases} \qquad j=1,\cdots,m</script></li>
<li>计算第 $i$ 个 field 的 query 向量与所有其他 field 特征对应的 key 向量的 attention 权重 <script type="math/tex">a_{i,j}^{(h)}</script>：<script type="math/tex; mode=display">
a_{i,j}^{(h)} = \frac{\exp(\boldsymbol{q}_i^{(h)}\cdot\boldsymbol{k}_j^{(h)})}{\sum_{l=1}^m \exp(\boldsymbol{q}_i^{(h)}\cdot \boldsymbol{k}_l^{(h)})}</script></li>
<li>计算第 $i$ 个 field 对应的所有其他 field 的加权 value 向量 $\tilde{\boldsymbol{e}}_i^{(h)}$，作为第 $h$ 个 head 中第 $i$ 个 field 特征与所有其他 field 特征交互后的组合向量：<script type="math/tex; mode=display">
\tilde{\boldsymbol{e}}_i^{(h)}=\sum_{j=1}^m a_{i,j}^{(h)} \boldsymbol{v}_j^{(h)}</script></li>
<li>将所有 head 的结果进行 concat，得到第 $i$ 个 field 特征与所有其他 field 特征交互后的组合向量：<script type="math/tex; mode=display">
\tilde{\boldsymbol{e}}_i = \tilde{\boldsymbol{e}}_i^{(1)}\oplus\tilde{\boldsymbol{e}}_i^{(2)}\oplus\cdots\oplus\tilde{\boldsymbol{e}}_i^{(k)}</script></li>
<li>将所有 field 的组合向量进行 concat，并加上输入层，得到单层 Self-Attention 的输出向量 $\tilde{\boldsymbol{e}}$：<script type="math/tex; mode=display">
\tilde{\boldsymbol{e}}' = \tilde{\boldsymbol{e}}_1 \oplus\tilde{\boldsymbol{e}}_2\oplus\cdots\oplus\tilde{\boldsymbol{e}}_m \\\tilde{\boldsymbol{e}}=\text{ReLU}(\tilde{\boldsymbol{e}}'+\boldsymbol{W}\cdot \boldsymbol{e})</script></li>
</ol>
<p><strong>说明：</strong></p>
<ul>
<li>与 google 的原始论文 $[5]$ 相比，<strong>AutoInt</strong> 中的 <strong>Self-Attention</strong> 没有进行 scale，即第 4 步求 softmax 之前没有将内积除以一个缩放系数，导致的结果是突出了高效组合的重要性。当然，在实现的时候还是可以尝试把缩放加进来；</li>
<li>文献 $[5]$ 在最后一步还会再过一个 <strong>LayerNormalization</strong>，文章里并没有加；实现的时候可以加了看看效果；</li>
<li>在实现的时候，假设 embedding 的维度为 $d$，head 的数量为 $k$，则可以设置每个 head 中 query、key、value 矩阵 $\boldsymbol{W}^{(h)}$ 的维度为 $(\frac{d}{k}, d)$，这样得到的 $\tilde{\boldsymbol{e}}_i^{(h)}$ 就是 $\frac{d}{k}$ 维，将 $k$ 个 head 的结果 concat 后，$\tilde{\boldsymbol{e}}_i$ 又变成了 $d$ 维，从而保证输入的维度与输出的维度相同；这样的话，最后一步中矩阵 $\boldsymbol{W}$ 其实就不需要了（<em>文章的实验中 $\boldsymbol{e}$ 与 $\tilde{\boldsymbol{e}}’$ 维度不同，因此需要通过 $\boldsymbol{W}$ 将 $\boldsymbol{e}$ 变成与 $\tilde{\boldsymbol{e}}’$ 相同的维度</em>）。</li>
</ul>
<h4 id="Self-Attention-交叉能力分析"><a href="#Self-Attention-交叉能力分析" class="headerlink" title="Self-Attention 交叉能力分析"></a>Self-Attention 交叉能力分析</h4><p>文章将有 $p$ 个不同 field 特征乘性组合的特征称为 $p$ 阶组合特征，记为 <script type="math/tex">g(x_{i_1},\cdots,x_{i_p})</script>，从计算过程容易看出来，<script type="math/tex">\tilde{\boldsymbol{e}}_i^{(h)}</script> 乃至 $\tilde{\boldsymbol{e}}_i$ 都是包含 $\boldsymbol{x}_i$ 与所有 <script type="math/tex">\boldsymbol{x}_j\ (j=1,\cdots,i-1,i+1,\cdots,m )</script> 交互的 2 阶组合特征：${g(x_i,x_1),g(x_i,x_2),\cdots,g(x_i,x_m)}$。因此，单层 Self-Attention 就能表征所有 field 的 2 阶组合特征。</p>
<p>到了两层时，由于第一层输出中每个 field 相当于都是包含了所有的 2 阶组合，因此它的输出就包含了 3 阶和 4 阶的组合特征，例如 $g(x_1,x_2,x_3,x_4)$ 就包含在 $\tilde{\boldsymbol{e}}_1$ 和 $\tilde{\boldsymbol{e}}_3$ 的交互中。同理，三层 <strong>Self-Attention</strong> 就包含 8 阶内的组合特征……与 <strong>DCN</strong> 中的 cross 层相比，cross 每层增加 1 阶特征组合，而 <strong>Self-Attention</strong> 每层增加 1 倍特征组合。</p>
<h4 id="应用与讨论"><a href="#应用与讨论" class="headerlink" title="应用与讨论"></a>应用与讨论</h4><p>上面已经介绍了 embedding 层和 <strong>Self-Attetion</strong> 层，其中，<strong>Self-Attention</strong> 层是可以直接堆叠的，由于有残差结构的设计（最后一步加上了输入），理论上可以堆的比较深（文章的实验也证明了这个设计是比较有效的）。它还可以作为子结构，通过串联或者并联的方式，嵌入到其他网络中去，例如：</p>
<ul>
<li><strong>串联：</strong>最上面一层的 <strong>Self-Attention</strong> 输出可以直接送到 <strong>LR</strong> 里输出预测结果，或者再接一个 <strong>MLP</strong> 再输出预测结果；</li>
<li><strong>并联：</strong>embedding 层同时作为输入，送到 <strong>MLP</strong>、<strong>FM</strong>、cross 等其他层中，最后所有层结果进行 concat，送到 <strong>LR</strong> 中输出预测结果；</li>
</ul>
<p>训练一般还是使用 logloss 作为损失函数，用 <strong>Adam</strong> 等优化算法进行优化。</p>
<p>我在我们的数据集上测试的时候，发现 <strong>Self-Attention</strong> 层数也是 3 层就够了，到了 4 层测试 <strong>AUC</strong> 反而会降低，这与文章的参数是吻合的。</p>
<p>至于文章另外一个鼓吹的亮点，即特征组合的可解释性，实际上就是画出 attention 权重的热力图，主要是用于数据分析，感觉除了汇报好看点，也没啥实际的用处。</p>
<p>最后想说的一点，文章将不同 field 的特征当成了序列来做 <strong>Self-Attention</strong>，但其实 <strong>Self-Attention</strong> 也经常会用于对序列特征做 pooling，这也会在以后一起介绍。</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] Wang, Xiang, et al. “Tem: Tree-enhanced embedding model for explainable recommendation.” <em>Proceedings of the 2018 World Wide Web Conference</em>. 2018.<br>[2] Zhao, Qian, Yue Shi, and Liangjie Hong. “Gb-cent: Gradient boosted categorical embedding and numerical trees.” <em>Proceedings of the 26th International Conference on World Wide Web</em>. 2017.<br>[3] Zhu, Jie, et al. “Deep embedding forest: Forest-based serving with deep embedding features.” <em>Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>. 2017.<br>[4] Blondel, Mathieu, et al. “Higher-order factorization machines.” <em>Advances in Neural Information Processing Systems</em>. 2016.<br>[5] Vaswani, Ashish, et al. “Attention is all you need.” <em>Advances in neural information processing systems</em>. 2017.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2020/04/30/paper-2017-noah-deepfm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/30/paper-2017-noah-deepfm/" itemprop="url">DeepFM 论文精读</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-04-30T22:30:24+08:00">
                2020-04-30
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文精读/" itemprop="url" rel="index">
                    <span itemprop="name">论文精读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/04/30/paper-2017-noah-deepfm/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2020/04/30/paper-2017-noah-deepfm/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.4k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  5
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p><strong>论文引用</strong>: Guo, Huifeng, et al. “DeepFM: a factorization-machine based neural network for CTR prediction.” <em>arXiv preprint arXiv:1703.04247</em> (2017).</p>
</blockquote>
<p><strong>DeepFM</strong> 是华为诺亚实验室受 <strong>FM</strong> 和 wide &amp; deep 模型启发，发表在 <strong>IJCAI 2017</strong> 的一个 <strong>CTR</strong> 预估模型，从国内企业的实践分享来看，其效果受到了广泛的认可。它的核心思想是将 wide &amp; deep 网络中的 wide 层用 <strong>FM</strong> 层代替，增加了特征的二阶自动交叉能力，并且在实现上天然可以将 <strong>FM</strong> 层的 embedding 与 deep 层共享。</p>
<h3 id="DeepFM-架构"><a href="#DeepFM-架构" class="headerlink" title="DeepFM 架构"></a>DeepFM 架构</h3><p>随着深度网络的兴起，<strong>DNN</strong> 尤其是 <strong>MLP</strong> 的结构往往被用作非线性的特征提取器，并且取得了比较好的效果。然而文章指出，<strong>只保留特征的高阶非线性组合并不如同时保留特征的低阶组合和高阶组合效果好</strong>。这也是文章核心的出发点之一。但是 wide &amp; deep 模型中只有特征的一阶和高阶组合，因此一些有效的的二阶/三阶组合只能靠工程师人工挖掘组合出来，放到 wide 层。这个时候 <strong>FM</strong> 模型又出场了，用它来代替 wide 层，既能保留原始特征，又能自动做原始特征的二阶组合，这样就能节省很多人工特征交叉的工作。当然对于三阶及以上特征的显式组合，还是只能靠人工做一些工作，或者用前面讲的 <strong>DCN</strong> 中的 cross 等结构去捕获。</p>
<p><strong>DeepFM</strong> 的模型架构如下图所示，首先将所有的特征转成长度相同的 embedding，然后依照 <strong>FM</strong> 模型构建 <strong>FM</strong> 层，再将所有 embedding 拼接后，送到 <strong>MLP</strong> 层，最后在顶层进行拼接后，送到 <strong>LR</strong> 层，计算二分类损失。</p>
<img src="/2020/04/30/paper-2017-noah-deepfm/deepfm_architecture.png" title="图 1. DeepFM 整体架构">
<p>从架构来看，<strong>DeepFM</strong> 没有什么创新的子结构，主要还是在当时提出了一个比较好的思路。下面再聊一聊模型中的一些细节处理。</p>
<h3 id="特征处理"><a href="#特征处理" class="headerlink" title="特征处理"></a>特征处理</h3><p>由于诺亚在应用市场推荐场景中没有使用连续特征，因此该模型也没有考虑连续特征的处理。但是实际上 <strong>FM</strong> 本身是支持连续特征的，所以如果有连续特征，应该也是需要将每一维连续特征转成一个 embedding。</p>
<p>对于多值的离散特征，这里有两种处理方案。一种是只考虑 field 之间的特征交叉，这种思路下，我们在生成多值离散特征的 embedding 时可以使用某种 pooling 策略，建议使用 sum pooling，因为这种情况下相当于是每个取值都与另外一维特征做了交叉；另一种是考虑所有特征取值的交叉，这种思路下，就需要将多值特征每个取值的 embedding 进行 concat，再送到 <strong>FM</strong> 层和 <strong>MLP</strong> 层。</p>
<h3 id="效果测试"><a href="#效果测试" class="headerlink" title="效果测试"></a>效果测试</h3><p>我测试了一下 <strong>DeepFM</strong> 每个子结构的性能（使用 pooling 策略），以只使用线性部分作为基线的话，只使用 FM 的交叉部分能够提升 $4.91\%$，只使用 <strong>MLP</strong> 部分能够提升 $9.30\%$，全部使用能够提升 $9.38\%$，从数据来看，<strong>FM</strong> 层的确能带来少量的提升。</p>
<h3 id="从-DeepFM-到-DeepFFM"><a href="#从-DeepFM-到-DeepFFM" class="headerlink" title="从 DeepFM 到 DeepFFM"></a>从 DeepFM 到 DeepFFM</h3><p>最后有一个小问题值得思考和讨论一下，<strong>DeepFM</strong> 使用 <strong>FM</strong> 层代替 wide 层，那能不能使用 <strong>FFM</strong> 来代替 wide 层呢？或者有没有什么类似的思路，让每个特征与其他 field 特征进行交叉的时候能够有不同的表征？</p>
<p>最直接的方案就是将 embedding 层进行扩展（称为 <strong>NeuralFFM</strong> $^{[1]}$），即将原来每个 field 对应一个二维的 embedding matrix，扩展为每个 field 对应一个三维的 embedding matrix，使得每个特征都对应于一个二维的 embedding matrix，在交叉时同时根据 source/target field ID 来 lookup 相应的 embedding vector，如图 2 所示。假设 field 的数量为 $m$，这种方案实际上是将 embedding 的参数量增加为原来的 $m$ 倍。这种方案貌似最早是南大在比赛中使用过，效果还不错。但是由于 embedding 层本来就已经贡献了整个模型主要的参数量，这种方案无论是在 train、store 还是 serving 都十分吃资源。</p>
<img src="/2020/04/30/paper-2017-noah-deepfm/neuralffm_architecture.png" title="图 2. NeuralFFM 整体架构">
<p>还有一种思路是使用 self-attention 的思路 $^{[2]}$，将每个 field 与其他 field 计算 attention 值，作为其他 field 对该 field 相关的权重，然后再计算加权的 pooling，作为该 field 与其他所有 field 特征的交互结果。这个方案我们在 后续介绍 <a href="https://guyuecanhui.github.io/2020/05/09/paper-2019-pku-autoint/">AutoInt</a> 时会再详细说明。</p>
<p>张俊林等人则同时采用了这两种思路，提出了 <strong>FAT-DeepFFM</strong> $^{[3]}$，即 embedding 层使用 <strong>FFM</strong> 的扩展，在交互层使用 attention 机制，如下所示。但是张俊林自己在分享中都表示这种思路尝试一下就好了 $^{[4]}$，所以这里就学习一下这种思路，不详细介绍了，大家在生产环境中还是谨慎使用。</p>
<img src="/2020/04/30/paper-2017-noah-deepfm/deepffm_architecture.png" title="图 3. FAT-DeepFFM 整体架构">
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] Yang, Yi, et al.. “Neural field-aware factorization machine.” <em><a href="https://cs.nju.edu.cn/31/60/c1654a209248/page.htm" target="_blank" rel="noopener">https://cs.nju.edu.cn/31/60/c1654a209248/page.htm</a></em>. 2017.</p>
<p>[2] Song, Weiping, et al. “Autoint: Automatic feature interaction learning via self-attentive neural networks.” <em>Proceedings of the 28th ACM International Conference on Information and Knowledge Management</em>. 2019.</p>
<p>[3] Zhang, Junlin, Tongwen Huang, and Zhiqi Zhang. “FAT-DeepFFM: Field Attentive Deep Field-aware Factorization Machine.” <em>arXiv preprint arXiv:1905.06336</em> (2019).</p>
<p>[4] 张俊林. “FFM及DeepFFM模型在推荐系统的探索.” <em><a href="https://zhuanlan.zhihu.com/p/67795161" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/67795161</a></em>. 2019.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2020/04/15/paper-2017-google-dcn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/15/paper-2017-google-dcn/" itemprop="url">Deep & Cross 论文精读</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-04-15T21:50:20+08:00">
                2020-04-15
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文精读/" itemprop="url" rel="index">
                    <span itemprop="name">论文精读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/04/15/paper-2017-google-dcn/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2020/04/15/paper-2017-google-dcn/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.2k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  8
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>论文引用: Wang, Ruoxi, et al. “Deep &amp; cross network for ad click predictions.” <em>Proceedings of the ADKDD’17</em>. 2017. 1-7.</p>
</blockquote>
<p>本文是 Stanford 和 Google 联合发表在 <strong>KDD</strong> 2017 workshop 上的一篇 <strong>CTR</strong> 预估模型，模型采用 <strong>Wide&amp;Deep</strong> 架构，最大的创新点在于将 wide 层替换成 cross 层，省去了原本大量的人工特征工程的工作，由 cross 层提供显式的高阶特征组合能力，同时保持较低的参数量和计算量。</p>
<h3 id="背景与动机"><a href="#背景与动机" class="headerlink" title="背景与动机"></a>背景与动机</h3><p>随着深度网络的兴起，各大厂纷纷尝试用深度网络来作为特征提取器，并取得了显著的效果。尤其是 Wide&amp;Deep 架构的提出，让大家意识到可以在模型中同时使用 <strong>DNN</strong> 来捕获特征的复杂映射关系，使用线性模型来记忆组合特征，但是这里的线性模型中的组合特征其实还是工程师针对具体场景人工构造的。</p>
<p>进一步，大家考虑将 wide 层用自动特征组合的网络来替换，例如用 <strong>FM</strong> 来代替 wide 层 (<strong>DeepFM</strong>)，能够提供了二阶的自动特征组合能力。本文则更进一步，设计出 cross 网络来代替 wide 层，能够提供任意高阶的特征组合能力 (与 cross 层数相同)，同时保持很低的计算和存储开销。</p>
<p>那有了 <strong>MLP</strong> 层为什么还需要 cross 层呢？我的理解是，<strong>MLP</strong> 层更擅长的是进行特征复杂的非线性变换，这些非线性变换通常是隐式的、对于乘性的特征组合捕获能力不强，而人基于对业务的深入理解能够显式构造一些十分有效的组合特征，如果让 <strong>MLP</strong> 层去学，可能需要比较大的参数规模才能学到。这也是 <strong>Wide&amp;Deep</strong> 为什么还需要保留 wide 层的原因。而 cross 层则设计为显式的进行特征组合，能够保证每一层都保留上一层的组合信息，并增加一阶组合，因此可以认为这两个结构是互补的。</p>
<p>当然，这里的 cross 层由于参数数量的限制，容量有限，我们仍然可以在 <strong>DCN</strong> 的基础上增加 wide 层来强化对部分人工特征的记忆，或者将 cross 层作为一个子网嵌入到其他排序网络中去，作为高阶特征提取器。</p>
<h3 id="DCN-网络架构"><a href="#DCN-网络架构" class="headerlink" title="DCN 网络架构"></a>DCN 网络架构</h3><p>前面提到了，<strong>DCN</strong> 的主要创新点在于设计了 cross 层来做特征的显式组合，同时只使用很少的参数。乍一看感觉有点神奇，如果要学习 $n$ 个特征的 $k$ 阶组合，按道理讲我们需要 $C_n^k$ 个参数 ($O(d^n)$)，那怎么进行参数的压缩呢？先可以回顾一下 <strong>FM</strong>，它本质上是学习了每个特征的隐向量，然后用两个特征隐向量的内积来代替这两个特征组合的系数，这样能够共享统计强度，并减少参数量。<strong>DCN</strong> 的 cross 层则更进一步，它每一层的设计如下：</p>
<script type="math/tex; mode=display">
\boldsymbol{x}_{l+1}=\boldsymbol{x}_0 \boldsymbol{x}_l^{\top}\boldsymbol{w}_l + \boldsymbol{b}_l + \boldsymbol{x}_l \qquad(1)</script><p>即第 $l+1$ 层的输入与第 $l$ 层的输入和原始的特征输入有关。再具体点来说，式 $(1)$ 右边的第一项是原始特征与 $l$ 阶特征的笛卡尔积，再与一个权重向量相乘。简单用归纳法可以看出，从表达式上来讲，$\boldsymbol{x}_0 \boldsymbol{x}_l$ 是能够包含所有 $l+1$ 阶的特征组合，这一项再乘以一个权重向量，相当于对特征组合的信息做了 weighted sum pooling，或者换句话说，$\boldsymbol{x}_0 \boldsymbol{x}_l^{\top}$ 的每一列 $i$ 共享同一个参数 $\boldsymbol{w}_l^{(i)}$；式 $(1)$ 最后再加上原始特征输入实际上是类似于残差网络的结构，主要是帮助模型训练。关于式 $(1)$ 文章还提供了一个可视化的图片方便理解，如下所示：</p>
<img src="/2020/04/15/paper-2017-google-dcn/dcn_cross.png" title="图 1. Cross 层结构设计">
<p>到这里我们可以简单的分析一下这个 cross 层有以下特点：</p>
<ol>
<li>它的显式特征组合是通过输入与每一层进行笛卡尔积来获得，但是在保存的时候，进行了 pooling，极大的降低了存储的开销；</li>
<li>它每层的权重实际上是一个 $d$ 维的向量 (而非两层全连接网络的 <script type="math/tex">n_i\times n_{i-1}</script> 的张量)，因此参数规模控制在 $O(md)$ 的级别，其中 $m$ 是 cross 网络的层数，$d$ 是初始特征维度；</li>
<li>实际计算的时候，可以根据交换律先计算 $\boldsymbol{x_0} (\boldsymbol{x}_l^{\top}\boldsymbol{w})$ 中括号内的部分，将乘法次数降到 $O(d)$ 次，从而整个 cross 网络的推理复杂度也降到了 $O(md)$。</li>
<li>cross 网络不存在非线性的变换，并且由于权重的连乘，在训练的时候存在梯度消失或者爆炸的风险。</li>
</ol>
<p>我们可以将 cross 层作为一个子结构加入到其他网络中去，例如 <strong>DCN</strong> 就可以看成是普通的 <strong>MLP</strong> + cross 的架构，其中，<strong>MLP</strong> 部分主要来做特征的非线性变换，一般就是几层全连接的隐含层，使用 <strong>relu</strong> 进行激活。整体的架构如下：</p>
<img src="/2020/04/15/paper-2017-google-dcn/dcn_architecture.png" title="图 1. DCN 整体架构">
<p>在特征处理时，连续特征做归一化，离散特征先查 embedding，拼接在一起作为原始输入 $\boldsymbol{x}_0$，并分别输入到 cross 层和 <strong>MLP</strong> 层，将两个结构的输出拼接后，经过一个 <strong>LR</strong> 输出预测结果，训练的时候使用带 <strong>L2</strong> 范数的 logloss 作为 <strong>Cost Function</strong>，用 <strong>Adam</strong> 之类的优化算法求解。</p>
<p>对于模型训练，文章还分享了一些小技巧：</p>
<ol>
<li><strong>MLP</strong> 层使用了 batch normalization，并设置梯度截断值为 100；</li>
<li>使用 early stop 来进行正则化，相对于 L2 正则和 dropout 更有效；感觉 <strong>DCN</strong> 的确比较容易过拟合，我在测试时发现，当数据量比较大，并且将模型的参数规模调整到一个合适的量级，一个 epoch 基本已经达到最优了，继续训练可能就会导致测试 <strong>AUC</strong> 下降；</li>
<li>$d$ 维类别特征的 embedding size 设置参考计算式：$6\times d^{\frac{1}{4}}$；但是感觉在我们的场景里还是太大了，个人倾向于设置成 $\log$ 的函数。在资源允许的情况下，embedding size 设置大一点对测试 <strong>AUC</strong> 是有正向帮助的，但是也增加了过拟合的风险；</li>
</ol>
<h3 id="实验与讨论"><a href="#实验与讨论" class="headerlink" title="实验与讨论"></a><strong>实验与讨论</strong></h3><p>文章主要在 <a href="https://www.kaggle.com/c/criteo-display-ad-challenge" target="_blank" rel="noopener">criteo 数据集</a>上进行了一些对比实验，除了证明 <strong>DCN</strong> 比 benchmark 都好很多以外，还重点强调了 <strong>DCN</strong> 在同等参数量下能够达到更低的误差、在同等误差的情况下能够使用更少的参数。另外，还单独测试了增加 cross 结构的确能够大幅的降低模型的误差。</p>
<p>文章比较的时候，<strong>LR</strong>、<strong>FM</strong> 等模型使用的特征与 <strong>DCN</strong> 实际上是有差别的，做了更多的特征工程。为了测试模型本身的效果，我在我们业务的数据集上也跟一些常见模型对比测试了一下，离线效果确实还不错，而且即使只用 cross 层，也能超过 <strong>FFM</strong> 的效果。</p>
<p>我也单独测试了 <strong>DCN</strong> 各个子结构的性能，经过若干贪心调优后，以 <strong>LR</strong> 作为基线 (即将 <strong>DCN</strong> 的 <strong>MLP</strong> 层和 cross 层的输入 $\boldsymbol{x_0}$ 直接送到 <strong>LR</strong> 层)，只使用 cross 层的测试 <strong>AUC</strong> 提升了 $4.5\%$，只使用 <strong>MLP</strong> 层的测试 <strong>AUC</strong> 提升了 $5.5\%$，而两者都用的测试 <strong>AUC</strong> 提升了 $6.3\%$。只使用 cross 层效果不如只使用 <strong>MLP</strong> 层的主要原因是参数数量少了很多，即使是 10 层的 cross 层参数量也就相当于一个只含有 20 个神经元的单层全连接 <strong>MLP</strong>。如果设定两者的参数量相同的情况下，在我们的数据集上，只使用 cross 层能够比只使用 <strong>MLP</strong> 层高出 $1‰$。但是 cross 层想要把参数量提上来其实很困难，在测试中，cross 层达到 20 层的时候，训练的时长比 4 层增加 $200\%$，并且 loss 在某个 batch 以后突然爆炸（不影响 <strong>AUC</strong> 评估），因此感觉 cross 层还是只能作为一个辅助的子结构使用。一个可以尝试的方法是同时使用 2 ~ 4 层的 cross 层 (5 层相对于 4 层的收益已经很少了)，在顶层进行 concat，最后送到 <strong>LR</strong> 中去。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2020/04/04/auc/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/04/auc/" itemprop="url">AUC 理解与应用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-04-04T21:54:19+08:00">
                2020-04-04
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/特征工程/" itemprop="url" rel="index">
                    <span itemprop="name">特征工程</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/04/04/auc/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2020/04/04/auc/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.7k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  10
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>AUC</strong> 是一个对分类器预测数值不敏感的指标，具有比较好的稳定性，也因此成为推荐系统中最常用的模型离线指标之一。但是就这个如此常见的指标，很多人对它也只是一知半解，知道该用它，也知道调用函数去计算它，但是对它的计算过程、它还有哪些用处，却知之甚少。这篇文章就再唠叨一下 <strong>AUC</strong> 的概念、计算过程以及它如何应用于特征选择上。</p>
<h2 id="AUC-Area-Under-the-Curve-的概念"><a href="#AUC-Area-Under-the-Curve-的概念" class="headerlink" title="AUC (Area Under the Curve) 的概念"></a>AUC (Area Under the Curve) 的概念</h2><p><strong>AUC</strong>（Area Under Curve）被定义为 <strong>ROC</strong> 曲线下与坐标轴围成的面积。<strong>AUC</strong> 主要用来评估二分类问题的准确率，即随机给定一个正样本和一个负样本，分类器预测该正样本的得分比预测该负样本的得分大的概率。</p>
<p><strong>AUC</strong> 越接近 1 表明这个分类器的性能越好，随机猜测的 <strong>AUC</strong> 接近 0.5，如果一个分类器的 <strong>AUC</strong> 低于 0.5，只需要将它的结果取反就能一下子提高模型性能。</p>
<h2 id="AUC-的计算"><a href="#AUC-的计算" class="headerlink" title="AUC 的计算"></a>AUC 的计算</h2><p>根据 <strong>AUC</strong> 的含义，给定样本的真实标签和预测得分，计算分类器的 <strong>AUC</strong> 指标，主要有三种方法：梯形法、穷举法和序数法。</p>
<h3 id="梯形法-trapezoid-method"><a href="#梯形法-trapezoid-method" class="headerlink" title="梯形法 (trapezoid method)"></a>梯形法 (trapezoid method)</h3><p>梯形法就是先根据真实标签和预测得分，画出 <strong>ROC</strong> 曲线，然后简单地将每个相邻的点以直线连接，计算连线下方的总面积。<strong>ROC</strong> 曲线的详细说明可以参考 wiki，这里给出一个简单的绘制方法：</p>
<ol>
<li>计算所有样本中正样本数 <script type="math/tex">n_{pos}</script> 和负样本数 <script type="math/tex">n_{neg}</script>，进一步计算 x 轴的步长为 <script type="math/tex">s_x=\frac{1}{n_{neg}}</script>，y 轴的步长为 <script type="math/tex">s_y=\frac{1}{n_{pos}}</script>；</li>
<li>初始化 <strong>ROC</strong> 曲线在原点 $(0,0)$；</li>
<li>将所有样本按预测得分降序排列，然后按顺序进行以下判断并绘制：<ul>
<li>如果当前样本为正样本，则 <strong>ROC</strong> 曲线沿 y 轴向上移动单位步长 $s_y$；</li>
<li>如果当前样本为负样本，则 <strong>ROC</strong> 曲线沿 x 轴向右移动单位步长 $s_x$；</li>
<li>假设有连续 $k$ 个样本预测得分相同，其中有 $k_p$ 个正样本和 $k_n$ 个负样本，则 <strong>ROC</strong> 曲线沿着向量 $(k_n\cdot s_x,k_p\cdot s_y)$ 进行移动；</li>
</ul>
</li>
</ol>
<p>有了 <strong>ROC</strong> 曲线，我们可以用梯形法计算 <strong>ROC</strong> 曲线下的面积。举个例子：假设有 6 条样本，某个分类器对每个样本的预测得分 <script type="math/tex">\hat{y}</script> 及其真实标签 <script type="math/tex">y</script> 如下表所示：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">ID</th>
<th style="text-align:center">$\hat{y}$</th>
<th style="text-align:center">$y$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">A</td>
<td style="text-align:center">0.1</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">B</td>
<td style="text-align:center">0.3</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">C</td>
<td style="text-align:center">0.5</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">D</td>
<td style="text-align:center">0.5</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">E</td>
<td style="text-align:center">0.7</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">F</td>
<td style="text-align:center">0.9</td>
<td style="text-align:center">1</td>
</tr>
</tbody>
</table>
</div>
<p>则根据上面的 <strong>ROC</strong> 画法，我们计算出步长 $s_x=s_y=\frac{1}{3}$，再通过依次观察 F $\rightarrow$ A 的真实标签，可以画出如下的红色 <strong>ROC</strong> 曲线，并计算出曲线下的面积为：$\frac{1}{3}\times \frac{1}{3}+\frac{1}{2}\times(\frac{1}{3}+\frac{2}{3})\times\frac{1}{3}+\frac{1}{3}=0.61$。</p>
<img src="/2020/04/04/auc/roc.png" title="图 1. ROC 曲线示例">
<h3 id="穷举法"><a href="#穷举法" class="headerlink" title="穷举法"></a>穷举法</h3><p>穷举法就是穷举样本中所有的正负样本对并计数，从而计算这些样本对中正样本预测得分大于负样本预测得分的比例。假设正例集合为 <script type="math/tex">N_{pos}</script>，正例数量为 <script type="math/tex">n_{pos}</script> ；负例集合为 <script type="math/tex">N_{neg}</script>，负例数量为 <script type="math/tex">n_{neg}</script>，则：</p>
<script type="math/tex; mode=display">
AUC = \frac{\sum I(\hat{y}_{pos}, \hat{y}_{neg})}{n_{pos}\cdot n_{neg}}\qquad(1)</script><p>其中，<script type="math/tex">I(.,.)</script> 是指示函数：</p>
<script type="math/tex; mode=display">
I(\hat{y}_{pos}, \hat{y}_{neg})=\begin{cases}
1, \qquad &\hat{y}_{pos} > \hat{y}_{neg} \\
0.5, \qquad &\hat{y}_{pos} = \hat{y}_{neg} \\
0, \qquad &\hat{y}_{pos} < \hat{y}_{neg}
\end{cases} \qquad(2)</script><p>例如，在上一小节中的例子中有 3 个正例 (BDF) 和 3 个负例 (ACE)，一共有 $3\times 3=9$ 种组合，每种组合的得分如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">负正样本对</th>
<th style="text-align:center">指示函数得分</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">AB</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">AD</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">AF</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">CB</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">CD</td>
<td style="text-align:center">0.5</td>
</tr>
<tr>
<td style="text-align:center">CF</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">EB</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">ED</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">EF</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">合计</td>
<td style="text-align:center">5.5</td>
</tr>
</tbody>
</table>
</div>
<p>因此，该分类器的 $AUC=\frac{5.5}{9}=0.61$，是个相当差的分类器了。</p>
<h3 id="序数法"><a href="#序数法" class="headerlink" title="序数法"></a>序数法</h3><p>穷举法比较适合小数据量情况下的计算，但是其实其中有很多比较是重复的。例如当我们按上例中 $\hat{y}$ 将样本排好序以后，对某个正样本而言，它上面的所有负样本数就是它的得分，没必要再穷举其他的样本对。因此我们考虑将样本排序后，基于样本序数来计算 <strong>AUC</strong>，这里略去推导过程，直接给出计算方法：</p>
<script type="math/tex; mode=display">
AUC=\frac{\sum_{i\in N_{pos}}r_i - \frac{n_{pos}(1+n_{pos})}{2}}{n_{pos}\cdot n_{neg}}\qquad(3)</script><p>其中，$r_i$ 就是按 $\hat{y}$ 排序后，第 $i$ 个样本的序号，如果有多个样本预测得分相同，则这些样本的序号直接求平均。例如对于上面的例子，我们可以对这些样本做如下的编号：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">ID</th>
<th style="text-align:center">$\hat{y}$</th>
<th style="text-align:center">$y$</th>
<th style="text-align:center">$r$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">A</td>
<td style="text-align:center">0.1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">B</td>
<td style="text-align:center">0.3</td>
<td style="text-align:center">1</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">C</td>
<td style="text-align:center">0.5</td>
<td style="text-align:center">0</td>
<td style="text-align:center">3.5</td>
</tr>
<tr>
<td style="text-align:center">D</td>
<td style="text-align:center">0.5</td>
<td style="text-align:center">1</td>
<td style="text-align:center">3.5</td>
</tr>
<tr>
<td style="text-align:center">E</td>
<td style="text-align:center">0.7</td>
<td style="text-align:center">0</td>
<td style="text-align:center">5</td>
</tr>
<tr>
<td style="text-align:center">F</td>
<td style="text-align:center">0.9</td>
<td style="text-align:center">1</td>
<td style="text-align:center">6</td>
</tr>
</tbody>
</table>
</div>
<p>其中，CD 的预测得分相同，因此它们的编号为 $\frac{3+4}{2}=3.5$。根据式 $(3)$ 我们可以算出所有正样本的序数和为 $2+3.5+6=11.5$，$AUC=\frac{11.5-3\times 4\div 2}{3\times 3}=0.61$。</p>
<h3 id="Group-AUC"><a href="#Group-AUC" class="headerlink" title="Group AUC"></a>Group AUC</h3><p>上面介绍了通常意义下 <strong>AUC</strong> 的计算方法，这个指标实际上是将所有的正负样本放在一起，来衡量模型整体的排序能力。但是在推荐场景下，实际上我们更关心的是<strong>对单个用户而言，推荐结果的相对顺序</strong>，至于不同用户之间是否正样本的得分一定比负样本高，其实影响并不大。</p>
<p>因此，在某些场景下 <strong>AUC</strong> 可能无法真实的度量模型的排序能力 (比如离线指标相对较高，但是线上指标相对较差)，这时可以考虑尝试使用 <strong>GAUC</strong> 来度量。</p>
<p><strong>GAUC</strong> 实际上就是按用户进行分组，计算每个用户下样本排序的 <strong>AUC</strong>，再汇总加权得分，计算公式如下：</p>
<script type="math/tex; mode=display">
GAUC=\frac{\sum_{u}w_u \cdot AUC_u}{\sum_{u}w_u}\qquad(4)</script><p>这里的用户权重 <script type="math/tex">w_u</script> 可以设置为该用户的点击数/曝光数。至于每个用户样本的 <script type="math/tex">AUC_u</script> 计算还是参考式 $(1)$ 或式 $(3)$。</p>
<h2 id="单特征-AUC-的计算"><a href="#单特征-AUC-的计算" class="headerlink" title="单特征 AUC 的计算"></a>单特征 AUC 的计算</h2><p>特征选择中一个重要的技术就是单特征 <strong>AUC</strong> 的计算，它体现了这维特征正确划分样本的能力。单特征 <strong>AUC</strong> 越高，这维特征也就越重要，尤其是在线性模型中。</p>
<h3 id="单值离散特征的-AUC-计算"><a href="#单值离散特征的-AUC-计算" class="headerlink" title="单值离散特征的 AUC 计算"></a>单值离散特征的 AUC 计算</h3><p>单值离散特征是指特征取值是离散特征，而且每个样本中该特征取值只有一个，例如用户的城市、性别等。我们基于训练数据和测试数据可以使用以下算法高效的计算该特征的 <strong>AUC</strong> (推导过程参考<a href="https://blog.csdn.net/u013019431/article/details/92851053" target="_blank" rel="noopener">这里</a>)：</p>
<ol>
<li>计算这维特征的每个特征值在训练数据中的正样本占比；</li>
<li>在测试数据中，用第 1 步计算的结果作为样本的预测值；</li>
<li>基于上一小节中的 <strong>AUC</strong> 计算方法计算理论上该特征在 <strong>LR</strong> 下的 <strong>AUC</strong>；</li>
</ol>
<p>举个例子，我们考虑性别特征的单值 <strong>AUC</strong> 计算，假设有 10 条样本 (前 6 条作为训练样本，后 4 条作为测试样本)：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">ID</th>
<th style="text-align:center">gender</th>
<th style="text-align:center">$y$</th>
<th style="text-align:center">$\hat{y}$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">A</td>
<td style="text-align:center">m</td>
<td style="text-align:center">0</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">B</td>
<td style="text-align:center">f</td>
<td style="text-align:center">1</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">C</td>
<td style="text-align:center">m</td>
<td style="text-align:center">1</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">D</td>
<td style="text-align:center">f</td>
<td style="text-align:center">0</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">E</td>
<td style="text-align:center">f</td>
<td style="text-align:center">1</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">F</td>
<td style="text-align:center">m</td>
<td style="text-align:center">0</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">G</td>
<td style="text-align:center">m</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0.33</td>
</tr>
<tr>
<td style="text-align:center">H</td>
<td style="text-align:center">f</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0.67</td>
</tr>
<tr>
<td style="text-align:center">I</td>
<td style="text-align:center">f</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0.67</td>
</tr>
<tr>
<td style="text-align:center">J</td>
<td style="text-align:center">m</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0.33</td>
</tr>
</tbody>
</table>
</div>
<p>我们先根据训练样本 A-F 计算性别为 m 的正样本比例为 $0.33$，性别为 f 的正样本比例为 $0.67$，因此我们预测样本 G-J 的得分依次为 $[0.33,0.67,0.67,0.33]$，从而根据式 $(1)$ 可以很快算出来，这维特征的 <strong>AUC</strong> 为 $(0.5+1+1)/3=0.83$。</p>
<h3 id="多值离散特征的-AUC-评估"><a href="#多值离散特征的-AUC-评估" class="headerlink" title="多值离散特征的 AUC 评估"></a>多值离散特征的 AUC 评估</h3><p>多值离散特征是指特征取值是离散特征，而且每个样本中该特征取值可能有多个，例如视频的标签、演员等。虽然单值离散特征可以高效的计算它的 <strong>AUC</strong>，遗憾的是，多值离散特征的 <strong>AUC</strong> 似乎无法进行类似的推导。因此我们目前还是通过仅使用这一维特征构建训练数据，用于训练 <strong>LR</strong> 模型，再用该 <strong>LR</strong> 模型预测测试数据的得分，用模型的 <strong>AUC</strong> 来作为该特征的 <strong>AUC</strong>。</p>
<p>实际上，单值离散特征也可以用建模型的方式来评估，我们两种方法都尝试了，结果证明两种方法得到的结果是十分接近的。</p>
<h3 id="连续特征的-AUC-评估"><a href="#连续特征的-AUC-评估" class="headerlink" title="连续特征的 AUC 评估"></a>连续特征的 AUC 评估</h3><p>连续特征就是指取值是连续值的特征，比如视频的播放次数、播放完成度等。</p>
<p>有一些特征如年龄，虽然是连续值，但是因为取值有限，既可以作为连续特征，也可以作为离散特征。但是连续特征，尤其是非均匀分布、或者偏序关系不明确的连续特征，对于线性模型是不太友好的，例如我们考虑预测用户是否播放一个恐怖电影，可能年龄大的或者年龄小的用户都不喜欢看，而比较年轻的用户最喜欢，线性模型就难以区分了。</p>
<p>因此，如果在线性模型中使用连续值特征，除了像播放完成度这类取值范围有限且偏序关系一致 (播放完成度越高，通常表明视频质量越好，用户点击的概率也越大) 的连续特征，我们最好还是按下面的算法来评估某连续特征的单特征 <strong>AUC</strong>：</p>
<ol>
<li>在训练数据中使用该连续特征训练 <strong>GBDT</strong> 模型；</li>
<li>如果第 1 步中使用多棵树，则用第 1 步训练的 <strong>GBDT</strong> 对测试数据中的该连续特征进行分桶，将分桶结果作为新的多值离散特征，并使用多值离散特征的 <strong>AUC</strong> 评估方法进行评估；</li>
<li>如果第 1 步中使用单棵树，则用第 1 步训练的 <strong>GBDT</strong> 对测试数据中的该连续特征进行分桶，将分桶结果作为新的单值离散特征，并使用单值离散特征的 <strong>AUC</strong> 计算方法进行评估；</li>
</ol>
<p>至于使用单棵树还是多棵树，最好参数与模型实际执行的特征变换保持一致。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2019/11/24/paper-2018-ali-dicm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/24/paper-2018-ali-dicm/" itemprop="url">DICM with AMS 论文精读</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-24T21:50:20+08:00">
                2019-11-24
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文精读/" itemprop="url" rel="index">
                    <span itemprop="name">论文精读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/11/24/paper-2018-ali-dicm/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/11/24/paper-2018-ali-dicm/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.1k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  7
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>论文引用：Ge, Tiezheng , et al. “Image Matters: Visually modeling user behaviors using Advanced Model Server.” (2018).</p>
</blockquote>
<p>本文是阿里发表在 <strong>CIKM 2018</strong> 上的文章，主要思路是将用户历史有过行为 (文章实际使用了点击行为) 的图片来对用户视觉兴趣进行建模，在广告 <strong>CTR</strong> 预估时就能够估计用户对广告图片的喜好，从而提升 <strong>CTR</strong> 预估的准确率。由于用户在商品页面行为历史通常较为丰富，因此训练样本中会包含大量的图片特征，这些特征使用传统的 <strong>PS</strong> 架构无法有效训练，因此文章提出了 <strong>AMS</strong> (<em>Advanced Model Server</em>) 架构，能够平衡存储和通信开销，使得天级更新模型成为可能。这篇文章主要的贡献也是在工程实现方面。</p>
<h3 id="背景和动机"><a href="#背景和动机" class="headerlink" title="背景和动机"></a>背景和动机</h3><p>广告 <strong>CTR</strong> 预估是广告系统中至关重要的环节，传统的 (非多模态) 预估模型，主要是使用一些 <strong>ID</strong> 和交叉统计之类的特征，但是由于 <strong>ID</strong> 没有语义，我们无法判断两个 <strong>ID</strong> 是不是有相关性，因此这些模型对于出现频次少或者新出现的 <strong>ID</strong> 无法充分训练，即存在冷启动的问题。</p>
<p>解决冷启动问题通常会想到引入内容特征，而在电商领域，图片就是能够描述广告/商品的最直观且最受用户关注的内容特征。用户在购买商品的时候，通常会点击、浏览商品的图片，结合商品的描述、评论等其他信息来决定是否购买，因此用户曾经点击过的图片能够在很大程度上表征用户的兴趣。而用户是否点击广告，图片、标题等信息是影响最大的因素。因此，文章就考虑使用用户点击过的图片来建立用户的兴趣模型，再与广告的图片进行匹配，从而估计用户在视觉层面是否对该广告有兴趣；将这方面的估计与传统的基于 <strong>ID</strong> 等特征的估计相结合，来提升 <strong>CTR</strong> 估计的性能。基于这个思路，文章提出了 <strong>DICM</strong> (<em>Deep Image CTR Model</em>)。 </p>
<p>使用用户图片历史来建立用户视觉偏好主要的问题就是数据传输和存储，如果使用传统的 <strong>PS</strong> 架构，图片数据是保存在 <strong>KV Store</strong> 里（也就是参数服务器），谁用谁来查一下，而图片的数量和数据量都是相对较大的，因此这种方式十分消耗资源，并且这种方式也难以针对 <strong>CTR</strong> 预估任务对预训练的图片特征进行进一步的组合和压缩，即图片数据不是目标相关的。文章针对这个问题，提出了一种扩展 <strong>PS</strong> 架构，称为 <strong>AMS</strong> 架构。下面就详细的介绍这两方面的工作。</p>
<h3 id="AMS-架构"><a href="#AMS-架构" class="headerlink" title="AMS 架构"></a>AMS 架构</h3><p>如上所述，文章在实现 <strong>DICM</strong> 模型时，实际上是基于 <strong>AMS</strong> 架构的。<strong>AMS</strong> 架构整体如图 1 右图所示：</p>
<img src="/2019/11/24/paper-2018-ali-dicm/ams-architecture.png" title="图 1. AMS 架构及基于 AMS 架构实现的 DICM 模型">
<p><strong>AMS</strong> 将节点分为 <strong>Worker</strong> 和 <strong>Server</strong> 组：</p>
<ul>
<li><strong>Server 组</strong>：保存图片原始特征数据（考虑到端到端训练和推理的时延，这里取的是预训练模型的低阶隐层输出），并且负责将图片原始特征数据映射到任务空间的高阶表达，实际上就是学一个 Tower 模型，这个 Tower 模型是所有 Server 共享的。使用这个图片 <strong>EmbedTower</strong>，可以将图片原始特征数据极大的压缩（文章使用 $4096\times 256\times 64\times 12$ 的 Tower，可以将数据量减少 340 多倍），Worker 查询的时候传输数据量就大大减少了。</li>
<li><strong>Worker 组</strong>：从 <strong>Server 组</strong>查询样本的各维特征（包括 <strong>ID</strong> embedding 和图片的高阶 embedding 等），将特征组合后进行推理；训练时还要将损失梯度传回 Server，用来更新图片 <strong>EmbedTower</strong>。</li>
</ul>
<p>这样分与传统 <strong>PS</strong> 架构最大的差别就在于，<strong>Server 组</strong>内的节点也是有通信的，也是需要更新模型的了 (更详细的比较可以参考文献 [1]，说的很清楚)。好处是，当图片的数据量非常大的时候：</p>
<ol>
<li>每个图片原始特征只保存在单个 Server 上，节约了存储；</li>
<li>每个图片的 embedding 只需要计算一次，而且可以通过预计算，缓存以后供多个 Worker 查询；</li>
<li>压缩后的图片 embedding 数据量小，减小了数据传输消耗；</li>
</ol>
<p>文章号称在他们的场景下能节省 31 倍的存储开销和 340 倍的传输开销，而推理的时延仅仅增加了 3 毫秒。不过大家在各自具体场景中可能需要权衡一下性价比。</p>
<h3 id="DICM-模型"><a href="#DICM-模型" class="headerlink" title="DICM 模型"></a>DICM 模型</h3><p>从图 1 左图来看，<strong>DICM</strong> 模型整体就是一个简单的 Embedding + MLP 架构。其中，最关键的部分实际上就是用户视觉偏好抽取的部分（后面简称为 <strong>VisualPrefExtractor</strong>），也就是图片 <strong>EmbedTower</strong> 和基于用户图片历史和当前广告图片生成兴趣特征向量的部分。</p>
<p><strong>EmbedTower</strong> 前面简单介绍过了，这里需要说明的是，文章在保存图片原始特征的时候，并不是使用原始的像素值，而是经过预训练的 <strong>VGG16</strong> 第 14 层的 <strong>FC-4096</strong> 作为原始特征（如图 2 所示）。虽然 <strong>VGG16</strong> 的训练目标是图像分类的任务，但是这种任务学到的语义特征有比较好的泛化性能，而且由于是逐层处理，取靠前的参数实际上使用的是图像的一些基础元素的特征，这些特征再进一步通过广告 <strong>CTR</strong> 预估任务进行训练，这样就能够得到有用的高阶特征。文章也尝试了使用其他层的输出作为图片的原始特征：太靠近输出会损失性能；而越靠近输入端，参数越多，并且边际效益递减，因此这也只是一种权衡。另外，淘宝主要是买商品，使用 <strong>ImageNet</strong> 的预训练模型可能比较契合，我们在视频场景下就会发现，<strong>VGG16</strong> 对于人物的识别权重很低，因此可能又不太适用。</p>
<img src="/2019/11/24/paper-2018-ali-dicm/vgg16.png" title="图 2. 使用配置 D (VGG16) 中第 1 个 FC-4096 作为图片的原始特征，该配置参考文献 [2]">
<p>而为了抽取用户的视觉偏好，我们需要从用户图片历史序列中抽取出有效的特征。在用户行为非常丰富的场景，比如淘宝，用户的兴趣是多元化的，用户是不是点击某件 T-恤的广告，主要取决他历史上对衣服款式的喜好，而受他买零食、饮料、矿泉水的影响较小，因此需要引入注意力机制来针对不同的广告从用户图片历史中抽取出不同的特征表达。</p>
<img src="/2019/11/24/paper-2018-ali-dicm/attentive-pooling.png" title="图 3. 几种 Pooling 方式的比较，文章使用 (d) 所示的 AttentivePooling">
<p>文章使用的注意力机制还是比较简单的，如图 3 右图所示，就是将广告图片特征和用户每条历史图片特征拼接后，经过一个 $64\times 16\times 1$ 的 Tower，用来计算每条历史图片的权重，然后再加权对所有历史图片特征计算 sum pooling，得到用户视觉偏好表达。这里的广告图片特征和用户历史图片特征都是经过 <strong>EmbedTower</strong> 映射后的高阶表达。为了增强记忆能力，文章还使用了 <strong>ID</strong> 行为列表来做相似的处理，将得到的 embedding 与图像偏好的 embedding 拼接，即实现了 <strong>MultiQueryAttentivePooling</strong>，两者互为补充，效果得到进一步提升。</p>
<p>这种方式很容易扩展，比如可以简单的添加 <strong>TextPrefExtractor</strong>、<strong>AudioPrefExtractor</strong> 等其他多模态的偏好模型，而且由于这些多模态数据不与其他特征进行交叉，因此训练与推理都是相对独立的。<strong>VisualPrefExtractor</strong> 也可以作为子模型嵌入到双塔结构里做召回，或者嵌入其他复杂排序模型，如 <strong>DIN</strong> 等，作为特征抽取器。</p>
<p>根据这篇文章的说明，该模型至少在当时是承接了淘宝的主流量，因此在多模态方面还是十分值得借鉴的。</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] 一图胜千言: 解读阿里的Deep Image CTR Model. <a href="https://zhuanlan.zhihu.com/p/57056588" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/57056588</a>.</p>
<p>[2] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556 (2014).</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2019/11/16/paper-2019-google-mmoe-bias/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/16/paper-2019-google-mmoe-bias/" itemprop="url">MMoE-PosBias 论文精读</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-16T22:19:16+08:00">
                2019-11-16
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文精读/" itemprop="url" rel="index">
                    <span itemprop="name">论文精读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/11/16/paper-2019-google-mmoe-bias/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/11/16/paper-2019-google-mmoe-bias/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  5
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>Zhao, Zhe, et al. “Recommending what video to watch next: a multitask ranking system.” <em>Proceedings of the 13th ACM Conference on Recommender Systems</em>. ACM, 2019. </p>
</blockquote>
<p>本文是 Youtube 发表在 <strong>RecSys</strong> <strong>2019</strong> 上的文章，主要解决的问题是提升用户的总体满意度，同时减少推荐造成的用户选择偏差对推荐系统的影响。解决这些问题主要的挑战在于：</p>
<ol>
<li><strong>视频推荐中包含多个可能互相冲突的目标，难以权衡</strong>。视频推荐的目标大体可以分为 <strong>engagement objectives</strong> (例如点击、播放等)、<strong>satistaction objective</strong> (例如点赞、收藏、不喜欢等)，这两类目标可能有冲突，例如用户点赞的视频可能是他比较喜欢的严肃的视频，但是用户真正播放的视频可能是一些娱乐性比较强的。</li>
<li><strong>推荐系统会引入一些隐式的偏差，尤其是推荐位置导致的用户选择偏差</strong>。用户往往倾向于点位置靠前的视频，而这些视频可能并不是用户真实喜欢的视频。如果推荐模型使用带偏差的用户行为日志进行训练，会进一步强化这种偏差，导致恶性循环。</li>
<li><strong>多模态特征</strong>。多模态特征包括语音、视频 、图像、文本、ID 类特征、连续型特征等。使用多模态的特征有助于信息互补，例如我们希望对低层次内容特征进行映射来跨越语义鸿沟、用于基于内容的过滤；同时将稀疏分布的 ID 类特征用于协同过滤等。</li>
<li><strong>可扩展性</strong>。模型需要考虑线下训练和线上服务的性能，因此在保证学习效果的情况下，尽可能使用简单易扩展的网络架构。</li>
</ol>
<p>为了应对这些挑战，文章提出了如下图所示的排序网络架构。该网络接收用户当前播放的视频信息和上下文信息，对数百个召回视频进行排序。这里的召回需要是从不同的角度进行召回，例如基于内容相似的召回、基于协同过滤的召回等，文章使用了 <strong>Deep Candidate Generation</strong> 模型$^{[1]}$等来生成召回。</p>
<img src="/2019/11/16/paper-2019-google-mmoe-bias/overview.png" title="MMoE with PosBias 整体架构">
<p>排序的整体架构服从 <strong>Wide &amp; Deep</strong> 架构，如上图所示。其中，左边的 <strong>wide</strong> 层是一个浅层的 <strong>tower</strong> 网络，用于学习选择偏差，这个偏差在上层会与 <strong>user engagement</strong> 的输出相加，用于抵消选择偏差；右边的 <strong>deep</strong> 层是一个 <strong>MMoE</strong> 的多目标网络（<strong>MMoE</strong> 的解读可以参考 [2]），用于从不同模态特征中学习不同的专家网络，并学习多个 <strong>Gate</strong> 来对多个目标进行预测，最后再对多个目标进行权衡，这里不同的目标使用不同的损失函数，对于目标是连续值的，使用 <strong>MSE</strong> 进行回归，对于目标是离散值的，使用 <strong>logLoss</strong> 进行分类，最终多个目标的结果使用线性加权的方式计算出最终的得分，权重目标是作者手调的。从训练和预测的工程效率角度出发，文章选择了最简单的 <strong>point-wise ranking</strong> 方案。</p>
<img src="/2019/11/16/paper-2019-google-mmoe-bias/mmoe.png" title="MMoE 架构拆解">
<p>多目标的深度网络是整体架构的主要核心，文章先将所有原始的输入压缩成了一个共享的隐含层，再基于该隐含层构建了 <strong>MMoE</strong> 的网络，基于这些网络再进一步学习多个目标。其中：</p>
<ol>
<li><p>隐含层的设置主要是为了提高训练的效率。直接用原始特征来训练 <strong>MMoE</strong> 网络可能对多模态特征的学习更有利，但是由于原始特征的维度过高，直接基于原始特征进行训练代价过高。在学习 <strong>Gate</strong> 的时候，作者也尝试过直接用原始特征作为输入，但是比用共享隐含层作为输入没有显著提升。</p>
</li>
<li><p>使用 <strong>MoE</strong> 层比使用 <strong>shared-bottom</strong> 策略更有助于学习多模态特征，文章使用了少量的 <strong>Expert</strong> 网络，这样可以在不同的 <strong>Gate</strong> 中充分共享 <strong>Expert</strong> 网络参数，并且工程上效率更高。</p>
</li>
<li><p>每个目标使用一个 <strong>Gate</strong> 来对原始特征和专家网络进行激活，每个 task 预测结果的变换函数如下：</p>
<script type="math/tex; mode=display">
\begin{cases}
y_k=h^k(f^k(x)) \\
f^k(x)=\sum_{i=1}^n g_i^k(x)\cdot f_i(x) \\
g^k(x) = \text{softmax}(W_{g^k}\cdot x)
\end{cases}</script><p>其中，<script type="math/tex">x</script> 为共享隐含层，<script type="math/tex">f_i(x)</script> 为第 $i$ 个专家网络的输出，$n$ 为专家网络的个数，<script type="math/tex">W_{g^k}</script> 为第 $k$ 个 <strong>Gate</strong> 的网络参数，<script type="math/tex">h^k(x)</script> 为第 $k$ 个目标的隐含层。</p>
</li>
</ol>
<img src="/2019/11/16/paper-2019-google-mmoe-bias/bias.png" title="PosBias 架构拆解">
<p>为了减少由于推荐产生的用户选择偏差，文章又增加了一个浅层网络，如上图所示，输入是与偏差相关的特征（简称偏差特征），主要包括物品展示的位置特征和用户的设备信息。学习的时候，为了减少过位置的过分依赖，对所有偏差特征扫行 10% 的 <strong>dropout</strong>。</p>
<p>学习选择偏差的其他策略包括：直接把偏差特征作为输入的一部分进行训练，这种方式主要用于线性网络，在深度网络里效果不好；使用 <strong>Adversarial Learning</strong>，即将位置作为一个辅助的学习目标来预测。文章的实验结果也表明还是使用浅层网络的效果最好，直接将偏差特征作为输入的效果还不如不加偏差特征。</p>
<p>以上关于模型的部分其实简洁明了，没有太多的花招。但是特征层就难以企及了，而且在工程效率上必然也是困难重重，文章中工程的部分以后在应用的时候可能还需要再细细品读。</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ol>
<li>Covington, Paul , J. Adams , and E. Sargin . “<strong>Deep Neural Networks for YouTube Recommendations.</strong>“ <em>Acm Conference on Recommender Systems</em> ACM, 2016:191-198.</li>
<li><strong>MMoE 论文精读</strong>. <a href="https://guyuecanhui.github.io/2019/11/16/paper-2018-google-mmoe/">https://guyuecanhui.github.io/2019/11/16/paper-2018-google-mmoe/</a>.</li>
<li><strong>YouTube 多目标排序系统：如何推荐接下来收看的视频</strong>. <a href="https://www.infoq.cn/article/cZNdKS5ssPiqhjCyKQZ6" target="_blank" rel="noopener">https://www.infoq.cn/article/cZNdKS5ssPiqhjCyKQZ6</a>.</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2019/11/16/paper-2018-google-mmoe/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/16/paper-2018-google-mmoe/" itemprop="url">MMoE 论文精读</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-16T09:42:59+08:00">
                2019-11-16
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文精读/" itemprop="url" rel="index">
                    <span itemprop="name">论文精读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/11/16/paper-2018-google-mmoe/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/11/16/paper-2018-google-mmoe/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  914
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  3
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>论文引用: Ma, Jiaqi , et al. “Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts.” <em>the 24th ACM SIGKDD International Conference</em> ACM, 2018.</p>
</blockquote>
<p>本文是 Google 发表在 <strong>KDD 2018</strong> 的论文，不过感觉少了一些工程的加持，内容略显单薄。文章主要提出了一种多专家子网的结构，显式的从数据中学习多个任务之间的关系，并能够通过门限网络对每个任务进行单独的优化。与传统的 <strong>share-bottom</strong> 结构相比，这种结构在任务之间关联较弱时，仍然能够取得比较好的效果。</p>
<p>近年来，在推荐领域逐渐引入多任务学习来减轻一些使用单个模型指标可能带来的负面影响。例如在视频推荐中，只考虑点击转化率时，会倾向推荐包含标题党、擦边海报的视频；只考虑完成度时，会倾向推荐时间比较短的视频等等。而这些倾向都会影响用户体验，并且可能导致业务长期目标的下降。因此，大家开始尝试引入多个相互关联但又不一致的目标来进行综合考虑建模，并且实践表示，多任务学习在推荐系统中能够提升上下文推荐的效果。</p>
<p>传统的基于神经网络的多任务学习大致分为两类，一共是底层参数共享，即共享输入到中间层的参数，上层再分别对各个任务建模；一类是参数软共享，并不显式的共享底层参数，而是通过正则等对多个任务的参数进行相互约束。目前看到的比较多的是第一种，如下图 (a) 所示。而这种方式一般都假设多个任务的数据分布和目标都是相似的，当任务间差异变大时，对某些任务的预测性能就会产生较大的影响。然而实际任务的相关性都是难以度量的，因此效果实际上无法事先评估，只能靠不断尝试。</p>
<img src="/2019/11/16/paper-2018-google-mmoe/mmoe.png" title="MMOE 架构比较">
<p>本文的作者受到 <strong>MoE</strong> 网络$^{[1]}$的启发，在多任务学习中引入 <strong>MoE</strong> 层，来显式的对多个任务的关系进行建模，或者理解成学习所有任务的不同方面；再对每个任务学习一个门限网络，这个门限网络可以理解成这个任务在各个方面的特点。整体结构如上图 (c) 所示。其中，每个共享的子网称为一个 <strong>Expert</strong>，文章中的 <strong>Expert</strong> 都使用前馈网络，它的输入是原始特征（也可以是一个共享的隐含层，直接使用原始特征效果会更好，但是维度可能过高），输出为各个 <strong>Gate</strong> 的权重分布（<strong>softmax</strong>），可以理解成是这个 <strong>Expert</strong> 对不同任务的影响程度。研究已经表明在 <strong>DNN</strong> 中，使用这种集成模型和集成子网络的方式有助于提高模型的性能。</p>
<p>文章在公开数据集和 Google 数据上进行了大量的对比实验，结果表明：</p>
<ol>
<li><strong>MMoE</strong> 在任务相关性变弱的情况下，性能影响较小，因此实用性也更强；</li>
<li><strong>MMoE</strong> 的训练误差收敛更快更稳定，即可训练性更好；这也与近年研究得出的结论一致，即 <em>Modulation and gating mechanisms can improve the trainability in training non-convex deep nurual networks</em>。</li>
</ol>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ol>
<li>Jacobs, Robert A. , et al. “<strong>Adaptive Mixtures of Local Experts.</strong>“ <em>Neural Computation</em> 3.1(1991):79-87.</li>
<li><strong>keras-mmoe</strong>: <a href="https://github.com/drawbridge/keras-mmoe" target="_blank" rel="noopener">https://github.com/drawbridge/keras-mmoe</a>.</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2019/11/09/paper-2018-ali-esmm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/09/paper-2018-ali-esmm/" itemprop="url">ESMM 论文精读</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-09T20:16:34+08:00">
                2019-11-09
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文精读/" itemprop="url" rel="index">
                    <span itemprop="name">论文精读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/11/09/paper-2018-ali-esmm/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/11/09/paper-2018-ali-esmm/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.2k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  4
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>论文引用: Ma, Xiao, et al. “Entire space multi-task model: An effective approach for estimating post-click conversion rate.” The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval. ACM, 2018.</p>
</blockquote>
<p>本文是阿里发表在 <strong>SIGIR 2018</strong> 年的短文，主要解决了精确预估 <strong>CVR</strong> 的问题。<strong>CVR</strong> 预估是最大化场景商品交易总额 (<strong>GMV</strong>=<code>流量×点击率×转化率×客单价</code>) 的重要因子，它可以用于 <strong>OCPC</strong> 模式下动态调整出价来使平台和广告主共同受益；并且从用户体验的角度来说，准确预估的 <strong>CVR</strong> 被用来平衡用户的点击偏好与购买偏好。文章认为当前的 <strong>CVR</strong> 预估主要存在两个问题：</p>
<ol>
<li><strong>Sample Selection Bias (SSB)</strong>：当前 <strong>CVR</strong> 预估是基于 <code>点击-&gt;转化</code> 数据进行训练的，而有点击的展示数据只是所有展示数据中的一小部分 (如下图所示)，这部分数据的分布与整体的分布通常并不一致。而在实际 serving 的时候，模型又是对整个空间中的所有样本进行预测，因此模型的泛化效果会受到影响。</li>
<li><strong>Data Sparsity (DS)</strong>：与前一个问题的根因相同，只使用点击数据会存在严重的数据稀疏问题。</li>
</ol>
<img src="/2019/11/09/paper-2018-ali-esmm/esmm-ssb.png" title="用户展示-点击-转化行为关系示意">
<p>业界也提出过一些解决这两个问题的方案：</p>
<ol>
<li><strong>SSB Solution</strong>：<strong>AMAN 方法</strong> 将所有展示未点击的数据也作为负样本进行训练，但是这种方法天然会导致 CVR 被低估 (因为对于一些展示未点击的物品，可能是因为用户并没有关注到，或者用户已经点击了其他的条目而遗漏，并非是真正不会产生转化的物品)；<strong>无偏估计方法</strong> 通过拒绝采样的方法来保证预估的 CVR 与真实的观察一致，但是这种方法在计算过程中会除以一个很小的数，因此可能导致数值不稳定的问题。</li>
<li><strong>DS Solution</strong>：<strong>分层建模方法</strong>使用不同的特征构建多个预估模型，然后使用 <strong>LR</strong> 等模型将这些模型的结果汇总，这种方法需要比较可靠的先验知识来构建分层模型，在数据量大的推荐场景下难以实现；<strong>过采样方法</strong>将数据量少的类别样本进行过采样，但是对采样参数十分敏感。</li>
</ol>
<p>文章在已有工作的基础上，提出使用多任务学习的框架，使用所有 <code>展示-&gt;点击-&gt;转化</code> 数据进行训练，将 <strong>CVR</strong> 预测问题转变为同时预测 <strong>CTR</strong> 和 <strong>CTCVR</strong> 的问题。由于使用所有展示样本，因此不存在 <strong>SSB</strong> 问题；在多任务学习下共享 embedding 向量，实际上是一种参数迁移学习，可以有效的解决 <strong>DS</strong> 问题。</p>
<p>具体来讲，将一个样本记为 $(\boldsymbol{x},y\rightarrow z)$，其中，$\boldsymbol{x}$ 表示样本特征，$y$ 表示是否点击，$z$ 表示是否转化。则：</p>
<script type="math/tex; mode=display">
\begin{cases}
pCTCVR = p(z=1,y=1|\boldsymbol{x}) = pCTR\times pCVR \\
pCTR = p(y=1|\boldsymbol{x})\\
pCVR = p(z=1|\boldsymbol{x},y=1)
\end{cases}</script><p>由于这三个变量的自由度为 2，因此损失函数只需要计算其中两个即可。文章将损失函数设计为 <strong>CTR</strong> 和 <strong>CTCVR</strong> 的预测损失，如下所示：</p>
<script type="math/tex; mode=display">
L(\theta_{cvr},\theta_{ctr}) = \sum_{i=1}^N l(y_i, f(\boldsymbol{x}_i;\theta_{ctr})) + \sum_{i=1}^N l(y_i\&z_i, f(\boldsymbol{x}_i;\theta_{ctr})\times f(\boldsymbol{x}_i;\theta_{cvr}))</script><p>整体网络架构如下图所示：</p>
<img src="/2019/11/09/paper-2018-ali-esmm/esmm-architect.png" title="ESMM 网络整体架构">
<p>可以看到，两个任务共享底层 embedding，同时通过顶层的 <strong>Dot</strong> 算子进行关联。文章没有将 <strong>pCVR</strong> 作为最终输出的结果，是因为 $pCVR = \frac{pCTCVR}{pCTR}$，如果将 <strong>pCVR</strong> 作为最终输出，则最后一步为除法算子，而除法具有数值不稳定性，可能会得出 $pCVR&gt;1$ 的情况，因此将 <strong>pCTCVR</strong> 作为最终输出的结果，这样能够保证 <strong>pCVR</strong> 的结果在 $[0,1]$ 范围内，避免了数值不稳定的问题。</p>
<p>文章在淘宝数据上与现有解决 <strong>SSB</strong> 和 <strong>DS</strong> 问题的几个策略进行了对比验证，发现基于 <strong>ESSM</strong> 模型的 <strong>CVR</strong> 和 <strong>CTCVR</strong> 预估任务的 <strong>AUC</strong> 是最高的。而且文章还发表了一个 mini 公开数据集，诚意满满~</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ol>
<li><strong>XDL ESSM</strong>: <a href="https://github.com/alibaba/x-deeplearning/tree/master/xdl-algorithm-solution/ESMM" target="_blank" rel="noopener">https://github.com/alibaba/x-deeplearning/tree/master/xdl-algorithm-solution/ESMM</a></li>
<li><strong>完整空间多任务模型：CVR预估的有效方法</strong>: <a href="http://xudongyang.coding.me/esmm/" target="_blank" rel="noopener">http://xudongyang.coding.me/esmm/</a></li>
<li><strong>构建分布式Tensorflow模型系列之CVR预估案例ESMM模型</strong>: <a href="http://xudongyang.coding.me/esmm-1/" target="_blank" rel="noopener">http://xudongyang.coding.me/esmm-1/</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2019/08/28/jupyter-config/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/28/jupyter-config/" itemprop="url">效率提升 10 倍的各种配置</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-28T22:36:04+08:00">
                2019-08-28
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/安装部署/" itemprop="url" rel="index">
                    <span itemprop="name">安装部署</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/08/28/jupyter-config/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/08/28/jupyter-config/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  592
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  3
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>由于工作经常会更换机器、更换环境，有时候一个机器用惯了，换了一台机器都不记得自己之前是怎么配置的了。为了防止老年痴呆阻止我配置好看的工作环境，我决定把所有喜欢的配置都记录在这里，可能有点乱。</p>
<h3 id="Jupyter-Notebook"><a href="#Jupyter-Notebook" class="headerlink" title="Jupyter Notebook"></a>Jupyter Notebook</h3><p>这个应该很常用了，大家第一件事应该就是设置主题吧，我试过各种主题，都无法满足我的诉求，所以就自己配置了一下 <code>~/.jupyter/custom/custom.css</code>，感觉下面这个配置简单又好看~</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-class">.introspection</span>, <span class="selector-class">.input_prompt</span>, <span class="selector-class">.output_prompt</span>, <span class="selector-class">.output</span>, <span class="selector-class">.CodeMirror</span> <span class="selector-tag">pre</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">"Microsoft YaHei Mono"</span>, Consolas, <span class="string">"Liberation Mono"</span>, Menlo, Courier, monospace;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">15px</span>;</span><br><span class="line">    <span class="attribute">line-height</span>: <span class="number">22px</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">div</span><span class="selector-class">.output_area</span> <span class="selector-tag">pre</span> &#123;</span><br><span class="line"> <span class="attribute">font-family</span>: <span class="string">"Microsoft YaHei Mono"</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">div</span><span class="selector-class">.text_cell</span>,</span><br><span class="line"><span class="selector-tag">div</span><span class="selector-class">.text_cell_render</span> <span class="selector-tag">pre</span>,</span><br><span class="line"><span class="selector-tag">div</span><span class="selector-class">.text_cell_render</span> &#123;</span><br><span class="line"> <span class="attribute">font-family</span>: sans-serif;</span><br><span class="line"> <span class="attribute">font-size</span>: <span class="number">11pt</span>;</span><br><span class="line"> <span class="attribute">line-height</span>: <span class="number">20pt</span>;</span><br><span class="line"> <span class="attribute">color</span>: <span class="number">#353535</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">div</span><span class="selector-class">.rendered_html</span> <span class="selector-tag">code</span> &#123;</span><br><span class="line"> <span class="attribute">font-family</span>: <span class="string">"Microsoft YaHei Mono"</span>;</span><br><span class="line"> <span class="attribute">font-size</span>: <span class="number">11pt</span>;</span><br><span class="line"> <span class="attribute">padding-top</span>: <span class="number">3px</span>;</span><br><span class="line"> <span class="attribute">padding-left</span>: <span class="number">6px</span>;</span><br><span class="line"> <span class="attribute">padding-right</span>: <span class="number">6px</span>;</span><br><span class="line"> <span class="attribute">color</span>: <span class="number">#a3be8c</span>;</span><br><span class="line"> <span class="attribute">background</span>: <span class="number">#efefef</span>;</span><br><span class="line"> <span class="attribute">background-color</span>: <span class="number">#efefef</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.rendered_html</span> <span class="selector-tag">thead</span> &#123;</span><br><span class="line"> <span class="attribute">font-family</span>: <span class="string">"Microsoft YaHei Mono"</span>;</span><br><span class="line"> <span class="attribute">font-size</span>: <span class="number">10.5pt</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.rendered_html</span> <span class="selector-tag">td</span> &#123;</span><br><span class="line"> <span class="attribute">font-family</span>: <span class="string">"Microsoft YaHei Mono"</span>;</span><br><span class="line"> <span class="attribute">font-size</span>: <span class="number">10pt</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.rendered_html</span> <span class="selector-tag">h1</span>,</span><br><span class="line"><span class="selector-class">.text_cell_render</span> <span class="selector-tag">h1</span> &#123;</span><br><span class="line"> <span class="attribute">color</span>: <span class="number">#126dce</span> <span class="meta">!important</span>;</span><br><span class="line"> <span class="attribute">font-size</span>: <span class="number">160%</span>;</span><br><span class="line"> <span class="attribute">text-align</span>: left;</span><br><span class="line"> <span class="attribute">font-style</span>: normal;</span><br><span class="line"> <span class="attribute">font-weight</span>: bold;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.rendered_html</span> <span class="selector-tag">h2</span>,</span><br><span class="line"><span class="selector-class">.text_cell_render</span> <span class="selector-tag">h2</span> &#123;</span><br><span class="line"> <span class="attribute">color</span>: <span class="number">#126dce</span> <span class="meta">!important</span>;</span><br><span class="line"> <span class="attribute">font-size</span>: <span class="number">140%</span>;</span><br><span class="line"> <span class="attribute">font-style</span>: normal;</span><br><span class="line"> <span class="attribute">font-weight</span>: bold;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.rendered_html</span> <span class="selector-tag">h3</span>,</span><br><span class="line"><span class="selector-class">.text_cell_render</span> <span class="selector-tag">h3</span> &#123;</span><br><span class="line"> <span class="attribute">color</span>: <span class="number">#126dce</span> <span class="meta">!important</span>;</span><br><span class="line"> <span class="attribute">font-size</span>: <span class="number">120%</span>;</span><br><span class="line"> <span class="attribute">font-style</span>: normal;</span><br><span class="line"> <span class="attribute">font-weight</span>: bold;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-class">.CodeMirror-linenumber</span> &#123;</span><br><span class="line"> <span class="attribute">font-family</span>: <span class="string">"Microsoft YaHei Mono"</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.cm-s-ipython</span><span class="selector-class">.CodeMirror</span> &#123;<span class="attribute">background</span>: <span class="number">#2b303b</span>; <span class="attribute">color</span>: <span class="number">#dfe1e8</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">div</span><span class="selector-class">.CodeMirror-selected</span> &#123;<span class="attribute">background</span>: <span class="number">#343d46</span> <span class="meta">!important</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-class">.CodeMirror-gutters</span> &#123;<span class="attribute">background</span>: <span class="number">#2b303b</span>; <span class="attribute">border-right</span>: <span class="number">0px</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-class">.CodeMirror-linenumber</span> &#123;<span class="attribute">color</span>: <span class="number">#65737e</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-class">.CodeMirror-cursor</span> &#123;<span class="attribute">border-left</span>: <span class="number">1px</span> solid <span class="number">#a7adba</span> <span class="meta">!important</span>;&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-comment</span> &#123;<span class="attribute">color</span>: <span class="number">#A3BE72</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-atom</span> &#123;<span class="attribute">color</span>: <span class="number">#b48ead</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-number</span> &#123;<span class="attribute">color</span>: <span class="number">#b48ead</span>;&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-property</span>, <span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-attribute</span> &#123;<span class="attribute">color</span>: <span class="number">#c0c5ce</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-keyword</span> &#123;<span class="attribute">color</span>: <span class="number">#DDD7A3</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-string</span> &#123;<span class="attribute">color</span>: <span class="number">#94C273</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-operator</span> &#123;<span class="attribute">color</span>: <span class="number">#ab7967</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-builtin</span> &#123;<span class="attribute">color</span>: <span class="number">#EA8080</span>;&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-variable</span> &#123;<span class="attribute">color</span>: <span class="number">#c0c5ce</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-variable-2</span> &#123;<span class="attribute">color</span>: <span class="number">#8fa1b3</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-def</span> &#123;<span class="attribute">color</span>: <span class="number">#61AFEF</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-error</span> &#123;<span class="attribute">background</span>: <span class="number">#bf616a</span>; <span class="attribute">color</span>: <span class="number">#a7adba</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-bracket</span> &#123;<span class="attribute">color</span>: <span class="number">#c0c5ce</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-tag</span> &#123;<span class="attribute">color</span>: <span class="number">#bf616a</span>;&#125;</span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-tag">span</span><span class="selector-class">.cm-link</span> &#123;<span class="attribute">color</span>: <span class="number">#b48ead</span>;&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.cm-s-ipython</span> <span class="selector-class">.CodeMirror-matchingbracket</span> &#123; <span class="attribute">text-decoration</span>: underline; <span class="attribute">color</span>: <span class="number">#dfe1e8</span> <span class="meta">!important</span>;&#125;</span><br></pre></td></tr></table></figure>
<p>另外，在 linux 上安装 jupyter notebook 的话，第一次启动时会报 `` 的错，需要修改以下文件：</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2019/08/18/conjugate-priors-video-quality/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/18/conjugate-priors-video-quality/" itemprop="url">例解共轭分布之视频质量评估</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-18T10:47:06+08:00">
                2019-08-18
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/数学/" itemprop="url" rel="index">
                    <span itemprop="name">数学</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/08/18/conjugate-priors-video-quality/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/08/18/conjugate-priors-video-quality/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  9
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在推荐领域阅读文献的时候，我们常常会遇到共轭分布、共轭先验 (<strong>conjugate prior</strong>) 之类的概念。由于共轭这个翻译实在不太直观，因此这些概念也很难理解，我想结合两个视频推荐中的例子来尝试说明这些概念。今天先介绍视频质量评估的例子。</p>
<h3 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h3><p>如何评估一个视频的质量是视频推荐中非常重要但是又很让人头疼的事情。尤其是在短视频场景下，每天新增大量的短视频，我们需要迅速判断一个新短视频的质量：如果质量很好，我们可以将它向更多的人推荐；如果质量不好，我们可能不再主动推荐该视频。这里判断的时效很重要，因为如果没有及时发现一个垃圾视频，它可能就会通过推荐系统祸害很多的用户 =.=!</p>
<p>由于视频非常多，我们无法人工对每个视频进行准确的质量评估，而且用户在短视频的观看行为呈现出更加多元的兴趣，因此小编们也无法代表所有用户的口味。因此，要评估一个短视频好不好，还是得看它在用户中的表现 (可以用完播率、点赞率、分享率等统计指标来度量)。</p>
<p>假设我们只考虑用完播率 $r$ 来度量一个视频的质量 (后面交替使用完播率和视频质量)，它表示一个视频被播放完 (或者播放超过一定比例) 的数量 $m$ 与它展现给用户的次数 $n$ 的比例：</p>
<script type="math/tex; mode=display">
r=\frac{m}{n} \qquad(1)</script><p>这个指标的优点是计算非常方便，而且能够在一定程度上表达业务诉求。但是实际应用的时候，往往会因为视频的展示次数过少而对某个视频进行错误的评价。例如，视频 $v_1$ 只展示了 $10$ 次，有 $5$ 次完播；视频 $v_2$ 展示了 $10000$ 次，有 $4900$ 次完播，相较而言，$v_1$ 和 $v_2$ 哪个质量更好呢？</p>
<p>很难说！我们只是比较确信 $v_2$ 的完播率稳定在了 $49\%$ 左右，而对于 $v_1$ 的评估就非常不确定了：有可能它再展示 $10$ 次以后，一次都没人看；也有可能它再展示 $10$ 次每次都完播了。这两种情况下我们对视频质量的评估将发生非常大的变化。</p>
<h3 id="模型假设-先验分布"><a href="#模型假设-先验分布" class="headerlink" title="模型假设 (先验分布)"></a>模型假设 (先验分布)</h3><p>从根本上来讲，我们简单的用式 $(1)$ 来计算完播率忽略了事件过少时候的不确定性。为了引入这种不确定性，我们可以用一个概率分布来表示视频的质量 (这就是贝叶斯学派的观点，$r$ 并不是一个固定的值，而是满足一定的概率分布)，也就是说，给定 $m$ 和 $n$，我们要来估计这个视频的质量呈现一个什么样的分布。这个分布的形状是我们在看到数据之前<strong>根据经验</strong>去假定的，因此我们也叫它<strong>先验分布</strong>。</p>
<p>我们的直观想法是，如果一个视频的完播率为 $r=\frac{m}{n}$，那么它质量的真实分布 $\theta$ 中，概率最大的点也应该是 $\frac{m}{n}$，并且与 $\frac{m}{n}$ 相差越多概率也越小。</p>
<p>根据这个想法，我们可以用 <strong>Beta</strong> 分布来进行建模，将 $\alpha=m$ 和 $\beta=n-m$ 作为 <strong>Beta</strong> 分布的参数 (<strong>Beta</strong> 分布的详细介绍可以参考 Wiki)。在我们的例子中，随着 $n$ 的增加，<strong>Beta</strong> 分布的概率密度越集中于 $r=\frac{m}{n}$。下图表示随着 $m$ 和 $n$ 变化，保持 $r=0.5$ 不变的情况下，<strong>Beta</strong> 分布的概率密度函数：</p>
<img src="/2019/08/18/conjugate-priors-video-quality/beta-pdf.png" title="图 1. 不同参数下 Beta 分布的形状">
<p>可以看到，当 $n$ 很小的时候，视频的质量是高度不确定的；而当 $n$ 很大的时候，视频的质量已经集中分布于 $r=\frac{m}{n}$ 附近了。因此，我们选的这个先验分布是能够满足我们的直观想法和假设要求的。这样，我们用式 $(2)$ 来代替式 $(1)$ 对视频质量进行初步的评估：</p>
<script type="math/tex; mode=display">
\begin{align}
p(\theta;\alpha,\beta)=Beta(\theta;\alpha,\beta)
&=\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}\\
&=\frac{1}{B(\alpha,\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}
\end{align} \qquad(2)</script><p>其中，$\Gamma(n)=(n-1)!$ 表示伽玛函数 (这个场景下参数都为整数)；$B(\alpha,\beta)$ 可以看成是归一化项，使得所有概率累加和为 $1$。</p>
<h3 id="更新模型-后验分布"><a href="#更新模型-后验分布" class="headerlink" title="更新模型 (后验分布)"></a>更新模型 (后验分布)</h3><p>问题才解决了一半，由于视频在不断的推荐给用户，我们的统计数据也在发生变化。因此另外一个至关重要的问题是，我们怎么根据新增的数据来更新我们对视频质量的评估。</p>
<p>例如，对于某个视频 $v$，假设我们已经收集到一些反馈数据，并统计出 $\alpha=m$，$\beta=n-m$，我们根据式 $(2)$ 对视频质量分布 $\theta$ 有了一个初步的估计。现在我们又将这个视频推荐给其他用户，并想看看放量以后，视频质量评估是否准确。假设这个视频又展示了 $b$ 次，完播了 $a$ 次，则我们根据先验假设，视频的质量应该是围绕 $r’=\frac{m+a}{n+b}$ 的钟形分布，并且比之前的分布更陡峭一些。为了实现这个过程，我们需要对模型进行更新。</p>
<p>由于用户的反馈只包含完播和未完播两类，因此很容易想到用二项分布的似然估计来估计这 $b$ 次展示中有 $a$ 次会完播的概率：</p>
<script type="math/tex; mode=display">
p(x=a|\theta)=C_b^a\theta^{a}(1-\theta)^{(b-a)} \qquad(3)</script><p>由于式 $(3)$ 中的 $\theta$ 实际上是满足式 $(2)$ 中的分布 (<em>注意，这里 $\theta$ 虽然仍然是一个分布，但是我们在这一步假设它是已知的</em>)，代入后可以算出 $a$ 次完播的概率为 $\theta$ 取所有可能值时式 $(3)$ 的积分：</p>
<script type="math/tex; mode=display">
p(x=a)=\int_0^1 p(x=a;\theta)p(\theta)d\theta \qquad(4)</script><p>这里我们要用最基础的贝叶斯公式，来基于初始的视频质量评估和增量收集来的统计数据，去修正我们在式 $(2)$ 中做出的视频质量评估，得到一个更加可靠的估计。贝叶斯公式如下：</p>
<script type="math/tex; mode=display">
p(\theta;X)=\frac{p(X;\theta)p(\theta)}{p(X)} \qquad(5)</script><p>其中，$p(\theta)$ 是我们对这个视频质量的初始评估，即先验分布，用式 $(2)$ 来计算；$p(X;\theta)$ 表示我们基于初始的评估结果，进一步估计事件 $X$ 发生的概率，即似然估计，用式 $(3)$ 来计算；$p(X)$ 表示 $\theta$ 取不同值时事件 $X$ 发生的概率之和，主要是用于做归一化，用式 $(4)$ 来计算；$p(\theta;X)$ 则表示基于先验分布和似然估计，得到的后验分布。</p>
<p>全部代入后，我们可以得到下面的简单推导：</p>
<script type="math/tex; mode=display">
\begin{align}
p(\theta;x=a)
&=\frac{p(x=a;\theta)p(\theta)}{\int_0^1 p(x=a;\theta)p(\theta)d(\theta)}\\
&=\frac{C_b^a\theta^{a}(1-\theta)^{(b-a)} \frac{1}{B(\alpha,\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}}{\int_0^1 C_b^a\theta^{a}(1-\theta)^{(b-a)}\frac{1}{B(\alpha,\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}d\theta}\\
&=\frac{\theta^{\alpha+a-1}(1-\theta)^{\beta+b-a-1}}{\int_0^1\theta^{\alpha+a-1}(1-\theta)^{\beta+b-a-1}d\theta}\\
&=\frac{1}{B(\alpha+a,\beta+b-a)}\theta^{\alpha+a-1}(1-\theta)^{\beta+b-a-1}\\
&=Beta(\theta;\alpha+a,\beta+b-a)
\end{align} \qquad(6)</script><p>也就是说，经过了这一轮的推荐以后，我们对这个视频的质量评估仅仅使模型的参数发了变化，而模型的形式不变，仍然为 <strong>Beta</strong> 分布！至此，我们终于触及本文的核心概念：共轭性。</p>
<blockquote>
<p> <strong>模型的先验分布与后验分布具有相同的函数形式，这个性质就叫做共轭性。</strong></p>
</blockquote>
<h3 id="共轭性"><a href="#共轭性" class="headerlink" title="共轭性"></a>共轭性</h3><p>共轭性给我们带来了什么样的好处呢？比较式 $(6)$ 和式 $(2)$，我们发现，在观察到 $b$ 次推荐中有 $a$ 次完播事件后，我们可以简单的将模型从 $Beta(\theta;\alpha,\beta)$ 更新为 $Beta(\theta;\alpha+a,\beta+b-a)$，即我们只需要更新如下模型参数：</p>
<script type="math/tex; mode=display">
\begin{cases}\begin{align}
\alpha&=\alpha+a \\
\beta&=\beta+b-a
\end{align}\end{cases}</script><p>它的最大意义在于简化了模型更新的过程，使得模型更新的实时性得到了保证。</p>
<p>一开始，我们基于先验知识对视频质量进行建模，但是由于数据量较少，我们对视频质量的估计置信度较低；随着用户反馈的数据越来越多，我们可以直接基于这些新增的数据去快速更新模型的参数；随着参数数值的增大，我们对视频质量的估计置信度越来越高，直到我们已经有充足的把握认定这个视频是不是高质量视频。</p>
<p>这里的置信度还体现在，当数据量较少的时候，少量的观测结果就会导致我们对视频质量评估发生巨大的变化；而当数据量充足的时候，即使再收集到很多数据，也很难改变我们的评估。</p>
<h3 id="Take-aways"><a href="#Take-aways" class="headerlink" title="Take-aways"></a>Take-aways</h3><p>至此，我们用视频质量评估的例子说明了共轭性和共轭分布是什么含义。一些关键点总结如下：</p>
<ol>
<li>共轭性是指模型的先验分布和后验分布有相同的形式，满足共轭性的分布称为共轭分布。例如：<strong>Beta</strong> 分布与二项分布是共轭分布，且 <strong>Beta</strong> 分布是 $\theta$ 的共轭先验；</li>
<li>共轭性极大的方便了我们基于增量观测的数据对模型进行更新；</li>
<li>在推导共轭性的时候，我们使用了贝叶斯公式，总结起来就是：后验分布=先验分布*似然函数/归一化因子；</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">古月残辉</p>
              <p class="site-description motion-element" itemprop="description">总结心得</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">27</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">62</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="mailto:guyuecanhui@icloud.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 &mdash; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">古月残辉</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">43.5k</span>
  
</div>









<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: '6du4Ppc2TvUuhcccRHSDNH2v-gzGzoHsz',
        appKey: 'zOKNml4W1Bq3OTzEuLt5hUjI',
        placeholder: '感谢阅读！欢迎评论！',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
