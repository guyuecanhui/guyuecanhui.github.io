<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">





  <link rel="alternate" href="/atom.xml" title="HCigmoid" type="application/atom+xml">






<meta name="description" content="总结心得">
<meta name="keywords" content="feature, model, algorithm">
<meta property="og:type" content="website">
<meta property="og:title" content="HCigmoid">
<meta property="og:url" content="https://guyuecanhui.github.io/index.html">
<meta property="og:site_name" content="HCigmoid">
<meta property="og:description" content="总结心得">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="HCigmoid">
<meta name="twitter:description" content="总结心得">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://guyuecanhui.github.io/">





  <title>HCigmoid</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">HCigmoid</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Watch, learn and practise</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2020/06/02/tversky-contrast-model/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/06/02/tversky-contrast-model/" itemprop="url">Tversky 对比模型及其在推荐系统中的应用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-06-02T23:18:08+08:00">
                2020-06-02
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/" itemprop="url" rel="index">
                    <span itemprop="name">推荐系统</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/06/02/tversky-contrast-model/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2020/06/02/tversky-contrast-model/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.8k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  10
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>物品相似度评估在推荐中当属核心问题之一，尤其是当用户有一些明确的喜好、或者当前有一个明确的消费目标的时候，推荐与用户搜索内容/当前浏览内容相似的内容，能够极大的提升用户体验。例如，“猜你喜欢”、“再来一条”、“相关推荐” 等场景，就是围绕用户的这类诉求设计的，它属于 ”探索与利用“ 中的 ”利用“。</p>
<p>相似度评估已经是一个研究十分深入的领域，尤其是在心理学领域。我们往往说不清楚到底什么样的物品是相似的，或者说为什么两个物品不相似。出现这个问题，可能是因为在不同的情境下，我们不自觉的有不同的判断标准，使用了不同的特征，或者对不同的特征有不同的权重等等。这也导致了我们很难客观度量模型相似度评估的准不准，在很多业务场景下引发一些 badcase。</p>
<p>本文先简单的介绍一下推荐系统中的相似模型，再重点介绍一个心理学研究上的经典相似模型：<strong>Tversky</strong> <strong>对比模型</strong>。</p>
<h2 id="推荐系统中的相似模型"><a href="#推荐系统中的相似模型" class="headerlink" title="推荐系统中的相似模型"></a>推荐系统中的相似模型</h2><p>目前业界常用的相似度评估的模型一般分为两类：基于内容相似和基于协同相似。</p>
<p>基于协同相似有经典的算法，比如 <strong>itemCF</strong>、<strong>ALS</strong>、<strong>SimRank++</strong> 等；也有深度的模型，比如 <strong>TowerModel</strong>、<strong>GCN</strong> 等，先生成物品的 embedding，然后基于距离度量函数（主要是 cosine 距离）来评估物品间相似度。虽然这里面有一些算法也能够结合物品的内容信息，但是它们的主要问题还是：不可解释、受物品热度影响大、冷启动效果不好。</p>
<p>而基于内容的相似模型（比如标签相似）则有比较好的解释性，而且只要标签的质量好，完全可以应对新内容的启动问题。当然，基于内容的相似也可以结合用户的协同信息进行调优，比如基于群体统计来学习不同标签的权重等。因此实际使用中，基于内容的相似模型还是不可或缺的，通常作为补充的召回，或者在特定场景下使用（例如物品冷启动）。</p>
<p>基于内容的相似通常使用内容特征（这里称为标签）的匹配来计算，比如基于标签集合的 <strong>Jaccard</strong> 加权相似度、基于词袋向量/加权向量的余弦/欧氏距离等，这些基于距离度量函数的评估方法（包括上面提到的基于协同的模型），隐式的假设了我们对物品的相似度评估是对称的，即物品 $a$ 与物品 $b$ 的相似度满足：$s(a,b)=s(b,a)$，这个假设是否满足，在心理学上也是过讨论的，下面再来看一个心理学上的经典理论。</p>
<h2 id="相似度评估的心理学研究"><a href="#相似度评估的心理学研究" class="headerlink" title="相似度评估的心理学研究"></a>相似度评估的心理学研究</h2><p>心理学家在研究是什么影响了人们对相似度的评估时，一般首先是会设计一些强迫选择（forced choice）的实验。实验常见的设计比如给用户两个物品，让用户回答它们是否相似；或者给用户一个目标物品和两个备选物品，让用户选择哪个与目标更相似。其中，后面一种方案评估的是人们相对相似的评价，可以避免每个人内在的偏好，因此得到的数据更客观和一致，预测能力也更强。例如文献 $[1]$ 就设计了相对相似实验，用来建立用户在线购买时装场景下的相似评估模型。</p>
<p>在相似评估建模方面，除了对称相似模型，还有非对称相似模型。Tversky 等人在上世纪 70 年代，针对人如何评估物品间的相似度进行研究，提出了<strong>对比模型</strong>（<strong>Tversky Contrast Model</strong> $^{[2] }$），它与我们当前流行使用的基于距离度量函数的方案相比最大的差别表现在，<strong>对比模型</strong>中物品间的相似度是非对称的。</p>
<p>为什么说我们的相似度评估是非对称的呢？文献 $[2]$ 中给出一些例子，挺有意思的（怕翻译了失去原来的意味，所以引的原文）：</p>
<ol>
<li>We say “the portrait resembles the person” rather than “the person resembles the portrait”.</li>
<li>We say “the son resembles the father” rather than “the father resembles the son”.</li>
<li>We say “an ellipse is like a circle”, not “a circle is like an ellipse”.</li>
<li>We say “Turks fight like tigers” and not “tigers fight like Turks”.</li>
<li>The poet writes “my love is as deep as the ocean”, not “the ocean is as deep as my love”.</li>
</ol>
<p>可以看到，尤其是当物品间存在一些类比、或者不那么直接的联系的时候，我们的相似评估呈现很明显的非对称性。这可能是因为我们在评估这些相似的时候，关注了不同的特征、使用了不同的权重。Tversky 基于这些观察，提出了经典的<strong>对比模型</strong>。</p>
<h3 id="Tversky-对比模型"><a href="#Tversky-对比模型" class="headerlink" title="Tversky 对比模型"></a>Tversky <strong>对比模型</strong></h3><p><strong>Tversky</strong> <strong>对比模型</strong>的核心思想是将人们评估相似度的过程抽象成一个特征比较的过程，而且比较不仅仅关注相同的特征，还关注不同的特征。其中，每个特征的权重可能不同，并且双方共有的特征与单方独有的特征权重也不相同。它基于如下假设：</p>
<ol>
<li><strong>Matching</strong>：对于 $a$ 和 $b$，它们的相似度是它们特征集合关系的函数：$s(a,b)=g(A\cap B,A-B,B-A)$；</li>
<li><strong>Monotonicity</strong>：当 $A\cap B \supset A\cap C,\ A-B \subset A- C, \ B-A\subset C-A$ 时，$s(a,b)\ge s(a,c)$；</li>
<li><strong>Independence</strong>：每个特征对相似度的影响是独立的；</li>
<li><strong>Solvability</strong>：基于现有的特征集合能够将不相似的物品区分开来；</li>
<li><strong>Invariance</strong>：Invariance ensures that the equivalence of intervals is preserved across factors.</li>
</ol>
<p>其中，满足条件 1, 2 的 $g$  被称为一个匹配函数（<strong>MatchingFunction</strong>），它衡量两个目标根据特征的匹配程度。Tversky 在文献 $[1]$ 中证明了，当满足以上 5 条假设的时候，一定存在一个相似度度量 $S$ 和一个非负的权重函数 $f$ 使下式成立：</p>
<script type="math/tex; mode=display">
\begin{align}&S(a,b)\ge S(c,d), &  \text{iff}\ \ s(a,b)\ge s(c,d)\\&S(a,b)=\theta f(A\cap B)-\alpha f(A- B) - \beta f(B-A), &\theta,\alpha,\beta\ge 0 \qquad (1)\end{align}</script><p>注意，这里 $s(a,b)$ 表示 $a,b$ 的实际相似度，而 $S(a,b)$ 表示我们建模后，对 $a,b$ 相似度的度量。</p>
<p>我们把式 $(1)$ 称为 <strong>Tversky</strong> <strong>对比模型</strong>，或简称<strong>对比模型</strong>。它最大的特点是将特征匹配拆分成 $A\cup B$、$A-B$、$B-A$ 三个部分，并分别赋予权重，从而当 $\alpha \not = \beta$ 时，$S(a,b)\not =S(b,a)$，即物品间相似是不对称的。另外，可以通过权重函数 $f()$ 函数来对每个特征赋予不同的重要性，这也满足我们在判断相似时更关注一些重要的特征是否匹配的现象。</p>
<p>作者还指出，<strong>对比模型</strong>可能是匹配函数最简单的形式。当然还可以考虑匹配函数的其他形式，例如下面的 <strong>RatioModel</strong>：</p>
<script type="math/tex; mode=display">
S(a,b)=\frac{f(A\cap B)}{f(A\cap B)+\alpha f(A-B) + \beta f(B-A)}, \quad\alpha,\beta\ge 0 \qquad(2)</script><p>由于式 $(2)$ 中每一项都为正，因此 $S(a,b) $ 取值范围为 $[0,1]$，并且：</p>
<ul>
<li>当 $\alpha=\beta=1$ 时，<strong>RatioModel</strong> 退化成 $\frac{f(A\cap B)}{f(A\cup B)}$；</li>
<li>当 $\alpha=\beta=0.5$ 时，<strong>RatioModel</strong> 退化成 $\frac{f(A\cap B)}{f(A)+f(B)}$；</li>
<li>当 $\alpha=1, \beta=0$ 时，<strong>RatioModel</strong> 退化成 $\frac{f(A\cap B)}{f(A)}$；</li>
</ul>
<h3 id="模型的应用"><a href="#模型的应用" class="headerlink" title="模型的应用"></a>模型的应用</h3><p><strong>Tversky</strong> <strong>对比模型</strong>一眼看上去就非常符合常理，十分吸引人。但是实际上在应用到推荐系统中时，其复杂性就远远高于它的形式上的简单性。我们需要根据实际场景数据学到参数 $\theta,\alpha,\beta$，并且学到一个合理的权重函数，这里的难点主要在于：如何设置正负样本？样本怎么组织？</p>
<p>文献 $[1]$ 介绍了他们在时装线上商城上实践的经验，他们通过设置一些问卷实验来收集数据。问卷发放给典型的用户，每次给他们一张时装的图片作为目标，然后给出两张在特征上有所不同的时装图片作为备选，让用户选择哪一张备选图片与目标最相似，如下图所示。用户问卷收集完毕后，还需要经过一些统计上的处理才能作为后续的训练数据。</p>
<img src="/2020/06/02/tversky-contrast-model/queries.png" title="实验设计：上面图片为目标图片，下面两张为备选图片">
<p>样本组织上，作者基于<strong>对比模型</strong>按如下过程来生成一个样本，并设置标签：</p>
<script type="math/tex; mode=display">
\begin{align}\begin{cases}Y&=I\big(S(T,A)-S(T,B)\big) \\S(T,X) &= \theta w^\top\cdot x_{T\cap A} -\alpha w^\top\cdot x_{T- A} -\beta w^\top\cdot x_{A-T}\end{cases}\end{align}</script><p>其中，$I(x)$ 是指示函数，当 $x&gt; 0$ 时 $I(x)=1$，否则 $I(x)=0$；$T$ 表示实验中的目标时装的特征集合，$A,B$ 表示两个备选时装的特征集合，$w$ 表示每个特征的权重。</p>
<p>根据这种方式，就可以对每个用户的每次选择生成一条样本：每条样本需要计算目标与备选的对比相似度，然后求差，作为样本的输入；假如用户选 $A$，则样本为正，否则样本为负。</p>
<p>在训练的时候，则用 $\delta\big(S(T,A)-S(T,B)\big)$ 来计算标签预测值，并设置如下损失函数：</p>
<script type="math/tex; mode=display">
L(\gamma)=logloss(\alpha,\beta,\theta,w)-\frac{1}{\mu}\log(\alpha)-\frac{1}{\mu}\log(\beta)-\frac{1}{\mu}\log(\theta)</script><p>其中，$-\frac{1}{\mu}\log(\alpha)-\frac{1}{\mu}\log(\beta)-\frac{1}{\mu}\log(\theta)$ 表示  <strong>LogBarrier</strong> 惩罚，主要是为了限制 $\alpha,\beta,\theta$ 非负，$\mu\gg 0$ 为 <strong>LogBarrier</strong> 参数。</p>
<p>文章实验结果表明，在他们的场景下，各个特征的权重确实不同，并且 $\theta&gt;\alpha&gt;\beta$，表明拥有共同特征还是占主导作用，而 $\alpha&gt;\beta$ 表明目标有而备选没有的特征起次要作用，并且用户的相似度估计确实是非对称的。</p>
<p>文献 $[1]$ 的经验在复用的时候，主要是要解决人工标注的问题，还有如何选择目标/备选物品，如何确定选用哪些特征等。在与运营发生类似于 ”给我推的一点也不相似“ 的争端时，给他们设计一个问卷吧~</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] Winecoff, Amy A., et al. “Users in the loop: a psychologically-informed approach to similar item retrieval.” <em>Proceedings of the 13th ACM Conference on Recommender Systems</em>. 2019.<br>[2] Tversky, Amos. “Features of similarity.” <em>Psychological review</em> 84.4 (1977): 327.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2020/05/26/paper-2018-msra-xdeepfm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/05/26/paper-2018-msra-xdeepfm/" itemprop="url">xDeepFM 论文精读</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-26T22:57:32+08:00">
                2020-05-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文精读/" itemprop="url" rel="index">
                    <span itemprop="name">论文精读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/05/26/paper-2018-msra-xdeepfm/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2020/05/26/paper-2018-msra-xdeepfm/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.9k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  7
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p><strong>论文引用：</strong>Lian, Jianxun, et al. “xdeepfm: Combining explicit and implicit feature interactions for recommender systems.” <em>Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</em>. 2018.</p>
</blockquote>
<p><strong>xDeepFM</strong> 是中科大和 <strong>MSRA</strong> 发表在 <strong>KDD 2018</strong> 上用于 <strong>CTR</strong> 预估的模型。这个模型充分借鉴了 <strong>DCN</strong>、<strong>FM</strong> 的思想，提出了一种新的将特征按 vector 进行交叉的结构 <strong>CIN</strong>，并且这个结构与 <strong>CNN</strong> 和 <strong>RNN</strong> 有一定的相似性。从实验来看，效果的确不错，但是工程效率实在是个难题。</p>
<h2 id="背景与动机"><a href="#背景与动机" class="headerlink" title="背景与动机"></a>背景与动机</h2><p>原始特征就像是未雕琢的原石，很难直接发挥出有效的作用，在预测系统中，我们通常需要对原始特征进行一定的组合变换，来取得比较好的效果。其中，特征交叉（即将离散特征值拼成一个新的特征值）能够衡量原始特征间的交互关系，提供在组合场景下有指导性的信息，对预测效果影响也比较显著，因此自动完成并提炼这种特征变换成为了众多模型（<strong>FM</strong>、<strong>DeepFM</strong>、<strong>DCN</strong> 等）设计显式交叉结构最主要的目的。</p>
<p>虽然 <strong>DeepFM</strong>、<strong>FNN</strong>、<strong>PNN</strong> 等模型能够完成特征的二阶显式交叉，并且通过 <strong>MLP</strong> 来完成特征的高阶隐式交叉，但是 <strong>xDeepFM</strong> 作者认为，单纯靠 <strong>DNN</strong> 来捕获高阶交叉特征效果无法保证，既说不清楚学到的函数是什么样的，也没法证明最多能学到几阶交叉，而且 <strong>MLP</strong> 本质上还是按 bit 进行交叉，物理含义也难以解释。</p>
<p><strong>DCN</strong> 模型前面也介绍过，是典型的能够提供高阶显式交叉能力，文章则证明了，<strong>DCN</strong> 的 CrossNet 结构每一层实际只能学到 embedding 层的张量积的形式。这个实际上就是看法的不同。对于第 $i+1$ 层 CrossNet，它的输出是根据 embedding 层的输入 $x_0$ 和第 $i$ 层的输出变换得到的：</p>
<script type="math/tex; mode=display">
x_{i+1} = x_0x_i^{\top}w_{i+1}+x_i</script><p>我们之前说 CrossNet 能够捕获所有特征两两交叉的信息，是源自它有一项 <script type="math/tex">x_0x_i^{\top}</script>，它的结果是个矩阵，包含两个向量每一位的乘积，然后再乘 $w_{i+1}$ 相当于是 pooling 或者信息压缩。</p>
<p>而文章作者是看到上式等价于 <script type="math/tex">x_{i+1}=x_0(x_i^{\top}w_{i+1})+x_i</script>，而括号内的是一个标量，因此我们可以根据归纳法得到：</p>
<script type="math/tex; mode=display">
\begin{align}x_1=&x_0(x_0^{\top}w_1)+x_0 = x_0(x_0^{\top}w_1+1)=\alpha^{(1)}x_0 \\x_2=&x_0(x_1^{\top}w_1)+x_1 = x_0\big((\alpha^1x_0)^{\top}w_1\big)+\alpha^{(1)}x_0=x_0\big((\alpha^{(1)}x_0)^{\top}w_1+\alpha^{(1)}\big)=\alpha^{(2)} x_0 \\\cdots \\x_{i+1}=& x_0\big((\alpha^{(i)}x_0)^{\top}w_{i+1}+\alpha^{(i)})=\alpha^{(i+1)}x_0\end{align}</script><p>这里的 $\alpha^i$ 是个标量，从这个表达式来看，CrossNet 的确每一层学到的是 $x_0$ 的张量积的形式。但是这并不是说 $x_k$ 与 $x_0$ 是线性相关的，只是说学到的函数形式比较受限。</p>
<p>因此文章设计 <strong>CIN</strong> 的核心思路有两个：一个是能够提供逐层高阶的显式特征交叉能力，另外特征交叉是按 vector 粒度进行，目标则是学到更加复杂的函数形式。</p>
<h2 id="CIN-架构"><a href="#CIN-架构" class="headerlink" title="CIN 架构"></a>CIN 架构</h2><p>文章提出 <strong>CIN</strong> 网络来完成特征显式交叉，简单来讲，它是将每一层的所有特征向量与输入层的所有特征向量进行点乘，然后用多个卷积核去做卷积，来生成特征交互的结果。具体来讲，它的交互过程如下：</p>
<p>记特征的 field 数量为 $m$，每个 field 特征对应的 embedding 维度都为 $d$，记 embedding 层输入为 $X^0\in \mathbb{R}^{m\times d}$，记第 $k+1$ 层 <strong>CIN</strong> 的输入（即第 $k$ 层的输出）为 <script type="math/tex">X^k\in \mathbb{R}^{h_k\times d}</script>。这里，<script type="math/tex">h_k</script> 是我们设置的超参数，例如，我们设置 <strong>CIN</strong> 的 layers 为 $[128, 128, 128]$ 时，它实际上指定了 <strong>CIN</strong> 有三层，且第 $k$ 层的权重矩阵 $W^k\in\mathbb{R}^{h_{k-1}\times m}$ 的数量为 $128$。</p>
<p>假设我们已经算出来前 $k-1$ 层的输出 $X^{k-1}$，则第 $k$ 层的输出 $X^k$ 的计算过程如下：</p>
<ol>
<li><p>计算出 $X^{k-1}$ 与 $X^0$ 的所有 field 特征向量间的 Hadamard 积，即将第 $k-1$ 层 <strong>CIN</strong> 输出的 <script type="math/tex">h_{k-1}</script> 个特征向量与 embedding 层的 $m$ 个特征向量做向量级的两两交叉，得到了 <script type="math/tex">h_{k-1}\times m</script> 个交叉向量，每个向量还是 $d$ 维：</p>
<script type="math/tex; mode=display">
Z^k_{i,j} = X^{k-1}_{i,*}\circ X^0_{j,*}, \qquad 1\le i\le h_{k-1},1\le j\le m</script></li>
<li><p>在第 $k$ 层构造 <script type="math/tex">h_k</script> 个可训练的权重矩阵，每个权重矩阵 <script type="math/tex">W^{k,h}</script> 的维度为 <script type="math/tex">(h_{k-1},m)</script>，矩阵的每个元素对应了上一步中每个向量的权重，计算第 $h$ 个权重矩阵对所有向量的加权和，得到这个权重矩阵对应的加权向量 <script type="math/tex">X_{h,*}^k</script>，即第 $k$ 层 <strong>CIN</strong> 的输出 $X^k$ 的第 $h$ 行，每一行还是 $d$ 维：</p>
</li>
</ol>
<script type="math/tex; mode=display">
X_{h,*}^k=\sum_{i=1}^{h_{k-1}} \sum_{j=1}^m W^{k,h}_{i,j} \cdot Z_{i,j}^k, \qquad 1\le h\le h_k</script><p>这样，我们就能够得到所有 <strong>CIN</strong> 层的输出 ${X^1,\cdots,X^n}$，并且一直保持 $X^i$ 的每一行是 $d$ 维的向量，从而保证每层都能与 $X^0$ 进行 vector 粒度的交叉。</p>
<p>整个 <strong>CIN</strong> 网络的输出则是将每个 <script type="math/tex">X^i\in \mathbb{R}^{h_i\times d}</script> 按列进行 sum pooling，得到一个 $h_i$ 维的向量 $x_i$，然后将所有 $x_i$ 进行拼接，得到一个 $\sum_i h_i$ 维的向量。上面的过程如果用卷积的思路，可以参考下面的图示：</p>
<img src="/2020/05/26/paper-2018-msra-xdeepfm/cin-flow.png" title="CIN 计算过程示意">
<p>由于 <strong>CIN</strong> 层中每个权重矩阵实际上是相对独立的，每一个权重矩阵都对应了所有的特征交叉信息。因此在实现中，还可以将每个 $X^i$ 分成 <script type="math/tex">X^i_{0:h_i/2-1,*}</script> 和 <script type="math/tex">X^i_{h_i/2:,*}</script>，前一半进行 sum pooling 后得到 $h_i/2$ 维向量直接接到输出层，后一半则作为下一层的输入。</p>
<h3 id="网络分析"><a href="#网络分析" class="headerlink" title="网络分析"></a>网络分析</h3><p>由于模型里可训练的参数主要是权重矩阵，根据上面的分析，<strong>CIN</strong> 的总参数量为 <script type="math/tex">\sum_k h_k\cdot h_{k-1}\cdot m</script>。文章也提出，如果 $h_k$ 比较大的话，可以将每个权重矩阵做 L-order decomposition，用两个小矩阵的乘积来代替，可以进一步减少参数量。</p>
<p>举个例子，比如 $100$ 个 field 的 $[128, 128, 128]$ 的 <strong>CIN</strong> 网络，参数量为 $3\times 128\times 128\times 100=4915200$；假设 embedding 维度为 $16$，$[128, 128, 128]$ 的 <strong>MLP</strong> 参数量为 $16\times 100\times 128+128\times 128+128\times 128=237568$；<strong>CIN</strong> 要明显多出不少。</p>
<p><strong>CIN</strong> 每一层计算需要 $O(mh^2d)$ 的时间复杂度，$t$ 层的复杂度为 $O(mh^2dt)$，明显比 <strong>MLP</strong> 的 $O(mhd+h^2t)$ 大很多，实际跑下来，<strong>xDeepFM</strong> 一个 epoch 用时大概是 <strong>DeepFM</strong> 的 3 倍。因此，<strong>xDeepFM</strong> 模型无论是参数量还是训练、推理的速度，都对工程化有很高的要求。</p>
<p>关于 <strong>CIN</strong> 的交叉能力，从上面的网络计算过程来看，也容易知道，<strong>CIN</strong> 的交叉阶数是逐层加 1 的，这里就不展开说明了。</p>
<p>最后，<strong>CIN</strong> 可以与 <strong>MLP</strong> 组成并行架构，也就是文章提出的 <strong>xDeepFM</strong>，兼具显式交叉和隐式交叉的能力，如下图所示，这貌似也已经是一个通用的做法了。</p>
<img src="/2020/05/26/paper-2018-msra-xdeepfm/xdeepfm-architecture.png" title="xDeepFM 整体架构">

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2020/05/09/paper-2019-pku-autoint/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/05/09/paper-2019-pku-autoint/" itemprop="url">AutoInt 论文精读</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-09T23:46:32+08:00">
                2020-05-09
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文精读/" itemprop="url" rel="index">
                    <span itemprop="name">论文精读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/05/09/paper-2019-pku-autoint/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2020/05/09/paper-2019-pku-autoint/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.4k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  9
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p><strong>论文引用:</strong> Song, Weiping, et al. “Autoint: Automatic feature interaction learning via self-attentive neural networks.” <em>Proceedings of the 28th ACM International Conference on Information and Knowledge Management</em>. 2019.</p>
</blockquote>
<p>这是一篇北京大学发表在 <strong>CIKM 2019</strong> 的文章，看作者列表没有企业背景，主要还是提供一些理论思路。文章的核心也是想通过自动挖掘特征间的高阶交互关系来提升减少人工特征工程，但是与前面的 <strong>DeepFM</strong>、<strong>DCN</strong> 等能够提供显式特征交叉能力的模型最大的差别在于：本文是通过不同 field 间特征做 <strong>Self-Attention</strong> 来实现特征的交互，也因此获得了一定的特征组合的可视化能力（<em>即文章中声称提供了较好的可解释性</em>）。</p>
<h3 id="背景与动机"><a href="#背景与动机" class="headerlink" title="背景与动机"></a>背景与动机</h3><p>其实已有的深度模型的相关工作基本核心都是在做高阶的特征交叉，但是诸如 <strong>PNN</strong>、<strong>FNN</strong>、<strong>DeepCrossing</strong>、<strong>Wide&amp;Deep</strong>、<strong>DeepFM</strong> 等模型，主要是依赖前馈网络来实现高阶特征交叉，主要的问题是特征交叉过程是隐式的，很难解释是哪些特征间的组合起到了关键作用，这个问题也存在于 <strong>DCN</strong>、<strong>xDeepFM</strong> 等提供显式特征交叉能力的模型中。</p>
<p>另外一些提供显式特征交叉能力的模型和算法也存在各种各样的问题，比如基于树+embedding 的$^{[1,2,3]}$，会将训练过程分裂成几个部分；比如显式做所有特征的高阶组合的 <strong>HOFM</strong> 模型$^{[4]}$，参数量过大，高于 5 阶的组合基本不可用（<em>实际上根据张俊林的说法，高于 4 阶的特征组合就已经收益很低了，这在 <strong>DCN</strong> 的测试中也得到了一定的验证</em>）。</p>
<p>基于这个背景，文章的目标是想找到一种特征自动进行高阶交叉的方法，既能弥补 <strong>MLP</strong> 对乘性特征组合捕获能力不强的弱点，又能够较好的解释哪些特征组合比较有效。</p>
<h3 id="AutoInt-网络设计"><a href="#AutoInt-网络设计" class="headerlink" title="AutoInt 网络设计"></a>AutoInt 网络设计</h3><h4 id="模型概览"><a href="#模型概览" class="headerlink" title="模型概览"></a>模型概览</h4><p><strong>AutoInt</strong> 网络内部主要包括两块，如下图所示：</p>
<img src="/2020/05/09/paper-2019-pku-autoint/autoint.png" title="AutoInt 整体架构">
<p><strong>AutoInt</strong> 底层是 embedding 层，类似于 <strong>DeepFM</strong> 的设计，将所有的离散、连续特征都映射成一个等长的 embedding 向量，其中，离散特征是直接 lookup embedding 表，多值的离散特征使用 average pooling；连续特征则相当于乘以一个不含 bias 的 <strong>Dense</strong> 层。</p>
<p><strong>AutoInt</strong> 核心是上面的交互层，使用 <strong>Multi-head Self-Attention</strong> 来实现，并且可以叠加多层，实现特征的高阶交叉。作者认为，特征组合的关键是知道哪些特征组合在一起有强大的表征能力，这个实际上相当于在人工特征工程中进行特征选择，那么在深度网络里怎么自动去实现特征组合的选择呢？作者受到 <strong>Self-Attention</strong> 的启发，考虑让每个 field 的特征与其他 field 的特征分别做 attention，根据 attention 的权重来判断该 field 特征与其他 field 特征组合的重要性，越重要的组合给予的权重越高，最后生成加权后的 sum pooling 作为该 field 特征与所有其他 field 特征组合的结果。</p>
<h4 id="Self-Attention-层计算流程详解"><a href="#Self-Attention-层计算流程详解" class="headerlink" title="Self-Attention 层计算流程详解"></a>Self-Attention 层计算流程详解</h4><p>关于 <strong>Self-Attention</strong> 相关的理论和应用，后面还会再单独介绍，感觉这一块是后面网络发展的重点。下面仅仅结合计算过程再详细的说明一下上面的思路，使用的符号与文章略有不同。</p>
<ol>
<li>假设输入特征一共有 $m$ 个 field，每个 field 的特征记为 $\boldsymbol{x}_i$，对应的 embedding 向量记为 $\boldsymbol{e}_i$；所有 field 拼接起来的 embedding 记为 $\boldsymbol{e}$；</li>
<li>考虑第 $i$ 个 field 的特征 $\boldsymbol{x}_i$ 对应的 embedding 向量 $\boldsymbol{e}_i$，首先计算它经过单层 Self-Attention 后生成的特征组合向量 $\tilde{\boldsymbol{e}}_i$（<em>其他 field 的计算过程完全相同</em>）；</li>
<li>对于 head $h$，根据该 head 中的 query、key、value 矩阵，计算第 $i$ 个 field 特征的 query 向量和所有其他 field 特征的 key、value 向量：<script type="math/tex; mode=display">
\begin{cases}\boldsymbol{q}_i^{(h)} = \boldsymbol{W}_q^{(h)}\boldsymbol{e}_i \\\boldsymbol{k}_j^{(h)} = \boldsymbol{W}_k^{(h)}\boldsymbol{e}_j \\\boldsymbol{v}_j^{(h)} = \boldsymbol{W}_v^{(h)}\boldsymbol{e}_j\end{cases} \qquad j=1,\cdots,m</script></li>
<li>计算第 $i$ 个 field 的 query 向量与所有其他 field 特征对应的 key 向量的 attention 权重 <script type="math/tex">a_{i,j}^{(h)}</script>：<script type="math/tex; mode=display">
a_{i,j}^{(h)} = \frac{\exp(\boldsymbol{q}_i^{(h)}\cdot\boldsymbol{k}_j^{(h)})}{\sum_{l=1}^m \exp(\boldsymbol{q}_i^{(h)}\cdot \boldsymbol{k}_l^{(h)})}</script></li>
<li>计算第 $i$ 个 field 对应的所有其他 field 的加权 value 向量 $\tilde{\boldsymbol{e}}_i^{(h)}$，作为第 $h$ 个 head 中第 $i$ 个 field 特征与所有其他 field 特征交互后的组合向量：<script type="math/tex; mode=display">
\tilde{\boldsymbol{e}}_i^{(h)}=\sum_{j=1}^m a_{i,j}^{(h)} \boldsymbol{v}_j^{(h)}</script></li>
<li>将所有 head 的结果进行 concat，得到第 $i$ 个 field 特征与所有其他 field 特征交互后的组合向量：<script type="math/tex; mode=display">
\tilde{\boldsymbol{e}}_i = \tilde{\boldsymbol{e}}_i^{(1)}\oplus\tilde{\boldsymbol{e}}_i^{(2)}\oplus\cdots\oplus\tilde{\boldsymbol{e}}_i^{(k)}</script></li>
<li>将所有 field 的组合向量进行 concat，并加上输入层，得到单层 Self-Attention 的输出向量 $\tilde{\boldsymbol{e}}$：<script type="math/tex; mode=display">
\tilde{\boldsymbol{e}}' = \tilde{\boldsymbol{e}}_1 \oplus\tilde{\boldsymbol{e}}_2\oplus\cdots\oplus\tilde{\boldsymbol{e}}_m \\\tilde{\boldsymbol{e}}=\text{ReLU}(\tilde{\boldsymbol{e}}'+\boldsymbol{W}\cdot \boldsymbol{e})</script></li>
</ol>
<p><strong>说明：</strong></p>
<ul>
<li>与 google 的原始论文 $[5]$ 相比，<strong>AutoInt</strong> 中的 <strong>Self-Attention</strong> 没有进行 scale，即第 4 步求 softmax 之前没有将内积除以一个缩放系数，导致的结果是突出了高效组合的重要性。当然，在实现的时候还是可以尝试把缩放加进来；</li>
<li>文献 $[5]$ 在最后一步还会再过一个 <strong>LayerNormalization</strong>，文章里并没有加；实现的时候可以加了看看效果；</li>
<li>在实现的时候，假设 embedding 的维度为 $d$，head 的数量为 $k$，则可以设置每个 head 中 query、key、value 矩阵 $\boldsymbol{W}^{(h)}$ 的维度为 $(\frac{d}{k}, d)$，这样得到的 $\tilde{\boldsymbol{e}}_i^{(h)}$ 就是 $\frac{d}{k}$ 维，将 $k$ 个 head 的结果 concat 后，$\tilde{\boldsymbol{e}}_i$ 又变成了 $d$ 维，从而保证输入的维度与输出的维度相同；这样的话，最后一步中矩阵 $\boldsymbol{W}$ 其实就不需要了（<em>文章的实验中 $\boldsymbol{e}$ 与 $\tilde{\boldsymbol{e}}’$ 维度不同，因此需要通过 $\boldsymbol{W}$ 将 $\boldsymbol{e}$ 变成与 $\tilde{\boldsymbol{e}}’$ 相同的维度</em>）。</li>
</ul>
<h4 id="Self-Attention-交叉能力分析"><a href="#Self-Attention-交叉能力分析" class="headerlink" title="Self-Attention 交叉能力分析"></a>Self-Attention 交叉能力分析</h4><p>文章将有 $p$ 个不同 field 特征乘性组合的特征称为 $p$ 阶组合特征，记为 <script type="math/tex">g(x_{i_1},\cdots,x_{i_p})</script>，从计算过程容易看出来，<script type="math/tex">\tilde{\boldsymbol{e}}_i^{(h)}</script> 乃至 $\tilde{\boldsymbol{e}}_i$ 都是包含 $\boldsymbol{x}_i$ 与所有 <script type="math/tex">\boldsymbol{x}_j\ (j=1,\cdots,i-1,i+1,\cdots,m )</script> 交互的 2 阶组合特征：${g(x_i,x_1),g(x_i,x_2),\cdots,g(x_i,x_m)}$。因此，单层 Self-Attention 就能表征所有 field 的 2 阶组合特征。</p>
<p>到了两层时，由于第一层输出中每个 field 相当于都是包含了所有的 2 阶组合，因此它的输出就包含了 3 阶和 4 阶的组合特征，例如 $g(x_1,x_2,x_3,x_4)$ 就包含在 $\tilde{\boldsymbol{e}}_1$ 和 $\tilde{\boldsymbol{e}}_3$ 的交互中。同理，三层 <strong>Self-Attention</strong> 就包含 8 阶内的组合特征……与 <strong>DCN</strong> 中的 cross 层相比，cross 每层增加 1 阶特征组合，而 <strong>Self-Attention</strong> 每层增加 1 倍特征组合。</p>
<h4 id="应用与讨论"><a href="#应用与讨论" class="headerlink" title="应用与讨论"></a>应用与讨论</h4><p>上面已经介绍了 embedding 层和 <strong>Self-Attetion</strong> 层，其中，<strong>Self-Attention</strong> 层是可以直接堆叠的，由于有残差结构的设计（最后一步加上了输入），理论上可以堆的比较深（文章的实验也证明了这个设计是比较有效的）。它还可以作为子结构，通过串联或者并联的方式，嵌入到其他网络中去，例如：</p>
<ul>
<li><strong>串联：</strong>最上面一层的 <strong>Self-Attention</strong> 输出可以直接送到 <strong>LR</strong> 里输出预测结果，或者再接一个 <strong>MLP</strong> 再输出预测结果；</li>
<li><strong>并联：</strong>embedding 层同时作为输入，送到 <strong>MLP</strong>、<strong>FM</strong>、cross 等其他层中，最后所有层结果进行 concat，送到 <strong>LR</strong> 中输出预测结果；</li>
</ul>
<p>训练一般还是使用 logloss 作为损失函数，用 <strong>Adam</strong> 等优化算法进行优化。</p>
<p>我在我们的数据集上测试的时候，发现 <strong>Self-Attention</strong> 层数也是 3 层就够了，到了 4 层测试 <strong>AUC</strong> 反而会降低，这与文章的参数是吻合的。</p>
<p>至于文章另外一个鼓吹的亮点，即特征组合的可解释性，实际上就是画出 attention 权重的热力图，主要是用于数据分析，感觉除了汇报好看点，也没啥实际的用处。</p>
<p>最后想说的一点，文章将不同 field 的特征当成了序列来做 <strong>Self-Attention</strong>，但其实 <strong>Self-Attention</strong> 也经常会用于对序列特征做 pooling，这也会在以后一起介绍。</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] Wang, Xiang, et al. “Tem: Tree-enhanced embedding model for explainable recommendation.” <em>Proceedings of the 2018 World Wide Web Conference</em>. 2018.<br>[2] Zhao, Qian, Yue Shi, and Liangjie Hong. “Gb-cent: Gradient boosted categorical embedding and numerical trees.” <em>Proceedings of the 26th International Conference on World Wide Web</em>. 2017.<br>[3] Zhu, Jie, et al. “Deep embedding forest: Forest-based serving with deep embedding features.” <em>Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>. 2017.<br>[4] Blondel, Mathieu, et al. “Higher-order factorization machines.” <em>Advances in Neural Information Processing Systems</em>. 2016.<br>[5] Vaswani, Ashish, et al. “Attention is all you need.” <em>Advances in neural information processing systems</em>. 2017.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2020/04/30/paper-2017-noah-deepfm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/30/paper-2017-noah-deepfm/" itemprop="url">DeepFM 论文精读</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-04-30T22:30:24+08:00">
                2020-04-30
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文精读/" itemprop="url" rel="index">
                    <span itemprop="name">论文精读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/04/30/paper-2017-noah-deepfm/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2020/04/30/paper-2017-noah-deepfm/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.4k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  5
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p><strong>论文引用</strong>: Guo, Huifeng, et al. “DeepFM: a factorization-machine based neural network for CTR prediction.” <em>arXiv preprint arXiv:1703.04247</em> (2017).</p>
</blockquote>
<p><strong>DeepFM</strong> 是华为诺亚实验室受 <strong>FM</strong> 和 wide &amp; deep 模型启发，发表在 <strong>IJCAI 2017</strong> 的一个 <strong>CTR</strong> 预估模型，从国内企业的实践分享来看，其效果受到了广泛的认可。它的核心思想是将 wide &amp; deep 网络中的 wide 层用 <strong>FM</strong> 层代替，增加了特征的二阶自动交叉能力，并且在实现上天然可以将 <strong>FM</strong> 层的 embedding 与 deep 层共享。</p>
<h3 id="DeepFM-架构"><a href="#DeepFM-架构" class="headerlink" title="DeepFM 架构"></a>DeepFM 架构</h3><p>随着深度网络的兴起，<strong>DNN</strong> 尤其是 <strong>MLP</strong> 的结构往往被用作非线性的特征提取器，并且取得了比较好的效果。然而文章指出，<strong>只保留特征的高阶非线性组合并不如同时保留特征的低阶组合和高阶组合效果好</strong>。这也是文章核心的出发点之一。但是 wide &amp; deep 模型中只有特征的一阶和高阶组合，因此一些有效的的二阶/三阶组合只能靠工程师人工挖掘组合出来，放到 wide 层。这个时候 <strong>FM</strong> 模型又出场了，用它来代替 wide 层，既能保留原始特征，又能自动做原始特征的二阶组合，这样就能节省很多人工特征交叉的工作。当然对于三阶及以上特征的显式组合，还是只能靠人工做一些工作，或者用前面讲的 <strong>DCN</strong> 中的 cross 等结构去捕获。</p>
<p><strong>DeepFM</strong> 的模型架构如下图所示，首先将所有的特征转成长度相同的 embedding，然后依照 <strong>FM</strong> 模型构建 <strong>FM</strong> 层，再将所有 embedding 拼接后，送到 <strong>MLP</strong> 层，最后在顶层进行拼接后，送到 <strong>LR</strong> 层，计算二分类损失。</p>
<img src="/2020/04/30/paper-2017-noah-deepfm/deepfm_architecture.png" title="图 1. DeepFM 整体架构">
<p>从架构来看，<strong>DeepFM</strong> 没有什么创新的子结构，主要还是在当时提出了一个比较好的思路。下面再聊一聊模型中的一些细节处理。</p>
<h3 id="特征处理"><a href="#特征处理" class="headerlink" title="特征处理"></a>特征处理</h3><p>由于诺亚在应用市场推荐场景中没有使用连续特征，因此该模型也没有考虑连续特征的处理。但是实际上 <strong>FM</strong> 本身是支持连续特征的，所以如果有连续特征，应该也是需要将每一维连续特征转成一个 embedding。</p>
<p>对于多值的离散特征，这里有两种处理方案。一种是只考虑 field 之间的特征交叉，这种思路下，我们在生成多值离散特征的 embedding 时可以使用某种 pooling 策略，建议使用 sum pooling，因为这种情况下相当于是每个取值都与另外一维特征做了交叉；另一种是考虑所有特征取值的交叉，这种思路下，就需要将多值特征每个取值的 embedding 进行 concat，再送到 <strong>FM</strong> 层和 <strong>MLP</strong> 层。</p>
<h3 id="效果测试"><a href="#效果测试" class="headerlink" title="效果测试"></a>效果测试</h3><p>我测试了一下 <strong>DeepFM</strong> 每个子结构的性能（使用 pooling 策略），以只使用线性部分作为基线的话，只使用 FM 的交叉部分能够提升 $4.91\%$，只使用 <strong>MLP</strong> 部分能够提升 $9.30\%$，全部使用能够提升 $9.38\%$，从数据来看，<strong>FM</strong> 层的确能带来少量的提升。</p>
<h3 id="从-DeepFM-到-DeepFFM"><a href="#从-DeepFM-到-DeepFFM" class="headerlink" title="从 DeepFM 到 DeepFFM"></a>从 DeepFM 到 DeepFFM</h3><p>最后有一个小问题值得思考和讨论一下，<strong>DeepFM</strong> 使用 <strong>FM</strong> 层代替 wide 层，那能不能使用 <strong>FFM</strong> 来代替 wide 层呢？或者有没有什么类似的思路，让每个特征与其他 field 特征进行交叉的时候能够有不同的表征？</p>
<p>最直接的方案就是将 embedding 层进行扩展（称为 <strong>NeuralFFM</strong> $^{[1]}$），即将原来每个 field 对应一个二维的 embedding matrix，扩展为每个 field 对应一个三维的 embedding matrix，使得每个特征都对应于一个二维的 embedding matrix，在交叉时同时根据 source/target field ID 来 lookup 相应的 embedding vector，如图 2 所示。假设 field 的数量为 $m$，这种方案实际上是将 embedding 的参数量增加为原来的 $m$ 倍。这种方案貌似最早是南大在比赛中使用过，效果还不错。但是由于 embedding 层本来就已经贡献了整个模型主要的参数量，这种方案无论是在 train、store 还是 serving 都十分吃资源。</p>
<img src="/2020/04/30/paper-2017-noah-deepfm/neuralffm_architecture.png" title="图 2. NeuralFFM 整体架构">
<p>还有一种思路是使用 self-attention 的思路 $^{[2]}$，将每个 field 与其他 field 计算 attention 值，作为其他 field 对该 field 相关的权重，然后再计算加权的 pooling，作为该 field 与其他所有 field 特征的交互结果。这个方案我们在 后续介绍 <a href="https://guyuecanhui.github.io/2020/05/09/paper-2019-pku-autoint/">AutoInt</a> 时会再详细说明。</p>
<p>张俊林等人则同时采用了这两种思路，提出了 <strong>FAT-DeepFFM</strong> $^{[3]}$，即 embedding 层使用 <strong>FFM</strong> 的扩展，在交互层使用 attention 机制，如下所示。但是张俊林自己在分享中都表示这种思路尝试一下就好了 $^{[4]}$，所以这里就学习一下这种思路，不详细介绍了，大家在生产环境中还是谨慎使用。</p>
<img src="/2020/04/30/paper-2017-noah-deepfm/deepffm_architecture.png" title="图 3. FAT-DeepFFM 整体架构">
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] Yang, Yi, et al.. “Neural field-aware factorization machine.” <em><a href="https://cs.nju.edu.cn/31/60/c1654a209248/page.htm" target="_blank" rel="noopener">https://cs.nju.edu.cn/31/60/c1654a209248/page.htm</a></em>. 2017.</p>
<p>[2] Song, Weiping, et al. “Autoint: Automatic feature interaction learning via self-attentive neural networks.” <em>Proceedings of the 28th ACM International Conference on Information and Knowledge Management</em>. 2019.</p>
<p>[3] Zhang, Junlin, Tongwen Huang, and Zhiqi Zhang. “FAT-DeepFFM: Field Attentive Deep Field-aware Factorization Machine.” <em>arXiv preprint arXiv:1905.06336</em> (2019).</p>
<p>[4] 张俊林. “FFM及DeepFFM模型在推荐系统的探索.” <em><a href="https://zhuanlan.zhihu.com/p/67795161" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/67795161</a></em>. 2019.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2020/04/15/paper-2017-google-dcn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/15/paper-2017-google-dcn/" itemprop="url">Deep & Cross 论文精读</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-04-15T21:50:20+08:00">
                2020-04-15
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文精读/" itemprop="url" rel="index">
                    <span itemprop="name">论文精读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/04/15/paper-2017-google-dcn/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2020/04/15/paper-2017-google-dcn/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.2k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  8
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>论文引用: Wang, Ruoxi, et al. “Deep &amp; cross network for ad click predictions.” <em>Proceedings of the ADKDD’17</em>. 2017. 1-7.</p>
</blockquote>
<p>本文是 Stanford 和 Google 联合发表在 <strong>KDD</strong> 2017 workshop 上的一篇 <strong>CTR</strong> 预估模型，模型采用 <strong>Wide&amp;Deep</strong> 架构，最大的创新点在于将 wide 层替换成 cross 层，省去了原本大量的人工特征工程的工作，由 cross 层提供显式的高阶特征组合能力，同时保持较低的参数量和计算量。</p>
<h3 id="背景与动机"><a href="#背景与动机" class="headerlink" title="背景与动机"></a>背景与动机</h3><p>随着深度网络的兴起，各大厂纷纷尝试用深度网络来作为特征提取器，并取得了显著的效果。尤其是 Wide&amp;Deep 架构的提出，让大家意识到可以在模型中同时使用 <strong>DNN</strong> 来捕获特征的复杂映射关系，使用线性模型来记忆组合特征，但是这里的线性模型中的组合特征其实还是工程师针对具体场景人工构造的。</p>
<p>进一步，大家考虑将 wide 层用自动特征组合的网络来替换，例如用 <strong>FM</strong> 来代替 wide 层 (<strong>DeepFM</strong>)，能够提供了二阶的自动特征组合能力。本文则更进一步，设计出 cross 网络来代替 wide 层，能够提供任意高阶的特征组合能力 (与 cross 层数相同)，同时保持很低的计算和存储开销。</p>
<p>那有了 <strong>MLP</strong> 层为什么还需要 cross 层呢？我的理解是，<strong>MLP</strong> 层更擅长的是进行特征复杂的非线性变换，这些非线性变换通常是隐式的、对于乘性的特征组合捕获能力不强，而人基于对业务的深入理解能够显式构造一些十分有效的组合特征，如果让 <strong>MLP</strong> 层去学，可能需要比较大的参数规模才能学到。这也是 <strong>Wide&amp;Deep</strong> 为什么还需要保留 wide 层的原因。而 cross 层则设计为显式的进行特征组合，能够保证每一层都保留上一层的组合信息，并增加一阶组合，因此可以认为这两个结构是互补的。</p>
<p>当然，这里的 cross 层由于参数数量的限制，容量有限，我们仍然可以在 <strong>DCN</strong> 的基础上增加 wide 层来强化对部分人工特征的记忆，或者将 cross 层作为一个子网嵌入到其他排序网络中去，作为高阶特征提取器。</p>
<h3 id="DCN-网络架构"><a href="#DCN-网络架构" class="headerlink" title="DCN 网络架构"></a>DCN 网络架构</h3><p>前面提到了，<strong>DCN</strong> 的主要创新点在于设计了 cross 层来做特征的显式组合，同时只使用很少的参数。乍一看感觉有点神奇，如果要学习 $n$ 个特征的 $k$ 阶组合，按道理讲我们需要 $C_n^k$ 个参数 ($O(d^n)$)，那怎么进行参数的压缩呢？先可以回顾一下 <strong>FM</strong>，它本质上是学习了每个特征的隐向量，然后用两个特征隐向量的内积来代替这两个特征组合的系数，这样能够共享统计强度，并减少参数量。<strong>DCN</strong> 的 cross 层则更进一步，它每一层的设计如下：</p>
<script type="math/tex; mode=display">
\boldsymbol{x}_{l+1}=\boldsymbol{x}_0 \boldsymbol{x}_l^{\top}\boldsymbol{w}_l + \boldsymbol{b}_l + \boldsymbol{x}_l \qquad(1)</script><p>即第 $l+1$ 层的输入与第 $l$ 层的输入和原始的特征输入有关。再具体点来说，式 $(1)$ 右边的第一项是原始特征与 $l$ 阶特征的笛卡尔积，再与一个权重向量相乘。简单用归纳法可以看出，从表达式上来讲，$\boldsymbol{x}_0 \boldsymbol{x}_l$ 是能够包含所有 $l+1$ 阶的特征组合，这一项再乘以一个权重向量，相当于对特征组合的信息做了 weighted sum pooling，或者换句话说，$\boldsymbol{x}_0 \boldsymbol{x}_l^{\top}$ 的每一列 $i$ 共享同一个参数 $\boldsymbol{w}_l^{(i)}$；式 $(1)$ 最后再加上原始特征输入实际上是类似于残差网络的结构，主要是帮助模型训练。关于式 $(1)$ 文章还提供了一个可视化的图片方便理解，如下所示：</p>
<img src="/2020/04/15/paper-2017-google-dcn/dcn_cross.png" title="图 1. Cross 层结构设计">
<p>到这里我们可以简单的分析一下这个 cross 层有以下特点：</p>
<ol>
<li>它的显式特征组合是通过输入与每一层进行笛卡尔积来获得，但是在保存的时候，进行了 pooling，极大的降低了存储的开销；</li>
<li>它每层的权重实际上是一个 $d$ 维的向量 (而非两层全连接网络的 <script type="math/tex">n_i\times n_{i-1}</script> 的张量)，因此参数规模控制在 $O(md)$ 的级别，其中 $m$ 是 cross 网络的层数，$d$ 是初始特征维度；</li>
<li>实际计算的时候，可以根据交换律先计算 $\boldsymbol{x_0} (\boldsymbol{x}_l^{\top}\boldsymbol{w})$ 中括号内的部分，将乘法次数降到 $O(d)$ 次，从而整个 cross 网络的推理复杂度也降到了 $O(md)$。</li>
<li>cross 网络不存在非线性的变换，并且由于权重的连乘，在训练的时候存在梯度消失或者爆炸的风险。</li>
</ol>
<p>我们可以将 cross 层作为一个子结构加入到其他网络中去，例如 <strong>DCN</strong> 就可以看成是普通的 <strong>MLP</strong> + cross 的架构，其中，<strong>MLP</strong> 部分主要来做特征的非线性变换，一般就是几层全连接的隐含层，使用 <strong>relu</strong> 进行激活。整体的架构如下：</p>
<img src="/2020/04/15/paper-2017-google-dcn/dcn_architecture.png" title="图 1. DCN 整体架构">
<p>在特征处理时，连续特征做归一化，离散特征先查 embedding，拼接在一起作为原始输入 $\boldsymbol{x}_0$，并分别输入到 cross 层和 <strong>MLP</strong> 层，将两个结构的输出拼接后，经过一个 <strong>LR</strong> 输出预测结果，训练的时候使用带 <strong>L2</strong> 范数的 logloss 作为 <strong>Cost Function</strong>，用 <strong>Adam</strong> 之类的优化算法求解。</p>
<p>对于模型训练，文章还分享了一些小技巧：</p>
<ol>
<li><strong>MLP</strong> 层使用了 batch normalization，并设置梯度截断值为 100；</li>
<li>使用 early stop 来进行正则化，相对于 L2 正则和 dropout 更有效；感觉 <strong>DCN</strong> 的确比较容易过拟合，我在测试时发现，当数据量比较大，并且将模型的参数规模调整到一个合适的量级，一个 epoch 基本已经达到最优了，继续训练可能就会导致测试 <strong>AUC</strong> 下降；</li>
<li>$d$ 维类别特征的 embedding size 设置参考计算式：$6\times d^{\frac{1}{4}}$；但是感觉在我们的场景里还是太大了，个人倾向于设置成 $\log$ 的函数。在资源允许的情况下，embedding size 设置大一点对测试 <strong>AUC</strong> 是有正向帮助的，但是也增加了过拟合的风险；</li>
</ol>
<h3 id="实验与讨论"><a href="#实验与讨论" class="headerlink" title="实验与讨论"></a><strong>实验与讨论</strong></h3><p>文章主要在 <a href="https://www.kaggle.com/c/criteo-display-ad-challenge" target="_blank" rel="noopener">criteo 数据集</a>上进行了一些对比实验，除了证明 <strong>DCN</strong> 比 benchmark 都好很多以外，还重点强调了 <strong>DCN</strong> 在同等参数量下能够达到更低的误差、在同等误差的情况下能够使用更少的参数。另外，还单独测试了增加 cross 结构的确能够大幅的降低模型的误差。</p>
<p>文章比较的时候，<strong>LR</strong>、<strong>FM</strong> 等模型使用的特征与 <strong>DCN</strong> 实际上是有差别的，做了更多的特征工程。为了测试模型本身的效果，我在我们业务的数据集上也跟一些常见模型对比测试了一下，离线效果确实还不错，而且即使只用 cross 层，也能超过 <strong>FFM</strong> 的效果。</p>
<p>我也单独测试了 <strong>DCN</strong> 各个子结构的性能，经过若干贪心调优后，以 <strong>LR</strong> 作为基线 (即将 <strong>DCN</strong> 的 <strong>MLP</strong> 层和 cross 层的输入 $\boldsymbol{x_0}$ 直接送到 <strong>LR</strong> 层)，只使用 cross 层的测试 <strong>AUC</strong> 提升了 $4.5\%$，只使用 <strong>MLP</strong> 层的测试 <strong>AUC</strong> 提升了 $5.5\%$，而两者都用的测试 <strong>AUC</strong> 提升了 $6.3\%$。只使用 cross 层效果不如只使用 <strong>MLP</strong> 层的主要原因是参数数量少了很多，即使是 10 层的 cross 层参数量也就相当于一个只含有 20 个神经元的单层全连接 <strong>MLP</strong>。如果设定两者的参数量相同的情况下，在我们的数据集上，只使用 cross 层能够比只使用 <strong>MLP</strong> 层高出 $1‰$。但是 cross 层想要把参数量提上来其实很困难，在测试中，cross 层达到 20 层的时候，训练的时长比 4 层增加 $200\%$，并且 loss 在某个 batch 以后突然爆炸（不影响 <strong>AUC</strong> 评估），因此感觉 cross 层还是只能作为一个辅助的子结构使用。一个可以尝试的方法是同时使用 2 ~ 4 层的 cross 层 (5 层相对于 4 层的收益已经很少了)，在顶层进行 concat，最后送到 <strong>LR</strong> 中去。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2020/04/04/auc/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/04/auc/" itemprop="url">AUC 理解与应用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-04-04T21:54:19+08:00">
                2020-04-04
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/特征工程/" itemprop="url" rel="index">
                    <span itemprop="name">特征工程</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/04/04/auc/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2020/04/04/auc/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.7k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  10
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>AUC</strong> 是一个对分类器预测数值不敏感的指标，具有比较好的稳定性，也因此成为推荐系统中最常用的模型离线指标之一。但是就这个如此常见的指标，很多人对它也只是一知半解，知道该用它，也知道调用函数去计算它，但是对它的计算过程、它还有哪些用处，却知之甚少。这篇文章就再唠叨一下 <strong>AUC</strong> 的概念、计算过程以及它如何应用于特征选择上。</p>
<h2 id="AUC-Area-Under-the-Curve-的概念"><a href="#AUC-Area-Under-the-Curve-的概念" class="headerlink" title="AUC (Area Under the Curve) 的概念"></a>AUC (Area Under the Curve) 的概念</h2><p><strong>AUC</strong>（Area Under Curve）被定义为 <strong>ROC</strong> 曲线下与坐标轴围成的面积。<strong>AUC</strong> 主要用来评估二分类问题的准确率，即随机给定一个正样本和一个负样本，分类器预测该正样本的得分比预测该负样本的得分大的概率。</p>
<p><strong>AUC</strong> 越接近 1 表明这个分类器的性能越好，随机猜测的 <strong>AUC</strong> 接近 0.5，如果一个分类器的 <strong>AUC</strong> 低于 0.5，只需要将它的结果取反就能一下子提高模型性能。</p>
<h2 id="AUC-的计算"><a href="#AUC-的计算" class="headerlink" title="AUC 的计算"></a>AUC 的计算</h2><p>根据 <strong>AUC</strong> 的含义，给定样本的真实标签和预测得分，计算分类器的 <strong>AUC</strong> 指标，主要有三种方法：梯形法、穷举法和序数法。</p>
<h3 id="梯形法-trapezoid-method"><a href="#梯形法-trapezoid-method" class="headerlink" title="梯形法 (trapezoid method)"></a>梯形法 (trapezoid method)</h3><p>梯形法就是先根据真实标签和预测得分，画出 <strong>ROC</strong> 曲线，然后简单地将每个相邻的点以直线连接，计算连线下方的总面积。<strong>ROC</strong> 曲线的详细说明可以参考 wiki，这里给出一个简单的绘制方法：</p>
<ol>
<li>计算所有样本中正样本数 <script type="math/tex">n_{pos}</script> 和负样本数 <script type="math/tex">n_{neg}</script>，进一步计算 x 轴的步长为 <script type="math/tex">s_x=\frac{1}{n_{neg}}</script>，y 轴的步长为 <script type="math/tex">s_y=\frac{1}{n_{pos}}</script>；</li>
<li>初始化 <strong>ROC</strong> 曲线在原点 $(0,0)$；</li>
<li>将所有样本按预测得分降序排列，然后按顺序进行以下判断并绘制：<ul>
<li>如果当前样本为正样本，则 <strong>ROC</strong> 曲线沿 y 轴向上移动单位步长 $s_y$；</li>
<li>如果当前样本为负样本，则 <strong>ROC</strong> 曲线沿 x 轴向右移动单位步长 $s_x$；</li>
<li>假设有连续 $k$ 个样本预测得分相同，其中有 $k_p$ 个正样本和 $k_n$ 个负样本，则 <strong>ROC</strong> 曲线沿着向量 $(k_n\cdot s_x,k_p\cdot s_y)$ 进行移动；</li>
</ul>
</li>
</ol>
<p>有了 <strong>ROC</strong> 曲线，我们可以用梯形法计算 <strong>ROC</strong> 曲线下的面积。举个例子：假设有 6 条样本，某个分类器对每个样本的预测得分 <script type="math/tex">\hat{y}</script> 及其真实标签 <script type="math/tex">y</script> 如下表所示：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">ID</th>
<th style="text-align:center">$\hat{y}$</th>
<th style="text-align:center">$y$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">A</td>
<td style="text-align:center">0.1</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">B</td>
<td style="text-align:center">0.3</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">C</td>
<td style="text-align:center">0.5</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">D</td>
<td style="text-align:center">0.5</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">E</td>
<td style="text-align:center">0.7</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">F</td>
<td style="text-align:center">0.9</td>
<td style="text-align:center">1</td>
</tr>
</tbody>
</table>
</div>
<p>则根据上面的 <strong>ROC</strong> 画法，我们计算出步长 $s_x=s_y=\frac{1}{3}$，再通过依次观察 F $\rightarrow$ A 的真实标签，可以画出如下的红色 <strong>ROC</strong> 曲线，并计算出曲线下的面积为：$\frac{1}{3}\times \frac{1}{3}+\frac{1}{2}\times(\frac{1}{3}+\frac{2}{3})\times\frac{1}{3}+\frac{1}{3}=0.61$。</p>
<img src="/2020/04/04/auc/roc.png" title="图 1. ROC 曲线示例">
<h3 id="穷举法"><a href="#穷举法" class="headerlink" title="穷举法"></a>穷举法</h3><p>穷举法就是穷举样本中所有的正负样本对并计数，从而计算这些样本对中正样本预测得分大于负样本预测得分的比例。假设正例集合为 <script type="math/tex">N_{pos}</script>，正例数量为 <script type="math/tex">n_{pos}</script> ；负例集合为 <script type="math/tex">N_{neg}</script>，负例数量为 <script type="math/tex">n_{neg}</script>，则：</p>
<script type="math/tex; mode=display">
AUC = \frac{\sum I(\hat{y}_{pos}, \hat{y}_{neg})}{n_{pos}\cdot n_{neg}}\qquad(1)</script><p>其中，<script type="math/tex">I(.,.)</script> 是指示函数：</p>
<script type="math/tex; mode=display">
I(\hat{y}_{pos}, \hat{y}_{neg})=\begin{cases}
1, \qquad &\hat{y}_{pos} > \hat{y}_{neg} \\
0.5, \qquad &\hat{y}_{pos} = \hat{y}_{neg} \\
0, \qquad &\hat{y}_{pos} < \hat{y}_{neg}
\end{cases} \qquad(2)</script><p>例如，在上一小节中的例子中有 3 个正例 (BDF) 和 3 个负例 (ACE)，一共有 $3\times 3=9$ 种组合，每种组合的得分如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">负正样本对</th>
<th style="text-align:center">指示函数得分</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">AB</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">AD</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">AF</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">CB</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">CD</td>
<td style="text-align:center">0.5</td>
</tr>
<tr>
<td style="text-align:center">CF</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">EB</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">ED</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">EF</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">合计</td>
<td style="text-align:center">5.5</td>
</tr>
</tbody>
</table>
</div>
<p>因此，该分类器的 $AUC=\frac{5.5}{9}=0.61$，是个相当差的分类器了。</p>
<h3 id="序数法"><a href="#序数法" class="headerlink" title="序数法"></a>序数法</h3><p>穷举法比较适合小数据量情况下的计算，但是其实其中有很多比较是重复的。例如当我们按上例中 $\hat{y}$ 将样本排好序以后，对某个正样本而言，它上面的所有负样本数就是它的得分，没必要再穷举其他的样本对。因此我们考虑将样本排序后，基于样本序数来计算 <strong>AUC</strong>，这里略去推导过程，直接给出计算方法：</p>
<script type="math/tex; mode=display">
AUC=\frac{\sum_{i\in N_{pos}}r_i - \frac{n_{pos}(1+n_{pos})}{2}}{n_{pos}\cdot n_{neg}}\qquad(3)</script><p>其中，$r_i$ 就是按 $\hat{y}$ 排序后，第 $i$ 个样本的序号，如果有多个样本预测得分相同，则这些样本的序号直接求平均。例如对于上面的例子，我们可以对这些样本做如下的编号：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">ID</th>
<th style="text-align:center">$\hat{y}$</th>
<th style="text-align:center">$y$</th>
<th style="text-align:center">$r$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">A</td>
<td style="text-align:center">0.1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">B</td>
<td style="text-align:center">0.3</td>
<td style="text-align:center">1</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">C</td>
<td style="text-align:center">0.5</td>
<td style="text-align:center">0</td>
<td style="text-align:center">3.5</td>
</tr>
<tr>
<td style="text-align:center">D</td>
<td style="text-align:center">0.5</td>
<td style="text-align:center">1</td>
<td style="text-align:center">3.5</td>
</tr>
<tr>
<td style="text-align:center">E</td>
<td style="text-align:center">0.7</td>
<td style="text-align:center">0</td>
<td style="text-align:center">5</td>
</tr>
<tr>
<td style="text-align:center">F</td>
<td style="text-align:center">0.9</td>
<td style="text-align:center">1</td>
<td style="text-align:center">6</td>
</tr>
</tbody>
</table>
</div>
<p>其中，CD 的预测得分相同，因此它们的编号为 $\frac{3+4}{2}=3.5$。根据式 $(3)$ 我们可以算出所有正样本的序数和为 $2+3.5+6=11.5$，$AUC=\frac{11.5-3\times 4\div 2}{3\times 3}=0.61$。</p>
<h3 id="Group-AUC"><a href="#Group-AUC" class="headerlink" title="Group AUC"></a>Group AUC</h3><p>上面介绍了通常意义下 <strong>AUC</strong> 的计算方法，这个指标实际上是将所有的正负样本放在一起，来衡量模型整体的排序能力。但是在推荐场景下，实际上我们更关心的是<strong>对单个用户而言，推荐结果的相对顺序</strong>，至于不同用户之间是否正样本的得分一定比负样本高，其实影响并不大。</p>
<p>因此，在某些场景下 <strong>AUC</strong> 可能无法真实的度量模型的排序能力 (比如离线指标相对较高，但是线上指标相对较差)，这时可以考虑尝试使用 <strong>GAUC</strong> 来度量。</p>
<p><strong>GAUC</strong> 实际上就是按用户进行分组，计算每个用户下样本排序的 <strong>AUC</strong>，再汇总加权得分，计算公式如下：</p>
<script type="math/tex; mode=display">
GAUC=\frac{\sum_{u}w_u \cdot AUC_u}{\sum_{u}w_u}\qquad(4)</script><p>这里的用户权重 <script type="math/tex">w_u</script> 可以设置为该用户的点击数/曝光数。至于每个用户样本的 <script type="math/tex">AUC_u</script> 计算还是参考式 $(1)$ 或式 $(3)$。</p>
<h2 id="单特征-AUC-的计算"><a href="#单特征-AUC-的计算" class="headerlink" title="单特征 AUC 的计算"></a>单特征 AUC 的计算</h2><p>特征选择中一个重要的技术就是单特征 <strong>AUC</strong> 的计算，它体现了这维特征正确划分样本的能力。单特征 <strong>AUC</strong> 越高，这维特征也就越重要，尤其是在线性模型中。</p>
<h3 id="单值离散特征的-AUC-计算"><a href="#单值离散特征的-AUC-计算" class="headerlink" title="单值离散特征的 AUC 计算"></a>单值离散特征的 AUC 计算</h3><p>单值离散特征是指特征取值是离散特征，而且每个样本中该特征取值只有一个，例如用户的城市、性别等。我们基于训练数据和测试数据可以使用以下算法高效的计算该特征的 <strong>AUC</strong> (推导过程参考<a href="https://blog.csdn.net/u013019431/article/details/92851053" target="_blank" rel="noopener">这里</a>)：</p>
<ol>
<li>计算这维特征的每个特征值在训练数据中的正样本占比；</li>
<li>在测试数据中，用第 1 步计算的结果作为样本的预测值；</li>
<li>基于上一小节中的 <strong>AUC</strong> 计算方法计算理论上该特征在 <strong>LR</strong> 下的 <strong>AUC</strong>；</li>
</ol>
<p>举个例子，我们考虑性别特征的单值 <strong>AUC</strong> 计算，假设有 10 条样本 (前 6 条作为训练样本，后 4 条作为测试样本)：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">ID</th>
<th style="text-align:center">gender</th>
<th style="text-align:center">$y$</th>
<th style="text-align:center">$\hat{y}$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">A</td>
<td style="text-align:center">m</td>
<td style="text-align:center">0</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">B</td>
<td style="text-align:center">f</td>
<td style="text-align:center">1</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">C</td>
<td style="text-align:center">m</td>
<td style="text-align:center">1</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">D</td>
<td style="text-align:center">f</td>
<td style="text-align:center">0</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">E</td>
<td style="text-align:center">f</td>
<td style="text-align:center">1</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">F</td>
<td style="text-align:center">m</td>
<td style="text-align:center">0</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">G</td>
<td style="text-align:center">m</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0.33</td>
</tr>
<tr>
<td style="text-align:center">H</td>
<td style="text-align:center">f</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0.67</td>
</tr>
<tr>
<td style="text-align:center">I</td>
<td style="text-align:center">f</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0.67</td>
</tr>
<tr>
<td style="text-align:center">J</td>
<td style="text-align:center">m</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0.33</td>
</tr>
</tbody>
</table>
</div>
<p>我们先根据训练样本 A-F 计算性别为 m 的正样本比例为 $0.33$，性别为 f 的正样本比例为 $0.67$，因此我们预测样本 G-J 的得分依次为 $[0.33,0.67,0.67,0.33]$，从而根据式 $(1)$ 可以很快算出来，这维特征的 <strong>AUC</strong> 为 $(0.5+1+1)/3=0.83$。</p>
<h3 id="多值离散特征的-AUC-评估"><a href="#多值离散特征的-AUC-评估" class="headerlink" title="多值离散特征的 AUC 评估"></a>多值离散特征的 AUC 评估</h3><p>多值离散特征是指特征取值是离散特征，而且每个样本中该特征取值可能有多个，例如视频的标签、演员等。虽然单值离散特征可以高效的计算它的 <strong>AUC</strong>，遗憾的是，多值离散特征的 <strong>AUC</strong> 似乎无法进行类似的推导。因此我们目前还是通过仅使用这一维特征构建训练数据，用于训练 <strong>LR</strong> 模型，再用该 <strong>LR</strong> 模型预测测试数据的得分，用模型的 <strong>AUC</strong> 来作为该特征的 <strong>AUC</strong>。</p>
<p>实际上，单值离散特征也可以用建模型的方式来评估，我们两种方法都尝试了，结果证明两种方法得到的结果是十分接近的。</p>
<h3 id="连续特征的-AUC-评估"><a href="#连续特征的-AUC-评估" class="headerlink" title="连续特征的 AUC 评估"></a>连续特征的 AUC 评估</h3><p>连续特征就是指取值是连续值的特征，比如视频的播放次数、播放完成度等。</p>
<p>有一些特征如年龄，虽然是连续值，但是因为取值有限，既可以作为连续特征，也可以作为离散特征。但是连续特征，尤其是非均匀分布、或者偏序关系不明确的连续特征，对于线性模型是不太友好的，例如我们考虑预测用户是否播放一个恐怖电影，可能年龄大的或者年龄小的用户都不喜欢看，而比较年轻的用户最喜欢，线性模型就难以区分了。</p>
<p>因此，如果在线性模型中使用连续值特征，除了像播放完成度这类取值范围有限且偏序关系一致 (播放完成度越高，通常表明视频质量越好，用户点击的概率也越大) 的连续特征，我们最好还是按下面的算法来评估某连续特征的单特征 <strong>AUC</strong>：</p>
<ol>
<li>在训练数据中使用该连续特征训练 <strong>GBDT</strong> 模型；</li>
<li>如果第 1 步中使用多棵树，则用第 1 步训练的 <strong>GBDT</strong> 对测试数据中的该连续特征进行分桶，将分桶结果作为新的多值离散特征，并使用多值离散特征的 <strong>AUC</strong> 评估方法进行评估；</li>
<li>如果第 1 步中使用单棵树，则用第 1 步训练的 <strong>GBDT</strong> 对测试数据中的该连续特征进行分桶，将分桶结果作为新的单值离散特征，并使用单值离散特征的 <strong>AUC</strong> 计算方法进行评估；</li>
</ol>
<p>至于使用单棵树还是多棵树，最好参数与模型实际执行的特征变换保持一致。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2019/11/24/paper-2018-ali-dicm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/24/paper-2018-ali-dicm/" itemprop="url">DICM with AMS 论文精读</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-24T21:50:20+08:00">
                2019-11-24
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文精读/" itemprop="url" rel="index">
                    <span itemprop="name">论文精读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/11/24/paper-2018-ali-dicm/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/11/24/paper-2018-ali-dicm/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.1k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  7
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>论文引用：Ge, Tiezheng , et al. “Image Matters: Visually modeling user behaviors using Advanced Model Server.” (2018).</p>
</blockquote>
<p>本文是阿里发表在 <strong>CIKM 2018</strong> 上的文章，主要思路是将用户历史有过行为 (文章实际使用了点击行为) 的图片来对用户视觉兴趣进行建模，在广告 <strong>CTR</strong> 预估时就能够估计用户对广告图片的喜好，从而提升 <strong>CTR</strong> 预估的准确率。由于用户在商品页面行为历史通常较为丰富，因此训练样本中会包含大量的图片特征，这些特征使用传统的 <strong>PS</strong> 架构无法有效训练，因此文章提出了 <strong>AMS</strong> (<em>Advanced Model Server</em>) 架构，能够平衡存储和通信开销，使得天级更新模型成为可能。这篇文章主要的贡献也是在工程实现方面。</p>
<h3 id="背景和动机"><a href="#背景和动机" class="headerlink" title="背景和动机"></a>背景和动机</h3><p>广告 <strong>CTR</strong> 预估是广告系统中至关重要的环节，传统的 (非多模态) 预估模型，主要是使用一些 <strong>ID</strong> 和交叉统计之类的特征，但是由于 <strong>ID</strong> 没有语义，我们无法判断两个 <strong>ID</strong> 是不是有相关性，因此这些模型对于出现频次少或者新出现的 <strong>ID</strong> 无法充分训练，即存在冷启动的问题。</p>
<p>解决冷启动问题通常会想到引入内容特征，而在电商领域，图片就是能够描述广告/商品的最直观且最受用户关注的内容特征。用户在购买商品的时候，通常会点击、浏览商品的图片，结合商品的描述、评论等其他信息来决定是否购买，因此用户曾经点击过的图片能够在很大程度上表征用户的兴趣。而用户是否点击广告，图片、标题等信息是影响最大的因素。因此，文章就考虑使用用户点击过的图片来建立用户的兴趣模型，再与广告的图片进行匹配，从而估计用户在视觉层面是否对该广告有兴趣；将这方面的估计与传统的基于 <strong>ID</strong> 等特征的估计相结合，来提升 <strong>CTR</strong> 估计的性能。基于这个思路，文章提出了 <strong>DICM</strong> (<em>Deep Image CTR Model</em>)。 </p>
<p>使用用户图片历史来建立用户视觉偏好主要的问题就是数据传输和存储，如果使用传统的 <strong>PS</strong> 架构，图片数据是保存在 <strong>KV Store</strong> 里（也就是参数服务器），谁用谁来查一下，而图片的数量和数据量都是相对较大的，因此这种方式十分消耗资源，并且这种方式也难以针对 <strong>CTR</strong> 预估任务对预训练的图片特征进行进一步的组合和压缩，即图片数据不是目标相关的。文章针对这个问题，提出了一种扩展 <strong>PS</strong> 架构，称为 <strong>AMS</strong> 架构。下面就详细的介绍这两方面的工作。</p>
<h3 id="AMS-架构"><a href="#AMS-架构" class="headerlink" title="AMS 架构"></a>AMS 架构</h3><p>如上所述，文章在实现 <strong>DICM</strong> 模型时，实际上是基于 <strong>AMS</strong> 架构的。<strong>AMS</strong> 架构整体如图 1 右图所示：</p>
<img src="/2019/11/24/paper-2018-ali-dicm/ams-architecture.png" title="图 1. AMS 架构及基于 AMS 架构实现的 DICM 模型">
<p><strong>AMS</strong> 将节点分为 <strong>Worker</strong> 和 <strong>Server</strong> 组：</p>
<ul>
<li><strong>Server 组</strong>：保存图片原始特征数据（考虑到端到端训练和推理的时延，这里取的是预训练模型的低阶隐层输出），并且负责将图片原始特征数据映射到任务空间的高阶表达，实际上就是学一个 Tower 模型，这个 Tower 模型是所有 Server 共享的。使用这个图片 <strong>EmbedTower</strong>，可以将图片原始特征数据极大的压缩（文章使用 $4096\times 256\times 64\times 12$ 的 Tower，可以将数据量减少 340 多倍），Worker 查询的时候传输数据量就大大减少了。</li>
<li><strong>Worker 组</strong>：从 <strong>Server 组</strong>查询样本的各维特征（包括 <strong>ID</strong> embedding 和图片的高阶 embedding 等），将特征组合后进行推理；训练时还要将损失梯度传回 Server，用来更新图片 <strong>EmbedTower</strong>。</li>
</ul>
<p>这样分与传统 <strong>PS</strong> 架构最大的差别就在于，<strong>Server 组</strong>内的节点也是有通信的，也是需要更新模型的了 (更详细的比较可以参考文献 [1]，说的很清楚)。好处是，当图片的数据量非常大的时候：</p>
<ol>
<li>每个图片原始特征只保存在单个 Server 上，节约了存储；</li>
<li>每个图片的 embedding 只需要计算一次，而且可以通过预计算，缓存以后供多个 Worker 查询；</li>
<li>压缩后的图片 embedding 数据量小，减小了数据传输消耗；</li>
</ol>
<p>文章号称在他们的场景下能节省 31 倍的存储开销和 340 倍的传输开销，而推理的时延仅仅增加了 3 毫秒。不过大家在各自具体场景中可能需要权衡一下性价比。</p>
<h3 id="DICM-模型"><a href="#DICM-模型" class="headerlink" title="DICM 模型"></a>DICM 模型</h3><p>从图 1 左图来看，<strong>DICM</strong> 模型整体就是一个简单的 Embedding + MLP 架构。其中，最关键的部分实际上就是用户视觉偏好抽取的部分（后面简称为 <strong>VisualPrefExtractor</strong>），也就是图片 <strong>EmbedTower</strong> 和基于用户图片历史和当前广告图片生成兴趣特征向量的部分。</p>
<p><strong>EmbedTower</strong> 前面简单介绍过了，这里需要说明的是，文章在保存图片原始特征的时候，并不是使用原始的像素值，而是经过预训练的 <strong>VGG16</strong> 第 14 层的 <strong>FC-4096</strong> 作为原始特征（如图 2 所示）。虽然 <strong>VGG16</strong> 的训练目标是图像分类的任务，但是这种任务学到的语义特征有比较好的泛化性能，而且由于是逐层处理，取靠前的参数实际上使用的是图像的一些基础元素的特征，这些特征再进一步通过广告 <strong>CTR</strong> 预估任务进行训练，这样就能够得到有用的高阶特征。文章也尝试了使用其他层的输出作为图片的原始特征：太靠近输出会损失性能；而越靠近输入端，参数越多，并且边际效益递减，因此这也只是一种权衡。另外，淘宝主要是买商品，使用 <strong>ImageNet</strong> 的预训练模型可能比较契合，我们在视频场景下就会发现，<strong>VGG16</strong> 对于人物的识别权重很低，因此可能又不太适用。</p>
<img src="/2019/11/24/paper-2018-ali-dicm/vgg16.png" title="图 2. 使用配置 D (VGG16) 中第 1 个 FC-4096 作为图片的原始特征，该配置参考文献 [2]">
<p>而为了抽取用户的视觉偏好，我们需要从用户图片历史序列中抽取出有效的特征。在用户行为非常丰富的场景，比如淘宝，用户的兴趣是多元化的，用户是不是点击某件 T-恤的广告，主要取决他历史上对衣服款式的喜好，而受他买零食、饮料、矿泉水的影响较小，因此需要引入注意力机制来针对不同的广告从用户图片历史中抽取出不同的特征表达。</p>
<img src="/2019/11/24/paper-2018-ali-dicm/attentive-pooling.png" title="图 3. 几种 Pooling 方式的比较，文章使用 (d) 所示的 AttentivePooling">
<p>文章使用的注意力机制还是比较简单的，如图 3 右图所示，就是将广告图片特征和用户每条历史图片特征拼接后，经过一个 $64\times 16\times 1$ 的 Tower，用来计算每条历史图片的权重，然后再加权对所有历史图片特征计算 sum pooling，得到用户视觉偏好表达。这里的广告图片特征和用户历史图片特征都是经过 <strong>EmbedTower</strong> 映射后的高阶表达。为了增强记忆能力，文章还使用了 <strong>ID</strong> 行为列表来做相似的处理，将得到的 embedding 与图像偏好的 embedding 拼接，即实现了 <strong>MultiQueryAttentivePooling</strong>，两者互为补充，效果得到进一步提升。</p>
<p>这种方式很容易扩展，比如可以简单的添加 <strong>TextPrefExtractor</strong>、<strong>AudioPrefExtractor</strong> 等其他多模态的偏好模型，而且由于这些多模态数据不与其他特征进行交叉，因此训练与推理都是相对独立的。<strong>VisualPrefExtractor</strong> 也可以作为子模型嵌入到双塔结构里做召回，或者嵌入其他复杂排序模型，如 <strong>DIN</strong> 等，作为特征抽取器。</p>
<p>根据这篇文章的说明，该模型至少在当时是承接了淘宝的主流量，因此在多模态方面还是十分值得借鉴的。</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] 一图胜千言: 解读阿里的Deep Image CTR Model. <a href="https://zhuanlan.zhihu.com/p/57056588" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/57056588</a>.</p>
<p>[2] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556 (2014).</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2019/11/16/paper-2019-google-mmoe-bias/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/16/paper-2019-google-mmoe-bias/" itemprop="url">MMoE-PosBias 论文精读</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-16T22:19:16+08:00">
                2019-11-16
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文精读/" itemprop="url" rel="index">
                    <span itemprop="name">论文精读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/11/16/paper-2019-google-mmoe-bias/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/11/16/paper-2019-google-mmoe-bias/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  5
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>Zhao, Zhe, et al. “Recommending what video to watch next: a multitask ranking system.” <em>Proceedings of the 13th ACM Conference on Recommender Systems</em>. ACM, 2019. </p>
</blockquote>
<p>本文是 Youtube 发表在 <strong>RecSys</strong> <strong>2019</strong> 上的文章，主要解决的问题是提升用户的总体满意度，同时减少推荐造成的用户选择偏差对推荐系统的影响。解决这些问题主要的挑战在于：</p>
<ol>
<li><strong>视频推荐中包含多个可能互相冲突的目标，难以权衡</strong>。视频推荐的目标大体可以分为 <strong>engagement objectives</strong> (例如点击、播放等)、<strong>satistaction objective</strong> (例如点赞、收藏、不喜欢等)，这两类目标可能有冲突，例如用户点赞的视频可能是他比较喜欢的严肃的视频，但是用户真正播放的视频可能是一些娱乐性比较强的。</li>
<li><strong>推荐系统会引入一些隐式的偏差，尤其是推荐位置导致的用户选择偏差</strong>。用户往往倾向于点位置靠前的视频，而这些视频可能并不是用户真实喜欢的视频。如果推荐模型使用带偏差的用户行为日志进行训练，会进一步强化这种偏差，导致恶性循环。</li>
<li><strong>多模态特征</strong>。多模态特征包括语音、视频 、图像、文本、ID 类特征、连续型特征等。使用多模态的特征有助于信息互补，例如我们希望对低层次内容特征进行映射来跨越语义鸿沟、用于基于内容的过滤；同时将稀疏分布的 ID 类特征用于协同过滤等。</li>
<li><strong>可扩展性</strong>。模型需要考虑线下训练和线上服务的性能，因此在保证学习效果的情况下，尽可能使用简单易扩展的网络架构。</li>
</ol>
<p>为了应对这些挑战，文章提出了如下图所示的排序网络架构。该网络接收用户当前播放的视频信息和上下文信息，对数百个召回视频进行排序。这里的召回需要是从不同的角度进行召回，例如基于内容相似的召回、基于协同过滤的召回等，文章使用了 <strong>Deep Candidate Generation</strong> 模型$^{[1]}$等来生成召回。</p>
<img src="/2019/11/16/paper-2019-google-mmoe-bias/overview.png" title="MMoE with PosBias 整体架构">
<p>排序的整体架构服从 <strong>Wide &amp; Deep</strong> 架构，如上图所示。其中，左边的 <strong>wide</strong> 层是一个浅层的 <strong>tower</strong> 网络，用于学习选择偏差，这个偏差在上层会与 <strong>user engagement</strong> 的输出相加，用于抵消选择偏差；右边的 <strong>deep</strong> 层是一个 <strong>MMoE</strong> 的多目标网络（<strong>MMoE</strong> 的解读可以参考 [2]），用于从不同模态特征中学习不同的专家网络，并学习多个 <strong>Gate</strong> 来对多个目标进行预测，最后再对多个目标进行权衡，这里不同的目标使用不同的损失函数，对于目标是连续值的，使用 <strong>MSE</strong> 进行回归，对于目标是离散值的，使用 <strong>logLoss</strong> 进行分类，最终多个目标的结果使用线性加权的方式计算出最终的得分，权重目标是作者手调的。从训练和预测的工程效率角度出发，文章选择了最简单的 <strong>point-wise ranking</strong> 方案。</p>
<img src="/2019/11/16/paper-2019-google-mmoe-bias/mmoe.png" title="MMoE 架构拆解">
<p>多目标的深度网络是整体架构的主要核心，文章先将所有原始的输入压缩成了一个共享的隐含层，再基于该隐含层构建了 <strong>MMoE</strong> 的网络，基于这些网络再进一步学习多个目标。其中：</p>
<ol>
<li><p>隐含层的设置主要是为了提高训练的效率。直接用原始特征来训练 <strong>MMoE</strong> 网络可能对多模态特征的学习更有利，但是由于原始特征的维度过高，直接基于原始特征进行训练代价过高。在学习 <strong>Gate</strong> 的时候，作者也尝试过直接用原始特征作为输入，但是比用共享隐含层作为输入没有显著提升。</p>
</li>
<li><p>使用 <strong>MoE</strong> 层比使用 <strong>shared-bottom</strong> 策略更有助于学习多模态特征，文章使用了少量的 <strong>Expert</strong> 网络，这样可以在不同的 <strong>Gate</strong> 中充分共享 <strong>Expert</strong> 网络参数，并且工程上效率更高。</p>
</li>
<li><p>每个目标使用一个 <strong>Gate</strong> 来对原始特征和专家网络进行激活，每个 task 预测结果的变换函数如下：</p>
<script type="math/tex; mode=display">
\begin{cases}
y_k=h^k(f^k(x)) \\
f^k(x)=\sum_{i=1}^n g_i^k(x)\cdot f_i(x) \\
g^k(x) = \text{softmax}(W_{g^k}\cdot x)
\end{cases}</script><p>其中，<script type="math/tex">x</script> 为共享隐含层，<script type="math/tex">f_i(x)</script> 为第 $i$ 个专家网络的输出，$n$ 为专家网络的个数，<script type="math/tex">W_{g^k}</script> 为第 $k$ 个 <strong>Gate</strong> 的网络参数，<script type="math/tex">h^k(x)</script> 为第 $k$ 个目标的隐含层。</p>
</li>
</ol>
<img src="/2019/11/16/paper-2019-google-mmoe-bias/bias.png" title="PosBias 架构拆解">
<p>为了减少由于推荐产生的用户选择偏差，文章又增加了一个浅层网络，如上图所示，输入是与偏差相关的特征（简称偏差特征），主要包括物品展示的位置特征和用户的设备信息。学习的时候，为了减少过位置的过分依赖，对所有偏差特征扫行 10% 的 <strong>dropout</strong>。</p>
<p>学习选择偏差的其他策略包括：直接把偏差特征作为输入的一部分进行训练，这种方式主要用于线性网络，在深度网络里效果不好；使用 <strong>Adversarial Learning</strong>，即将位置作为一个辅助的学习目标来预测。文章的实验结果也表明还是使用浅层网络的效果最好，直接将偏差特征作为输入的效果还不如不加偏差特征。</p>
<p>以上关于模型的部分其实简洁明了，没有太多的花招。但是特征层就难以企及了，而且在工程效率上必然也是困难重重，文章中工程的部分以后在应用的时候可能还需要再细细品读。</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ol>
<li>Covington, Paul , J. Adams , and E. Sargin . “<strong>Deep Neural Networks for YouTube Recommendations.</strong>“ <em>Acm Conference on Recommender Systems</em> ACM, 2016:191-198.</li>
<li><strong>MMoE 论文精读</strong>. <a href="https://guyuecanhui.github.io/2019/11/16/paper-2018-google-mmoe/">https://guyuecanhui.github.io/2019/11/16/paper-2018-google-mmoe/</a>.</li>
<li><strong>YouTube 多目标排序系统：如何推荐接下来收看的视频</strong>. <a href="https://www.infoq.cn/article/cZNdKS5ssPiqhjCyKQZ6" target="_blank" rel="noopener">https://www.infoq.cn/article/cZNdKS5ssPiqhjCyKQZ6</a>.</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2019/11/16/paper-2018-google-mmoe/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/16/paper-2018-google-mmoe/" itemprop="url">MMoE 论文精读</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-16T09:42:59+08:00">
                2019-11-16
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文精读/" itemprop="url" rel="index">
                    <span itemprop="name">论文精读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/11/16/paper-2018-google-mmoe/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/11/16/paper-2018-google-mmoe/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  914
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  3
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>论文引用: Ma, Jiaqi , et al. “Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts.” <em>the 24th ACM SIGKDD International Conference</em> ACM, 2018.</p>
</blockquote>
<p>本文是 Google 发表在 <strong>KDD 2018</strong> 的论文，不过感觉少了一些工程的加持，内容略显单薄。文章主要提出了一种多专家子网的结构，显式的从数据中学习多个任务之间的关系，并能够通过门限网络对每个任务进行单独的优化。与传统的 <strong>share-bottom</strong> 结构相比，这种结构在任务之间关联较弱时，仍然能够取得比较好的效果。</p>
<p>近年来，在推荐领域逐渐引入多任务学习来减轻一些使用单个模型指标可能带来的负面影响。例如在视频推荐中，只考虑点击转化率时，会倾向推荐包含标题党、擦边海报的视频；只考虑完成度时，会倾向推荐时间比较短的视频等等。而这些倾向都会影响用户体验，并且可能导致业务长期目标的下降。因此，大家开始尝试引入多个相互关联但又不一致的目标来进行综合考虑建模，并且实践表示，多任务学习在推荐系统中能够提升上下文推荐的效果。</p>
<p>传统的基于神经网络的多任务学习大致分为两类，一共是底层参数共享，即共享输入到中间层的参数，上层再分别对各个任务建模；一类是参数软共享，并不显式的共享底层参数，而是通过正则等对多个任务的参数进行相互约束。目前看到的比较多的是第一种，如下图 (a) 所示。而这种方式一般都假设多个任务的数据分布和目标都是相似的，当任务间差异变大时，对某些任务的预测性能就会产生较大的影响。然而实际任务的相关性都是难以度量的，因此效果实际上无法事先评估，只能靠不断尝试。</p>
<img src="/2019/11/16/paper-2018-google-mmoe/mmoe.png" title="MMOE 架构比较">
<p>本文的作者受到 <strong>MoE</strong> 网络$^{[1]}$的启发，在多任务学习中引入 <strong>MoE</strong> 层，来显式的对多个任务的关系进行建模，或者理解成学习所有任务的不同方面；再对每个任务学习一个门限网络，这个门限网络可以理解成这个任务在各个方面的特点。整体结构如上图 (c) 所示。其中，每个共享的子网称为一个 <strong>Expert</strong>，文章中的 <strong>Expert</strong> 都使用前馈网络，它的输入是原始特征（也可以是一个共享的隐含层，直接使用原始特征效果会更好，但是维度可能过高），输出为各个 <strong>Gate</strong> 的权重分布（<strong>softmax</strong>），可以理解成是这个 <strong>Expert</strong> 对不同任务的影响程度。研究已经表明在 <strong>DNN</strong> 中，使用这种集成模型和集成子网络的方式有助于提高模型的性能。</p>
<p>文章在公开数据集和 Google 数据上进行了大量的对比实验，结果表明：</p>
<ol>
<li><strong>MMoE</strong> 在任务相关性变弱的情况下，性能影响较小，因此实用性也更强；</li>
<li><strong>MMoE</strong> 的训练误差收敛更快更稳定，即可训练性更好；这也与近年研究得出的结论一致，即 <em>Modulation and gating mechanisms can improve the trainability in training non-convex deep nurual networks</em>。</li>
</ol>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ol>
<li>Jacobs, Robert A. , et al. “<strong>Adaptive Mixtures of Local Experts.</strong>“ <em>Neural Computation</em> 3.1(1991):79-87.</li>
<li><strong>keras-mmoe</strong>: <a href="https://github.com/drawbridge/keras-mmoe" target="_blank" rel="noopener">https://github.com/drawbridge/keras-mmoe</a>.</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2019/11/09/paper-2018-ali-esmm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/09/paper-2018-ali-esmm/" itemprop="url">ESMM 论文精读</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-09T20:16:34+08:00">
                2019-11-09
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文精读/" itemprop="url" rel="index">
                    <span itemprop="name">论文精读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/11/09/paper-2018-ali-esmm/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/11/09/paper-2018-ali-esmm/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.2k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  4
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>论文引用: Ma, Xiao, et al. “Entire space multi-task model: An effective approach for estimating post-click conversion rate.” The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval. ACM, 2018.</p>
</blockquote>
<p>本文是阿里发表在 <strong>SIGIR 2018</strong> 年的短文，主要解决了精确预估 <strong>CVR</strong> 的问题。<strong>CVR</strong> 预估是最大化场景商品交易总额 (<strong>GMV</strong>=<code>流量×点击率×转化率×客单价</code>) 的重要因子，它可以用于 <strong>OCPC</strong> 模式下动态调整出价来使平台和广告主共同受益；并且从用户体验的角度来说，准确预估的 <strong>CVR</strong> 被用来平衡用户的点击偏好与购买偏好。文章认为当前的 <strong>CVR</strong> 预估主要存在两个问题：</p>
<ol>
<li><strong>Sample Selection Bias (SSB)</strong>：当前 <strong>CVR</strong> 预估是基于 <code>点击-&gt;转化</code> 数据进行训练的，而有点击的展示数据只是所有展示数据中的一小部分 (如下图所示)，这部分数据的分布与整体的分布通常并不一致。而在实际 serving 的时候，模型又是对整个空间中的所有样本进行预测，因此模型的泛化效果会受到影响。</li>
<li><strong>Data Sparsity (DS)</strong>：与前一个问题的根因相同，只使用点击数据会存在严重的数据稀疏问题。</li>
</ol>
<img src="/2019/11/09/paper-2018-ali-esmm/esmm-ssb.png" title="用户展示-点击-转化行为关系示意">
<p>业界也提出过一些解决这两个问题的方案：</p>
<ol>
<li><strong>SSB Solution</strong>：<strong>AMAN 方法</strong> 将所有展示未点击的数据也作为负样本进行训练，但是这种方法天然会导致 CVR 被低估 (因为对于一些展示未点击的物品，可能是因为用户并没有关注到，或者用户已经点击了其他的条目而遗漏，并非是真正不会产生转化的物品)；<strong>无偏估计方法</strong> 通过拒绝采样的方法来保证预估的 CVR 与真实的观察一致，但是这种方法在计算过程中会除以一个很小的数，因此可能导致数值不稳定的问题。</li>
<li><strong>DS Solution</strong>：<strong>分层建模方法</strong>使用不同的特征构建多个预估模型，然后使用 <strong>LR</strong> 等模型将这些模型的结果汇总，这种方法需要比较可靠的先验知识来构建分层模型，在数据量大的推荐场景下难以实现；<strong>过采样方法</strong>将数据量少的类别样本进行过采样，但是对采样参数十分敏感。</li>
</ol>
<p>文章在已有工作的基础上，提出使用多任务学习的框架，使用所有 <code>展示-&gt;点击-&gt;转化</code> 数据进行训练，将 <strong>CVR</strong> 预测问题转变为同时预测 <strong>CTR</strong> 和 <strong>CTCVR</strong> 的问题。由于使用所有展示样本，因此不存在 <strong>SSB</strong> 问题；在多任务学习下共享 embedding 向量，实际上是一种参数迁移学习，可以有效的解决 <strong>DS</strong> 问题。</p>
<p>具体来讲，将一个样本记为 $(\boldsymbol{x},y\rightarrow z)$，其中，$\boldsymbol{x}$ 表示样本特征，$y$ 表示是否点击，$z$ 表示是否转化。则：</p>
<script type="math/tex; mode=display">
\begin{cases}
pCTCVR = p(z=1,y=1|\boldsymbol{x}) = pCTR\times pCVR \\
pCTR = p(y=1|\boldsymbol{x})\\
pCVR = p(z=1|\boldsymbol{x},y=1)
\end{cases}</script><p>由于这三个变量的自由度为 2，因此损失函数只需要计算其中两个即可。文章将损失函数设计为 <strong>CTR</strong> 和 <strong>CTCVR</strong> 的预测损失，如下所示：</p>
<script type="math/tex; mode=display">
L(\theta_{cvr},\theta_{ctr}) = \sum_{i=1}^N l(y_i, f(\boldsymbol{x}_i;\theta_{ctr})) + \sum_{i=1}^N l(y_i\&z_i, f(\boldsymbol{x}_i;\theta_{ctr})\times f(\boldsymbol{x}_i;\theta_{cvr}))</script><p>整体网络架构如下图所示：</p>
<img src="/2019/11/09/paper-2018-ali-esmm/esmm-architect.png" title="ESMM 网络整体架构">
<p>可以看到，两个任务共享底层 embedding，同时通过顶层的 <strong>Dot</strong> 算子进行关联。文章没有将 <strong>pCVR</strong> 作为最终输出的结果，是因为 $pCVR = \frac{pCTCVR}{pCTR}$，如果将 <strong>pCVR</strong> 作为最终输出，则最后一步为除法算子，而除法具有数值不稳定性，可能会得出 $pCVR&gt;1$ 的情况，因此将 <strong>pCTCVR</strong> 作为最终输出的结果，这样能够保证 <strong>pCVR</strong> 的结果在 $[0,1]$ 范围内，避免了数值不稳定的问题。</p>
<p>文章在淘宝数据上与现有解决 <strong>SSB</strong> 和 <strong>DS</strong> 问题的几个策略进行了对比验证，发现基于 <strong>ESSM</strong> 模型的 <strong>CVR</strong> 和 <strong>CTCVR</strong> 预估任务的 <strong>AUC</strong> 是最高的。而且文章还发表了一个 mini 公开数据集，诚意满满~</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ol>
<li><strong>XDL ESSM</strong>: <a href="https://github.com/alibaba/x-deeplearning/tree/master/xdl-algorithm-solution/ESMM" target="_blank" rel="noopener">https://github.com/alibaba/x-deeplearning/tree/master/xdl-algorithm-solution/ESMM</a></li>
<li><strong>完整空间多任务模型：CVR预估的有效方法</strong>: <a href="http://xudongyang.coding.me/esmm/" target="_blank" rel="noopener">http://xudongyang.coding.me/esmm/</a></li>
<li><strong>构建分布式Tensorflow模型系列之CVR预估案例ESMM模型</strong>: <a href="http://xudongyang.coding.me/esmm-1/" target="_blank" rel="noopener">http://xudongyang.coding.me/esmm-1/</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">古月残辉</p>
              <p class="site-description motion-element" itemprop="description">总结心得</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">29</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">66</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="mailto:guyuecanhui@icloud.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 &mdash; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">古月残辉</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">48.2k</span>
  
</div>









<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: '6du4Ppc2TvUuhcccRHSDNH2v-gzGzoHsz',
        appKey: 'zOKNml4W1Bq3OTzEuLt5hUjI',
        placeholder: '感谢阅读！欢迎评论！',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
