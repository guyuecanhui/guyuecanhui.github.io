<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">





  <link rel="alternate" href="/atom.xml" title="HCigmoid" type="application/atom+xml">






<meta name="description" content="总结心得">
<meta name="keywords" content="feature, model, algorithm">
<meta property="og:type" content="website">
<meta property="og:title" content="HCigmoid">
<meta property="og:url" content="https://guyuecanhui.github.io/index.html">
<meta property="og:site_name" content="HCigmoid">
<meta property="og:description" content="总结心得">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="HCigmoid">
<meta name="twitter:description" content="总结心得">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://guyuecanhui.github.io/">





  <title>HCigmoid</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">HCigmoid</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Watch, learn and practise</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2019/11/24/paper-2018-ali-dicm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/24/paper-2018-ali-dicm/" itemprop="url">DICM with AMS 论文精读</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-24T21:50:20+08:00">
                2019-11-24
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文精读/" itemprop="url" rel="index">
                    <span itemprop="name">论文精读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/11/24/paper-2018-ali-dicm/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/11/24/paper-2018-ali-dicm/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.1k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  7
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>论文引用：Ge, Tiezheng , et al. “Image Matters: Visually modeling user behaviors using Advanced Model Server.” (2018).</p>
</blockquote>
<p>本文是阿里发表在 <strong>CIKM 2018</strong> 上的文章，主要思路是将用户历史有过行为 (文章实际使用了点击行为) 的图片来对用户视觉兴趣进行建模，在广告 <strong>CTR</strong> 预估时就能够估计用户对广告图片的喜好，从而提升 <strong>CTR</strong> 预估的准确率。由于用户在商品页面行为历史通常较为丰富，因此训练样本中会包含大量的图片特征，这些特征使用传统的 <strong>PS</strong> 架构无法有效训练，因此文章提出了 <strong>AMS</strong> (<em>Advanced Model Server</em>) 架构，能够平衡存储和通信开销，使得天级更新模型成为可能。这篇文章主要的贡献也是在工程实现方面。</p>
<h3 id="背景和动机"><a href="#背景和动机" class="headerlink" title="背景和动机"></a>背景和动机</h3><p>广告 <strong>CTR</strong> 预估是广告系统中至关重要的环节，传统的 (非多模态) 预估模型，主要是使用一些 <strong>ID</strong> 和交叉统计之类的特征，但是由于 <strong>ID</strong> 没有语义，我们无法判断两个 <strong>ID</strong> 是不是有相关性，因此这些模型对于出现频次少或者新出现的 <strong>ID</strong> 无法充分训练，即存在冷启动的问题。</p>
<p>解决冷启动问题通常会想到引入内容特征，而在电商领域，图片就是能够描述广告/商品的最直观且最受用户关注的内容特征。用户在购买商品的时候，通常会点击、浏览商品的图片，结合商品的描述、评论等其他信息来决定是否购买，因此用户曾经点击过的图片能够在很大程度上表征用户的兴趣。而用户是否点击广告，图片、标题等信息是影响最大的因素。因此，文章就考虑使用用户点击过的图片来建立用户的兴趣模型，再与广告的图片进行匹配，从而估计用户在视觉层面是否对该广告有兴趣；将这方面的估计与传统的基于 <strong>ID</strong> 等特征的估计相结合，来提升 <strong>CTR</strong> 估计的性能。基于这个思路，文章提出了 <strong>DICM</strong> (<em>Deep Image CTR Model</em>)。 </p>
<p>使用用户图片历史来建立用户视觉偏好主要的问题就是数据传输和存储，如果使用传统的 <strong>PS</strong> 架构，图片数据是保存在 <strong>KV Store</strong> 里（也就是参数服务器），谁用谁来查一下，而图片的数量和数据量都是相对较大的，因此这种方式十分消耗资源，并且这种方式也难以针对 <strong>CTR</strong> 预估任务对预训练的图片特征进行进一步的组合和压缩，即图片数据不是目标相关的。文章针对这个问题，提出了一种扩展 <strong>PS</strong> 架构，称为 <strong>AMS</strong> 架构。下面就详细的介绍这两方面的工作。</p>
<h3 id="AMS-架构"><a href="#AMS-架构" class="headerlink" title="AMS 架构"></a>AMS 架构</h3><p>如上所述，文章在实现 <strong>DICM</strong> 模型时，实际上是基于 <strong>AMS</strong> 架构的。<strong>AMS</strong> 架构整体如图 1 右图所示：</p>
<img src="/2019/11/24/paper-2018-ali-dicm/ams-architecture.png" title="图 1. AMS 架构及基于 AMS 架构实现的 DICM 模型">
<p><strong>AMS</strong> 将节点分为 <strong>Worker</strong> 和 <strong>Server</strong> 组：</p>
<ul>
<li><strong>Server 组</strong>：保存图片原始特征数据（考虑到端到端训练和推理的时延，这里取的是预训练模型的低阶隐层输出），并且负责将图片原始特征数据映射到任务空间的高阶表达，实际上就是学一个 Tower 模型，这个 Tower 模型是所有 Server 共享的。使用这个图片 <strong>EmbedTower</strong>，可以将图片原始特征数据极大的压缩（文章使用 $4096\times 256\times 64\times 12$ 的 Tower，可以将数据量减少 340 多倍），Worker 查询的时候传输数据量就大大减少了。</li>
<li><strong>Worker 组</strong>：从 <strong>Server 组</strong>查询样本的各维特征（包括 <strong>ID</strong> embedding 和图片的高阶 embedding 等），将特征组合后进行推理；训练时还要将损失梯度传回 Server，用来更新图片 <strong>EmbedTower</strong>。</li>
</ul>
<p>这样分与传统 <strong>PS</strong> 架构最大的差别就在于，<strong>Server 组</strong>内的节点也是有通信的，也是需要更新模型的了 (更详细的比较可以参考文献 [1]，说的很清楚)。好处是，当图片的数据量非常大的时候：</p>
<ol>
<li>每个图片原始特征只保存在单个 Server 上，节约了存储；</li>
<li>每个图片的 embedding 只需要计算一次，而且可以通过预计算，缓存以后供多个 Worker 查询；</li>
<li>压缩后的图片 embedding 数据量小，减小了数据传输消耗；</li>
</ol>
<p>文章号称在他们的场景下能节省 31 倍的存储开销和 340 倍的传输开销，而推理的时延仅仅增加了 3 毫秒。不过大家在各自具体场景中可能需要权衡一下性价比。</p>
<h3 id="DICM-模型"><a href="#DICM-模型" class="headerlink" title="DICM 模型"></a>DICM 模型</h3><p>从图 1 左图来看，<strong>DICM</strong> 模型整体就是一个简单的 Embedding + MLP 架构。其中，最关键的部分实际上就是用户视觉偏好抽取的部分（后面简称为 <strong>VisualPrefExtractor</strong>），也就是图片 <strong>EmbedTower</strong> 和基于用户图片历史和当前广告图片生成兴趣特征向量的部分。</p>
<p><strong>EmbedTower</strong> 前面简单介绍过了，这里需要说明的是，文章在保存图片原始特征的时候，并不是使用原始的像素值，而是经过预训练的 <strong>VGG16</strong> 第 14 层的 <strong>FC-4096</strong> 作为原始特征（如图 2 所示）。虽然 <strong>VGG16</strong> 的训练目标是图像分类的任务，但是这种任务学到的语义特征有比较好的泛化性能，而且由于是逐层处理，取靠前的参数实际上使用的是图像的一些基础元素的特征，这些特征再进一步通过广告 <strong>CTR</strong> 预估任务进行训练，这样就能够得到有用的高阶特征。文章也尝试了使用其他层的输出作为图片的原始特征：太靠近输出会损失性能；而越靠近输入端，参数越多，并且边际效益递减，因此这也只是一种权衡。另外，淘宝主要是买商品，使用 <strong>ImageNet</strong> 的预训练模型可能比较契合，我们在视频场景下就会发现，<strong>VGG16</strong> 对于人物的识别权重很低，因此可能又不太适用。</p>
<img src="/2019/11/24/paper-2018-ali-dicm/vgg16.png" title="图 2. 使用配置 D (VGG16) 中第 1 个 FC-4096 作为图片的原始特征，该配置参考文献 [2]">
<p>而为了抽取用户的视觉偏好，我们需要从用户图片历史序列中抽取出有效的特征。在用户行为非常丰富的场景，比如淘宝，用户的兴趣是多元化的，用户是不是点击某件 T-恤的广告，主要取决他历史上对衣服款式的喜好，而受他买零食、饮料、矿泉水的影响较小，因此需要引入注意力机制来针对不同的广告从用户图片历史中抽取出不同的特征表达。</p>
<img src="/2019/11/24/paper-2018-ali-dicm/attentive-pooling.png" title="图 3. 几种 Pooling 方式的比较，文章使用 (d) 所示的 AttentivePooling">
<p>文章使用的注意力机制还是比较简单的，如图 3 右图所示，就是将广告图片特征和用户每条历史图片特征拼接后，经过一个 $64\times 16\times 1$ 的 Tower，用来计算每条历史图片的权重，然后再加权对所有历史图片特征计算 sum pooling，得到用户视觉偏好表达。这里的广告图片特征和用户历史图片特征都是经过 <strong>EmbedTower</strong> 映射后的高阶表达。为了增强记忆能力，文章还使用了 <strong>ID</strong> 行为列表来做相似的处理，将得到的 embedding 与图像偏好的 embedding 拼接，即实现了 <strong>MultiQueryAttentivePooling</strong>，两者互为补充，效果得到进一步提升。</p>
<p>这种方式很容易扩展，比如可以简单的添加 <strong>TextPrefExtractor</strong>、<strong>AudioPrefExtractor</strong> 等其他多模态的偏好模型，而且由于这些多模态数据不与其他特征进行交叉，因此训练与推理都是相对独立的。<strong>VisualPrefExtractor</strong> 也可以作为子模型嵌入到双塔结构里做召回，或者嵌入其他复杂排序模型，如 <strong>DIN</strong> 等，作为特征抽取器。</p>
<p>根据这篇文章的说明，该模型至少在当时是承接了淘宝的主流量，因此在多模态方面还是十分值得借鉴的。</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] 一图胜千言: 解读阿里的Deep Image CTR Model. <a href="https://zhuanlan.zhihu.com/p/57056588" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/57056588</a>.</p>
<p>[2] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556 (2014).</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2019/11/16/paper-2019-google-mmoe-bias/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/16/paper-2019-google-mmoe-bias/" itemprop="url">MMoE-PosBias 论文精读</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-16T22:19:16+08:00">
                2019-11-16
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文精读/" itemprop="url" rel="index">
                    <span itemprop="name">论文精读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/11/16/paper-2019-google-mmoe-bias/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/11/16/paper-2019-google-mmoe-bias/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  5
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>Zhao, Zhe, et al. “Recommending what video to watch next: a multitask ranking system.” <em>Proceedings of the 13th ACM Conference on Recommender Systems</em>. ACM, 2019. </p>
</blockquote>
<p>本文是 Youtube 发表在 <strong>RecSys</strong> <strong>2019</strong> 上的文章，主要解决的问题是提升用户的总体满意度，同时减少推荐造成的用户选择偏差对推荐系统的影响。解决这些问题主要的挑战在于：</p>
<ol>
<li><strong>视频推荐中包含多个可能互相冲突的目标，难以权衡</strong>。视频推荐的目标大体可以分为 <strong>engagement objectives</strong> (例如点击、播放等)、<strong>satistaction objective</strong> (例如点赞、收藏、不喜欢等)，这两类目标可能有冲突，例如用户点赞的视频可能是他比较喜欢的严肃的视频，但是用户真正播放的视频可能是一些娱乐性比较强的。</li>
<li><strong>推荐系统会引入一些隐式的偏差，尤其是推荐位置导致的用户选择偏差</strong>。用户往往倾向于点位置靠前的视频，而这些视频可能并不是用户真实喜欢的视频。如果推荐模型使用带偏差的用户行为日志进行训练，会进一步强化这种偏差，导致恶性循环。</li>
<li><strong>多模态特征</strong>。多模态特征包括语音、视频 、图像、文本、ID 类特征、连续型特征等。使用多模态的特征有助于信息互补，例如我们希望对低层次内容特征进行映射来跨越语义鸿沟、用于基于内容的过滤；同时将稀疏分布的 ID 类特征用于协同过滤等。</li>
<li><strong>可扩展性</strong>。模型需要考虑线下训练和线上服务的性能，因此在保证学习效果的情况下，尽可能使用简单易扩展的网络架构。</li>
</ol>
<p>为了应对这些挑战，文章提出了如下图所示的排序网络架构。该网络接收用户当前播放的视频信息和上下文信息，对数百个召回视频进行排序。这里的召回需要是从不同的角度进行召回，例如基于内容相似的召回、基于协同过滤的召回等，文章使用了 <strong>Deep Candidate Generation</strong> 模型$^{[1]}$等来生成召回。</p>
<img src="/2019/11/16/paper-2019-google-mmoe-bias/overview.png" title="MMoE with PosBias 整体架构">
<p>排序的整体架构服从 <strong>Wide &amp; Deep</strong> 架构，如上图所示。其中，左边的 <strong>wide</strong> 层是一个浅层的 <strong>tower</strong> 网络，用于学习选择偏差，这个偏差在上层会与 <strong>user engagement</strong> 的输出相加，用于抵消选择偏差；右边的 <strong>deep</strong> 层是一个 <strong>MMoE</strong> 的多目标网络（<strong>MMoE</strong> 的解读可以参考 [2]），用于从不同模态特征中学习不同的专家网络，并学习多个 <strong>Gate</strong> 来对多个目标进行预测，最后再对多个目标进行权衡，这里不同的目标使用不同的损失函数，对于目标是连续值的，使用 <strong>MSE</strong> 进行回归，对于目标是离散值的，使用 <strong>logLoss</strong> 进行分类，最终多个目标的结果使用线性加权的方式计算出最终的得分，权重目标是作者手调的。从训练和预测的工程效率角度出发，文章选择了最简单的 <strong>point-wise ranking</strong> 方案。</p>
<img src="/2019/11/16/paper-2019-google-mmoe-bias/mmoe.png" title="MMoE 架构拆解">
<p>多目标的深度网络是整体架构的主要核心，文章先将所有原始的输入压缩成了一个共享的隐含层，再基于该隐含层构建了 <strong>MMoE</strong> 的网络，基于这些网络再进一步学习多个目标。其中：</p>
<ol>
<li><p>隐含层的设置主要是为了提高训练的效率。直接用原始特征来训练 <strong>MMoE</strong> 网络可能对多模态特征的学习更有利，但是由于原始特征的维度过高，直接基于原始特征进行训练代价过高。在学习 <strong>Gate</strong> 的时候，作者也尝试过直接用原始特征作为输入，但是比用共享隐含层作为输入没有显著提升。</p>
</li>
<li><p>使用 <strong>MoE</strong> 层比使用 <strong>shared-bottom</strong> 策略更有助于学习多模态特征，文章使用了少量的 <strong>Expert</strong> 网络，这样可以在不同的 <strong>Gate</strong> 中充分共享 <strong>Expert</strong> 网络参数，并且工程上效率更高。</p>
</li>
<li><p>每个目标使用一个 <strong>Gate</strong> 来对原始特征和专家网络进行激活，每个 task 预测结果的变换函数如下：</p>
<script type="math/tex; mode=display">
\begin{cases}
y_k=h^k(f^k(x)) \\
f^k(x)=\sum_{i=1}^n g_i^k(x)\cdot f_i(x) \\
g^k(x) = \text{softmax}(W_{g^k}\cdot x)
\end{cases}</script><p>其中，<script type="math/tex">x</script> 为共享隐含层，<script type="math/tex">f_i(x)</script> 为第 $i$ 个专家网络的输出，$n$ 为专家网络的个数，<script type="math/tex">W_{g^k}</script> 为第 $k$ 个 <strong>Gate</strong> 的网络参数，<script type="math/tex">h^k(x)</script> 为第 $k$ 个目标的隐含层。</p>
</li>
</ol>
<img src="/2019/11/16/paper-2019-google-mmoe-bias/bias.png" title="PosBias 架构拆解">
<p>为了减少由于推荐产生的用户选择偏差，文章又增加了一个浅层网络，如上图所示，输入是与偏差相关的特征（简称偏差特征），主要包括物品展示的位置特征和用户的设备信息。学习的时候，为了减少过位置的过分依赖，对所有偏差特征扫行 10% 的 <strong>dropout</strong>。</p>
<p>学习选择偏差的其他策略包括：直接把偏差特征作为输入的一部分进行训练，这种方式主要用于线性网络，在深度网络里效果不好；使用 <strong>Adversarial Learning</strong>，即将位置作为一个辅助的学习目标来预测。文章的实验结果也表明还是使用浅层网络的效果最好，直接将偏差特征作为输入的效果还不如不加偏差特征。</p>
<p>以上关于模型的部分其实简洁明了，没有太多的花招。但是特征层就难以企及了，而且在工程效率上必然也是困难重重，文章中工程的部分以后在应用的时候可能还需要再细细品读。</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ol>
<li>Covington, Paul , J. Adams , and E. Sargin . “<strong>Deep Neural Networks for YouTube Recommendations.</strong>“ <em>Acm Conference on Recommender Systems</em> ACM, 2016:191-198.</li>
<li><strong>MMoE 论文精读</strong>. <a href="https://guyuecanhui.github.io/2019/11/16/paper-2018-google-mmoe/">https://guyuecanhui.github.io/2019/11/16/paper-2018-google-mmoe/</a>.</li>
<li><strong>YouTube 多目标排序系统：如何推荐接下来收看的视频</strong>. <a href="https://www.infoq.cn/article/cZNdKS5ssPiqhjCyKQZ6" target="_blank" rel="noopener">https://www.infoq.cn/article/cZNdKS5ssPiqhjCyKQZ6</a>.</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2019/11/16/paper-2018-google-mmoe/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/16/paper-2018-google-mmoe/" itemprop="url">MMoE 论文精读</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-16T09:42:59+08:00">
                2019-11-16
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文精读/" itemprop="url" rel="index">
                    <span itemprop="name">论文精读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/11/16/paper-2018-google-mmoe/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/11/16/paper-2018-google-mmoe/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  914
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  3
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>论文引用: Ma, Jiaqi , et al. “Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts.” <em>the 24th ACM SIGKDD International Conference</em> ACM, 2018.</p>
</blockquote>
<p>本文是 Google 发表在 <strong>KDD 2018</strong> 的论文，不过感觉少了一些工程的加持，内容略显单薄。文章主要提出了一种多专家子网的结构，显式的从数据中学习多个任务之间的关系，并能够通过门限网络对每个任务进行单独的优化。与传统的 <strong>share-bottom</strong> 结构相比，这种结构在任务之间关联较弱时，仍然能够取得比较好的效果。</p>
<p>近年来，在推荐领域逐渐引入多任务学习来减轻一些使用单个模型指标可能带来的负面影响。例如在视频推荐中，只考虑点击转化率时，会倾向推荐包含标题党、擦边海报的视频；只考虑完成度时，会倾向推荐时间比较短的视频等等。而这些倾向都会影响用户体验，并且可能导致业务长期目标的下降。因此，大家开始尝试引入多个相互关联但又不一致的目标来进行综合考虑建模，并且实践表示，多任务学习在推荐系统中能够提升上下文推荐的效果。</p>
<p>传统的基于神经网络的多任务学习大致分为两类，一共是底层参数共享，即共享输入到中间层的参数，上层再分别对各个任务建模；一类是参数软共享，并不显式的共享底层参数，而是通过正则等对多个任务的参数进行相互约束。目前看到的比较多的是第一种，如下图 (a) 所示。而这种方式一般都假设多个任务的数据分布和目标都是相似的，当任务间差异变大时，对某些任务的预测性能就会产生较大的影响。然而实际任务的相关性都是难以度量的，因此效果实际上无法事先评估，只能靠不断尝试。</p>
<img src="/2019/11/16/paper-2018-google-mmoe/mmoe.png" title="MMOE 架构比较">
<p>本文的作者受到 <strong>MoE</strong> 网络$^{[1]}$的启发，在多任务学习中引入 <strong>MoE</strong> 层，来显式的对多个任务的关系进行建模，或者理解成学习所有任务的不同方面；再对每个任务学习一个门限网络，这个门限网络可以理解成这个任务在各个方面的特点。整体结构如上图 (c) 所示。其中，每个共享的子网称为一个 <strong>Expert</strong>，文章中的 <strong>Expert</strong> 都使用前馈网络，它的输入是原始特征（也可以是一个共享的隐含层，直接使用原始特征效果会更好，但是维度可能过高），输出为各个 <strong>Gate</strong> 的权重分布（<strong>softmax</strong>），可以理解成是这个 <strong>Expert</strong> 对不同任务的影响程度。研究已经表明在 <strong>DNN</strong> 中，使用这种集成模型和集成子网络的方式有助于提高模型的性能。</p>
<p>文章在公开数据集和 Google 数据上进行了大量的对比实验，结果表明：</p>
<ol>
<li><strong>MMoE</strong> 在任务相关性变弱的情况下，性能影响较小，因此实用性也更强；</li>
<li><strong>MMoE</strong> 的训练误差收敛更快更稳定，即可训练性更好；这也与近年研究得出的结论一致，即 <em>Modulation and gating mechanisms can improve the trainability in training non-convex deep nurual networks</em>。</li>
</ol>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ol>
<li>Jacobs, Robert A. , et al. “<strong>Adaptive Mixtures of Local Experts.</strong>“ <em>Neural Computation</em> 3.1(1991):79-87.</li>
<li><strong>keras-mmoe</strong>: <a href="https://github.com/drawbridge/keras-mmoe" target="_blank" rel="noopener">https://github.com/drawbridge/keras-mmoe</a>.</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2019/11/09/paper-2018-ali-esmm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/09/paper-2018-ali-esmm/" itemprop="url">ESMM 论文精读</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-09T20:16:34+08:00">
                2019-11-09
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文精读/" itemprop="url" rel="index">
                    <span itemprop="name">论文精读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/11/09/paper-2018-ali-esmm/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/11/09/paper-2018-ali-esmm/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.2k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  4
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>论文引用: Ma, Xiao, et al. “Entire space multi-task model: An effective approach for estimating post-click conversion rate.” The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval. ACM, 2018.</p>
</blockquote>
<p>本文是阿里发表在 <strong>SIGIR 2018</strong> 年的短文，主要解决了精确预估 <strong>CVR</strong> 的问题。<strong>CVR</strong> 预估是最大化场景商品交易总额 (<strong>GMV</strong>=<code>流量×点击率×转化率×客单价</code>) 的重要因子，它可以用于 <strong>OCPC</strong> 模式下动态调整出价来使平台和广告主共同受益；并且从用户体验的角度来说，准确预估的 <strong>CVR</strong> 被用来平衡用户的点击偏好与购买偏好。文章认为当前的 <strong>CVR</strong> 预估主要存在两个问题：</p>
<ol>
<li><strong>Sample Selection Bias (SSB)</strong>：当前 <strong>CVR</strong> 预估是基于 <code>点击-&gt;转化</code> 数据进行训练的，而有点击的展示数据只是所有展示数据中的一小部分 (如下图所示)，这部分数据的分布与整体的分布通常并不一致。而在实际 serving 的时候，模型又是对整个空间中的所有样本进行预测，因此模型的泛化效果会受到影响。</li>
<li><strong>Data Sparsity (DS)</strong>：与前一个问题的根因相同，只使用点击数据会存在严重的数据稀疏问题。</li>
</ol>
<img src="/2019/11/09/paper-2018-ali-esmm/esmm-ssb.png" title="用户展示-点击-转化行为关系示意">
<p>业界也提出过一些解决这两个问题的方案：</p>
<ol>
<li><strong>SSB Solution</strong>：<strong>AMAN 方法</strong> 将所有展示未点击的数据也作为负样本进行训练，但是这种方法天然会导致 CVR 被低估 (因为对于一些展示未点击的物品，可能是因为用户并没有关注到，或者用户已经点击了其他的条目而遗漏，并非是真正不会产生转化的物品)；<strong>无偏估计方法</strong> 通过拒绝采样的方法来保证预估的 CVR 与真实的观察一致，但是这种方法在计算过程中会除以一个很小的数，因此可能导致数值不稳定的问题。</li>
<li><strong>DS Solution</strong>：<strong>分层建模方法</strong>使用不同的特征构建多个预估模型，然后使用 <strong>LR</strong> 等模型将这些模型的结果汇总，这种方法需要比较可靠的先验知识来构建分层模型，在数据量大的推荐场景下难以实现；<strong>过采样方法</strong>将数据量少的类别样本进行过采样，但是对采样参数十分敏感。</li>
</ol>
<p>文章在已有工作的基础上，提出使用多任务学习的框架，使用所有 <code>展示-&gt;点击-&gt;转化</code> 数据进行训练，将 <strong>CVR</strong> 预测问题转变为同时预测 <strong>CTR</strong> 和 <strong>CTCVR</strong> 的问题。由于使用所有展示样本，因此不存在 <strong>SSB</strong> 问题；在多任务学习下共享 embedding 向量，实际上是一种参数迁移学习，可以有效的解决 <strong>DS</strong> 问题。</p>
<p>具体来讲，将一个样本记为 $(\boldsymbol{x},y\rightarrow z)$，其中，$\boldsymbol{x}$ 表示样本特征，$y$ 表示是否点击，$z$ 表示是否转化。则：</p>
<script type="math/tex; mode=display">
\begin{cases}
pCTCVR = p(z=1,y=1|\boldsymbol{x}) = pCTR\times pCVR \\
pCTR = p(y=1|\boldsymbol{x})\\
pCVR = p(z=1|\boldsymbol{x},y=1)
\end{cases}</script><p>由于这三个变量的自由度为 2，因此损失函数只需要计算其中两个即可。文章将损失函数设计为 <strong>CTR</strong> 和 <strong>CTCVR</strong> 的预测损失，如下所示：</p>
<script type="math/tex; mode=display">
L(\theta_{cvr},\theta_{ctr}) = \sum_{i=1}^N l(y_i, f(\boldsymbol{x}_i;\theta_{ctr})) + \sum_{i=1}^N l(y_i\&z_i, f(\boldsymbol{x}_i;\theta_{ctr})\times f(\boldsymbol{x}_i;\theta_{cvr}))</script><p>整体网络架构如下图所示：</p>
<img src="/2019/11/09/paper-2018-ali-esmm/esmm-architect.png" title="ESMM 网络整体架构">
<p>可以看到，两个任务共享底层 embedding，同时通过顶层的 <strong>Dot</strong> 算子进行关联。文章没有将 <strong>pCVR</strong> 作为最终输出的结果，是因为 $pCVR = \frac{pCTCVR}{pCTR}$，如果将 <strong>pCVR</strong> 作为最终输出，则最后一步为除法算子，而除法具有数值不稳定性，可能会得出 $pCVR&gt;1$ 的情况，因此将 <strong>pCTCVR</strong> 作为最终输出的结果，这样能够保证 <strong>pCVR</strong> 的结果在 $[0,1]$ 范围内，避免了数值不稳定的问题。</p>
<p>文章在淘宝数据上与现有解决 <strong>SSB</strong> 和 <strong>DS</strong> 问题的几个策略进行了对比验证，发现基于 <strong>ESSM</strong> 模型的 <strong>CVR</strong> 和 <strong>CTCVR</strong> 预估任务的 <strong>AUC</strong> 是最高的。而且文章还发表了一个 mini 公开数据集，诚意满满~</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ol>
<li><strong>XDL ESSM</strong>: <a href="https://github.com/alibaba/x-deeplearning/tree/master/xdl-algorithm-solution/ESMM" target="_blank" rel="noopener">https://github.com/alibaba/x-deeplearning/tree/master/xdl-algorithm-solution/ESMM</a></li>
<li><strong>完整空间多任务模型：CVR预估的有效方法</strong>: <a href="http://xudongyang.coding.me/esmm/" target="_blank" rel="noopener">http://xudongyang.coding.me/esmm/</a></li>
<li><strong>构建分布式Tensorflow模型系列之CVR预估案例ESMM模型</strong>: <a href="http://xudongyang.coding.me/esmm-1/" target="_blank" rel="noopener">http://xudongyang.coding.me/esmm-1/</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2019/08/18/conjugate-priors-video-quality/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/18/conjugate-priors-video-quality/" itemprop="url">例解共轭分布之视频质量评估</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-18T10:47:06+08:00">
                2019-08-18
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/数学/" itemprop="url" rel="index">
                    <span itemprop="name">数学</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/08/18/conjugate-priors-video-quality/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/08/18/conjugate-priors-video-quality/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  9
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在推荐领域阅读文献的时候，我们常常会遇到共轭分布、共轭先验 (<strong>conjugate prior</strong>) 之类的概念。由于共轭这个翻译实在不太直观，因此这些概念也很难理解，我想结合两个视频推荐中的例子来尝试说明这些概念。今天先介绍视频质量评估的例子。</p>
<h3 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h3><p>如何评估一个视频的质量是视频推荐中非常重要但是又很让人头疼的事情。尤其是在短视频场景下，每天新增大量的短视频，我们需要迅速判断一个新短视频的质量：如果质量很好，我们可以将它向更多的人推荐；如果质量不好，我们可能不再主动推荐该视频。这里判断的时效很重要，因为如果没有及时发现一个垃圾视频，它可能就会通过推荐系统祸害很多的用户 =.=!</p>
<p>由于视频非常多，我们无法人工对每个视频进行准确的质量评估，而且用户在短视频的观看行为呈现出更加多元的兴趣，因此小编们也无法代表所有用户的口味。因此，要评估一个短视频好不好，还是得看它在用户中的表现 (可以用完播率、点赞率、分享率等统计指标来度量)。</p>
<p>假设我们只考虑用完播率 $r$ 来度量一个视频的质量 (后面交替使用完播率和视频质量)，它表示一个视频被播放完 (或者播放超过一定比例) 的数量 $m$ 与它展现给用户的次数 $n$ 的比例：</p>
<script type="math/tex; mode=display">
r=\frac{m}{n} \qquad(1)</script><p>这个指标的优点是计算非常方便，而且能够在一定程度上表达业务诉求。但是实际应用的时候，往往会因为视频的展示次数过少而对某个视频进行错误的评价。例如，视频 $v_1$ 只展示了 $10$ 次，有 $5$ 次完播；视频 $v_2$ 展示了 $10000$ 次，有 $4900$ 次完播，相较而言，$v_1$ 和 $v_2$ 哪个质量更好呢？</p>
<p>很难说！我们只是比较确信 $v_2$ 的完播率稳定在了 $49\%$ 左右，而对于 $v_1$ 的评估就非常不确定了：有可能它再展示 $10$ 次以后，一次都没人看；也有可能它再展示 $10$ 次每次都完播了。这两种情况下我们对视频质量的评估将发生非常大的变化。</p>
<h3 id="模型假设-先验分布"><a href="#模型假设-先验分布" class="headerlink" title="模型假设 (先验分布)"></a>模型假设 (先验分布)</h3><p>从根本上来讲，我们简单的用式 $(1)$ 来计算完播率忽略了事件过少时候的不确定性。为了引入这种不确定性，我们可以用一个概率分布来表示视频的质量 (这就是贝叶斯学派的观点，$r$ 并不是一个固定的值，而是满足一定的概率分布)，也就是说，给定 $m$ 和 $n$，我们要来估计这个视频的质量呈现一个什么样的分布。这个分布的形状是我们在看到数据之前<strong>根据经验</strong>去假定的，因此我们也叫它<strong>先验分布</strong>。</p>
<p>我们的直观想法是，如果一个视频的完播率为 $r=\frac{m}{n}$，那么它质量的真实分布 $\theta$ 中，概率最大的点也应该是 $\frac{m}{n}$，并且与 $\frac{m}{n}$ 相差越多概率也越小。</p>
<p>根据这个想法，我们可以用 <strong>Beta</strong> 分布来进行建模，将 $\alpha=m$ 和 $\beta=n-m$ 作为 <strong>Beta</strong> 分布的参数 (<strong>Beta</strong> 分布的详细介绍可以参考 Wiki)。在我们的例子中，随着 $n$ 的增加，<strong>Beta</strong> 分布的概率密度越集中于 $r=\frac{m}{n}$。下图表示随着 $m$ 和 $n$ 变化，保持 $r=0.5$ 不变的情况下，<strong>Beta</strong> 分布的概率密度函数：</p>
<img src="/2019/08/18/conjugate-priors-video-quality/beta-pdf.png" title="图 1. 不同参数下 Beta 分布的形状">
<p>可以看到，当 $n$ 很小的时候，视频的质量是高度不确定的；而当 $n$ 很大的时候，视频的质量已经集中分布于 $r=\frac{m}{n}$ 附近了。因此，我们选的这个先验分布是能够满足我们的直观想法和假设要求的。这样，我们用式 $(2)$ 来代替式 $(1)$ 对视频质量进行初步的评估：</p>
<script type="math/tex; mode=display">
\begin{align}
p(\theta;\alpha,\beta)=Beta(\theta;\alpha,\beta)
&=\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}\\
&=\frac{1}{B(\alpha,\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}
\end{align} \qquad(2)</script><p>其中，$\Gamma(n)=(n-1)!$ 表示伽玛函数 (这个场景下参数都为整数)；$B(\alpha,\beta)$ 可以看成是归一化项，使得所有概率累加和为 $1$。</p>
<h3 id="更新模型-后验分布"><a href="#更新模型-后验分布" class="headerlink" title="更新模型 (后验分布)"></a>更新模型 (后验分布)</h3><p>问题才解决了一半，由于视频在不断的推荐给用户，我们的统计数据也在发生变化。因此另外一个至关重要的问题是，我们怎么根据新增的数据来更新我们对视频质量的评估。</p>
<p>例如，对于某个视频 $v$，假设我们已经收集到一些反馈数据，并统计出 $\alpha=m$，$\beta=n-m$，我们根据式 $(2)$ 对视频质量分布 $\theta$ 有了一个初步的估计。现在我们又将这个视频推荐给其他用户，并想看看放量以后，视频质量评估是否准确。假设这个视频又展示了 $b$ 次，完播了 $a$ 次，则我们根据先验假设，视频的质量应该是围绕 $r’=\frac{m+a}{n+b}$ 的钟形分布，并且比之前的分布更陡峭一些。为了实现这个过程，我们需要对模型进行更新。</p>
<p>由于用户的反馈只包含完播和未完播两类，因此很容易想到用二项分布的似然估计来估计这 $b$ 次展示中有 $a$ 次会完播的概率：</p>
<script type="math/tex; mode=display">
p(x=a|\theta)=C_b^a\theta^{a}(1-\theta)^{(b-a)} \qquad(3)</script><p>由于式 $(3)$ 中的 $\theta$ 实际上是满足式 $(2)$ 中的分布 (<em>注意，这里 $\theta$ 虽然仍然是一个分布，但是我们在这一步假设它是已知的</em>)，代入后可以算出 $a$ 次完播的概率为 $\theta$ 取所有可能值时式 $(3)$ 的积分：</p>
<script type="math/tex; mode=display">
p(x=a)=\int_0^1 p(x=a;\theta)p(\theta)d\theta \qquad(4)</script><p>这里我们要用最基础的贝叶斯公式，来基于初始的视频质量评估和增量收集来的统计数据，去修正我们在式 $(2)$ 中做出的视频质量评估，得到一个更加可靠的估计。贝叶斯公式如下：</p>
<script type="math/tex; mode=display">
p(\theta;X)=\frac{p(X;\theta)p(\theta)}{p(X)} \qquad(5)</script><p>其中，$p(\theta)$ 是我们对这个视频质量的初始评估，即先验分布，用式 $(2)$ 来计算；$p(X;\theta)$ 表示我们基于初始的评估结果，进一步估计事件 $X$ 发生的概率，即似然估计，用式 $(3)$ 来计算；$p(X)$ 表示 $\theta$ 取不同值时事件 $X$ 发生的概率之和，主要是用于做归一化，用式 $(4)$ 来计算；$p(\theta;X)$ 则表示基于先验分布和似然估计，得到的后验分布。</p>
<p>全部代入后，我们可以得到下面的简单推导：</p>
<script type="math/tex; mode=display">
\begin{align}
p(\theta;x=a)
&=\frac{p(x=a;\theta)p(\theta)}{\int_0^1 p(x=a;\theta)p(\theta)d(\theta)}\\
&=\frac{C_b^a\theta^{a}(1-\theta)^{(b-a)} \frac{1}{B(\alpha,\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}}{\int_0^1 C_b^a\theta^{a}(1-\theta)^{(b-a)}\frac{1}{B(\alpha,\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}d\theta}\\
&=\frac{\theta^{\alpha+a-1}(1-\theta)^{\beta+b-a-1}}{\int_0^1\theta^{\alpha+a-1}(1-\theta)^{\beta+b-a-1}d\theta}\\
&=\frac{1}{B(\alpha+a,\beta+b-a)}\theta^{\alpha+a-1}(1-\theta)^{\beta+b-a-1}\\
&=Beta(\theta;\alpha+a,\beta+b-a)
\end{align} \qquad(6)</script><p>也就是说，经过了这一轮的推荐以后，我们对这个视频的质量评估仅仅使模型的参数发了变化，而模型的形式不变，仍然为 <strong>Beta</strong> 分布！至此，我们终于触及本文的核心概念：共轭性。</p>
<blockquote>
<p> <strong>模型的先验分布与后验分布具有相同的函数形式，这个性质就叫做共轭性。</strong></p>
</blockquote>
<h3 id="共轭性"><a href="#共轭性" class="headerlink" title="共轭性"></a>共轭性</h3><p>共轭性给我们带来了什么样的好处呢？比较式 $(6)$ 和式 $(2)$，我们发现，在观察到 $b$ 次推荐中有 $a$ 次完播事件后，我们可以简单的将模型从 $Beta(\theta;\alpha,\beta)$ 更新为 $Beta(\theta;\alpha+a,\beta+b-a)$，即我们只需要更新如下模型参数：</p>
<script type="math/tex; mode=display">
\begin{cases}\begin{align}
\alpha&=\alpha+a \\
\beta&=\beta+b-a
\end{align}\end{cases}</script><p>它的最大意义在于简化了模型更新的过程，使得模型更新的实时性得到了保证。</p>
<p>一开始，我们基于先验知识对视频质量进行建模，但是由于数据量较少，我们对视频质量的估计置信度较低；随着用户反馈的数据越来越多，我们可以直接基于这些新增的数据去快速更新模型的参数；随着参数数值的增大，我们对视频质量的估计置信度越来越高，直到我们已经有充足的把握认定这个视频是不是高质量视频。</p>
<p>这里的置信度还体现在，当数据量较少的时候，少量的观测结果就会导致我们对视频质量评估发生巨大的变化；而当数据量充足的时候，即使再收集到很多数据，也很难改变我们的评估。</p>
<h3 id="Take-aways"><a href="#Take-aways" class="headerlink" title="Take-aways"></a>Take-aways</h3><p>至此，我们用视频质量评估的例子说明了共轭性和共轭分布是什么含义。一些关键点总结如下：</p>
<ol>
<li>共轭性是指模型的先验分布和后验分布有相同的形式，满足共轭性的分布称为共轭分布。例如：<strong>Beta</strong> 分布与二项分布是共轭分布，且 <strong>Beta</strong> 分布是 $\theta$ 的共轭先验；</li>
<li>共轭性极大的方便了我们基于增量观测的数据对模型进行更新；</li>
<li>在推导共轭性的时候，我们使用了贝叶斯公式，总结起来就是：后验分布=先验分布*似然函数/归一化因子；</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2019/08/10/feature-selection-kendall/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/10/feature-selection-kendall/" itemprop="url">常用的特征选择方法之 Kendall 秩相关系数</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-10T22:44:41+08:00">
                2019-08-10
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/特征工程/" itemprop="url" rel="index">
                    <span itemprop="name">特征工程</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/08/10/feature-selection-kendall/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/08/10/feature-selection-kendall/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  888
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  3
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>前面我们已经讨论了 <a href="https://guyuecanhui.github.io/2019/07/20/feature-selection-pearson/"><strong>Pearson</strong> 相关系数</a>和 <a href="https://guyuecanhui.github.io/2019/07/28/feature-selection-spearman/"><strong>Spearman</strong> 秩相关系数</a>，它们可以检测连续变量间的相关性，并且 <strong>Spearman</strong> 秩相关系数还能够检测有序的离散变量间的相关系数。今天我们再讨论一个能够检测有序变量相关性的系数：<strong>Kendall</strong> 秩相关系数。这里有序变量既包括实数变量，也包括可以排序的类别变量，比如名次、年龄段等。</p>
<h3 id="Kendall-秩相关系数的定义"><a href="#Kendall-秩相关系数的定义" class="headerlink" title="Kendall 秩相关系数的定义"></a>Kendall 秩相关系数的定义</h3><p><strong>Kendall</strong> 秩相关系数是一个非参数性质（与分布无关）的秩统计参数，是用来度量两个<strong>有序变量</strong>之间<strong>单调关系</strong>强弱的相关系数，它的取值范围是 $[-1,1]$，绝对值越大，表示单调相关性越强，取值为 $0$ 时表示完全不相关。</p>
<p>原始的 <strong>Kendall</strong> 秩相关系数定义在<strong>一致对</strong> (<strong>concordant pairs</strong>) 和<strong>分歧对</strong> (<strong>discordant pairs</strong>) 的概念上。所谓一致对，就是两个变量取值的相对关系一致；分歧对则是指它们的相对关系不一致。这么说有点难以理解，我们举个例子。</p>
<p>假设我们为很多不同年龄的用户推送了一条社保相关的视频，然后回收了这些用户的播放完成度，如下表所示：</p>
<img src="/2019/08/10/feature-selection-kendall/age-value-pairs.png" title="图 1. 用户年龄与播放完成度的关系">
<p>我们想用 <strong>Kendall</strong> 秩相关系数来分析用户年龄与该社保视频的播放情况是否相关。为此，我们将年龄和播放完成度分别排序后，对样本中取值进行排序和编号，分别得到 <code>年龄序号</code> 和 <code>播放序号</code>。这时，对于样本 $3$ 和样本 $4$，它们的年龄序号是 $[3,4]$，播放序号是 $[2,4]$，虽然序号不同，但是变化趋势是相同的，因此它们是一致的；对于样本 $2$ 和样本 $3$，它们的年龄序号是 $[2,3]$，播放序号是 $[5,2]$，它们的变化趋势是相反的，因此它们是分歧的。</p>
<p>进一步的，我们观察可以发现，当样本已经按年龄升序排列后，对于每个样本，我们可以简单的数一下该样本后续样本中播放序号大于该样本的样本数量，作为该样本引入的一致对数 (该样本之前的样本与该样本也可能一致，但是已经算过一次了)，将所有样本引入的一致对数加起来就能得到所有样本的一致对数，记为 $c$。</p>
<p>同样的，对于每个样本，我们可以简单的数一下该样本后续样本中播放序号小于该样本的样本数量，作为该样本引入的分歧对数，累加后得到所有样本的分歧对数，记为 $d$。</p>
<p>则原始的 <strong>Kendall</strong> 秩相关系数定义为：</p>
<script type="math/tex; mode=display">
\tau_a=\frac{c-d}{c+d}=\frac{c-d}{\frac{1}{2}\cdot n\cdot (n-1)}\qquad (1)</script><p>其中，$m=\frac{n\cdot (n-1)}{2}$ 表示所有样本两两组合的数量，在变量没有重复取值的情况下，$m=c+d$。定义 $(1)$ 也被称为 <a href="https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient" target="_blank" rel="noopener"><strong>Tau-a</strong></a>，从定义也容易看出，它不能处理变量有相同取值的情况。</p>
<p>为了处理变量有相同取值的情况，我们还要将每个变量中相同取值的数量考虑进来，从而得到扩展的定义：</p>
<script type="math/tex; mode=display">
\tau_b=\frac{c-d}{\sqrt{(c+d+t_x)(c+d+t_y)}}\qquad (2)</script><p>其中，$c$ 在计算的时候只能算 <script type="math/tex">a_i<a_j</script> 且 <script type="math/tex">b_i<b_j</script> 的对数，$d$ 也只能算 <script type="math/tex">a_i<a_j</script> 且 <script type="math/tex">b_i>b_j</script> 的对数 (<script type="math/tex">i<j</script>)；$t_x$，$t_y$ 分别表示变量 $x$，$y$ 取值中序号相同的样本对数排除共同平局的部分 (在下一小节举例说明)。式 <script type="math/tex">(2)</script> 通常又被称为 <strong>Tau-b</strong>，是实际中应用最广泛的定义 (另外还有 <strong>Tau-c</strong> 的变种这里就不介绍了)。在 <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kendalltau.html" target="_blank" rel="noopener"><strong>scipy 1.3.0</strong></a> 版本的实现中，同时支持式 $(1)$ 和式 $(2)$。</p>
<h3 id="举例说明"><a href="#举例说明" class="headerlink" title="举例说明"></a>举例说明</h3><p>首先，我们根据式 $(1)$ 算一下图 $1$ 中年龄与播放的相关度。</p>
<ol>
<li>将样本按年龄升序排列，将播放完成度按从小到大的顺序编号，如图 $1$ 所示；</li>
<li>分别计算每个样本新引入的一致对数和分歧对数，如图 $1$ 所示，进而算出 $c=40$，$d=5$；</li>
<li>根据式 $(1)$ 得到 $\tau_a=\frac{40-5}{40+5}=0.778$；</li>
</ol>
<p>因此，年龄与播放社保视频的时长呈现强相关性，基于这个分析我们就可以尝试对更多年龄大一些的用户推送此视频。</p>
<p>在工程实现的时候，用户的年龄通常会被划分成不同的区间，而播放完成度只有超过一定阈值 (如 $0.3$) 我们才算作有效播放。因此，图 $1$ 的数据我们又可以转换成下面的离散情况：</p>
<img src="/2019/08/10/feature-selection-kendall/age-discrete-pairs.png" title="图 2. 离散化的用户年龄与播放完成度的关系">
<p>可以发现，年龄段序号和有效播放序号存在大量的重复数据，因此我们基于式 $(2)$ 来计算：</p>
<ol>
<li>将样本按年龄段升序排列，相同的年龄段按是否有效播放排序，对年龄段和是否有效播放进行编号，如图 $2$ 所示；</li>
<li>计算每个样本引入的一致对数和分歧对数，如图 $2$ 所示 (例如样本 $4$ 与 样本 $8\sim 10$ 一致)，进而算出 $c=21$，$d=0$；</li>
<li>计算公共平局的数量 $t_c$，公共平局是指 $a_i=a_j$ 且 $b_i=b_j$ 的情况 (例如样本 $1\sim 3$ 互为平局，样本 $4,5,7$ 互为平局，样本 $8,9$ 互为平局)，根据图 $2$ 易知：$t_c=\frac{3\cdot (3-1)}{2}+\frac{3\cdot (3-1)}{2}+\frac{2\cdot (2-1)}{2}=7$；</li>
<li>计算只在年龄段平局的数量 $t_x=\frac{3\cdot (3-1)}{2}+\frac{4\cdot (4-1)}{2}+\frac{2\cdot (2-1)}{2}-t_c=10-7=3$；</li>
<li>计算只在有效播放平均局的数量 $t_y=\frac{6\cdot (6-1)}{2}+\frac{4\cdot (4-1)}{2}-t_c=21-7=14$；</li>
<li>根据式 $(2)$ 得到 $\tau_b=\frac{21}{\sqrt{(21+3)(21+14)}}=0.725$；</li>
</ol>
<p>对比发现，离散化后，我们发现这两个因素之间仍然是强相关的。</p>
<blockquote>
<p>附示例的 python 代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> kendalltau</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y=[<span class="number">1</span>,<span class="number">5</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">7</span>,<span class="number">6</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>kendalltau(x,y)</span><br><span class="line">(<span class="number">0.7777777777777779</span>, <span class="number">0.0017451191944018172</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x=[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y=[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>kendalltau(x,y)</span><br><span class="line">(<span class="number">0.72456883730947197</span>, <span class="number">0.0035417200011750309</span>)</span><br></pre></td></tr></table></figure></p>
<p>其中，<code>kendalltau</code> 返回的第二个结果是 p-value，其具体含义可参考<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kendalltau.html" target="_blank" rel="noopener">官方文档</a>。</p>
</blockquote>
<h3 id="Take-aways"><a href="#Take-aways" class="headerlink" title="Take-aways"></a>Take-aways</h3><ol>
<li><strong>Kendall</strong> 秩相关系数可以用于度量有序变量间相关性，只要求变量取值之间可比，对变量的分布和数据的距离不作假设；</li>
<li>能用 <strong>Pearson</strong> 相关系数和 <strong>Spearman</strong> 秩相关系数的地方都能用 <strong>Kendall</strong> 秩相关系数，但是 <strong>Spearman</strong> 和 <strong>Kendall</strong> 秩相关系数要对数据排序，复杂度远高于 <strong>Pearson</strong> 相关系数，因此能用 <strong>Pearson</strong> 相关系数的时候优先考虑 <strong>Pearson</strong> 相关系数；</li>
<li><strong>Kendall</strong> 秩相关系数依赖一致对和分歧对的计数，这里需要注意数据中是否有重复取值的情况，来选择使用 <strong>Tau-a</strong> 还是 <strong>Tau-b</strong> 进行计算。</li>
</ol>
<hr>
<blockquote>
<h4 id="这是特征选择系列文章的第三篇，其他文章可参考："><a href="#这是特征选择系列文章的第三篇，其他文章可参考：" class="headerlink" title="这是特征选择系列文章的第三篇，其他文章可参考："></a>这是特征选择系列文章的第三篇，其他文章可参考：</h4><ol>
<li><a href="https://guyuecanhui.github.io/2019/07/20/feature-selection-pearson/">常用的特征选择方法之 Pearson 相关系数</a></li>
<li><a href="https://guyuecanhui.github.io/2019/07/28/feature-selection-spearman/">常用的特征选择方法之 Spearman 相关系数</a></li>
<li><a href="https://guyuecanhui.github.io/2019/07/28/feature-selection-kendall/">常用的特征选择方法之 Kendall 秩相关系数</a></li>
</ol>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2019/07/28/feature-selection-spearman/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/28/feature-selection-spearman/" itemprop="url">常用的特征选择方法之 Spearman 秩相关系数</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-07-28T10:36:03+08:00">
                2019-07-28
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/特征工程/" itemprop="url" rel="index">
                    <span itemprop="name">特征工程</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/07/28/feature-selection-spearman/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/07/28/feature-selection-spearman/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  6
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="https://guyuecanhui.github.io/2019/07/20/feature-selection-pearson/">上一篇</a>里，我们简单的介绍了基于 <strong>Pearson</strong> 相关系数的特征选择方法，本篇介绍另一种使用更加广泛的相关系数：<strong>Spearman</strong> 秩相关系数，简称 <strong>Spearman</strong> 相关系数。<strong>Spearman</strong> 相关系数与 <strong>Pearson</strong> 相关系数、<strong>Kendall</strong> 相关系数并称统计学三大相关系数，足见其重要性。</p>
<p>有了 <strong>Pearson</strong> 相关系数，为什么还要用 <strong>Spearman</strong> 相关系数呢，主要是 <strong>Pearson</strong> 系数只能度量两个服从正态分布的变量之间线性相关性的强弱 (如果不熟悉可以回顾一下上一篇的介绍)，而 <strong>Spearman</strong> 系数只度量<strong>单调关系</strong>，而不考虑具体数值的影响，因此 <strong>Spearman</strong> 相关系数的应用范围更广，不仅对数据分布不作任何假设，能够容忍异常值，也不需要数据的取值是等距的（例如比赛中，第 1 名和第 2 名的距离与第 2 名和第 3 名的距离是不等的），因此除非是考虑性能的影响，能用 <strong>Pearson</strong> 系数的地方都能用 <strong>Spearman</strong> 系数。</p>
<h3 id="Spearman-秩相关系数的定义"><a href="#Spearman-秩相关系数的定义" class="headerlink" title="Spearman 秩相关系数的定义"></a>Spearman 秩相关系数的定义</h3><p><a href="https://blog.csdn.net/liuyuan_jq/article/details/52542211" target="_blank" rel="noopener"><strong>Spearman</strong> 秩相关系数</a>是一个非参数性质（与分布无关）的秩统计参数，是用来度量两个<strong>连续型变量</strong>之间<strong>单调关系</strong>强弱的相关系数，取值范围也是 $[-1,1]$。在没有重复数据的情况下，如果一个变量是另外一个变量的严格单调函数，则 <strong>Spearman</strong> 秩相关系数就是 $1$ 或 $-1$，称变量完全 <strong>Spearman</strong> 秩相关。</p>
<p>这里的秩相关 (<strong>Rank Correlation</strong>)，又称等级相关，是将两变量的样本值按数据的大小顺序排列位次，以各要素样本值的位次代替实际数据而求得的一种统计量。排序不论从大到小还是从小到大排都无所谓，只要保证大家排序的标准一致即可。</p>
<p>用 $\rho_s$ 来表示 <strong>Spearman</strong> 相关系数 (用 $\rho_p$ 表示 <strong>Pearson</strong> 相关系数)。如果每个变量都没有相同的取值 (即没有相同的秩次)，则 <strong>Spearman</strong> 相关系数可由下式计算：</p>
<script type="math/tex; mode=display">
\rho_s=1-\frac{6\sum{d_i^2}}{n(n^2-1)}</script><p>其中，$n$ 表示数据点的个数；<script type="math/tex">d_i</script> 表示数据点 <script type="math/tex">(x_i,y_i)</script> 的秩次 <script type="math/tex">(r_{x_i},r_{y_i})</script> 之差：<script type="math/tex">d_i=r_{x_i}-r_{y_i}</script>。</p>
<p>如果某个变量有重复数据，则计算变量之间的 <strong>Spearman</strong> 相关系数就是计算变量数据秩次之间的 <strong>Pearson</strong> 相关系数：</p>
<script type="math/tex; mode=display">
\rho_s=\rho_{r_x,r_y}=\frac{\text{cov}(r_x,r_y)}{\sigma_{r_x}\sigma_{r_y}}</script><p>其中，$r_x$ 表示变量 $\boldsymbol{x}$ 转换后的秩次。从这个定义可以看出来，<strong>Spearman</strong> 相关系数实际上就是对数据做了秩次变换后的 <strong>Pearson</strong> 相关系数。</p>
<h3 id="举例说明"><a href="#举例说明" class="headerlink" title="举例说明"></a>举例说明</h3><p>我们还是拿上一篇的例子来说明。首先将样本进行秩次变换，样本升序排列后的位次如图 1 所示：</p>
<img src="/2019/07/28/feature-selection-spearman/rank-correlation.png" title="图 1. 将变量 $x$, $y$ 用其排序的位次 $r_x$, $r_y$ 来代替">
<p>需要说明的是，这里变量 $y$ 有两个重复数据 $0.1$，在排序的时候它们的位次相同，此时可以用相同位次的数据所占的位次之和除以数据的数量 (即 $\frac{1+2}{2}=1.5$) 来作为这些重复数据的位次。</p>
<p>根据定义，当存在重复数据的时候，我们计算秩次 (即 $r_x$, $r_y$) 的 <strong>Pearson</strong> 相关系数 (过程省略)，得到结果 $\rho_s=0.994$，几乎是单调相关了，其数值比直接计算原始数据的 <strong>Pearson</strong> 相关系数 $\rho_p=0.972$ 还要大一些。</p>
<p>实际上，当 <strong>Pearson</strong> 相关系数比较大的时候，<strong>Spearman</strong> 相关系数也比较大；而当 <strong>Pearson</strong> 相关系数比较小的时候，<strong>Spearman</strong> 相关系数仍然可能较大，例如变量之间是指数相关 ($y=e^x$，如图 2 所示) 时，它们的 <strong>Pearson</strong> 相关系数和 <strong>Spearman</strong> 相关系数分别是 $0.7758$ 和 $1.0$。</p>
<img src="/2019/07/28/feature-selection-spearman/pearson-vs-spearman.png" title="图 2. 变量 $x$, $y$ 之间的 Pearson 相关系数为 $0.7758$，Spearman 相关系数为 $1.0$">
<p>最后，我们看看<a href="https://guyuecanhui.github.io/2019/07/20/feature-selection-pearson/">上一篇图 3</a> 所示的异常数据对 <strong>Spearman</strong> 相关系数的影响，引入异常点 $(0.9,-1.0)$ 后，变量 $x$, $y$ 的 <strong>Pearson</strong> 相关系数降为了 $\rho_p=-0.0556$，它们的 <strong>Spearman</strong> 相关系数也受到了较大的影响，降到了 $\rho_s=0.3234$，也就是较弱的正相关性。但是从这个例子仍然可以看出，与 <strong>Pearson</strong> 相关系数相比，<strong>Spearman</strong> 相关系数对异常值容忍度更高一些。</p>
<blockquote>
<p>附示例的 python 代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> spearmanr, pearsonr</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x=[<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y=[<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>, <span class="number">1.0</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>spearmanr(x,y)</span><br><span class="line">(<span class="number">0.99402979738800479</span>, <span class="number">5.2961535156451228e-07</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rx=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ry=[<span class="number">1.5</span>, <span class="number">1.5</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pearsonr(rx,ry)</span><br><span class="line">(<span class="number">0.99402979738800501</span>, <span class="number">5.2961535156445373e-07</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z=[<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>, <span class="number">-1.0</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>spearmanr(x,z)</span><br><span class="line">(<span class="number">0.32335909071657992</span>, <span class="number">0.43463944855085729</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z=[<span class="number">0.1</span>, <span class="number">0.12</span>, <span class="number">0.2</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>, <span class="number">-1.0</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>spearmanr(x,z)</span><br><span class="line">(<span class="number">0.32335909071657992</span>, <span class="number">0.43463944855085729</span>)</span><br></pre></td></tr></table></figure>
<p>这里，<code>spearmanr</code> 返回的第二个结果是 p-value，其具体含义可参考<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html" target="_blank" rel="noopener">官方文档</a>。</p>
</blockquote>
<h3 id="Take-aways"><a href="#Take-aways" class="headerlink" title="Take-aways"></a>Take-aways</h3><p>本文简单介绍了 Spearman 相关系数，主要注意点总结如下：</p>
<ol>
<li><strong>Spearman</strong> 相关系数是度量两个<strong>连续型变量</strong>之间<strong>单调关系</strong>强弱的相关系数，它对数据的分布不作任何假设，能够容忍异常值，也不需要数据的取值是等距的；</li>
<li><strong>Spearman</strong> 相关系数实际上就是对数据做了秩次变换后的 <strong>Pearson</strong> 相关系数，只要能用 <strong>Pearson</strong> 相关系数的地方就能使用 <strong>Spearman</strong> 相关系数；</li>
<li><strong>Spearman</strong> 相关系数还需要对原始数据进行排序，因此计算复杂度高于 <strong>Pearson</strong> 相关系数，当数据满足 <strong>Pearson​</strong> 相关系数的使用条件时，优先考虑使用 <strong>Pearson</strong> 相关系数。</li>
</ol>
<hr>
<blockquote>
<h4 id="这是特征选择系列文章的第二篇，其他文章可参考："><a href="#这是特征选择系列文章的第二篇，其他文章可参考：" class="headerlink" title="这是特征选择系列文章的第二篇，其他文章可参考："></a>这是特征选择系列文章的第二篇，其他文章可参考：</h4><ol>
<li><a href="https://guyuecanhui.github.io/2019/07/20/feature-selection-pearson/">常用的特征选择方法之 Pearson 相关系数</a></li>
<li><a href="https://guyuecanhui.github.io/2019/07/28/feature-selection-spearman/">常用的特征选择方法之 Spearman 相关系数</a></li>
<li><a href="https://guyuecanhui.github.io/2019/07/28/feature-selection-kendall/">常用的特征选择方法之 Kendall 秩相关系数</a></li>
</ol>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2019/07/20/feature-selection-pearson/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/20/feature-selection-pearson/" itemprop="url">常用的特征选择方法之 Pearson 相关系数</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-07-20T22:36:03+08:00">
                2019-07-20
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/特征工程/" itemprop="url" rel="index">
                    <span itemprop="name">特征工程</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/07/20/feature-selection-pearson/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/07/20/feature-selection-pearson/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.3k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  8
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>众所周知，特征选择是机器学习活动至关重要的一步。最理想的情况下，我们把所有影响目标的独立因素给找出来，然后使用合适的量化手段，就能够得到完美描述目标问题的特征列表，用这些特征去建立合适容量的模型，这样的模型能够完美的匹配我们要解决的任务。</p>
<p>但是实际上这种想法太难实现了，我们往往只能从已有的数据出发，通过一些特征变换和组合得到一些原始特征，然后从这些原始特征中选出与目标相关的特征。</p>
<p>随着深度网络的崛起，越来越多的未经复杂变换的原始特征被加入到了深度网络中，大家期待有用的特征能够被自动的抽取和组合出来。但是这并不意味着特征工程就不需要了，推荐系统的大牛 Xavier 在技术博客《Rules of Machine Learning: Best Practices for ML Engineering》中提到很多关于特征工程的建议，非常值得一读，其中包含的思想就是特征是随着系统的优化进程而逐步添加的，并非一蹴而就，要始终保证特征的简单、直观、可复用、可监控和可靠性，这意味着我们需要时常对系统中存量特征做测试和筛选。</p>
<p>特征选择通常有过滤法（Filter）、打包法（Wrap）和嵌入法（Embed），其中，后两者都是与模型相关的，需要具体问题具体对待，而过滤法是指对特征进行预处理，提前过滤掉一些对目标无益（即对模型无益）的特征，它只考虑任务目标，而与模型无关。</p>
<p>我打算把常用的特征选择方法都再回顾一遍，力争把每种方法都讲得通俗易懂。这篇文章先介绍 <strong>Pearson</strong> 相关系数。</p>
<h3 id="Pearson-相关系数的定义"><a href="#Pearson-相关系数的定义" class="headerlink" title="Pearson 相关系数的定义"></a>Pearson 相关系数的定义</h3><p><strong>Pearson</strong> 相关系数是用来检测两个<strong>连续型变量</strong>之间<strong>线性相关</strong>的程度，取值范围为 $[-1,1]$，正值表示正相关，负值表示负相关，绝对值越大表示线性相关程度越高。在实际做特征工程时候，如果两个变量的相关系数取值为负，可以将特征变量取负号，使之与目标变量正相关，这样来保证所有特征与目标之间都是正相关。</p>
<p>两个变量之间的 <strong>Pearson</strong> 相关系数定义为两个变量之间的协方差和标准差的商：</p>
<script type="math/tex; mode=display">
\rho_{\boldsymbol{x},\boldsymbol{y}}=\frac{\text{cov}(\boldsymbol{x},\boldsymbol{y})}{\sigma_\boldsymbol{x}\sigma_\boldsymbol{y}}=\frac{E[(\boldsymbol{x}-\mu_\boldsymbol{x},\boldsymbol{y}-\mu_\boldsymbol{y})]}{\sigma_\boldsymbol{x}\sigma_\boldsymbol{y}} \qquad(1)</script><p>上式定义了<strong>总体</strong>相关系数，常用希腊小写字母 $\rho$ 作为代表符号。估算样本的协方差和标准差，可得到<strong>样本 Pearson 相关系数</strong>，用英文小写字母 $r$ 表示：</p>
<script type="math/tex; mode=display">
r_{\boldsymbol{x},\boldsymbol{y}}=\frac{\sum ^n _{i=1}(x_i - \overline{x})(y_i - \overline{y})}{\sqrt{\sum ^n _{i=1}(x_i - \overline{x})^2} \sqrt{\sum ^n _{i=1}(y_i - \overline{y})^2}} \qquad(2)</script><p>记 $\boldsymbol{x}’=\boldsymbol{x}-\overline{x}$ 和 $\boldsymbol{y}’=\boldsymbol{y}-\overline{y}$ 表示对变量 $\boldsymbol{x}$ 和 $\boldsymbol{y}$ 进行 $0$ 均值化，则实际上 $\boldsymbol{x}$ 和 $\boldsymbol{y}$ 的 <strong>Pearson</strong> 相关系数就是 $\boldsymbol{x}’$ 和 $\boldsymbol{y}’$ 的 <strong>cosine</strong> 相似度：$r_{\boldsymbol{x},\boldsymbol{y}}=\cos(\boldsymbol{x}’,\boldsymbol{y}’)=\frac{\boldsymbol{x}’\cdot\boldsymbol{y}’}{|\boldsymbol{x}’|\cdot|\boldsymbol{y}’|}$。</p>
<h3 id="Pearson-相关系数的使用条件"><a href="#Pearson-相关系数的使用条件" class="headerlink" title="Pearson 相关系数的使用条件"></a>Pearson 相关系数的使用条件</h3><p>使用 <strong>Pearson</strong> 相关系数之前需要检查数据是否满足前置条件：</p>
<ol>
<li>两个变量间有线性关系；</li>
<li>变量是连续变量；</li>
<li>变量均符合正态分布，且二元分布也符合正态分布；</li>
<li>两变量独立；</li>
<li>两变量的方差不为 0；</li>
</ol>
<p>这些条件在实际中很容易被忽略。</p>
<p>例如，在视频推荐中，我们可以将用户对视频的播放完成度作为目标变量，检测其他连续型特征与它的相关性，或者将这些连续型特征做特定的变换后，检测其与播放完成度的相关性。</p>
<p>但是播放完成度实际上不是正态分布的，如下图所示（实际上大多数日志统计特征，如用户播放视频数、视频播放完成度等，也都不服从正态分布），因此实际上是不能使用 <strong>Pearson</strong> 相关系数的，这时候可以用 <strong>Spearman</strong> 或者 <strong>Kendall</strong> 相关系数来代替。</p>
<img src="/2019/07/20/feature-selection-pearson/play-ratio-distribution.png" title="图 1. 视频播放完成度分布">
<p>另外要注意的是，如果两个变量本身就是线性的关系，那么 <strong>Pearson</strong> 相关系数绝对值越大相关性越强，绝对值越小相关性越弱；但在当两个变量关系未知情况下，<strong>Pearson</strong> 相关系数的大小就没有什么指导意义了，它的绝对值大小并不能表征变量间的相关性强弱，这个时候最好能够画图出来看看作为辅助判断。我会在下面的例子里再详细的说明这一点。</p>
<h3 id="举例说明"><a href="#举例说明" class="headerlink" title="举例说明"></a>举例说明</h3><p>我们举个例子来看如何计算 <strong>Pearson</strong> 相关系数（这里仅仅演示计算过程，实际上数据的分布也不满足使用 <strong>Pearson</strong> 相关系数的条件）。</p>
<p>考虑视频推荐场景下，假设我们的目标 (之一) 是最大化视频的播放完成度 $y$，播放完成度的取值范围是 $[0,1]$，我们需要分析哪些因素跟 $y$ 相关，例如有一维特征是表示用户对视频的偏好度，记为 $x$，它的取值范围也是 $[0,1]$，我们把几条样本中 $x$ 和 $y$ 的取值计算出来，并画成散点图，如下所示：</p>
<img src="/2019/07/20/feature-selection-pearson/ratio-preference.png" title="图 2. 用户对视频的偏好度与播放完成度的对应关系">
<p>我们可以按照公式 (2) 来计算 $x$ 与 $y$ 的 <strong>Pearson</strong> 相关系数：</p>
<ol>
<li>计算变量平均值：$\overline{x} = 0.5,\ \overline{y}=0.55$；</li>
<li>计算平移后的变量：$\boldsymbol{x}=[-0.4,-0.3,-0.2,-0.1,0.1,0.2,0.3,0.4]$，$\boldsymbol{y}=[-0.45,-0.45,-0.35,0.05,0.15,0.25,0.35,0.45]$；</li>
<li>计算公式 (2) 的结果：$r=\frac{0.73}{\sqrt{0.6}\cdot\sqrt{ 0.94}}=0.972$； </li>
</ol>
<p>通过计算，我们发现，这个特征与目标变量之间的线性相关性非常高，这与我们看图得到的认知是一致的。因此我们可以把这一维特征作为有效特征加入。</p>
<p>但是，如果我们对这个例子稍加修改，将最后一个数据点 $(0.9,1.0)$ 改为 $(0.9,-1.0)$，如图 3 所示：</p>
<img src="/2019/07/20/feature-selection-pearson/ratio-preference-abnormal.png" title="图 3. 引入异常数据对 Pearson 相关系数的影响">
<p>从我们的观察来看，最后一个数据点可能是噪声或者异常值，对我们判断两个变量的线性相关性应该不造成影响，但是实际上，我们再次计算一下这两个变量的 <strong>Pearson</strong> 相关系数，此时的值仅仅只有 $-0.0556$，可以说是几乎不线性相关了，这说明 <strong>Pearson</strong> 相关系数小并不代表线性相关性一定弱。在这种情况下，我们应该在数据清洗阶段把特征的异常值过滤或者平滑掉以后，再计算它与目标的相关系数。</p>
<p>反过来，<strong>Pearson</strong> 相关系数大也并不代表线性相关性一定强。<a href="https://en.wikiversity.org/wiki/Correlation" target="_blank" rel="noopener">图 4</a> 列举了几个 <strong>Pearson</strong> 相关系数均为 $0.816$ 的变量数据，其中有些变量间并非明显的线性相关，或者是明显的二次相关，只是 <strong>Pearson</strong> 相关系数恰好较大而已。</p>
<img src="/2019/07/20/feature-selection-pearson/different-shape-of-same-pearson.png" title="图 4. 几组 Pearson 相关系数为 $0.816$ 的数据">
<blockquote>
<p>附示例的 python 代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = [<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = [<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>, <span class="number">1.0</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pearsonr(x, y)</span><br><span class="line">(<span class="number">0.97203814535663591</span>, <span class="number">5.3516208203873684e-05</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z = [<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>, <span class="number">-1.0</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pearsonr(x, z)</span><br><span class="line">(<span class="number">-0.055618651039326214</span>, <span class="number">0.89592989552025337</span>)</span><br></pre></td></tr></table></figure>
<p>这里，<code>pearsonr</code> 返回的第二个结果是 p-value，其具体含义可参考<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html" target="_blank" rel="noopener">官方文档</a>。</p>
</blockquote>
<h3 id="Take-aways"><a href="#Take-aways" class="headerlink" title="Take-aways"></a>Take-aways</h3><p>本文简单的介绍了基于 <strong>Pearson</strong> 相关系数的特征选择方法，主要注意点总结如下：</p>
<ol>
<li><strong>Pearson</strong> 相关系数是用来检测两个<strong>连续型变量</strong>之间<strong>线性相关</strong>的程度，并且要求这两个变量分别分布服从正态分布；</li>
<li><strong>Pearson</strong> 相关系数仅能度量变量间的线性相关性，如果变量间相关性未知，则 <strong>Pearson</strong> 相关系数的大小没有指导意义，此时需要借助可视化手段辅助判断；</li>
<li>两变量的 <strong>Pearson</strong> 相关系数实际上是这两个变量 $0$ 均值化后的 <strong>cosine</strong> 相似度；</li>
<li>如果两个变量是非线性相关，为了使用线性模型，可以先将特征变量进行非线性变换，使之与目标线性相关；</li>
<li><strong>Pearson</strong> 相关系数对异常值比较敏感，在数据清洗阶段需要将异常值过滤或者平滑处理。</li>
</ol>
<hr>
<blockquote>
<h4 id="这是特征选择系列文章的第一篇，其他文章可参考："><a href="#这是特征选择系列文章的第一篇，其他文章可参考：" class="headerlink" title="这是特征选择系列文章的第一篇，其他文章可参考："></a>这是特征选择系列文章的第一篇，其他文章可参考：</h4><ol>
<li><a href="https://guyuecanhui.github.io/2019/07/20/feature-selection-pearson/">常用的特征选择方法之 Pearson 相关系数</a></li>
<li><a href="https://guyuecanhui.github.io/2019/07/28/feature-selection-spearman/">常用的特征选择方法之 Spearman 相关系数</a></li>
<li><a href="https://guyuecanhui.github.io/2019/07/28/feature-selection-kendall/">常用的特征选择方法之 Kendall 秩相关系数</a></li>
</ol>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2019/07/03/ftrl-fm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/03/ftrl-fm/" itemprop="url">用 FTRL 训练 FM 模型</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-07-03T22:45:49+08:00">
                2019-07-03
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/" itemprop="url" rel="index">
                    <span itemprop="name">推荐系统</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/07/03/ftrl-fm/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/07/03/ftrl-fm/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  7
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>近期尝试了基于 <strong>FTRL</strong> 来训练 <strong>FM</strong> 模型，用于短视频的排序。这篇博客主要总结一下算法的理论推导和工程化的一些心得。</p>
<h2 id="一、FM-Factorization-Machines-模型推导"><a href="#一、FM-Factorization-Machines-模型推导" class="headerlink" title="一、FM (Factorization Machines) 模型推导"></a>一、FM (Factorization Machines) 模型推导</h2><h3 id="FM-模型简介"><a href="#FM-模型简介" class="headerlink" title="FM 模型简介"></a>FM 模型简介</h3><p>在设计排序模型时，至关重要的步骤就是特征的构造和选择。除了一些简单单特征外，往往要对特征进行组合，例如对用户的年龄、性别组合，对视频的演员、类别进行组合等，更大的特征空间能够增加模型表征能力。对于特征组合来说，业界现在通用的做法主要有两大类：</p>
<ul>
<li><strong>FM</strong> 系列，常见的模型包括 <strong>FM</strong>，<strong>FFM</strong>，<strong>DeepFM</strong>，它们对特征的取值范围比较敏感。</li>
<li><strong>Tree</strong> 系列，常见的模型包括 <strong>GBDT</strong>，它们对特征的取值范围不敏感。</li>
</ul>
<p>其中，<strong>FM</strong> 系列由于适合处理大规模稀疏数据，并且易于与深度神经网络结合，因此使用十分广泛，成为大厂居家必备。</p>
<p><strong>FM</strong> 模型的主要思想是在 <strong>LR</strong> 的基础上，对所有的特征自动做两两组合$^{[1,2]}$。两两组合最直观的方法就是为每对特征组合设置一个参数（例如 <strong>Poly2</strong> 模型），但是这样就需要 $\text{O}(n^2)$ 个参数，当特征数量很多时，需要的样本量也是巨大的，往往不可能所有的参数都有充足的样本训练。因此 <strong>FM</strong> 考虑使用矩阵分解的方式来还原这个 $n\times n$ 的参数矩阵，只需要 $n\times k$ （$k$ 通常是个很小的常数）的参数即可实现特征两两组合的目的。 </p>
<p>具体来说，给定样本 $z=(\boldsymbol{x},y)$，记 $\boldsymbol{v}_i = (v_i^{(1)},\cdots,v_i^{(d)})^\top$ 为第 $i$ 维特征对应的隐式向量，则 <strong>FM</strong> 模型为：</p>
<script type="math/tex; mode=display">
\begin{align}
f(\boldsymbol{x}|\boldsymbol{w})&=w_0+\sum_{i=1}^n w_ix_i+\sum_{i=1}^{n}\sum_{j=i+1}^{n} (\boldsymbol{v}_i^\top \boldsymbol{v}_j)x_ix_j \\
&=w_0+\sum_{i=1}^n w_ix_i+\frac{1}{2}\Big(\sum_{i=1}^{n}\sum_{j=1}^{n}\sum_{k=1}^{d} v_i^{(k)} v_j^{(k)}x_ix_j- \sum_{i=1}^{n}\sum_{k=1}^{d} (v_i^{(k)}x_i)^2\Big) \\
&=w_0+\sum_{i=1}^n w_ix_i+\frac{1}{2}\sum_{k=1}^{d}\Big(\sum_{i=1}^{n}v_i^{(k)} x_i\sum_{j=1}^{n} v_j^{(k)} x_j- \sum_{i=1}^{n} (v_i^{(k)}x_i)^2\Big) \\
&=w_0+\sum_{i=1}^n w_ix_i+\frac{1}{2}\sum_{k=1}^{d}\Big(\big(\sum_{i=1}^{n}v_i^{(k)} x_i \big)^2- \sum_{i=1}^{n} (v_i^{(k)}x_i)^2\Big)
\end{align} \qquad (1)</script><p><strong>FM</strong> 的参数包括 $\boldsymbol{w}={w_0,\cdots w_n,v_1^{(1)},\cdots v_n^{(d)}}$，容易得到 <strong>FM</strong> 对各参数的偏导如下：</p>
<script type="math/tex; mode=display">
\frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w}=
\begin{cases}
\begin{align}
1 &, \qquad w=w_0 \\
x_i &, \qquad w=w_i,\ i=1,\cdots,n \\
x_i\Big(\sum_{j=1}^n v_j^{(k)}x_j - v_i^{(k)}x_i\Big) &, \qquad w=v_i^{(k)},\ i=1,\cdots,n;\ k=1,\cdots,d
\end{align}
\end{cases} \qquad (2)</script><h3 id="FM-模型求解（回归问题）"><a href="#FM-模型求解（回归问题）" class="headerlink" title="FM 模型求解（回归问题）"></a>FM 模型求解（回归问题）</h3><p>此时直接将 $\hat{y} = f(\boldsymbol{x}|\boldsymbol{w})$ 作为对 $y$ 的预测结果，因此可以将样本 $z=(\boldsymbol{x},y)$ 的损失函数定义为：</p>
<script type="math/tex; mode=display">
l(\boldsymbol{w},z) = \big(\hat{y}-y\big)^2= \big(f(\boldsymbol{x}|\boldsymbol{w})-y\big)^2 \qquad(3)</script><p>损失函数对参数的偏导为：</p>
<script type="math/tex; mode=display">
\begin{align}
\frac{\partial l(\boldsymbol{w},z)}{\partial w} 
&= 2\big(\hat{y}-y\big)\cdot \frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w} \\
&= 2 \big(f(\boldsymbol{x}|\boldsymbol{w})-y\big)\cdot \frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w}
\end{align}\qquad(4)</script><h3 id="FM-模型求解（二分类问题）"><a href="#FM-模型求解（二分类问题）" class="headerlink" title="FM 模型求解（二分类问题）"></a>FM 模型求解（二分类问题）</h3><p>此时将 $\hat{y} = \pi(f(\boldsymbol{x}|\boldsymbol{w}))=\frac{1}{1+e^{-f(\boldsymbol{x}|\boldsymbol{w})}}$  作为对 $y$ 的预测结果，其中，$\pi(x)$ 为 <strong>Sigmoid</strong> 函数。还是分标签取值来进行讨论（损失函数的推导参考 <strong><a href="https://guyuecanhui.github.io/2019/05/15/lr/">LR 模型</a></strong>）。</p>
<h4 id="1-Label-为-1-0"><a href="#1-Label-为-1-0" class="headerlink" title="1. Label 为 {1,0}"></a>1. Label 为 {1,0}</h4><p>则将样本 $z=(\boldsymbol{x},y)$ 的损失函数定义为 <strong>LogLoss</strong> 函数：</p>
<script type="math/tex; mode=display">
l(\boldsymbol{w},z) = -yf(\boldsymbol{x}|\boldsymbol{w})+\ln(1+e^{f(\boldsymbol{x}|\boldsymbol{w})})\big)\qquad(5)</script><p>损失函数对参数的偏导为：</p>
<script type="math/tex; mode=display">
\begin{align}
\frac{\partial l(\boldsymbol{w},z)}{\partial w} &= -y\cdot\frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w}+\frac{1}{1+e^{f(\boldsymbol{x}|\boldsymbol{w})}}\cdot e^{f(\boldsymbol{x}|\boldsymbol{w})} \cdot\frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w} \\
&=\big(\pi(f(\boldsymbol{x}|\boldsymbol{w}))-y\big)\cdot \frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w} \\
&=\big(\hat{y}-y\big)\cdot \frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w}
\end{align} \qquad (6)</script><h4 id="2-Label-为-1-1"><a href="#2-Label-为-1-1" class="headerlink" title="2. Label 为 {1,-1}"></a>2. Label 为 {1,-1}</h4><p>则将样本 $z=(\boldsymbol{x},y)$ 的损失函数定义为 <strong>SigmoidLoss</strong> 函数：</p>
<script type="math/tex; mode=display">
l(\boldsymbol{w},z) = \ln(1+e^{-yf(\boldsymbol{x}|\boldsymbol{w})})\big)\qquad(7)</script><p>损失函数对参数的偏导为：</p>
<script type="math/tex; mode=display">
\begin{align}
\frac{\partial l(\boldsymbol{w},z)}{\partial w} 
&= \frac{1}{1+e^{-yf(\boldsymbol{x}|\boldsymbol{w})}}\cdot e^{-yf(\boldsymbol{x}|\boldsymbol{w})} \cdot(-y)\cdot\frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w} \\
&=y\cdot\big(\frac{1}{1+e^{-yf(\boldsymbol{x}|\boldsymbol{w})}}-1\big)\cdot \frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w} \\
&=y\cdot\Big(\pi\big(yf(\boldsymbol{x}|\boldsymbol{w})\big)-1\Big)\cdot \frac{\partial f(\boldsymbol{x}|\boldsymbol{w})}{\partial w}
\end{align} \qquad (8)</script><h2 id="二、FTRL-Optimizer-介绍"><a href="#二、FTRL-Optimizer-介绍" class="headerlink" title="二、FTRL Optimizer 介绍"></a>二、FTRL Optimizer 介绍</h2><p>上面一陀公式实际上是优化算法求梯度的时候用到的。优化算法目前有很多种，在如在线更新模型或者在线排序等对性能有严格要求的场景中，模型的稀疏解十分关键。稀疏的模型意味着只保留最关键特征的参数，意味着更少的存储、查询与计算。为了得到模型的稀疏解，通常的做法是使用 <strong>L1</strong> 正则、基于参数大小或者累积梯度大小的截断等技术。其中，<strong>FTRL</strong> 集众家之长，实现了精度与稀疏性的平衡$^{[3]}$。</p>
<p><strong>FTRL</strong> 更像是一种启发式的模型组装，其特征权重的更新公式为：</p>
<script type="math/tex; mode=display">
\boldsymbol{w}^{t+1}=\arg \min_\boldsymbol{w}(\boldsymbol{g}^{1:t}\cdot \boldsymbol{w}+\lambda_1 || \boldsymbol{w}||_1+\frac{1}{2}\lambda_2 || \boldsymbol{w}||_2^2 +\frac{1}{2}\sum_{j=1}^t\sigma^j || \boldsymbol{w}-\boldsymbol{w}^j ||_2^2) \qquad(9)</script><p>其中，$\boldsymbol{g}^{1:t}$ 表示 $1\sim t$ 轮迭代中参数梯度的累积和，其中，<strong>L1</strong> 正则化部分是为了生成稀疏解，<strong>L2</strong> 正则化部分是为了使解更平滑（在论文的推导中不包含这一项），而 $\parallel \boldsymbol{w}-\boldsymbol{w}^t\parallel^2_2$ 是为了保证 $\boldsymbol{w}$ 不要离已迭代过的解太远。经过比较复杂的推导（参考文献 [4]），可以得到每一维参数的求解式：</p>
<script type="math/tex; mode=display">
w^{t+1}_i=
\begin{cases}
\begin{align}
0  &, \qquad |z^t_i|<\lambda_1 \\
-\Big(\lambda_2+\frac{\beta+\sqrt{s^t_i}}{\alpha}\Big)^{-1}\cdot\big(z^t_i-\lambda_1\cdot \text{sgn}(z^t_i)\big) &, \qquad \text{otherwise}
\end{align}
\end{cases} \qquad(10)</script><p>其中，令 <script type="math/tex">z_i^t=g^{1:t}-\sum_{s=1}^t\sigma_s\boldsymbol{w}_s, \ s_i^t=\sum_{j=1}^t (g_i^j)^2</script>，主要是方便存储和迭代计算。</p>
<h2 id="三、基于-FTRL-训练-FM-的算法流程"><a href="#三、基于-FTRL-训练-FM-的算法流程" class="headerlink" title="三、基于 FTRL 训练 FM 的算法流程"></a>三、基于 FTRL 训练 FM 的算法流程</h2><p>用 <strong>FTRL</strong> 来训练 <strong>FM</strong> 模型，由于我们组习惯用 {0,1} 作为样本标签，则根据式 (2), (6), (10)，可以得到如下算法流程：</p>
<h3 id="Algorithm-Ftrl-FM"><a href="#Algorithm-Ftrl-FM" class="headerlink" title="Algorithm Ftrl+FM"></a><strong>Algorithm</strong> Ftrl+FM</h3><img src="/2019/07/03/ftrl-fm/alg-ftrl-fm.png" title="用 FTRL 算法训练 FM 模型流程">
<p><strong>FTRL</strong> 算法特别适合在线更新模型，即基于每条实时样本更新模型。但是出于性能和可靠性考虑，也可以稍加修改应用于离线训练或者近线批量训练。例如，离线训练任务，将每天/每小时的数据作为一个批次用来更新 <strong>FM</strong> 模型：在每轮迭代时，需要将一批次样本的所有梯度、损失等计算结果进行汇总（可以简单的用平均值来代替），再用汇总后的值更新模型。为了训练充分，可以对每个批次的样本迭代训练若干轮。训练完的模型需要将参数 $\boldsymbol{w}, \boldsymbol{s}, \boldsymbol{z}$ 保存起来，下次加载后再增量更新；而在线预测时，只需要加载参数 $\boldsymbol{w}$ 即可。</p>
<p>另外，由于短视频的标签、UP 主等特征变化较快，因此对于离散特征的编码可以考虑使用特征 Hash，虽然牺牲了一定的可解释性，并且存在一定的编码冲突，但是实测下来效果还是不错的，并且工程上确实能省下很多麻烦，提升不少性能。</p>
<p>最后，虽然 <strong>FM</strong> 模型具备表征特征两两组合的能力，但是实际上我们发现由于样本、调参等的限制，并不能充分发掘每对特征组合的作用，并且该模型对于三个及以上特征的组合就完全无能为力了。因此，实际应用时还是不能太依赖模型的自动特征组合能力，如果有什么对业务比较有帮助的特征，还是人工生成，再一起丢到模型里去训练吧。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Rendle, S. (2011). Factorization Machines. <em>IEEE International Conference on Data Mining</em>.<br>[2] Rendle, S. (2012). Factorization machines with libfm. <em>Acm Transactions on Intelligent Systems &amp; Technology, 3</em>(3), 1-22.<br>[3] McMahan, H. B., Holt, G., Sculley, D., Young, M., Ebner, D., Grady, J., … &amp; Chikkerur, S. (2013, August). Ad click prediction: a view from the trenches. In <em>Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining</em> (pp. 1222-1230). ACM.<br>[4] 冯扬 (2014). 在线最优化求解.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guyuecanhui.github.io/2019/05/15/lr/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="古月残辉">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HCigmoid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/15/lr/" itemprop="url">二项 Logistic Regression 模型</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-05-15T22:02:00+08:00">
                2019-05-15
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/数学/" itemprop="url" rel="index">
                    <span itemprop="name">数学</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/05/15/lr/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/05/15/lr/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  721
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  3
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="二项-Logistic-Regression-模型推导"><a href="#二项-Logistic-Regression-模型推导" class="headerlink" title="二项 Logistic Regression 模型推导"></a>二项 <strong>Logistic Regression</strong> 模型推导</h2><h3 id="模型描述"><a href="#模型描述" class="headerlink" title="模型描述"></a>模型描述</h3><p>记 $\pi(x)=\frac{1}{1+e^{-x}}$，二项 <strong>Logistic Regression</strong> 模型是如下的条件概率分布：</p>
<script type="math/tex; mode=display">
\begin{cases}
P(y=1|\boldsymbol{x})=\pi(\boldsymbol{wx})=\frac{1}{1+e^{-\boldsymbol{wx}}}=\frac{e^{\boldsymbol{wx}}}{1+e^{\boldsymbol{wx}}} \\
P(y\not=1|\boldsymbol{x})=1-\pi(\boldsymbol{wx})=\frac{1}{1+e^{\boldsymbol{wx}}}
\end{cases}\qquad(1)</script><h3 id="模型求解（极大似然估计）"><a href="#模型求解（极大似然估计）" class="headerlink" title="模型求解（极大似然估计）"></a>模型求解（极大似然估计）</h3><p>常见的 label 设置有正负样本分别为 {1,0} 或 {1,-1}，下面分别讨论两种设置下的损失函数和梯度的推导。首先要假设训练样本独立同分布并且数量足够，模型中待估计的参数为 $\boldsymbol{w}$，似然函数的目标是 $y_i=1$ 时 $\pi(\boldsymbol{wx}_i)$ 尽可能大，且 $y_i\not =1$ 时 $1-\pi(\boldsymbol{wx}_i)$ 尽可能大。</p>
<h4 id="1-label-为-1-0"><a href="#1-label-为-1-0" class="headerlink" title="1. label 为 {1,0}"></a>1. label 为 {1,0}</h4><p>此时，可以直接将 $\hat{y}=\pi(\boldsymbol{wx})$ 的结果作为对 $y$ 值的预测（或者说是预测结果为 1 的概率）。根据<a href="https://guyuecanhui.github.io/2019/05/11/terminology/">最大似然估计公式</a>，$p(\boldsymbol{x}_i|\boldsymbol{w})=\big(\pi(\boldsymbol{wx}_i)\big)^{y_i}\cdot\big(1-\pi(\boldsymbol{wx}_i)\big)^{1-y_i}$，对数似然函数可以设计为：</p>
<script type="math/tex; mode=display">
\begin{align}
H(\boldsymbol{w}) &=\arg \max_{\boldsymbol{w}}\sum_{i=1}^N \ln\Big(\big(\pi(\boldsymbol{wx}_i)\big)^{y_i}\cdot\big(1-\pi(\boldsymbol{wx}_i)\big)^{1-y_i}\Big) \\
&=\arg \max_{\boldsymbol{w}}\sum_{i=1}^N \Big(y_i\cdot \ln\big(\pi(\boldsymbol{wx}_i)\big)+(1-y_i)\cdot\big(1-\pi(\boldsymbol{wx}_i)\big)\Big) \\
&=\arg \max_{\boldsymbol{w}}\sum_{i=1}^N \Big(y_i\cdot \ln(\frac{e^{\boldsymbol{wx}_i}}{1+e^{\boldsymbol{wx}_i}})+(1-y_i)\cdot \ln(\frac{1}{1+e^{\boldsymbol{wx}_i}})\Big) \\
&=\arg \max_{\boldsymbol{w}}\sum_{i=1}^N \Big(y_i\boldsymbol{wx}_i-\ln(1+e^{\boldsymbol{wx}_i})\Big)\qquad(2)
\end{align}</script><p>这里，$l_l(\boldsymbol{x},y)=-\big(y\cdot \ln(\hat{y})+(1-y)\cdot\ln(1-\hat{y})\big)=\ln(1+e^{f(\boldsymbol{x})})-yf(\boldsymbol{x})$ 记作样本 $ (\boldsymbol{x},y)$ 的 <strong>LogLoss</strong>，后面会经常见到。</p>
<p>根据损失函数 $l_l(\boldsymbol{x},y)$，对每个维度上的参数分别求导：</p>
<script type="math/tex; mode=display">
\begin{align}
\frac{\partial l_l(\boldsymbol{x},y)}{\partial w_i}
&=\frac{1}{(1+e^{\boldsymbol{wx}})}\cdot e^{\boldsymbol{wx}}\cdot x_i-y\cdot x_i\\
&=\big(\pi(\boldsymbol{wx})-y\big)\cdot x_i\\
&=(\hat{y}-y)\cdot x_i\qquad(3)
\end{align}</script><h4 id="2-label-为-1-1"><a href="#2-label-为-1-1" class="headerlink" title="2. label 为 {1,-1}"></a>2. label 为 {1,-1}</h4><p>此时仍然可以认为 $\pi(\boldsymbol{wx})$ 输出了模型预测样本结果为 1 的概率，但是由于负样本的标签为 -1，因此考虑使用 $p(\boldsymbol{x}_i|\boldsymbol{w})=\frac{1}{1+e^{-y_i\boldsymbol{wx}_i}}$，则对数似然函数可以设计为：</p>
<script type="math/tex; mode=display">
\begin{align}
H(\boldsymbol{w}) &=\arg \max_{\boldsymbol{w}}\sum_{i=1}^N \ln(\frac{1}{1+e^{-y_i\boldsymbol{wx}_i}}) \\
&=\arg \min_{\boldsymbol{w}}\sum_{i=1}^N \ln(1+e^{-y_i\boldsymbol{wx}_i}) \qquad(4)\\
\end{align}</script><p>这里，$l_s(\boldsymbol{x},y)=\ln(1+e^{-y\boldsymbol{wx}})$ 称作样本 $(\boldsymbol{x},y)$ 的 <strong>SigmoidLoss</strong>，后面也会经常看到。</p>
<p>根据损失函数 $l_s(\boldsymbol{x},y)$，对每个维度上的参数分别求导：</p>
<script type="math/tex; mode=display">
\begin{align}
\frac{\partial l_s(\boldsymbol{x},y)}{\partial w_i}
&=\frac{1}{1+e^{-y\boldsymbol{wx}}}\cdot e^{-y\boldsymbol{wx}}\cdot (-y\cdot x_i) \\
&=y\cdot \big(\pi(y\boldsymbol{wx})-1\big)\cdot x_i\qquad(4)\\
\end{align}</script>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">古月残辉</p>
              <p class="site-description motion-element" itemprop="description">总结心得</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">22</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">56</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="mailto:guyuecanhui@icloud.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">古月残辉</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">34.3k</span>
  
</div>









<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: '6du4Ppc2TvUuhcccRHSDNH2v-gzGzoHsz',
        appKey: 'zOKNml4W1Bq3OTzEuLt5hUjI',
        placeholder: '感谢阅读！欢迎评论！',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
